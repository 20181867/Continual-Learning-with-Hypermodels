Hyperparameters,Results,Classes in task
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317910ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553175c4110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37604262, 'precision': 0.36609461444856072, 'recall': 0.37250174161419324, 'f1_score': 0.34776897837797495, 'confusion_matrix': array([[ 28,  27,   9,  10,  99],
       [ 28,  32,   6,  14, 106],
       [ 23,  39,   8,  18,  80],
       [ 24,  41,   8,   5,  96],
       [ 39,  42,  12,  16,  90]]), 'forgetting_measure': [0.37628415, 0.02740564, -0.052129522]}","{""Every task  has these classes:"": [""three"", ""bed"", ""down"", ""six"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317910ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553175c4110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40567359, 'precision': 0.3796277283804859, 'recall': 0.40357185935408947, 'f1_score': 0.3654672805560693, 'confusion_matrix': array([[30, 31,  0,  6, 46],
       [26, 26,  0,  4, 50],
       [33, 37,  0,  7, 50],
       [22, 39,  0, 11, 62],
       [31, 33,  0,  5, 51]]), 'forgetting_measure': [0.42082593, 0.16782305, -0.15597165]}","{""Every task  has these classes:"": [""three"", ""bed"", ""down"", ""six"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b42ed50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dab9df10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4796437, 'precision': 0.48655082426502654, 'recall': 0.4833239135592077, 'f1_score': 0.4671598123136896, 'confusion_matrix': array([[ 68,  81,  20,  13,   7],
       [ 57, 101,  22,  18,   6],
       [ 34,  72,  35,  49,   5],
       [ 25,  66,  26,  64,   6],
       [ 41,  40,  15,  24,   5]]), 'forgetting_measure': [0.43863566, 0.15708922, -0.98433894]}","{""Every task  has these classes:"": [""marvel"", ""left"", ""zero"", ""down"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b42ed50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dab9df10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42474203, 'precision': 0.42757349527877974, 'recall': 0.42016099970442551, 'f1_score': 0.41583487389426376, 'confusion_matrix': array([[30, 40, 15, 38,  6],
       [49, 47, 17, 37,  9],
       [24, 33, 25, 18,  0],
       [25, 40, 22, 35,  5],
       [26, 24,  7, 24,  4]]), 'forgetting_measure': [0.44544738, 0.08929051, 0.08179527]}","{""Every task  has these classes:"": [""marvel"", ""left"", ""zero"", ""down"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c611abd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c6ced610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45518274, 'precision': 0.26795659295659295, 'recall': 0.39657522123893806, 'f1_score': 0.2812494150280361, 'confusion_matrix': array([[  0, 173,   1,   0,   0],
       [  1, 221,   4,   0,   0],
       [  0, 199,   1,   0,   0],
       [  0, 171,   3,   0,   0],
       [  0, 124,   2,   0,   0]]), 'forgetting_measure': [0.47720612, 0.3368304, -0.6564199]}","{""Every task  has these classes:"": [""tree"", ""one"", ""cat"", ""on"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c611abd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c6ced610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47755228, 'precision': 0.33316869887328292, 'recall': 0.40195360195360196, 'f1_score': 0.30402643263559508, 'confusion_matrix': array([[  0, 121,   0,   0,   0],
       [  0, 178,   4,   0,   0],
       [  0, 122,   4,   0,   0],
       [  0,  81,   0,   0,   0],
       [  0,  87,   3,   0,   0]]), 'forgetting_measure': [0.51276888, 0.33899733, -0.51468164]}","{""Every task  has these classes:"": [""tree"", ""one"", ""cat"", ""on"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c68ffbd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c61cbe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4247801, 'precision': 0.44715248336433304, 'recall': 0.43935981435981435, 'f1_score': 0.39291383059656222, 'confusion_matrix': array([[  0,  50,  14,  72,   0],
       [  0,  81,  18, 122,   1],
       [  0,  65,  35,  76,   0],
       [  0,  56,  26, 139,   1],
       [  0,  59,   5,  79,   1]]), 'forgetting_measure': [0.49539898, 0.5945733, -1.1641039]}","{""Every task  has these classes:"": [""no"", ""yes"", ""one"", ""four"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c68ffbd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c61cbe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45814623, 'precision': 0.35571759563179155, 'recall': 0.42758381015030596, 'f1_score': 0.38009303933867282, 'confusion_matrix': array([[  0,  32,  10,  50,   0],
       [  0,  57,  17,  49,   1],
       [  0,  43,  14,  56,   0],
       [  1,  49,  31, 102,   1],
       [  0,  39,   7,  41,   0]]), 'forgetting_measure': [0.54701675, 0.38392845, 0.00071283133]}","{""Every task  has these classes:"": [""no"", ""yes"", ""one"", ""four"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c95cded0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c5113e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44514593, 'precision': 0.28608958608958608, 'recall': 0.39747582444830153, 'f1_score': 0.28956428547506615, 'confusion_matrix': array([[207,   9,   2,   0,   0],
       [177,   7,   1,   0,   0],
       [129,   6,   0,   1,   0],
       [181,   9,   1,   0,   0],
       [164,   6,   0,   0,   0]]), 'forgetting_measure': [0.42489461, -0.107636206, -0.04953935]}","{""Every task  has these classes:"": [""yes"", ""bed"", ""five"", ""tree"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c95cded0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c5113e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42792378, 'precision': 0.26097642936008833, 'recall': 0.39651656754460495, 'f1_score': 0.28085131894484412, 'confusion_matrix': array([[126,   6,   0,   0,   0],
       [104,   3,   0,   0,   0],
       [109,  10,   0,   0,   0],
       [113,   8,   0,   0,   0],
       [111,  10,   0,   0,   0]]), 'forgetting_measure': [0.43202099, 0.16691156, -0.3371155]}","{""Every task  has these classes:"": [""yes"", ""bed"", ""five"", ""tree"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c533abd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552be2fd610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5211944, 'precision': 0.7486594117640371, 'recall': 0.47565639236836437, 'f1_score': 0.4409072940054505, 'confusion_matrix': array([[ 14,  49,   4,   0,  70],
       [  1, 133,   6,   0,  77],
       [  1,  73,  14,   0,  70],
       [  4,  63,   0,   2,  52],
       [  3, 109,   6,   0, 149]]), 'forgetting_measure': [0.5538622, 0.11768762, 0.047124147]}","{""Every task  has these classes:"": [""six"", ""yes"", ""two"", ""cat"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c533abd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552be2fd610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4965781, 'precision': 0.3894910710279535, 'recall': 0.4390943555649438, 'f1_score': 0.37937627237501114, 'confusion_matrix': array([[  3,  29,   3,   0,  50],
       [  0,  65,   4,   0,  42],
       [  8,  44,   4,   0,  61],
       [  3,  40,   2,   0,  44],
       [  4,  77,  10,   0, 107]]), 'forgetting_measure': [0.58466206, 0.28542206, 0.16251145]}","{""Every task  has these classes:"": [""six"", ""yes"", ""two"", ""cat"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1576510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528cfaef10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54685582, 'precision': 0.6093833092696406, 'recall': 0.5586508187855329, 'f1_score': 0.54728723606710243, 'confusion_matrix': array([[  4,  43,  24,  13,  24],
       [  1, 163,  58,  13,  15],
       [  2,  86,  83,  16,  20],
       [  2,  56,  38,  47,  23],
       [  2,  43,  40,  13,  71]]), 'forgetting_measure': [0.57422705, 0.37075248, -0.82969356]}","{""Every task  has these classes:"": [""three"", ""house"", ""eight"", ""six"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1576510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528cfaef10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.528084, 'precision': 0.4721782637828326, 'recall': 0.45113768075600135, 'f1_score': 0.43489161632018773, 'confusion_matrix': array([[ 2, 28, 16,  7, 17],
       [ 2, 78, 29, 27, 26],
       [ 0, 38, 53, 19, 21],
       [ 1, 54, 34, 18, 19],
       [ 2, 45, 31, 11, 22]]), 'forgetting_measure': [0.54749085, 0.02739922, 0.1159232]}","{""Every task  has these classes:"": [""three"", ""house"", ""eight"", ""six"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529d2c2710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528cf721d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4268319, 'precision': 0.372102732332366, 'recall': 0.39008342337473133, 'f1_score': 0.33481067303185074, 'confusion_matrix': array([[  0,   0, 106,  21,  23],
       [  0,   1, 121,  17,  22],
       [  0,   0, 141,  29,  43],
       [  1,   1, 130,  21,  36],
       [  1,   2, 122,  30,  32]]), 'forgetting_measure': [0.43274252, 0.0006101509, 0.07501187]}","{""Every task  has these classes:"": [""zero"", ""happy"", ""one"", ""bird"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529d2c2710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528cf721d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41376753, 'precision': 0.3466442618691798, 'recall': 0.4219052540913006, 'f1_score': 0.3598838550978229, 'confusion_matrix': array([[ 0,  1, 57, 15, 28],
       [ 1,  0, 70, 12, 27],
       [ 1,  0, 90, 16, 22],
       [ 0,  0, 81, 20, 24],
       [ 0,  1, 81, 19, 34]]), 'forgetting_measure': [0.43789269, 0.18863033, -0.09000184]}","{""Every task  has these classes:"": [""zero"", ""happy"", ""one"", ""bird"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529c9cad50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a37b17d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46352587, 'precision': 0.24733333333333333, 'recall': 0.4, 'f1_score': 0.27654986522911052, 'confusion_matrix': array([[213,   0,   0,   0,   0],
       [186,   0,   0,   0,   0],
       [162,   0,   0,   0,   0],
       [171,   0,   0,   0,   0],
       [168,   0,   0,   0,   0]]), 'forgetting_measure': [0.4635259, 0.0, 0.0]}","{""Every task  has these classes:"": [""up"", ""sheila"", ""two"", ""wow"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529c9cad50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a37b17d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48020284, 'precision': 0.25500000000000001, 'recall': 0.4, 'f1_score': 0.28627450980392158, 'confusion_matrix': array([[165,   0,   0,   0,   0],
       [ 94,   0,   0,   0,   0],
       [ 86,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [153,   0,   0,   0,   0]]), 'forgetting_measure': [0.48020284, 0.0, 0.0]}","{""Every task  has these classes:"": [""up"", ""sheila"", ""two"", ""wow"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a3a5a250>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a30624d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35919246, 'precision': 0.23422222222222222, 'recall': 0.4, 'f1_score': 0.25844402277039847, 'confusion_matrix': array([[154,   0,   0,   0,   0],
       [195,   0,   0,   0,   0],
       [206,   0,   0,   0,   0],
       [193,   0,   0,   0,   0],
       [152,   0,   0,   0,   0]]), 'forgetting_measure': [0.36176322, 0.04767641, -0.050063245]}","{""Every task  has these classes:"": [""cat"", ""bed"", ""three"", ""yes"", ""dog""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a3a5a250>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a30624d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41642083, 'precision': 0.238, 'recall': 0.4, 'f1_score': 0.2638655462184874, 'confusion_matrix': array([[114,   0,   0,   0,   0],
       [146,   0,   0,   0,   0],
       [106,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0],
       [141,   0,   0,   0,   0]]), 'forgetting_measure': [0.41642083, 0.0, 0.0]}","{""Every task  has these classes:"": [""cat"", ""bed"", ""three"", ""yes"", ""dog""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ba46a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528493be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45530505, 'precision': 0.3632129827804261, 'recall': 0.44710205861578122, 'f1_score': 0.37059010544247302, 'confusion_matrix': array([[158,   9,  60,   6,   0],
       [122,   2,  51,   5,   0],
       [ 86,   1, 102,   3,   0],
       [ 76,   4,  51,   2,   0],
       [ 99,   3,  56,   4,   0]]), 'forgetting_measure': [0.4318726, -0.24232993, 0.14608666]}","{""Every task  has these classes:"": [""two"", ""off"", ""right"", ""down"", ""seven""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ba46a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528493be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46358256, 'precision': 0.34449763722282807, 'recall': 0.46603995299647476, 'f1_score': 0.3627615189444172, 'confusion_matrix': array([[104,   2,  32,   0,   0],
       [ 89,   1,  21,   0,   0],
       [ 46,   2,  63,   0,   0],
       [ 87,   1,  50,   0,   0],
       [ 67,   1,  34,   0,   0]]), 'forgetting_measure': [0.4209573, -0.5220673, 0.30576777]}","{""Every task  has these classes:"": [""two"", ""off"", ""right"", ""down"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317911210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42f710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53937228, 'precision': 0.26174496644295302, 'recall': 0.3985611510791367, 'f1_score': 0.29419795221843004, 'confusion_matrix': array([[  0,   0, 168,   0,   1],
       [  0,   0, 178,   0,   1],
       [  0,   0, 276,   0,   2],
       [  0,   0, 143,   0,   1],
       [  0,   1, 129,   0,   0]]), 'forgetting_measure': [0.52472438, -0.045178104, -0.0430262]}","{""Every task  has these classes:"": [""yes"", ""stop"", ""off"", ""wow"", ""bed""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317911210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42f710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4980592, 'precision': 0.253000000000000005, 'recall': 0.4, 'f1_score': 0.28379446640316204, 'confusion_matrix': array([[  0,   0, 115,   0,   0],
       [  0,   0,  96,   0,   0],
       [  0,   0, 159,   0,   0],
       [  0,   0, 107,   0,   0],
       [  0,   0, 123,   0,   0]]), 'forgetting_measure': [0.49705384, -0.010153226, 0.010051173]}","{""Every task  has these classes:"": [""yes"", ""stop"", ""off"", ""wow"", ""bed""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a3c31710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528529fc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48000534, 'precision': 0.5892835322849451, 'recall': 0.57731687686336474, 'f1_score': 0.5785998408287711, 'confusion_matrix': array([[68, 14, 39, 32, 34],
       [29, 48, 22, 38, 23],
       [34, 12, 62, 33, 36],
       [25, 15, 33, 84, 29],
       [38, 11, 39, 22, 80]]), 'forgetting_measure': [0.47073833, 0.14710845, -0.4653611]}","{""Every task  has these classes:"": [""nine"", ""no"", ""one"", ""up"", ""go""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a3c31710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528529fc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44557899, 'precision': 0.4624110671936759, 'recall': 0.44126412351543647, 'f1_score': 0.44020943768070208, 'confusion_matrix': array([[36, 12, 36, 35, 35],
       [18, 24, 23, 32, 25],
       [11,  9, 37, 28, 38],
       [25, 13, 19, 23, 32],
       [15,  5, 23, 22, 24]]), 'forgetting_measure': [0.4482191, 0.0875736, -0.15698655]}","{""Every task  has these classes:"": [""nine"", ""no"", ""one"", ""up"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b877f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531813a650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41162623, 'precision': 0.37166442048517522, 'recall': 0.39798802946593003, 'f1_score': 0.3132366337327447, 'confusion_matrix': array([[182,   4,  11,   2,  11],
       [158,   5,   7,   3,   8],
       [155,   3,   6,   2,  15],
       [148,   6,   5,   0,   9],
       [141,   2,   3,   4,  10]]), 'forgetting_measure': [0.39627088, -0.117353156, 0.0]}","{""Every task  has these classes:"": [""six"", ""bird"", ""dog"", ""go"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b877f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531813a650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4069513, 'precision': 0.39357935067553944, 'recall': 0.40777862216012663, 'f1_score': 0.30701616900090341, 'confusion_matrix': array([[117,   3,   4,   2,   0],
       [ 92,   7,   4,   0,   0],
       [132,   2,   4,   5,   0],
       [126,   7,   4,   2,   0],
       [ 84,   2,   2,   1,   0]]), 'forgetting_measure': [0.42102116, 0.09548761, 0.0]}","{""Every task  has these classes:"": [""six"", ""bird"", ""dog"", ""go"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531de618d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db93be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51951728, 'precision': 0.62370962370962373, 'recall': 0.5437936578481281, 'f1_score': 0.52028191633939435, 'confusion_matrix': array([[  9,  48,  12,   8,  63],
       [  3,  90,  31,   4,  78],
       [  0,  21,  80,   1,  77],
       [  9,  49,  15,  15,  58],
       [  0,  44,  30,   2, 153]]), 'forgetting_measure': [0.4731843, 0.17171805, -1.0289322]}","{""Every task  has these classes:"": [""off"", ""nine"", ""bed"", ""three"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531de618d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db93be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43505329, 'precision': 0.41078712838855918, 'recall': 0.41368233679003593, 'f1_score': 0.37791507385970404, 'confusion_matrix': array([[ 3, 23, 14,  6, 45],
       [ 8, 54, 33,  7, 69],
       [ 1, 22,  7,  4, 65],
       [ 6, 28, 19,  6, 56],
       [ 2, 23, 22,  3, 74]]), 'forgetting_measure': [0.41407463, -0.29776946, 0.23235865]}","{""Every task  has these classes:"": [""off"", ""nine"", ""bed"", ""three"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15530502a550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e5ea0110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44026474, 'precision': 0.3073562945368171, 'recall': 0.39646882784079708, 'f1_score': 0.29614456702503923, 'confusion_matrix': array([[  8,   0, 167,   0,   3],
       [  8,   0, 173,   0,   2],
       [ 15,   0, 212,   0,   1],
       [  8,   0, 170,   0,   1],
       [ 11,   0, 120,   0,   1]]), 'forgetting_measure': [0.42461721, -0.0343407, -0.13564953]}","{""Every task  has these classes:"": [""three"", ""happy"", ""no"", ""dog"", ""cat""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15530502a550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e5ea0110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42568145, 'precision': 0.24766666666666667, 'recall': 0.4, 'f1_score': 0.27698519515477793, 'confusion_matrix': array([[  0,   0, 137,   0,   0],
       [  0,   0, 144,   0,   0],
       [  0,   0, 143,   0,   0],
       [  0,   0, 131,   0,   0],
       [  0,   0,  45,   0,   0]]), 'forgetting_measure': [0.43514579, 0.120746434, -0.13732834]}","{""Every task  has these classes:"": [""three"", ""happy"", ""no"", ""dog"", ""cat""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531a3e8610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531ce27590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48679186, 'precision': 0.31873218935153865, 'recall': 0.42563111345399167, 'f1_score': 0.35024460162652292, 'confusion_matrix': array([[ 57,   0, 132,   0,   0],
       [ 43,   0, 121,   0,   0],
       [ 47,   0, 224,   0,   0],
       [ 29,   0,  79,   0,   0],
       [ 37,   0, 131,   0,   0]]), 'forgetting_measure': [0.56164874, 0.36263537, -0.16365366]}","{""Every task  has these classes:"": [""yes"", ""eight"", ""on"", ""no"", ""down""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531a3e8610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531ce27590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54084693, 'precision': 0.33664021164021162, 'recall': 0.4611060245376305, 'f1_score': 0.37533280951846447, 'confusion_matrix': array([[ 58,   0,  69,   0,   0],
       [ 34,   0,  93,   0,   0],
       [ 26,   0, 146,   0,   0],
       [ 22,   0,  53,   0,   0],
       [ 28,   0,  71,   0,   0]]), 'forgetting_measure': [0.55638392, 0.13078885, -0.15046844]}","{""Every task  has these classes:"": [""yes"", ""eight"", ""on"", ""no"", ""down""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e94bd190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e95c3390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55643768, 'precision': 0.5159123585457297, 'recall': 0.40933009309157408, 'f1_score': 0.3194137134087696, 'confusion_matrix': array([[  0, 151,   0,   1,   1],
       [  0, 281,   2,   0,   2],
       [  0, 172,   1,   1,   0],
       [  0, 113,   1,   1,   0],
       [  0, 164,   1,   0,   8]]), 'forgetting_measure': [0.5635663, 0.065301746, -0.07679581]}","{""Every task  has these classes:"": [""cat"", ""yes"", ""dog"", ""off"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e94bd190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e95c3390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50907303, 'precision': 0.25540540540540541, 'recall': 0.39408284023668637, 'f1_score': 0.28620236530880421, 'confusion_matrix': array([[  0,  66,   0,   0,   1],
       [  0, 164,   1,   0,   4],
       [  0, 131,   0,   0,   0],
       [  0, 118,   0,   0,   2],
       [  0, 113,   0,   0,   0]]), 'forgetting_measure': [0.52114768, 0.025346031, 0.06371824]}","{""Every task  has these classes:"": [""cat"", ""yes"", ""dog"", ""off"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e50c5190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e938a0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40947811, 'precision': 0.39846924758181891, 'recall': 0.4151261291717482, 'f1_score': 0.36572297211832093, 'confusion_matrix': array([[ 10, 135,  31,  16,  15],
       [ 17, 148,  33,  10,  10],
       [  5,  99,  41,  10,   3],
       [  7,  94,  50,   5,   6],
       [ 12,  98,  31,   5,   9]]), 'forgetting_measure': [0.44036336, 0.12504569, 0.15474014]}","{""Every task  has these classes:"": [""right"", ""down"", ""bed"", ""four"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e50c5190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e938a0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40857763, 'precision': 0.41430277719095825, 'recall': 0.426129700572785, 'f1_score': 0.35200344350442332, 'confusion_matrix': array([[  5, 101,  20,   3,   0],
       [  3,  92,  21,   4,   0],
       [  1,  89,  36,   7,   0],
       [  1,  56,  47,   6,   0],
       [  4,  75,  25,   4,   0]]), 'forgetting_measure': [0.40829998, -0.028701441, 0.05191431]}","{""Every task  has these classes:"": [""right"", ""down"", ""bed"", ""four"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dac8af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db533e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45246122, 'precision': 0.51310860304886645, 'recall': 0.5085593155106035, 'f1_score': 0.49379175966545024, 'confusion_matrix': array([[ 20,  41,  81,  14,  16],
       [ 13,  52,  76,  22,  20],
       [ 14,  40, 100,  26,  14],
       [ 25,  49,  65,  16,  16],
       [  7,  19,  54,   4,  96]]), 'forgetting_measure': [0.39902427, -0.076619536, -0.60582644]}","{""Every task  has these classes:"": [""wow"", ""tree"", ""cat"", ""no"", ""one""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dac8af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db533e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41068439, 'precision': 0.39182072356182286, 'recall': 0.39572457244216596, 'f1_score': 0.37647859959977463, 'confusion_matrix': array([[17, 14, 78, 17, 37],
       [16, 11, 49,  4, 20],
       [16, 22, 52,  9, 25],
       [15, 10, 44,  9, 27],
       [13, 19, 40,  8, 28]]), 'forgetting_measure': [0.44301824, 0.20140584, -0.0045807688]}","{""Every task  has these classes:"": [""wow"", ""tree"", ""cat"", ""no"", ""one""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f3fe5090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4445210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59485717, 'precision': 0.61008589336087214, 'recall': 0.49244524382375775, 'f1_score': 0.4903616001198467, 'confusion_matrix': array([[ 43,   0, 134,   1,   2],
       [  5,  14,  78,  11,   7],
       [ 35,   5, 266,   8,  12],
       [  7,   6, 112,  23,   8],
       [ 11,   6,  75,  14,  17]]), 'forgetting_measure': [0.53946905, -0.11491445, -0.23289153]}","{""Every task  has these classes:"": [""cat"", ""stop"", ""go"", ""house"", ""eight""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f3fe5090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4445210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44959594, 'precision': 0.35839438115006085, 'recall': 0.38601886924382816, 'f1_score': 0.33590175523962653, 'confusion_matrix': array([[ 12,  11,  96,  12,   4],
       [  8,   3,  78,   9,   1],
       [ 22,   7, 119,  14,   2],
       [ 11,   6,  77,   8,   5],
       [ 14,   2,  72,   6,   1]]), 'forgetting_measure': [0.46081544, 0.04189121, 0.047248073]}","{""Every task  has these classes:"": [""cat"", ""stop"", ""go"", ""house"", ""eight""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e435af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6b21650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4683119, 'precision': 0.53221235962297996, 'recall': 0.49956362057728714, 'f1_score': 0.48594076991469086, 'confusion_matrix': array([[ 66,   5,  62,  26,  23],
       [ 40,  18,  54,  10,  27],
       [ 38,   5, 131,  29,  13],
       [ 32,   5,  95,  38,  16],
       [ 41,   9,  60,  23,  34]]), 'forgetting_measure': [0.462598, 0.17544168, -0.504707]}","{""Every task  has these classes:"": [""five"", ""one"", ""on"", ""nine"", ""dog""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e435af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6b21650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46038262, 'precision': 0.40074942142355517, 'recall': 0.4142082062013911, 'f1_score': 0.3966893531564513, 'confusion_matrix': array([[52, 15, 44, 11, 20],
       [42,  4, 36,  6, 12],
       [38, 13, 71, 18, 15],
       [26,  4, 46, 11, 17],
       [40,  5, 36,  8, 10]]), 'forgetting_measure': [0.47658185, 0.11947868, -0.07183158]}","{""Every task  has these classes:"": [""five"", ""one"", ""on"", ""nine"", ""dog""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b2ba2f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6f23e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42140004, 'precision': 0.388843537414966, 'recall': 0.39791982986558138, 'f1_score': 0.27733530649627993, 'confusion_matrix': array([[186,   2,   3,   1,   0],
       [239,   1,   1,   1,   0],
       [195,   2,   2,   0,   0],
       [145,   0,   4,   1,   0],
       [117,   0,   0,   0,   0]]), 'forgetting_measure': [0.42613302, 0.18607812, -0.3800934]}","{""Every task  has these classes:"": [""tree"", ""dog"", ""sheila"", ""right"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b2ba2f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6f23e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40187718, 'precision': 0.237, 'recall': 0.4, 'f1_score': 0.26244725738396624, 'confusion_matrix': array([[111,   0,   0,   0,   0],
       [161,   0,   0,   0,   0],
       [109,   0,   0,   0,   0],
       [116,   0,   0,   0,   0],
       [103,   0,   0,   0,   0]]), 'forgetting_measure': [0.4092046, 0.10507545, -0.117412634]}","{""Every task  has these classes:"": [""tree"", ""dog"", ""sheila"", ""right"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cc33af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cb8abe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41817462, 'precision': 0.24022222222222222, 'recall': 0.4, 'f1_score': 0.2669750231267345, 'confusion_matrix': array([[181,   0,   0,   0,   0],
       [203,   0,   0,   0,   0],
       [208,   0,   0,   0,   0],
       [133,   0,   0,   0,   0],
       [175,   0,   0,   0,   0]]), 'forgetting_measure': [0.41983099, 0.022604207, -0.023126973]}","{""Every task  has these classes:"": [""right"", ""zero"", ""left"", ""seven"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cc33af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cb8abe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33609974, 'precision': 0.23133333333333334, 'recall': 0.4, 'f1_score': 0.25417867435158501, 'confusion_matrix': array([[ 94,   0,   0,   0,   0],
       [136,   0,   0,   0,   0],
       [135,   0,   0,   0,   0],
       [139,   0,   0,   0,   0],
       [ 96,   0,   0,   0,   0]]), 'forgetting_measure': [0.33639499, 0.0064941514, -0.006536601]}","{""Every task  has these classes:"": [""right"", ""zero"", ""left"", ""seven"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e442dd50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3ff7610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41198991, 'precision': 0.26824890157347253, 'recall': 0.39422400803616274, 'f1_score': 0.28351023834088168, 'confusion_matrix': array([[  0,   0, 148,   0,   7],
       [  0,   0, 159,   1,   8],
       [  1,   2, 210,   0,   7],
       [  0,   3, 167,   0,   6],
       [  1,   0, 175,   2,   3]]), 'forgetting_measure': [0.37822006, -0.22065073, -0.10416605]}","{""Every task  has these classes:"": [""one"", ""zero"", ""sheila"", ""cat"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e442dd50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3ff7610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38090057, 'precision': 0.24166666666666667, 'recall': 0.4, 'f1_score': 0.26896551724137931, 'confusion_matrix': array([[  0,   0, 125,   0,   0],
       [  0,   0, 123,   0,   0],
       [  0,   0, 125,   0,   0],
       [  0,   0,  89,   0,   0],
       [  0,   0, 138,   0,   0]]), 'forgetting_measure': [0.38677703, 0.09438709, -0.10422454]}","{""Every task  has these classes:"": [""one"", ""zero"", ""sheila"", ""cat"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1e2a290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d23e6510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42447364, 'precision': 0.242444444444444444, 'recall': 0.4, 'f1_score': 0.27002749770852429, 'confusion_matrix': array([[191,   0,   0,   0,   0],
       [181,   0,   0,   0,   0],
       [179,   0,   0,   0,   0],
       [208,   0,   0,   0,   0],
       [141,   0,   0,   0,   0]]), 'forgetting_measure': [0.42353439, -0.01260551, 0.012448588]}","{""Every task  has these classes:"": [""go"", ""nine"", ""down"", ""six"", ""eight""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1e2a290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d23e6510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41175528, 'precision': 0.23966666666666667, 'recall': 0.4, 'f1_score': 0.26620305980528512, 'confusion_matrix': array([[119,   0,   0,   0,   0],
       [136,   0,   0,   0,   0],
       [127,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [116,   0,   0,   0,   0]]), 'forgetting_measure': [0.4113002, -0.006461019, 0.0064195422]}","{""Every task  has these classes:"": [""go"", ""nine"", ""down"", ""six"", ""eight""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c7b25190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c99d3390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39353075, 'precision': 0.40822402446638355, 'recall': 0.40229147826809263, 'f1_score': 0.3782812272702415, 'confusion_matrix': array([[ 4, 59, 57,  6, 30],
       [ 5, 86, 63,  6, 53],
       [ 7, 94, 65,  9, 35],
       [ 4, 61, 41,  8, 45],
       [ 7, 56, 59,  4, 36]]), 'forgetting_measure': [0.41620013, 0.3641027, -0.6504887]}","{""Every task  has these classes:"": [""five"", ""zero"", ""bird"", ""up"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c7b25190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c99d3390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4280222, 'precision': 0.42803615996211174, 'recall': 0.41214910619603092, 'f1_score': 0.3754942631234928, 'confusion_matrix': array([[ 1, 45, 21,  4, 34],
       [ 0, 69, 29,  2, 38],
       [ 2, 70, 28,  5, 33],
       [ 0, 50, 14,  3, 29],
       [ 1, 56, 25,  2, 39]]), 'forgetting_measure': [0.45756282, 0.104752585, 0.15032002]}","{""Every task  has these classes:"": [""five"", ""zero"", ""bird"", ""up"", ""happy""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ee6dd650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da0946d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4969163, 'precision': 0.605175162055896, 'recall': 0.43919370136789092, 'f1_score': 0.3935049734313293, 'confusion_matrix': array([[  4,  60,  84,   9,   2],
       [  1,  92, 140,   2,   0],
       [  0,  74, 139,   0,   2],
       [  0,  47,  79,  16,   0],
       [  1,  54,  76,  15,   3]]), 'forgetting_measure': [0.46488647, 0.04373526, -0.4708189]}","{""Every task  has these classes:"": [""tree"", ""on"", ""one"", ""off"", ""bed""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ee6dd650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da0946d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4982582, 'precision': 0.3794767511921362, 'recall': 0.40572229409715784, 'f1_score': 0.36857942781855825, 'confusion_matrix': array([[ 0, 50, 36, 11,  0],
       [ 2, 78, 73,  4,  2],
       [ 3, 89, 90,  9,  3],
       [ 0, 26, 34,  4,  0],
       [ 0, 46, 35,  4,  1]]), 'forgetting_measure': [0.51805536, 0.070682645, 0.048818644]}","{""Every task  has these classes:"": [""tree"", ""on"", ""one"", ""off"", ""bed""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b0a4af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552afeabe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42148898, 'precision': 0.24404894327030033, 'recall': 0.39899497487437184, 'f1_score': 0.2721311475409836, 'confusion_matrix': array([[  0,   0, 210,   0,   0],
       [  0,   0, 178,   0,   0],
       [  0,   1, 198,   0,   0],
       [  0,   0, 148,   0,   0],
       [  0,   0, 165,   0,   0]]), 'forgetting_measure': [0.41193725, -0.03639315, -0.06022808]}","{""Every task  has these classes:"": [""no"", ""cat"", ""wow"", ""zero"", ""five""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b0a4af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552afeabe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4248433, 'precision': 0.25266666666666666, 'recall': 0.4, 'f1_score': 0.28337730870712401, 'confusion_matrix': array([[  0,   0, 141,   0,   0],
       [  0,   0, 129,   0,   0],
       [  0,   0, 158,   0,   0],
       [  0,   0,  85,   0,   0],
       [  0,   0,  87,   0,   0]]), 'forgetting_measure': [0.43224135, 0.09556501, -0.105662666]}","{""Every task  has these classes:"": [""no"", ""cat"", ""wow"", ""zero"", ""five""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c55ed190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a7e83390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39805129, 'precision': 0.32436147186147187, 'recall': 0.4018237501379539, 'f1_score': 0.33680254481561965, 'confusion_matrix': array([[ 74, 125,   9,   0,   0],
       [ 74, 139,   6,   2,   0],
       [ 56, 104,   4,   0,   0],
       [ 51,  99,   5,   0,   0],
       [ 53,  93,   6,   0,   0]]), 'forgetting_measure': [0.39255157, 0.023827966, -0.1365976]}","{""Every task  has these classes:"": [""bed"", ""down"", ""marvel"", ""house"", ""six""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c55ed190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a7e83390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48125387, 'precision': 0.3105, 'recall': 0.42712215320910972, 'f1_score': 0.34163656088389878, 'confusion_matrix': array([[64, 97,  0,  0,  0],
       [33, 93,  0,  0,  0],
       [31, 72,  0,  0,  0],
       [42, 78,  0,  0,  0],
       [30, 60,  0,  0,  0]]), 'forgetting_measure': [0.50553657, -0.12452983, 0.43350253]}","{""Every task  has these classes:"": [""bed"", ""down"", ""marvel"", ""house"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddfd5090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ee5f78d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4543215, 'precision': 0.39783236607993504, 'recall': 0.41093509141228753, 'f1_score': 0.36561005297541273, 'confusion_matrix': array([[  0,  36,  86,   4,   2],
       [  0,  58, 136,   4,   7],
       [  0,  64, 155,   5,  12],
       [  0,  21, 124,  14,   6],
       [  0,  32, 110,  19,   5]]), 'forgetting_measure': [0.51665942, 0.33930254, -0.1332251]}","{""Every task  has these classes:"": [""three"", ""off"", ""right"", ""stop"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddfd5090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ee5f78d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43504278, 'precision': 0.41424122023963096, 'recall': 0.41802922808467645, 'f1_score': 0.36779501349344267, 'confusion_matrix': array([[ 0, 36, 66,  5,  1],
       [ 0, 32, 67,  4,  2],
       [ 0, 44, 96,  9,  4],
       [ 0, 28, 77, 16,  1],
       [ 0, 20, 77, 12,  3]]), 'forgetting_measure': [0.43846933, 0.08132869, -0.13013385]}","{""Every task  has these classes:"": [""three"", ""off"", ""right"", ""stop"", ""on""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a0e5d190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a1810a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49019085, 'precision': 0.5311183027687882, 'recall': 0.4902670797274222, 'f1_score': 0.45391963041284576, 'confusion_matrix': array([[  0,  59,  66,   7,   3],
       [  2,  95, 106,   8,   1],
       [  0,  56, 180,  21,   1],
       [  1,  30,  91,  43,   1],
       [  0,  69,  43,  11,   6]]), 'forgetting_measure': [0.46211593, 0.40474728, -1.8997331]}","{""Every task  has these classes:"": [""three"", ""six"", ""off"", ""eight"", ""five""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a0e5d190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a1810a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40328215, 'precision': 0.31432313650567971, 'recall': 0.40942649776682581, 'f1_score': 0.3433151417870519, 'confusion_matrix': array([[ 0, 33, 43, 19,  0],
       [ 1, 52, 76, 18,  4],
       [ 0, 36, 84,  8,  0],
       [ 0, 35, 46,  4,  1],
       [ 0, 57, 68, 15,  0]]), 'forgetting_measure': [0.42694457, 0.11402488, 0.09565251]}","{""Every task  has these classes:"": [""three"", ""six"", ""off"", ""eight"", ""five""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155296572f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155296f7e410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4047264, 'precision': 0.35167542732791708, 'recall': 0.39244928428692926, 'f1_score': 0.34412657183360633, 'confusion_matrix': array([[  1, 100,  15,  16,   0],
       [  5, 156,  18,  57,   0],
       [  3, 129,  16,  33,   1],
       [  4, 143,  19,  43,   0],
       [  4,  99,   8,  30,   0]]), 'forgetting_measure': [0.3752437, -0.14321622, -0.19093706]}","{""Every task  has these classes:"": [""on"", ""cat"", ""six"", ""tree"", ""four""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155296572f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155296f7e410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48493664, 'precision': 0.34549689961454668, 'recall': 0.41893256631511665, 'f1_score': 0.34889625545285018, 'confusion_matrix': array([[  0,  90,   2,  26,   0],
       [  0, 110,   6,  34,   0],
       [  0,  75,   2,  28,   0],
       [  0,  95,   3,  51,   0],
       [  0,  55,   0,  23,   0]]), 'forgetting_measure': [0.46037326, -0.12786096, -0.024200516]}","{""Every task  has these classes:"": [""on"", ""cat"", ""six"", ""tree"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ee205090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ee1f8550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56825535, 'precision': 0.651208580206276, 'recall': 0.49720140324791483, 'f1_score': 0.4724721279571479, 'confusion_matrix': array([[ 78,   6, 102,   0,   9],
       [ 30,   5,  97,   2,   9],
       [ 41,   0, 246,   2,  12],
       [ 29,   0,  75,  11,   6],
       [ 18,   1, 100,   1,  20]]), 'forgetting_measure': [0.5484301, 0.08865895, -0.3818705]}","{""Every task  has these classes:"": [""bed"", ""up"", ""wow"", ""four"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ee205090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ee1f8550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54984303, 'precision': 0.4028094504365691, 'recall': 0.40611947516969278, 'f1_score': 0.37115537025899757, 'confusion_matrix': array([[ 19,   2,  70,   6,   4],
       [ 17,   1,  60,   2,   2],
       [ 41,   5, 174,   4,   9],
       [ 19,   2,  55,   2,   5],
       [ 22,   2,  70,   1,   6]]), 'forgetting_measure': [0.583372, 0.12582271, 0.012272895]}","{""Every task  has these classes:"": [""bed"", ""up"", ""wow"", ""four"", ""sheila""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155296d50a10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155296987250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53951998, 'precision': 0.63688321037585487, 'recall': 0.58161877109041364, 'f1_score': 0.5907262553233437, 'confusion_matrix': array([[119,  70,  14,   2,   9],
       [104, 107,   7,   0,   9],
       [ 52,  16,  42,   5,  38],
       [ 40,  11,  13,  44,  17],
       [ 56,  15,  47,  17,  46]]), 'forgetting_measure': [0.5780921, 0.45016578, -1.0808315]}","{""Every task  has these classes:"": [""left"", ""right"", ""no"", ""tree"", ""go""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155296d50a10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155296987250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36606888, 'precision': 0.39236250597800097, 'recall': 0.40390508271176974, 'f1_score': 0.3884300984769181, 'confusion_matrix': array([[57, 34, 16,  8, 18],
       [69, 50, 25,  5, 21],
       [49, 35, 13, 17,  9],
       [33, 32, 15,  3,  9],
       [38, 17, 13,  1, 13]]), 'forgetting_measure': [0.36794418, -0.026592065, 0.08443724]}","{""Every task  has these classes:"": [""left"", ""right"", ""no"", ""tree"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c41c4410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c4baf8d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59598408, 'precision': 0.679063478350759, 'recall': 0.63754940102816625, 'f1_score': 0.6445633033188795, 'confusion_matrix': array([[101,   5,  73,   3,  19],
       [ 22,  89,  40,   6,  29],
       [ 43,  15, 146,   7,  23],
       [ 15,  21,  38,  39,  15],
       [ 21,  32,  45,  11,  42]]), 'forgetting_measure': [0.4961194, -0.28001088, -0.3528971]}","{""Every task  has these classes:"": [""stop"", ""go"", ""zero"", ""left"", ""happy""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c41c4410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c4baf8d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42910535, 'precision': 0.39449767199875345, 'recall': 0.39803760212691746, 'f1_score': 0.3889842056422199, 'confusion_matrix': array([[24, 31, 57,  9, 14],
       [20, 29, 43, 10, 12],
       [27, 23, 49, 16, 20],
       [32, 19, 38,  7, 13],
       [30, 15, 38, 10, 14]]), 'forgetting_measure': [0.38817085, -0.54059035, 0.2781814]}","{""Every task  has these classes:"": [""stop"", ""go"", ""zero"", ""left"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527bb7ddd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529424e410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5519169, 'precision': 0.6049604694086681, 'recall': 0.5923299715549328, 'f1_score': 0.58339550869107164, 'confusion_matrix': array([[ 85,   6,  50,  11,  27],
       [ 33,  20,  41,  18,  15],
       [ 36,   4, 155,  20,  20],
       [ 35,  15,  51,  26,  22],
       [ 43,  12,  36,  15, 104]]), 'forgetting_measure': [0.5213937, 0.18211542, -0.79368806]}","{""Every task  has these classes:"": [""stop"", ""sheila"", ""off"", ""yes"", ""eight""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527bb7ddd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529424e410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47196026, 'precision': 0.42375085296552033, 'recall': 0.4358322069388478, 'f1_score': 0.41189109008505352, 'confusion_matrix': array([[26,  3, 32,  8, 18],
       [23,  3, 34,  5, 21],
       [21, 11, 69,  7, 29],
       [21, 10, 48, 12, 30],
       [44, 16, 56, 12, 41]]), 'forgetting_measure': [0.46827538, -0.13140075, 0.19585931]}","{""Every task  has these classes:"": [""stop"", ""sheila"", ""off"", ""yes"", ""eight""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529393d190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155294013390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47295646, 'precision': 0.35198056680161945, 'recall': 0.42235397452788758, 'f1_score': 0.35832494714264045, 'confusion_matrix': array([[  0,   5,  45,   0,  73],
       [  1,   7,  50,   0, 140],
       [  0,   4,  67,   0, 130],
       [  0,   9,  36,   0,  80],
       [  0,  13,  52,   0, 188]]), 'forgetting_measure': [0.4878657, 0.15105112, -0.17283195]}","{""Every task  has these classes:"": [""left"", ""six"", ""nine"", ""eight"", ""off""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529393d190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155294013390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53470577, 'precision': 0.3466923076923077, 'recall': 0.4311315984408732, 'f1_score': 0.36461873962829374, 'confusion_matrix': array([[  0,   1,  25,   0,  35],
       [  0,   1,  38,   0,  87],
       [  0,   4,  59,   0,  78],
       [  0,   0,  33,   0,  58],
       [  0,   4,  45,   0, 132]]), 'forgetting_measure': [0.52210177, -0.11197886, 0.09583487]}","{""Every task  has these classes:"": [""left"", ""six"", ""nine"", ""eight"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d411d090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d49078d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45583038, 'precision': 0.36375360081391704, 'recall': 0.42174350971769044, 'f1_score': 0.34576605173904766, 'confusion_matrix': array([[  0, 107,   0,  39,   1],
       [  0, 179,   0,  45,   4],
       [  0, 114,   0,  39,   3],
       [  0, 146,   0,  64,   0],
       [  0, 108,   0,  48,   3]]), 'forgetting_measure': [0.49298234, 0.21254538, -0.056730136]}","{""Every task  has these classes:"": [""dog"", ""zero"", ""up"", ""cat"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d411d090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d49078d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50592135, 'precision': 0.31499999999999999, 'recall': 0.44328482328482331, 'f1_score': 0.35351470913514706, 'confusion_matrix': array([[  0,  60,   0,  30,   0],
       [  0, 114,   0,  34,   0],
       [  0,  76,   0,  36,   0],
       [  0,  72,   0,  58,   0],
       [  0,  78,   0,  42,   0]]), 'forgetting_measure': [0.48685027, -0.19945294, 0.16628659]}","{""Every task  has these classes:"": [""dog"", ""zero"", ""up"", ""cat"", ""house""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527994a290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527927be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39557998, 'precision': 0.24, 'recall': 0.4, 'f1_score': 0.26666666666666668, 'confusion_matrix': array([[180,   0,   0,   0,   0],
       [110,   0,   0,   0,   0],
       [201,   0,   0,   0,   0],
       [168,   0,   0,   0,   0],
       [241,   0,   0,   0,   0]]), 'forgetting_measure': [0.39557996, 0.0, 0.0]}","{""Every task  has these classes:"": [""house"", ""yes"", ""eight"", ""zero"", ""off""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527994a290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527927be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.30428373, 'precision': 0.22, 'recall': 0.4, 'f1_score': 0.23636363636363636, 'confusion_matrix': array([[ 60,   0,   0,   0,   0],
       [103,   0,   0,   0,   0],
       [151,   0,   0,   0,   0],
       [139,   0,   0,   0,   0],
       [147,   0,   0,   0,   0]]), 'forgetting_measure': [0.304283735, 0.0, 0.0]}","{""Every task  has these classes:"": [""house"", ""yes"", ""eight"", ""zero"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cf5aced0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cf098150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45410873, 'precision': 0.25444444444444444, 'recall': 0.4, 'f1_score': 0.28558951965065502, 'confusion_matrix': array([[245,   0,   0,   0,   0],
       [190,   0,   0,   0,   0],
       [146,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [175,   0,   0,   0,   0]]), 'forgetting_measure': [0.5022885, 0.47815037, -0.9162608]}","{""Every task  has these classes:"": [""house"", ""right"", ""go"", ""nine"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cf5aced0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cf098150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46944497, 'precision': 0.25433333333333333, 'recall': 0.4, 'f1_score': 0.2854521625163827, 'confusion_matrix': array([[163,   0,   0,   0,   0],
       [127,   0,   0,   0,   0],
       [ 94,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0],
       [123,   0,   0,   0,   0]]), 'forgetting_measure': [0.53548453, 0.59054476, -1.4422693]}","{""Every task  has these classes:"": [""house"", ""right"", ""go"", ""nine"", ""sheila""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155279080d10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527899be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39753024, 'precision': 0.24044444444444444, 'recall': 0.4, 'f1_score': 0.26728280961182995, 'confusion_matrix': array([[182,   0,   0,   0,   0],
       [165,   0,   0,   0,   0],
       [205,   0,   0,   0,   0],
       [198,   0,   0,   0,   0],
       [150,   0,   0,   0,   0]]), 'forgetting_measure': [0.40351721, 0.088252366, -0.09679473]}","{""Every task  has these classes:"": [""tree"", ""zero"", ""three"", ""five"", ""up""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155279080d10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527899be50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39075927, 'precision': 0.239, 'recall': 0.4, 'f1_score': 0.26527196652719666, 'confusion_matrix': array([[117,   0,   0,   0,   0],
       [128,   0,   0,   0,   0],
       [129,   0,   0,   0,   0],
       [ 94,   0,   0,   0,   0],
       [132,   0,   0,   0,   0]]), 'forgetting_measure': [0.39386579, 0.04807237, -0.050500028]}","{""Every task  has these classes:"": [""tree"", ""zero"", ""three"", ""five"", ""up""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155253412f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155253741650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43863864, 'precision': 0.30170381136950905, 'recall': 0.40941495463551987, 'f1_score': 0.33647207720297422, 'confusion_matrix': array([[136,  87,   0,   0,   0],
       [120,  94,   0,   1,   0],
       [ 80,  62,   0,   0,   0],
       [ 74,  69,   0,   0,   0],
       [102,  75,   0,   0,   0]]), 'forgetting_measure': [0.44744156, 0.074052416, -0.044686917]}","{""Every task  has these classes:"": [""two"", ""wow"", ""one"", ""tree"", ""sheila""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155253412f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155253741650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43275688, 'precision': 0.31672613939202311, 'recall': 0.42280883367839888, 'f1_score': 0.34982217411473636, 'confusion_matrix': array([[76, 50,  0,  0,  0],
       [90, 94,  0,  0,  0],
       [62, 45,  0,  0,  0],
       [48, 30,  0,  0,  0],
       [62, 43,  0,  0,  0]]), 'forgetting_measure': [0.4610553, 0.16315845, -0.0013342445]}","{""Every task  has these classes:"": [""two"", ""wow"", ""one"", ""tree"", ""sheila""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525d1e2f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525ccdbe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51076878, 'precision': 0.5759187800027428, 'recall': 0.4396748562274594, 'f1_score': 0.3940039842171754, 'confusion_matrix': array([[ 12, 130,   3,   1,   8],
       [ 11, 286,   2,   4,   7],
       [  7, 133,   6,   0,   2],
       [  8, 128,   1,   3,   1],
       [  3, 119,   2,   3,  20]]), 'forgetting_measure': [0.46565826, -0.16131143, -0.16085017]}","{""Every task  has these classes:"": [""down"", ""off"", ""right"", ""up"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525d1e2f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525ccdbe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4927709, 'precision': 0.37259162303664924, 'recall': 0.40310394586256653, 'f1_score': 0.31203427824457397, 'confusion_matrix': array([[  1,  95,   0,   0,   3],
       [  0, 165,   4,   0,   5],
       [  0, 104,   0,   0,   1],
       [  0, 114,   2,   0,   1],
       [  4,  95,   0,   0,   6]]), 'forgetting_measure': [0.51159058, 0.018396126, 0.14711034]}","{""Every task  has these classes:"": [""down"", ""off"", ""right"", ""up"", ""yes""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c251d650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c25cead0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44600075, 'precision': 0.252000000000000005, 'recall': 0.4, 'f1_score': 0.28253968253968255, 'confusion_matrix': array([[234,   0,   0,   0,   0],
       [160,   0,   0,   0,   0],
       [197,   0,   0,   0,   0],
       [132,   0,   0,   0,   0],
       [177,   0,   0,   0,   0]]), 'forgetting_measure': [0.44600077, 0.0, 0.0]}","{""Every task  has these classes:"": [""go"", ""wow"", ""sheila"", ""yes"", ""two""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c251d650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c25cead0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4701169, 'precision': 0.252000000000000005, 'recall': 0.4, 'f1_score': 0.28253968253968255, 'confusion_matrix': array([[156,   0,   0,   0,   0],
       [137,   0,   0,   0,   0],
       [111,   0,   0,   0,   0],
       [ 76,   0,   0,   0,   0],
       [120,   0,   0,   0,   0]]), 'forgetting_measure': [0.4701169, 0.0, 0.0]}","{""Every task  has these classes:"": [""go"", ""wow"", ""sheila"", ""yes"", ""two""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155265142f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265466410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37858246, 'precision': 0.36156129911424028, 'recall': 0.3900878299246816, 'f1_score': 0.36341530932130527, 'confusion_matrix': array([[ 4, 57, 39,  0, 29],
       [ 4, 84, 67,  0, 63],
       [12, 86, 50,  0, 55],
       [ 1, 63, 49,  0, 32],
       [ 7, 85, 54,  0, 59]]), 'forgetting_measure': [0.43678675, 0.4451872, -0.27567422]}","{""Every task  has these classes:"": [""stop"", ""six"", ""on"", ""four"", ""two""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155265142f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265466410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47906346, 'precision': 0.35903688633055446, 'recall': 0.4350700325512919, 'f1_score': 0.3824034715479316, 'confusion_matrix': array([[ 0, 47, 10,  0, 45],
       [ 0, 63, 16,  0, 36],
       [ 0, 38, 25,  0, 48],
       [ 0, 55, 13,  0, 30],
       [ 0, 72, 32,  0, 70]]), 'forgetting_measure': [0.503132, 0.15664692, -0.08904396]}","{""Every task  has these classes:"": [""stop"", ""six"", ""on"", ""four"", ""two""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524b38af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524b465250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51355414, 'precision': 0.50956952712840613, 'recall': 0.45919039504237196, 'f1_score': 0.39146601689590187, 'confusion_matrix': array([[187,   0,  16,   3,   1],
       [148,   5,  17,   1,  18],
       [160,   1,  36,   2,   7],
       [101,   3,  14,   0,  18],
       [114,   1,  14,   2,  31]]), 'forgetting_measure': [0.45128996, -0.12187241, -0.4453178]}","{""Every task  has these classes:"": [""nine"", ""two"", ""yes"", ""stop"", ""go""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524b38af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524b465250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52772055, 'precision': 0.36002564051763138, 'recall': 0.39133730467063798, 'f1_score': 0.32827957921946767, 'confusion_matrix': array([[125,   2,  15,   0,  20],
       [103,   3,  23,   1,  13],
       [ 95,   1,  12,   0,  12],
       [ 69,   2,  13,   0,  13],
       [ 64,   3,   6,   0,   5]]), 'forgetting_measure': [0.5336254, -0.008922507, 0.07031479]}","{""Every task  has these classes:"": [""nine"", ""two"", ""yes"", ""stop"", ""go""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521f295190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521f7d6410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3730134, 'precision': 0.37768105391370886, 'recall': 0.3837822829863921, 'f1_score': 0.35717480527748637, 'confusion_matrix': array([[70, 45, 72,  4,  6],
       [72, 33, 71,  5,  9],
       [76, 36, 65,  4, 13],
       [59, 15, 53,  3,  6],
       [75, 27, 68,  7,  6]]), 'forgetting_measure': [0.36019505, -0.25845924, 0.22000475]}","{""Every task  has these classes:"": [""wow"", ""three"", ""right"", ""nine"", ""marvel""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521f295190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521f7d6410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40398669, 'precision': 0.37738687260412736, 'recall': 0.4178338019589182, 'f1_score': 0.3698040689145387, 'confusion_matrix': array([[50, 28, 38,  0,  2],
       [40, 26, 24,  0,  4],
       [58, 24, 47,  0,  4],
       [47, 21, 41,  0,  5],
       [58, 29, 49,  0,  5]]), 'forgetting_measure': [0.43444569, 0.26322615, -0.18553132]}","{""Every task  has these classes:"": [""wow"", ""three"", ""right"", ""nine"", ""marvel""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552301daf50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552392ce410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50124417, 'precision': 0.47810222932148065, 'recall': 0.4596679930216771, 'f1_score': 0.3893672859201893, 'confusion_matrix': array([[105,  90,   2,   5,   0],
       [ 64, 145,   0,   4,   0],
       [ 75,  76,   3,   8,   0],
       [ 53,  96,   2,  13,   0],
       [ 78,  77,   0,   4,   0]]), 'forgetting_measure': [0.5550854, 0.6311359, -2.1888402]}","{""Every task  has these classes:"": [""go"", ""eight"", ""three"", ""tree"", ""zero""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552301daf50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552392ce410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42731262, 'precision': 0.31007564266719197, 'recall': 0.4083689292805159, 'f1_score': 0.3348523649454135, 'confusion_matrix': array([[59, 57,  0,  7,  0],
       [59, 75,  2,  2,  0],
       [60, 65,  0,  3,  0],
       [61, 41,  3,  2,  0],
       [47, 46,  0, 11,  0]]), 'forgetting_measure': [0.41980976, 0.046981722, -0.20604402]}","{""Every task  has these classes:"": [""go"", ""eight"", ""three"", ""tree"", ""zero""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c6cb4ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c701f8d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39554347, 'precision': 0.32606761675972564, 'recall': 0.37477704048568293, 'f1_score': 0.31200584893641063, 'confusion_matrix': array([[  3, 112,   1,   0,  46],
       [  9, 124,   3,   0,  66],
       [  8, 112,   1,   0,  40],
       [  1, 132,   2,   0,  36],
       [  2, 151,   3,   0,  48]]), 'forgetting_measure': [0.39678316, -0.056049973, 0.12404658]}","{""Every task  has these classes:"": [""happy"", ""three"", ""marvel"", ""zero"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c6cb4ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c701f8d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39833344, 'precision': 0.28221880346795876, 'recall': 0.40985853227232537, 'f1_score': 0.31186033453899691, 'confusion_matrix': array([[  0,  83,   0,   0,  30],
       [  0,  89,   0,   0,  27],
       [  0, 111,   0,   0,  35],
       [  0,  76,   0,   0,  32],
       [  0,  84,   0,   0,  33]]), 'forgetting_measure': [0.41623686, 0.079945646, 0.096184514]}","{""Every task  has these classes:"": [""happy"", ""three"", ""marvel"", ""zero"", ""tree""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155239695790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155248688d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.66806213, 'precision': 0.7408290577045678, 'recall': 0.68558155218925086, 'f1_score': 0.68810456836267624, 'confusion_matrix': array([[ 51,  18,  67,   3,  19],
       [ 21,  66,  44,   5,  24],
       [ 13,  12, 193,   1,   9],
       [  7,  17,  52,  81,  26],
       [  6,  24,  56,  16,  69]]), 'forgetting_measure': [0.57835315, -0.15970942, -0.33792317]}","{""Every task  has these classes:"": [""sheila"", ""left"", ""down"", ""zero"", ""dog""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155239695790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155248688d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42142, 'precision': 0.40929546250647166, 'recall': 0.42854978354978353, 'f1_score': 0.40658830866484, 'confusion_matrix': array([[ 5, 34, 40, 17, 24],
       [ 8, 43, 49,  9, 20],
       [19, 20, 48,  8, 10],
       [15, 20, 40, 19, 38],
       [16, 15, 41, 23, 19]]), 'forgetting_measure': [0.39763531, -0.15142937, -0.050528955]}","{""Every task  has these classes:"": [""sheila"", ""left"", ""down"", ""zero"", ""dog""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522355af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521f233410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43400156, 'precision': 0.36113857705103996, 'recall': 0.40228012036062157, 'f1_score': 0.34585720607491068, 'confusion_matrix': array([[  2,   0,  53,  49,   6],
       [  0,   0,  52,  99,   0],
       [  4,   0,  85, 131,  10],
       [  3,   0,  84, 139,   3],
       [  4,   0,  63, 110,   3]]), 'forgetting_measure': [0.39431233, -0.35930425, 0.07786635]}","{""Every task  has these classes:"": [""zero"", ""off"", ""one"", ""dog"", ""house""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522355af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521f233410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4731612, 'precision': 0.30359020947256241, 'recall': 0.40409187415556845, 'f1_score': 0.3258177412841567, 'confusion_matrix': array([[  0,   0,  24,  61,   0],
       [  0,   0,  28,  63,   0],
       [  0,   0,  27, 130,   0],
       [  0,   0,  25, 140,   0],
       [  0,   0,  15,  87,   0]]), 'forgetting_measure': [0.48796068, 0.146532, -0.16272667]}","{""Every task  has these classes:"": [""zero"", ""off"", ""one"", ""dog"", ""house""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ee55090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529f116ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5120615, 'precision': 0.61737471875548576, 'recall': 0.56875813592092654, 'f1_score': 0.5700865079518114, 'confusion_matrix': array([[93, 14, 35,  9, 35],
       [44, 74, 46,  4, 27],
       [55, 32, 97,  1, 40],
       [47, 22, 21, 25, 14],
       [55, 27, 22,  5, 56]]), 'forgetting_measure': [0.49210302, 0.18006182, -0.68920344]}","{""Every task  has these classes:"": [""dog"", ""two"", ""seven"", ""go"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ee55090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529f116ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4127371, 'precision': 0.40428826967170527, 'recall': 0.40499668118090617, 'f1_score': 0.3996697050394827, 'confusion_matrix': array([[39, 24, 36,  7, 21],
       [27, 31, 25,  8, 28],
       [50, 34, 25,  2, 31],
       [17, 19, 17,  5, 21],
       [30, 36, 27, 11, 29]]), 'forgetting_measure': [0.39471443, -0.36080056, 0.32622153]}","{""Every task  has these classes:"": [""dog"", ""two"", ""seven"", ""go"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155223a5ab50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155223f477d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37230093, 'precision': 0.24066666666666667, 'recall': 0.4, 'f1_score': 0.26759002770083103, 'confusion_matrix': array([[183,   0,   0,   0,   0],
       [169,   0,   0,   0,   0],
       [177,   0,   0,   0,   0],
       [113,   0,   0,   0,   0],
       [258,   0,   0,   0,   0]]), 'forgetting_measure': [0.37230095, 0.0, 0.0]}","{""Every task  has these classes:"": [""one"", ""stop"", ""eight"", ""four"", ""two""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155223a5ab50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155223f477d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42115448, 'precision': 0.247, 'recall': 0.4, 'f1_score': 0.27611336032388664, 'confusion_matrix': array([[141,   0,   0,   0,   0],
       [ 73,   0,   0,   0,   0],
       [152,   0,   0,   0,   0],
       [ 88,   0,   0,   0,   0],
       [146,   0,   0,   0,   0]]), 'forgetting_measure': [0.42115448, 0.0, 0.0]}","{""Every task  has these classes:"": [""one"", ""stop"", ""eight"", ""four"", ""two""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155224cf5050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240463390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37514288, 'precision': 0.23711111111111111, 'recall': 0.4, 'f1_score': 0.26260543580131209, 'confusion_matrix': array([[167,   0,   0,   0,   0],
       [222,   0,   0,   0,   0],
       [142,   0,   0,   0,   0],
       [234,   0,   0,   0,   0],
       [135,   0,   0,   0,   0]]), 'forgetting_measure': [0.30864677, -1.8361179, 0.6474053]}","{""Every task  has these classes:"": [""four"", ""on"", ""two"", ""nine"", ""marvel""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155224cf5050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240463390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34833488, 'precision': 0.233666666666666664, 'recall': 0.4, 'f1_score': 0.25763195435092724, 'confusion_matrix': array([[101,   0,   0,   0,   0],
       [131,   0,   0,   0,   0],
       [ 68,   0,   0,   0,   0],
       [192,   0,   0,   0,   0],
       [108,   0,   0,   0,   0]]), 'forgetting_measure': [0.32160158, -0.65952957, 0.3974196]}","{""Every task  has these classes:"": [""four"", ""on"", ""two"", ""nine"", ""marvel""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b800d090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a0c66ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48550452, 'precision': 0.248491620111731845, 'recall': 0.39638009049773755, 'f1_score': 0.27777777777777778, 'confusion_matrix': array([[  0, 167,   0,   0,   0],
       [  0, 217,   1,   0,   3],
       [  0, 183,   0,   0,   1],
       [  0, 140,   0,   0,   0],
       [  0, 188,   0,   0,   0]]), 'forgetting_measure': [0.465151, 0.0049760644, -0.24143949]}","{""Every task  has these classes:"": [""five"", ""sheila"", ""eight"", ""happy"", ""up""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b800d090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a0c66ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41674657, 'precision': 0.24533333333333333, 'recall': 0.4, 'f1_score': 0.27391304347826087, 'confusion_matrix': array([[  0, 124,   0,   0,   0],
       [  0, 136,   0,   0,   0],
       [  0, 137,   0,   0,   0],
       [  0,  96,   0,   0,   0],
       [  0, 107,   0,   0,   0]]), 'forgetting_measure': [0.43600666, 0.24482472, -0.3241959]}","{""Every task  has these classes:"": [""five"", ""sheila"", ""eight"", ""happy"", ""up""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531f021d50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42ef50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49518852, 'precision': 0.31435733184793204, 'recall': 0.40222295952222957, 'f1_score': 0.33447182691195186, 'confusion_matrix': array([[ 45,   0, 174,   1,   0],
       [ 31,   0, 159,   0,   0],
       [ 52,   0, 221,   1,   0],
       [ 17,   0,  82,   0,   0],
       [ 22,   0,  95,   0,   0]]), 'forgetting_measure': [0.4882048, -0.05547276, 0.036239836]}","{""Every task  has these classes:"": [""off"", ""sheila"", ""no"", ""five"", ""house""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531f021d50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42ef50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47665234, 'precision': 0.31981534090909092, 'recall': 0.4056995870845461, 'f1_score': 0.32456987788331073, 'confusion_matrix': array([[ 29,   0, 158,   0,   0],
       [ 13,   0,  95,   0,   0],
       [ 20,   0, 138,   0,   0],
       [ 15,   0,  57,   0,   0],
       [ 11,   0,  64,   0,   0]]), 'forgetting_measure': [0.51928137, 0.150362, 0.11748839]}","{""Every task  has these classes:"": [""off"", ""sheila"", ""no"", ""five"", ""house""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155314406610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1495110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5649518, 'precision': 0.4278497724244261, 'recall': 0.4812447103458339, 'f1_score': 0.40899365410090648, 'confusion_matrix': array([[ 81,   3,  95,   1,   0],
       [ 16,   2, 213,   0,   0],
       [  8,   4, 253,   2,   0],
       [ 12,   1,  79,   0,   0],
       [  5,   4, 121,   0,   0]]), 'forgetting_measure': [0.5242421, -0.1026293, -0.15544781]}","{""Every task  has these classes:"": [""wow"", ""off"", ""up"", ""on"", ""sheila""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155314406610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1495110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47853134, 'precision': 0.32456575682382134, 'recall': 0.38858024691358025, 'f1_score': 0.32305191244941471, 'confusion_matrix': array([[ 15,   3,  90,   0,   0],
       [ 21,   2, 139,   0,   0],
       [ 38,   2, 152,   0,   0],
       [ 10,   3,  64,   0,   0],
       [  9,   3,  49,   0,   0]]), 'forgetting_measure': [0.46567924, -0.14809546, 0.13158107]}","{""Every task  has these classes:"": [""wow"", ""off"", ""up"", ""on"", ""sheila""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b25aef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d8ca5dd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52971168, 'precision': 0.6190297742078428, 'recall': 0.6029634524058615, 'f1_score': 0.6045420392733841, 'confusion_matrix': array([[ 58,  45,  29,  15,  18],
       [ 26, 122,  30,  16,  18],
       [ 23,  59, 107,   9,  28],
       [ 30,  33,  16,  60,  14],
       [ 27,  34,  44,   7,  32]]), 'forgetting_measure': [0.54470966, 0.34231314, -0.8424968]}","{""Every task  has these classes:"": [""one"", ""six"", ""left"", ""nine"", ""no""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b25aef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d8ca5dd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43445424, 'precision': 0.42094855323011137, 'recall': 0.42149095107937092, 'f1_score': 0.4131216632940593, 'confusion_matrix': array([[22, 35, 33, 12, 17],
       [23, 34, 38, 28, 15],
       [15, 22, 42, 16, 13],
       [17, 30, 29, 11, 10],
       [23, 35, 39, 17, 24]]), 'forgetting_measure': [0.44215287, -0.047393806, 0.18156016]}","{""Every task  has these classes:"": [""one"", ""six"", ""left"", ""nine"", ""no""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c3e1ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f089dd90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4257366, 'precision': 0.33405312788575338, 'recall': 0.39151398646130216, 'f1_score': 0.30781969845225219, 'confusion_matrix': array([[  0,  17, 135,   4,   3],
       [  0,  17, 174,   5,   3],
       [  0,  20, 181,   9,   5],
       [  0,  27, 149,   3,   4],
       [  0,  10, 130,   2,   2]]), 'forgetting_measure': [0.43672464, 0.064496115, 0.010965827]}","{""Every task  has these classes:"": [""no"", ""cat"", ""eight"", ""sheila"", ""three""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c3e1ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f089dd90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39208208, 'precision': 0.33354195902329496, 'recall': 0.40079584666294617, 'f1_score': 0.3076413782296135, 'confusion_matrix': array([[  0,   7,  89,   3,   0],
       [  1,  24, 134,   5,   0],
       [  0,  13,  89,   5,   0],
       [  0,  14,  99,   3,   0],
       [  0,  12,  98,   4,   0]]), 'forgetting_measure': [0.40200513, 0.11628438, -0.09641138]}","{""Every task  has these classes:"": [""no"", ""cat"", ""eight"", ""sheila"", ""three""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553180f06d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553175c8090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49465377, 'precision': 0.260579064587973276, 'recall': 0.39854014598540146, 'f1_score': 0.29283276450511944, 'confusion_matrix': array([[  0, 133,   0,   0,   0],
       [  0, 272,   0,   2,   0],
       [  0, 199,   0,   0,   0],
       [  0, 165,   0,   0,   0],
       [  0, 129,   0,   0,   0]]), 'forgetting_measure': [0.53180064, 0.45205387, -1.0370389]}","{""Every task  has these classes:"": [""three"", ""go"", ""off"", ""nine"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553180f06d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553175c8090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.502959, 'precision': 0.25433333333333333, 'recall': 0.4, 'f1_score': 0.2854521625163827, 'confusion_matrix': array([[  0,  95,   0,   0,   0],
       [  0, 163,   0,   0,   0],
       [  0, 136,   0,   0,   0],
       [  0, 122,   0,   0,   0],
       [  0,  84,   0,   0,   0]]), 'forgetting_measure': [0.56655274, 0.5204742, -1.0853935]}","{""Every task  has these classes:"": [""three"", ""go"", ""off"", ""nine"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d820e550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d844cb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39873036, 'precision': 0.23688888888888889, 'recall': 0.4, 'f1_score': 0.262288930581613514, 'confusion_matrix': array([[166,   0,   0,   0,   0],
       [232,   0,   0,   0,   0],
       [148,   0,   0,   0,   0],
       [174,   0,   0,   0,   0],
       [180,   0,   0,   0,   0]]), 'forgetting_measure': [0.42429334, 0.34191367, -0.5195575]}","{""Every task  has these classes:"": [""up"", ""two"", ""cat"", ""no"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d820e550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d844cb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3963503, 'precision': 0.24166666666666667, 'recall': 0.4, 'f1_score': 0.26896551724137931, 'confusion_matrix': array([[125,   0,   0,   0,   0],
       [179,   0,   0,   0,   0],
       [ 99,   0,   0,   0,   0],
       [ 81,   0,   0,   0,   0],
       [116,   0,   0,   0,   0]]), 'forgetting_measure': [0.42790802, 0.41540053, -0.7105729]}","{""Every task  has these classes:"": [""up"", ""two"", ""cat"", ""no"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0676b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d851a110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39806565, 'precision': 0.23977777777777778, 'recall': 0.4, 'f1_score': 0.26635773864689527, 'confusion_matrix': array([[179,   0,   0,   0,   0],
       [358,   0,   0,   0,   0],
       [123,   0,   0,   0,   0],
       [116,   0,   0,   0,   0],
       [124,   0,   0,   0,   0]]), 'forgetting_measure': [0.38781406, -0.16375142, 0.14070997]}","{""Every task  has these classes:"": [""eight"", ""go"", ""no"", ""on"", ""bed""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0676b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d851a110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.321223375, 'precision': 0.229333333333333333, 'recall': 0.4, 'f1_score': 0.25116279069767442, 'confusion_matrix': array([[ 88,   0,   0,   0,   0],
       [187,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0],
       [ 95,   0,   0,   0,   0],
       [137,   0,   0,   0,   0]]), 'forgetting_measure': [0.31465647, -0.1718237, 0.1466293]}","{""Every task  has these classes:"": [""eight"", ""go"", ""no"", ""on"", ""bed""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0646b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e06cdc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37315999, 'precision': 0.31041164382528926, 'recall': 0.37976689976689975, 'f1_score': 0.32723678812285183, 'confusion_matrix': array([[ 18,  55,  92,   0,   0],
       [ 25,  49, 121,   0,   0],
       [ 26,  64, 105,   0,   0],
       [ 22,  44, 108,   0,   0],
       [ 18,  46, 107,   0,   0]]), 'forgetting_measure': [0.37068787, 0.20901975, -0.5834397]}","{""Every task  has these classes:"": [""marvel"", ""cat"", ""eight"", ""bird"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0646b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e06cdc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39702326, 'precision': 0.33670784699623922, 'recall': 0.4248176291793313, 'f1_score': 0.35630849150849152, 'confusion_matrix': array([[12, 15, 67,  0,  0],
       [17, 45, 78,  0,  0],
       [13, 26, 81,  0,  0],
       [18, 36, 81,  0,  0],
       [14, 24, 73,  0,  0]]), 'forgetting_measure': [0.41184033, 0.13645388, -0.0730411]}","{""Every task  has these classes:"": [""marvel"", ""cat"", ""eight"", ""bird"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552da6e63d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552de344d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44206397, 'precision': 0.47074096659788466, 'recall': 0.47233835931510353, 'f1_score': 0.46715369284626334, 'confusion_matrix': array([[57, 34, 32, 44, 15],
       [26, 27, 45, 52, 25],
       [22, 22, 84, 40, 28],
       [32, 30, 42, 53, 18],
       [29, 26, 36, 53, 28]]), 'forgetting_measure': [0.4058235, 0.12616976, -0.89326996]}","{""Every task  has these classes:"": [""zero"", ""yes"", ""dog"", ""go"", ""bed""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552da6e63d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552de344d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44716115, 'precision': 0.44936728493328392, 'recall': 0.44792705113179886, 'f1_score': 0.43906905817229637, 'confusion_matrix': array([[24, 11, 40, 32, 24],
       [24, 12, 30, 25, 12],
       [27, 11, 55, 29, 19],
       [19, 11, 17, 30, 16],
       [23,  4, 44, 31, 30]]), 'forgetting_measure': [0.45515208, 0.057162, -0.021603942]}","{""Every task  has these classes:"": [""zero"", ""yes"", ""dog"", ""go"", ""bed""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a5ec1550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a6493c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49214174, 'precision': 0.732154673875324, 'recall': 0.50926353356584274, 'f1_score': 0.4966940070522643, 'confusion_matrix': array([[ 68,  70,  55,   0,  11],
       [ 10, 119,  69,   0,  10],
       [ 23,  92,  74,   0,   6],
       [ 22,  76,  30,   3,   3],
       [  1,  91,  29,   0,  38]]), 'forgetting_measure': [0.43535955, 0.025161017, -0.794073]}","{""Every task  has these classes:"": [""seven"", ""stop"", ""six"", ""tree"", ""up""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a5ec1550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a6493c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36154395, 'precision': 0.43723172855702973, 'recall': 0.41480618006497187, 'f1_score': 0.36719821436060292, 'confusion_matrix': array([[23, 57, 46,  0,  3],
       [16, 61, 30,  2, 11],
       [12, 47, 31,  0,  6],
       [13, 70, 40,  1,  8],
       [19, 62, 35,  0,  7]]), 'forgetting_measure': [0.39318184, 0.36740997, -0.3849288]}","{""Every task  has these classes:"": [""seven"", ""stop"", ""six"", ""tree"", ""up""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d7ea2710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b7c00710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43545736, 'precision': 0.31588108498735343, 'recall': 0.39666251427385031, 'f1_score': 0.29069530847144955, 'confusion_matrix': array([[  0,   3, 132,   0,   0],
       [  0,   5, 187,   0,   3],
       [  0,  10, 217,   0,   1],
       [  0,   9, 163,   0,   1],
       [  0,   4, 164,   0,   1]]), 'forgetting_measure': [0.42498202, 0.0308737, -0.20784658]}","{""Every task  has these classes:"": [""left"", ""no"", ""six"", ""zero"", ""right""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d7ea2710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b7c00710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36475146, 'precision': 0.23966666666666667, 'recall': 0.4, 'f1_score': 0.26620305980528512, 'confusion_matrix': array([[  0,   0, 110,   0,   0],
       [  0,   0, 172,   0,   0],
       [  0,   0, 119,   0,   0],
       [  0,   0, 121,   0,   0],
       [  0,   0,  78,   0,   0]]), 'forgetting_measure': [0.36913044, 0.077673584, -0.08421486]}","{""Every task  has these classes:"": [""left"", ""no"", ""six"", ""zero"", ""right""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b7abf650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cac54d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52306817, 'precision': 0.7471809991809992, 'recall': 0.4203063279789573, 'f1_score': 0.3554817891423782, 'confusion_matrix': array([[ 12,   8,   0, 118,   1],
       [  5,  11,   0, 176,   0],
       [  5,  10,   1, 107,   0],
       [ 21,   1,   0, 268,   0],
       [  7,   0,   0, 145,   4]]), 'forgetting_measure': [0.53749202, 0.4097816, -1.1713431]}","{""Every task  has these classes:"": [""nine"", ""one"", ""tree"", ""five"", ""four""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b7abf650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cac54d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54405908, 'precision': 0.36884283246977544, 'recall': 0.40549516908212562, 'f1_score': 0.31234837300269182, 'confusion_matrix': array([[  0,   2,   0,  90,   2],
       [  0,   5,   0, 138,   1],
       [  0,   2,   0, 107,   0],
       [  0,   2,   1, 180,   1],
       [  0,   4,   0,  64,   1]]), 'forgetting_measure': [0.5864243, 0.32154813, -0.463105]}","{""Every task  has these classes:"": [""nine"", ""one"", ""tree"", ""five"", ""four""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155546dd12d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317579e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36283284, 'precision': 0.240311804008908686, 'recall': 0.39781420765027322, 'f1_score': 0.2669750231267345, 'confusion_matrix': array([[  0,   0,   0, 165,   0],
       [  0,   0,   0, 201,   0],
       [  0,   0,   0, 160,   0],
       [  0,   0,   1, 181,   1],
       [  0,   0,   0, 191,   0]]), 'forgetting_measure': [0.3578304, 0.057077922, -0.22190711]}","{""Every task  has these classes:"": [""bed"", ""down"", ""happy"", ""eight"", ""marvel""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155546dd12d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317579e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40347686, 'precision': 0.23866666666666667, 'recall': 0.4, 'f1_score': 0.26480446927374302, 'confusion_matrix': array([[  0,   0,   0, 115,   0],
       [  0,   0,   0, 110,   0],
       [  0,   0,   0, 131,   0],
       [  0,   0,   0, 116,   0],
       [  0,   0,   0, 128,   0]]), 'forgetting_measure': [0.41486884, 0.15905479, -0.1891381]}","{""Every task  has these classes:"": [""bed"", ""down"", ""happy"", ""eight"", ""marvel""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ce3a6f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ce1bcd10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43301323, 'precision': 0.33716513719084236, 'recall': 0.40410186521297632, 'f1_score': 0.34348328280343786, 'confusion_matrix': array([[  0,  98,  52,   3,   0],
       [  0, 151,  83,   8,   1],
       [  0, 130,  82,   4,   0],
       [  0,  97,  54,   3,   0],
       [  0,  90,  43,   1,   0]]), 'forgetting_measure': [0.40580369, -0.11527463, -0.14891739]}","{""Every task  has these classes:"": [""tree"", ""dog"", ""four"", ""go"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ce3a6f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ce1bcd10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4603677, 'precision': 0.31505507955936353, 'recall': 0.43735251798561152, 'f1_score': 0.35462308779259076, 'confusion_matrix': array([[ 0, 76, 49,  0,  0],
       [ 0, 96, 54,  0,  0],
       [ 0, 63, 76,  0,  0],
       [ 0, 56, 45,  0,  0],
       [ 0, 51, 34,  0,  0]]), 'forgetting_measure': [0.48685895, -0.09271407, 0.4232364]}","{""Every task  has these classes:"": [""tree"", ""dog"", ""four"", ""go"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186fbad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553180f40d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47473068, 'precision': 0.4145370063060073, 'recall': 0.41900490704095396, 'f1_score': 0.38821006751318492, 'confusion_matrix': array([[  3,  19,  56,  15,   0],
       [  3,  65, 131,  24,   3],
       [  3,  62, 155,  37,   0],
       [  1,  46, 107,  32,   0],
       [  2,  38,  75,  23,   0]]), 'forgetting_measure': [0.4582964, -0.058642164, -0.06951611]}","{""Every task  has these classes:"": [""one"", ""off"", ""dog"", ""house"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186fbad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553180f40d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43010588, 'precision': 0.33095050453541018, 'recall': 0.3912448775406713, 'f1_score': 0.3510749767190508, 'confusion_matrix': array([[ 0, 41, 49, 21,  0],
       [ 0, 42, 71, 21,  0],
       [ 0, 56, 64, 24,  0],
       [ 0, 35, 62, 24,  0],
       [ 0, 24, 50, 16,  0]]), 'forgetting_measure': [0.45698414, 0.20417596, -0.11884321]}","{""Every task  has these classes:"": [""one"", ""off"", ""dog"", ""house"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f49fe150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4a6d590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46779935, 'precision': 0.45288868332638686, 'recall': 0.43336714419288054, 'f1_score': 0.4008215662748194, 'confusion_matrix': array([[ 53,  77,   3,   4,  31],
       [ 46, 111,  14,   5,  34],
       [ 42,  75,   7,   3,  28],
       [ 38,  93,   4,   5,  20],
       [ 64,  85,   6,   1,  51]]), 'forgetting_measure': [0.45432822, 0.027543407, -0.22005032]}","{""Every task  has these classes:"": [""marvel"", ""one"", ""yes"", ""bird"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f49fe150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4a6d590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39083545, 'precision': 0.46583702294736433, 'recall': 0.40416275364481012, 'f1_score': 0.36915142264739857, 'confusion_matrix': array([[30, 60,  2,  2, 18],
       [36, 67,  7,  1, 22],
       [24, 47,  3,  0, 15],
       [32, 75,  3,  3, 12],
       [50, 59,  5,  0, 27]]), 'forgetting_measure': [0.36532658, -0.37170753, 0.20451432]}","{""Every task  has these classes:"": [""marvel"", ""one"", ""yes"", ""bird"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e6196150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dd33a750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43741418, 'precision': 0.27131788720852268, 'recall': 0.39630769230769232, 'f1_score': 0.28844801607232547, 'confusion_matrix': array([[  0,   0, 142,   0,   8],
       [  0,   0, 182,   0,   7],
       [  0,   0, 225,   0,   9],
       [  0,   0, 173,   0,   4],
       [  0,   3, 144,   0,   3]]), 'forgetting_measure': [0.39505885, -0.325712, 0.0]}","{""Every task  has these classes:"": [""left"", ""tree"", ""sheila"", ""seven"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e6196150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dd33a750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5234153, 'precision': 0.254000000000000006, 'recall': 0.4, 'f1_score': 0.28503937007874016, 'confusion_matrix': array([[  0,   0, 126,   0,   0],
       [  0,   0,  96,   0,   0],
       [  0,   0, 162,   0,   0],
       [  0,   0, 129,   0,   0],
       [  0,   0,  87,   0,   0]]), 'forgetting_measure': [0.5234153, 0.0, 0.0]}","{""Every task  has these classes:"": [""left"", ""tree"", ""sheila"", ""seven"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f0296150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f070a750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45241756, 'precision': 0.452987012987013, 'recall': 0.41615348031570178, 'f1_score': 0.3199360492122318, 'confusion_matrix': array([[  0,   2,   3, 132,   1],
       [  0,   1,   8, 165,   3],
       [  0,   2,   8, 184,   3],
       [  0,   3,   5, 199,   1],
       [  0,   0,   6, 160,  14]]), 'forgetting_measure': [0.48191113, 0.49464822, -1.3365661]}","{""Every task  has these classes:"": [""four"", ""yes"", ""one"", ""right"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f0296150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f070a750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43696996, 'precision': 0.32298905283198476, 'recall': 0.39806060606060605, 'f1_score': 0.2908568609813423, 'confusion_matrix': array([[  0,   0,   3, 121,   5],
       [  0,   0,   1,  69,   2],
       [  0,   0,   4, 124,   4],
       [  0,   0,   1, 144,   5],
       [  0,   0,   2, 115,   0]]), 'forgetting_measure': [0.50809852, 0.5770952, -1.0915014]}","{""Every task  has these classes:"": [""four"", ""yes"", ""one"", ""right"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0356990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eefab810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46404282, 'precision': 0.3594402195283153, 'recall': 0.42474747474747475, 'f1_score': 0.36754594940762088, 'confusion_matrix': array([[103,  17, 100,   0,   0],
       [ 74,  13,  93,   0,   0],
       [ 82,  13, 133,   0,   0],
       [ 44,   5,  63,   0,   0],
       [ 77,   6,  77,   0,   0]]), 'forgetting_measure': [0.47935883, 0.024180777, 0.11899235]}","{""Every task  has these classes:"": [""three"", ""house"", ""yes"", ""six"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0356990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eefab810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52516733, 'precision': 0.33359576181778993, 'recall': 0.44624233128834358, 'f1_score': 0.3724969431569369, 'confusion_matrix': array([[109,   0,  54,   0,   0],
       [ 82,   0,  52,   0,   0],
       [ 70,   0,  90,   0,   0],
       [ 44,   0,  26,   0,   0],
       [ 38,   0,  35,   0,   0]]), 'forgetting_measure': [0.53194908, -0.26668525, 0.46946216]}","{""Every task  has these classes:"": [""three"", ""house"", ""yes"", ""six"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a6976490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1443c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42070056, 'precision': 0.36989431683908168, 'recall': 0.4021670901562206, 'f1_score': 0.33043816656493423, 'confusion_matrix': array([[ 15,   6, 138,   1,   0],
       [ 21,  15, 129,   3,   0],
       [ 20,  21, 189,   0,   0],
       [ 14,  12, 138,   1,   0],
       [  9,   8, 159,   1,   0]]), 'forgetting_measure': [0.46990712, 0.4161434, -0.48874888]}","{""Every task  has these classes:"": [""eight"", ""happy"", ""on"", ""dog"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a6976490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1443c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42383891, 'precision': 0.3109133170814672, 'recall': 0.41495098039215685, 'f1_score': 0.30638968001340258, 'confusion_matrix': array([[ 10,   0,  86,   0,   0],
       [  5,   0,  97,   0,   0],
       [  4,   0, 132,   0,   0],
       [  3,   0, 125,   0,   0],
       [  9,   0, 129,   0,   0]]), 'forgetting_measure': [0.46321292, 0.4487701, -0.81412506]}","{""Every task  has these classes:"": [""eight"", ""happy"", ""on"", ""dog"", ""yes""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ba33ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ba664d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4896497, 'precision': 0.6463980288908533, 'recall': 0.5498754060635644, 'f1_score': 0.5446893325654536, 'confusion_matrix': array([[ 43,  85,   6,  14,   5],
       [  8, 142,  14,  27,   3],
       [ 13,  91,  21,  36,   9],
       [  7, 109,  31,  78,   2],
       [  9,  85,  11,   9,  42]]), 'forgetting_measure': [0.48268144, 0.16360314, -0.47962666]}","{""Every task  has these classes:"": [""seven"", ""eight"", ""dog"", ""zero"", ""tree""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ba33ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ba664d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40013137, 'precision': 0.3903043089928336, 'recall': 0.4031026834905202, 'f1_score': 0.36253870159626815, 'confusion_matrix': array([[10, 57, 10, 22,  6],
       [14, 69,  3, 21,  6],
       [16, 61,  6, 22, 10],
       [20, 81,  6, 30, 16],
       [10, 65,  5, 27,  7]]), 'forgetting_measure': [0.39826424, -0.01648773, 0.0046465485]}","{""Every task  has these classes:"": [""seven"", ""eight"", ""dog"", ""zero"", ""tree""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d92de150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d83aa750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4579384, 'precision': 0.6362025129856991, 'recall': 0.49734251914386156, 'f1_score': 0.4711006361289081, 'confusion_matrix': array([[ 50,   1,   4,  38,  84],
       [ 20,  14,   0,  36,  89],
       [  2,   4,  11,  39, 106],
       [  9,   4,   2,  56, 108],
       [ 10,   4,   3,  42, 164]]), 'forgetting_measure': [0.5086352, 0.5144924, -1.1044134]}","{""Every task  has these classes:"": [""four"", ""left"", ""wow"", ""nine"", ""zero""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d92de150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d83aa750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48199664, 'precision': 0.43312163227319518, 'recall': 0.4521885230041939, 'f1_score': 0.40438486611988121, 'confusion_matrix': array([[ 15,   4,   1,  26,  50],
       [ 18,   3,   0,  25,  74],
       [ 18,   0,   1,  18,  50],
       [ 14,   1,   4,  47,  74],
       [  8,   6,   5,  23, 115]]), 'forgetting_measure': [0.51834424, 0.30326393, -0.37890518]}","{""Every task  has these classes:"": [""four"", ""left"", ""wow"", ""nine"", ""zero""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7e16c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e79c5550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4445116, 'precision': 0.49511130329040774, 'recall': 0.44822138502036717, 'f1_score': 0.42619218153318688, 'confusion_matrix': array([[ 67,  27, 100,   8,   2],
       [ 28,  29,  94,   5,  10],
       [ 48,  27,  97,   6,   5],
       [ 47,  14,  98,   2,   2],
       [ 44,  20,  80,   4,  36]]), 'forgetting_measure': [0.45533965, 0.26335928, -0.5423256]}","{""Every task  has these classes:"": [""nine"", ""left"", ""dog"", ""cat"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7e16c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e79c5550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34058945, 'precision': 0.41823126933918244, 'recall': 0.3996977611833003, 'f1_score': 0.3555353992419065, 'confusion_matrix': array([[47,  5, 66,  4,  4],
       [31,  6, 59,  1,  7],
       [48,  5, 54,  0,  8],
       [38,  4, 57,  1,  9],
       [52,  5, 75,  1, 13]]), 'forgetting_measure': [0.35544808, 0.21135198, -0.17237915]}","{""Every task  has these classes:"": [""nine"", ""left"", ""dog"", ""cat"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbc9e990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bba97110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41153675, 'precision': 0.240934371523915464, 'recall': 0.39891891891891894, 'f1_score': 0.26789667896678966, 'confusion_matrix': array([[  0, 180,   0,   0,   0],
       [  0, 184,   1,   0,   0],
       [  0, 214,   0,   0,   0],
       [  0, 138,   0,   0,   0],
       [  0, 183,   0,   0,   0]]), 'forgetting_measure': [0.42343135, 0.25343806, -0.4650223]}","{""Every task  has these classes:"": [""dog"", ""happy"", ""yes"", ""right"", ""two""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbc9e990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bba97110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4742941, 'precision': 0.245, 'recall': 0.4, 'f1_score': 0.27346938775510203, 'confusion_matrix': array([[  0, 105,   0,   0,   0],
       [  0, 135,   0,   0,   0],
       [  0, 170,   0,   0,   0],
       [  0,  74,   0,   0,   0],
       [  0, 116,   0,   0,   0]]), 'forgetting_measure': [0.51543112, 0.39124563, -0.64269865]}","{""Every task  has these classes:"": [""dog"", ""happy"", ""yes"", ""right"", ""two""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d21c6990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5482a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3329522, 'precision': 0.226444444444444444, 'recall': 0.4, 'f1_score': 0.24671246319921492, 'confusion_matrix': array([[119,   0,   0,   0,   0],
       [168,   0,   0,   0,   0],
       [337,   0,   0,   0,   0],
       [163,   0,   0,   0,   0],
       [113,   0,   0,   0,   0]]), 'forgetting_measure': [0.32535252, -0.18187967, 0.15389018]}","{""Every task  has these classes:"": [""marvel"", ""happy"", ""nine"", ""bed"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d21c6990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5482a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3167623, 'precision': 0.226666666666666665, 'recall': 0.4, 'f1_score': 0.247058823529411764, 'confusion_matrix': array([[ 80,   0,   0,   0,   0],
       [107,   0,   0,   0,   0],
       [199,   0,   0,   0,   0],
       [132,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0]]), 'forgetting_measure': [0.30216522, -0.4286315, 0.30002946]}","{""Every task  has these classes:"": [""marvel"", ""happy"", ""nine"", ""bed"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cda26150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d28f7550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39056633, 'precision': 0.24466666666666667, 'recall': 0.4, 'f1_score': 0.27302452316076294, 'confusion_matrix': array([[201,   0,   0,   0,   0],
       [240,   0,   0,   0,   0],
       [163,   0,   0,   0,   0],
       [164,   0,   0,   0,   0],
       [132,   0,   0,   0,   0]]), 'forgetting_measure': [0.38333612, -0.11831109, 0.10579444]}","{""Every task  has these classes:"": [""one"", ""nine"", ""left"", ""no"", ""down""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cda26150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d28f7550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39511962, 'precision': 0.23233333333333333, 'recall': 0.4, 'f1_score': 0.25566714490674318, 'confusion_matrix': array([[ 97,   0,   0,   0,   0],
       [158,   0,   0,   0,   0],
       [137,   0,   0,   0,   0],
       [ 97,   0,   0,   0,   0],
       [111,   0,   0,   0,   0]]), 'forgetting_measure': [0.37378464, -0.36830035, 0.2691663]}","{""Every task  has these classes:"": [""one"", ""nine"", ""left"", ""no"", ""down""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c2bbe150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c39e2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37252794, 'precision': 0.3356654790370152, 'recall': 0.34853786634495658, 'f1_score': 0.32598999537545982, 'confusion_matrix': array([[67, 11, 99, 11, 16],
       [65,  6, 75, 16,  8],
       [98, 16, 63, 17, 19],
       [71,  9, 39,  6, 17],
       [89, 11, 52, 12,  7]]), 'forgetting_measure': [0.36015808, -0.12479137, 0.015893409]}","{""Every task  has these classes:"": [""one"", ""marvel"", ""stop"", ""seven"", ""two""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c2bbe150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c39e2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41857168, 'precision': 0.4157985044229515, 'recall': 0.42543526651121168, 'f1_score': 0.40163687579133546, 'confusion_matrix': array([[55,  9, 37, 11, 11],
       [46,  8, 21,  8,  7],
       [42, 14, 65,  8, 22],
       [47,  7, 40, 12, 13],
       [51,  8, 40, 11,  7]]), 'forgetting_measure': [0.4311124, -0.068872616, 0.28116783]}","{""Every task  has these classes:"": [""one"", ""marvel"", ""stop"", ""seven"", ""two""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a9cce8d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552aa294450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56951566, 'precision': 0.5711805387891876, 'recall': 0.57734380310648197, 'f1_score': 0.5513523828825761, 'confusion_matrix': array([[112,  38,  39,   4,  15],
       [ 40, 148,  19,   0,   7],
       [ 42,  40, 100,  11,  18],
       [ 42,  29,  29,   5,  12],
       [ 55,  31,  41,   2,  21]]), 'forgetting_measure': [0.53763567, -0.032746255, -0.21086599]}","{""Every task  has these classes:"": [""three"", ""no"", ""zero"", ""right"", ""go""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a9cce8d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552aa294450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40729822, 'precision': 0.37510989010989012, 'recall': 0.4064567446415552, 'f1_score': 0.3841690664582071, 'confusion_matrix': array([[36, 49, 37,  7,  9],
       [19, 36, 33,  1, 12],
       [38, 64, 55,  4, 20],
       [20, 40, 33,  0, 15],
       [17, 21, 24,  2,  8]]), 'forgetting_measure': [0.39135784, -0.13792412, 0.022799354]}","{""Every task  has these classes:"": [""three"", ""no"", ""zero"", ""right"", ""go""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c17f6c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c74a2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43358697, 'precision': 0.4333924679435954, 'recall': 0.4277433068698726, 'f1_score': 0.40431096926288878, 'confusion_matrix': array([[139,  21,  28,  35,   8],
       [112,  20,  13,  24,  17],
       [ 99,  17,  12,  25,   8],
       [ 85,  15,  13,  50,  11],
       [ 97,  14,  15,  12,  10]]), 'forgetting_measure': [0.39525893, -0.25695097, -0.05965063]}","{""Every task  has these classes:"": [""up"", ""one"", ""eight"", ""five"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c17f6c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c74a2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39645971, 'precision': 0.38966232934532648, 'recall': 0.3862037255103525, 'f1_score': 0.35540799986239043, 'confusion_matrix': array([[59, 22, 12, 17,  6],
       [70, 18, 11, 27,  6],
       [94, 14,  7, 20, 13],
       [68,  5,  2, 16,  7],
       [56, 13, 10, 19,  8]]), 'forgetting_measure': [0.42006012, 0.19168214, -0.07624284]}","{""Every task  has these classes:"": [""up"", ""one"", ""eight"", ""five"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b0256150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529a642750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42530766, 'precision': 0.3048311286236983, 'recall': 0.39092837492956813, 'f1_score': 0.328267608539975, 'confusion_matrix': array([[ 49,   1,   0, 171,   5],
       [ 27,   0,   0,  97,   1],
       [ 37,   0,   0, 108,   1],
       [ 69,   0,   0, 197,   1],
       [ 27,   2,   0, 107,   0]]), 'forgetting_measure': [0.44369822, 0.22757669, -0.29615843]}","{""Every task  has these classes:"": [""bed"", ""four"", ""dog"", ""cat"", ""off""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b0256150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529a642750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47874723, 'precision': 0.30814814814814815, 'recall': 0.4076535448785112, 'f1_score': 0.31583297447171792, 'confusion_matrix': array([[ 17,   0,   0, 114,   0],
       [  7,   0,   0,  91,   0],
       [ 10,   0,   0, 114,   0],
       [ 14,   0,   0, 139,   0],
       [ 12,   0,   0,  82,   0]]), 'forgetting_measure': [0.47903095, 0.014762156, -0.026870692]}","{""Every task  has these classes:"": [""bed"", ""four"", ""dog"", ""cat"", ""off""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528a21ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528acd13d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4152554, 'precision': 0.40637625598868156, 'recall': 0.40437817897536484, 'f1_score': 0.38050483001542292, 'confusion_matrix': array([[14, 79,  5, 10, 82],
       [20, 85,  6, 21, 64],
       [14, 61,  4, 16, 39],
       [17, 79,  4, 23, 49],
       [30, 84,  7, 14, 73]]), 'forgetting_measure': [0.46981366, 0.24663205, 0.15046753]}","{""Every task  has these classes:"": [""two"", ""three"", ""yes"", ""bed"", ""wow""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528a21ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528acd13d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44449179, 'precision': 0.38152695093241286, 'recall': 0.42950704990003024, 'f1_score': 0.3704720133263143, 'confusion_matrix': array([[16, 54,  4,  1, 60],
       [12, 65,  1,  2, 63],
       [13, 47,  2,  1, 55],
       [10, 37,  2,  0, 42],
       [11, 35,  4,  0, 63]]), 'forgetting_measure': [0.40830323, -0.42755377, 0.23390861]}","{""Every task  has these classes:"": [""two"", ""three"", ""yes"", ""bed"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ab44ec90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552abb7aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4944614, 'precision': 0.41742964060713105, 'recall': 0.40716898156155947, 'f1_score': 0.3456330052549328, 'confusion_matrix': array([[  1, 135,  24,   0,   0],
       [  1, 199,  74,   0,   0],
       [  0, 147,  64,   0,   0],
       [  0,  83,  19,   0,   0],
       [  0, 117,  36,   0,   0]]), 'forgetting_measure': [0.4935413, 0.26647472, -0.7393786]}","{""Every task  has these classes:"": [""on"", ""one"", ""no"", ""up"", ""off""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ab44ec90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552abb7aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51468523, 'precision': 0.33545986177565122, 'recall': 0.42886625569552402, 'f1_score': 0.36021095978101457, 'confusion_matrix': array([[  0,  81,  27,   0,   0],
       [  0, 130,  34,   0,   0],
       [  0, 118,  64,   0,   0],
       [  0,  40,  25,   0,   0],
       [  0,  60,  21,   0,   0]]), 'forgetting_measure': [0.5232434, -0.045003116, 0.16213746]}","{""Every task  has these classes:"": [""on"", ""one"", ""no"", ""up"", ""off""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529b6de8d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a5f4cd10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35858857, 'precision': 0.23333333333333333, 'recall': 0.4, 'f1_score': 0.25714285714285714, 'confusion_matrix': array([[150,   0,   0,   0,   0],
       [166,   0,   0,   0,   0],
       [197,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [243,   0,   0,   0,   0]]), 'forgetting_measure': [0.35858857, 0.0, 0.0]}","{""Every task  has these classes:"": [""four"", ""cat"", ""six"", ""nine"", ""left""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529b6de8d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a5f4cd10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3820754, 'precision': 0.233, 'recall': 0.4, 'f1_score': 0.25665236051502146, 'confusion_matrix': array([[ 99,   0,   0,   0,   0],
       [ 94,   0,   0,   0,   0],
       [130,   0,   0,   0,   0],
       [126,   0,   0,   0,   0],
       [151,   0,   0,   0,   0]]), 'forgetting_measure': [0.38207541, 0.0, 0.0]}","{""Every task  has these classes:"": [""four"", ""cat"", ""six"", ""nine"", ""left""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155285ad6b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528c46d550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.57830764, 'precision': 0.32955665024630542, 'recall': 0.40295508274231677, 'f1_score': 0.32034245300576958, 'confusion_matrix': array([[  0, 131,   0,   1,   0],
       [  0, 315,   0,   8,   1],
       [  0, 156,   0,   4,   0],
       [  0, 179,   0,   8,   1],
       [  0,  89,   0,   7,   0]]), 'forgetting_measure': [0.5409347, -0.16185367, -0.0044323965]}","{""Every task  has these classes:"": [""bird"", ""happy"", ""nine"", ""go"", ""off""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155285ad6b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528c46d550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54601274, 'precision': 0.30486111111111111, 'recall': 0.397463429816371, 'f1_score': 0.31522921522921523, 'confusion_matrix': array([[  0,  82,   0,   2,   0],
       [  0, 206,   0,  10,   0],
       [  0,  81,   0,   3,   0],
       [  0, 115,   0,   4,   0],
       [  0,  92,   0,   5,   0]]), 'forgetting_measure': [0.54837708, 0.0, 0.020360159]}","{""Every task  has these classes:"": [""bird"", ""happy"", ""nine"", ""go"", ""off""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528b0ee990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528b20f110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49365534, 'precision': 0.5057070325976523, 'recall': 0.4962366210763788, 'f1_score': 0.46599696239321163, 'confusion_matrix': array([[  9,  16,  50,  48,  49],
       [  6,  22,  44,  57,  37],
       [  2,   2, 139,  54,   9],
       [  9,  17,  51,  43,  44],
       [  5,   8,  77,  33,  69]]), 'forgetting_measure': [0.42844642, 0.5763935, -4.742898]}","{""Every task  has these classes:"": [""happy"", ""cat"", ""wow"", ""right"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528b0ee990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528b20f110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3990416, 'precision': 0.36055985130875, 'recall': 0.38910830172966095, 'f1_score': 0.36653991722758194, 'confusion_matrix': array([[ 0, 11, 52, 32, 27],
       [ 5, 11, 33, 28, 31],
       [10,  7, 69, 32, 38],
       [ 3,  7, 36, 20, 37],
       [ 4, 16, 37, 31, 23]]), 'forgetting_measure': [0.4852545, 0.41634068, 0.12680905]}","{""Every task  has these classes:"": [""happy"", ""cat"", ""wow"", ""right"", ""yes""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a0832010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529c482410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41588053, 'precision': 0.23866666666666667, 'recall': 0.4, 'f1_score': 0.26480446927374302, 'confusion_matrix': array([[174,   0,   0,   0,   0],
       [174,   0,   0,   0,   0],
       [194,   0,   0,   0,   0],
       [124,   0,   0,   0,   0],
       [234,   0,   0,   0,   0]]), 'forgetting_measure': [0.41588051, 0.0, 0.0]}","{""Every task  has these classes:"": [""five"", ""one"", ""stop"", ""two"", ""four""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a0832010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529c482410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44976802, 'precision': 0.24, 'recall': 0.4, 'f1_score': 0.26666666666666668, 'confusion_matrix': array([[120,   0,   0,   0,   0],
       [ 85,   0,   0,   0,   0],
       [128,   0,   0,   0,   0],
       [ 77,   0,   0,   0,   0],
       [190,   0,   0,   0,   0]]), 'forgetting_measure': [0.44976803, 0.0, 0.0]}","{""Every task  has these classes:"": [""five"", ""one"", ""stop"", ""two"", ""four""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528a8b7850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528f395550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40148218, 'precision': 0.33936291240045506, 'recall': 0.3944129867472409, 'f1_score': 0.27158338516829084, 'confusion_matrix': array([[  2, 187,   0,   0,   0],
       [  0, 173,   2,   4,   2],
       [  2, 209,   0,   1,   0],
       [  0, 170,   4,   1,   1],
       [  2, 140,   0,   0,   0]]), 'forgetting_measure': [0.37374189, -0.41648275, 0.24989688]}","{""Every task  has these classes:"": [""five"", ""one"", ""dog"", ""cat"", ""stop""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528a8b7850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528f395550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4358013, 'precision': 0.6740261215218625, 'recall': 0.4137617673331959, 'f1_score': 0.3031389184695701, 'confusion_matrix': array([[  3, 141,   0,   2,   1],
       [  0, 139,   0,   0,   0],
       [  0,  87,   1,   0,   0],
       [  0, 118,   0,   0,   0],
       [  0, 102,   2,   0,   4]]), 'forgetting_measure': [0.42412676, -0.18357581, 0.17817608]}","{""Every task  has these classes:"": [""five"", ""one"", ""dog"", ""cat"", ""stop""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1a02410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c1313f50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47189147, 'precision': 0.5771591724558477, 'recall': 0.4997290770285789, 'f1_score': 0.4628429119780381, 'confusion_matrix': array([[ 14, 125,   5,   5,   8],
       [  7, 173,   9,   9,  16],
       [  6, 124,  26,   4,  21],
       [  8,  94,   6,   8,  37],
       [  4, 100,   4,   8,  79]]), 'forgetting_measure': [0.46122367, 0.27794045, -0.939527]}","{""Every task  has these classes:"": [""down"", ""wow"", ""bird"", ""dog"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1a02410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c1313f50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43808275, 'precision': 0.3931429912601436, 'recall': 0.4125985333951001, 'f1_score': 0.3614537490545233, 'confusion_matrix': array([[  4,  91,   9,   0,  21],
       [  8, 115,  13,   3,  20],
       [  3,  61,   6,   2,  10],
       [  9,  96,  10,   2,  12],
       [  5,  61,  11,   5,  23]]), 'forgetting_measure': [0.45715292, 0.1384933, -0.063273124]}","{""Every task  has these classes:"": [""down"", ""wow"", ""bird"", ""dog"", ""tree""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bdc3e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531687ee90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38333611, 'precision': 0.242714126807563965, 'recall': 0.4, 'f1_score': 0.27039413382218149, 'confusion_matrix': array([[192,   0,   0,   0,   0],
       [140,   0,   0,   0,   0],
       [229,   0,   0,   0,   0],
       [149,   0,   1,   0,   0],
       [189,   0,   0,   0,   0]]), 'forgetting_measure': [0.38333612, 0.0, 0.0]}","{""Every task  has these classes:"": [""wow"", ""zero"", ""bird"", ""marvel"", ""up""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bdc3e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531687ee90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39817479, 'precision': 0.231, 'recall': 0.4, 'f1_score': 0.25367965367965368, 'confusion_matrix': array([[ 93,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0],
       [155,   0,   0,   0,   0],
       [127,   0,   0,   0,   0],
       [132,   0,   0,   0,   0]]), 'forgetting_measure': [0.39817477, 0.0, 0.0]}","{""Every task  has these classes:"": [""wow"", ""zero"", ""bird"", ""marvel"", ""up""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528fc012d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527199d590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46918635, 'precision': 0.24516129032258064, 'recall': 0.39901960784313727, 'f1_score': 0.27361740707162284, 'confusion_matrix': array([[  0,   0, 177,   0,   0],
       [  0,   0, 151,   0,   0],
       [  0,   1, 203,   0,   0],
       [  0,   0, 191,   0,   0],
       [  0,   0, 177,   0,   0]]), 'forgetting_measure': [0.45927308, -0.033931736, -0.04530371]}","{""Every task  has these classes:"": [""one"", ""cat"", ""stop"", ""seven"", ""bird""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528fc012d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527199d590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38260111, 'precision': 0.24033333333333333, 'recall': 0.4, 'f1_score': 0.26712898751733704, 'confusion_matrix': array([[  0,   0, 120,   0,   0],
       [  0,   0, 102,   0,   0],
       [  0,   0, 121,   0,   0],
       [  0,   0, 130,   0,   0],
       [  0,   0, 127,   0,   0]]), 'forgetting_measure': [0.38853176, 0.09437098, -0.1042049]}","{""Every task  has these classes:"": [""one"", ""cat"", ""stop"", ""seven"", ""bird""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280e06150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528ee1aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43993808, 'precision': 0.24022222222222222, 'recall': 0.4, 'f1_score': 0.2669750231267345, 'confusion_matrix': array([[181,   0,   0,   0,   0],
       [203,   0,   0,   0,   0],
       [218,   0,   0,   0,   0],
       [151,   0,   0,   0,   0],
       [147,   0,   0,   0,   0]]), 'forgetting_measure': [0.4608829, 0.24085326, -0.3172684]}","{""Every task  has these classes:"": [""one"", ""stop"", ""up"", ""down"", ""right""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280e06150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528ee1aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38572177, 'precision': 0.238, 'recall': 0.4, 'f1_score': 0.2638655462184874, 'confusion_matrix': array([[114,   0,   0,   0,   0],
       [141,   0,   0,   0,   0],
       [129,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [114,   0,   0,   0,   0]]), 'forgetting_measure': [0.39321617, 0.116363235, -0.13168673]}","{""Every task  has these classes:"": [""one"", ""stop"", ""up"", ""down"", ""right""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bdc2e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bde8bb50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41236801, 'precision': 0.24088888888888889, 'recall': 0.4, 'f1_score': 0.26789667896678966, 'confusion_matrix': array([[  0,   0,   0, 135,   0],
       [  0,   0,   0, 254,   0],
       [  0,   0,   0, 191,   0],
       [  0,   0,   0, 184,   0],
       [  0,   0,   0, 136,   0]]), 'forgetting_measure': [0.42152922, 0.124063015, -0.14163463]}","{""Every task  has these classes:"": [""dog"", ""off"", ""zero"", ""seven"", ""up""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bdc2e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bde8bb50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38236746, 'precision': 0.235333333333333335, 'recall': 0.4, 'f1_score': 0.26005665722379603, 'confusion_matrix': array([[  0,   0,   0,  81,   0],
       [  0,   0,   0, 156,   0],
       [  0,   0,   0, 154,   0],
       [  0,   0,   0, 106,   0],
       [  0,   0,   0, 103,   0]]), 'forgetting_measure': [0.39817895, 0.23935184, -0.31466827]}","{""Every task  has these classes:"": [""dog"", ""off"", ""zero"", ""seven"", ""up""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155270502dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155279d82a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37979641, 'precision': 0.24022222222222222, 'recall': 0.4, 'f1_score': 0.2669750231267345, 'confusion_matrix': array([[181,   0,   0,   0,   0],
       [223,   0,   0,   0,   0],
       [190,   0,   0,   0,   0],
       [114,   0,   0,   0,   0],
       [192,   0,   0,   0,   0]]), 'forgetting_measure': [0.368336, -0.20424157, 0.16960183]}","{""Every task  has these classes:"": [""one"", ""tree"", ""sheila"", ""two"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155270502dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155279d82a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35677856, 'precision': 0.24066666666666667, 'recall': 0.4, 'f1_score': 0.26759002770083103, 'confusion_matrix': array([[122,   0,   0,   0,   0],
       [140,   0,   0,   0,   0],
       [112,   0,   0,   0,   0],
       [118,   0,   0,   0,   0],
       [108,   0,   0,   0,   0]]), 'forgetting_measure': [0.35111217, -0.11249372, 0.10111852]}","{""Every task  has these classes:"": [""one"", ""tree"", ""sheila"", ""two"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155258ad6150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552588e2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38408003, 'precision': 0.38504003374148703, 'recall': 0.39416130869216214, 'f1_score': 0.3711776424444164, 'confusion_matrix': array([[ 4, 57, 33, 60, 14],
       [ 5, 68, 40, 63, 16],
       [ 3, 66, 28, 59, 18],
       [ 7, 66, 44, 68,  9],
       [11, 59, 41, 47, 14]]), 'forgetting_measure': [0.38266296, -0.047607727, 0.068672344]}","{""Every task  has these classes:"": [""up"", ""bed"", ""eight"", ""tree"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155258ad6150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552588e2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3935356, 'precision': 0.40248289346139972, 'recall': 0.40295246452812726, 'f1_score': 0.37068304742028445, 'confusion_matrix': array([[ 2, 40, 14, 46,  4],
       [ 4, 32, 26, 63,  5],
       [ 1, 37, 19, 34, 11],
       [ 1, 39, 23, 72,  5],
       [ 2, 43, 29, 42,  6]]), 'forgetting_measure': [0.39445302, 0.16033968, -0.36505893]}","{""Every task  has these classes:"": [""up"", ""bed"", ""eight"", ""tree"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155275676b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155274ae2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41821938, 'precision': 0.44256298486161834, 'recall': 0.44695853914244661, 'f1_score': 0.41575371855342046, 'confusion_matrix': array([[ 44,  85,  32,  11,   7],
       [ 55, 114,  21,   7,   2],
       [ 47,  63,  65,  12,   6],
       [ 81,  75,  20,  11,   4],
       [ 35,  73,  13,  14,   3]]), 'forgetting_measure': [0.43915179, 0.24684364, -0.30684727]}","{""Every task  has these classes:"": [""down"", ""on"", ""happy"", ""cat"", ""six""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155275676b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155274ae2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3885833, 'precision': 0.4138816565053717, 'recall': 0.40386459776278354, 'f1_score': 0.37228828065319396, 'confusion_matrix': array([[24, 53, 23,  9,  3],
       [35, 75, 13, 13,  2],
       [42, 66, 25,  6,  0],
       [26, 53, 28,  7,  1],
       [18, 51, 19,  6,  2]]), 'forgetting_measure': [0.42049884, 0.1752746, 0.10146197]}","{""Every task  has these classes:"": [""down"", ""on"", ""happy"", ""cat"", ""six""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525cf0eb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525c752a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47531326, 'precision': 0.29364705882352942, 'recall': 0.39745824255628178, 'f1_score': 0.29918810468910963, 'confusion_matrix': array([[ 10, 194,   0,   0,   0],
       [ 15, 228,   0,   0,   0],
       [  4, 175,   0,   0,   0],
       [ 12, 154,   0,   0,   0],
       [  9,  99,   0,   0,   0]]), 'forgetting_measure': [0.46188266, -0.07692717, 0.0]}","{""Every task  has these classes:"": [""yes"", ""left"", ""stop"", ""nine"", ""go""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525cf0eb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525c752a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38457927, 'precision': 0.249, 'recall': 0.4, 'f1_score': 0.278714859437751, 'confusion_matrix': array([[  0, 141,   0,   0,   0],
       [  0, 147,   0,   0,   0],
       [  0, 129,   0,   0,   0],
       [  0,  93,   0,   0,   0],
       [  0,  90,   0,   0,   0]]), 'forgetting_measure': [0.38457928, 0.0, 0.0]}","{""Every task  has these classes:"": [""yes"", ""left"", ""stop"", ""nine"", ""go""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525c100550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525c7fcd50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48840193, 'precision': 0.4091899223213185, 'recall': 0.39625950424426555, 'f1_score': 0.31661032051786042, 'confusion_matrix': array([[  0,   8,   0, 115,   0],
       [  0,  13,   0, 205,   0],
       [  0,   7,   0, 101,   0],
       [  0,  23,   1, 270,   1],
       [  0,   7,   0, 148,   1]]), 'forgetting_measure': [0.51766912, 0.34547898, -0.63338625]}","{""Every task  has these classes:"": [""seven"", ""down"", ""four"", ""nine"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525c100550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525c7fcd50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54804285, 'precision': 0.26333333333333332, 'recall': 0.4, 'f1_score': 0.29620253164556962, 'confusion_matrix': array([[  0,   0,   0,  84,   0],
       [  0,   0,   0, 158,   0],
       [  0,   0,   0,  99,   0],
       [  0,   0,   0, 190,   0],
       [  0,   0,   0,  69,   0]]), 'forgetting_measure': [0.5864243, 0.29797363, -0.42444792]}","{""Every task  has these classes:"": [""seven"", ""down"", ""four"", ""nine"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155261e77f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522b3a0790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54024298, 'precision': 0.5805698748062755, 'recall': 0.467255211831483, 'f1_score': 0.438455895533701, 'confusion_matrix': array([[ 32, 120,  11,   0,   2],
       [  1, 341,  10,   1,   1],
       [  7, 117,   6,   3,   2],
       [ 11,  69,   9,   0,   1],
       [  8, 117,   8,   2,  21]]), 'forgetting_measure': [0.47385885, -0.15566877, -0.35985285]}","{""Every task  has these classes:"": [""zero"", ""off"", ""tree"", ""wow"", ""no""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155261e77f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522b3a0790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53186263, 'precision': 0.33214814814814815, 'recall': 0.39577276524644943, 'f1_score': 0.3265501586452504, 'confusion_matrix': array([[  7, 104,   0,   0,   3],
       [ 15, 184,   0,   0,   8],
       [  4,  80,   0,   0,   6],
       [  4,  75,   0,   0,   5],
       [  5,  97,   0,   0,   3]]), 'forgetting_measure': [0.54190017, 0.0, 0.08807414]}","{""Every task  has these classes:"": [""zero"", ""off"", ""tree"", ""wow"", ""no""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155253ace990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525bb2aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5148397, 'precision': 0.6128298023717871, 'recall': 0.49161804295516647, 'f1_score': 0.4780273974018658, 'confusion_matrix': array([[92,  2, 88, 19,  3],
       [69, 22, 67,  2,  8],
       [66,  5, 86, 14,  4],
       [59,  3, 76, 63,  1],
       [50,  7, 76,  7, 11]]), 'forgetting_measure': [0.51172606, 0.2572215, -0.73293453]}","{""Every task  has these classes:"": [""left"", ""sheila"", ""dog"", ""seven"", ""two""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155253ace990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525bb2aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38864974, 'precision': 0.39562138055862932, 'recall': 0.40574899717887357, 'f1_score': 0.36063337367920189, 'confusion_matrix': array([[67,  6, 55, 15,  4],
       [50,  5, 39,  8,  6],
       [41,  7, 37,  5,  0],
       [72, 11, 56, 15,  4],
       [52,  7, 30,  6,  2]]), 'forgetting_measure': [0.38062013, -0.049184933, -0.03335676]}","{""Every task  has these classes:"": [""left"", ""sheila"", ""dog"", ""seven"", ""two""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524444e450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155244335590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40011017, 'precision': 0.36821442053605135, 'recall': 0.4045993965806235, 'f1_score': 0.27507235338918508, 'confusion_matrix': array([[154,   0,   1,   1,   1],
       [188,   0,   0,   1,   0],
       [156,   0,   0,   0,   1],
       [205,   0,   0,   0,   2],
       [180,   1,   0,   1,   8]]), 'forgetting_measure': [0.38618469, -0.2889848, 0.27431518]}","{""Every task  has these classes:"": [""wow"", ""nine"", ""dog"", ""happy"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524444e450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155244335590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38107927, 'precision': 0.33563025210084034, 'recall': 0.4028169014084507, 'f1_score': 0.26596447345279738, 'confusion_matrix': array([[106,   0,   0,   0,   0],
       [118,   0,   0,   0,   0],
       [ 76,   0,   0,   0,   2],
       [155,   1,   0,   0,   0],
       [140,   0,   0,   0,   2]]), 'forgetting_measure': [0.36824873, -0.24021934, 0.20291626]}","{""Every task  has these classes:"": [""wow"", ""nine"", ""dog"", ""happy"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155244a17590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522fad2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36180296, 'precision': 0.56413690476190474, 'recall': 0.40224240809372707, 'f1_score': 0.260591456736035054, 'confusion_matrix': array([[  2,   0, 160,   0,   0],
       [  0,   1, 164,   0,   0],
       [  1,   0, 138,   0,   0],
       [  0,   0, 257,   0,   0],
       [  0,   0, 177,   0,   0]]), 'forgetting_measure': [0.38345165, 0.20444672, -0.068971656]}","{""Every task  has these classes:"": [""wow"", ""up"", ""eight"", ""four"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155244a17590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522fad2750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35171675, 'precision': 0.230666666666666665, 'recall': 0.4, 'f1_score': 0.25317919075144508, 'confusion_matrix': array([[  0,   0, 136,   0,   0],
       [  0,   0, 129,   0,   0],
       [  0,   0,  92,   0,   0],
       [  0,   0, 159,   0,   0],
       [  0,   0,  84,   0,   0]]), 'forgetting_measure': [0.33603929, -0.3457265, 0.25690696]}","{""Every task  has these classes:"": [""wow"", ""up"", ""eight"", ""four"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523a456b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523a135550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42228913, 'precision': 0.246, 'recall': 0.4, 'f1_score': 0.27479674796747968, 'confusion_matrix': array([[207,   0,   0,   0,   0],
       [142,   0,   0,   0,   0],
       [214,   0,   0,   0,   0],
       [205,   0,   0,   0,   0],
       [132,   0,   0,   0,   0]]), 'forgetting_measure': [0.4628356, 0.46279648, -0.86149186]}","{""Every task  has these classes:"": [""bird"", ""house"", ""bed"", ""left"", ""on""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523a456b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523a135550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4661473, 'precision': 0.243, 'recall': 0.4, 'f1_score': 0.27078189300411522, 'confusion_matrix': array([[129,   0,   0,   0,   0],
       [114,   0,   0,   0,   0],
       [151,   0,   0,   0,   0],
       [128,   0,   0,   0,   0],
       [ 78,   0,   0,   0,   0]]), 'forgetting_measure': [0.51313008, 0.45012736, -0.8186029]}","{""Every task  has these classes:"": [""bird"", ""house"", ""bed"", ""left"", ""on""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523538e690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155234ebaa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31972421, 'precision': 0.227555555555555555, 'recall': 0.4, 'f1_score': 0.2484375, 'confusion_matrix': array([[124,   0,   0,   0,   0],
       [301,   0,   0,   0,   0],
       [145,   0,   0,   0,   0],
       [189,   0,   0,   0,   0],
       [141,   0,   0,   0,   0]]), 'forgetting_measure': [0.319240865, -0.012160717, 0.01201461]}","{""Every task  has these classes:"": [""seven"", ""nine"", ""house"", ""eight"", ""marvel""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523538e690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155234ebaa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.32914217, 'precision': 0.23, 'recall': 0.4, 'f1_score': 0.25217391304347826, 'confusion_matrix': array([[ 90,   0,   0,   0,   0],
       [164,   0,   0,   0,   0],
       [109,   0,   0,   0,   0],
       [141,   0,   0,   0,   0],
       [ 96,   0,   0,   0,   0]]), 'forgetting_measure': [0.32914217, 0.0, 0.0]}","{""Every task  has these classes:"": [""seven"", ""nine"", ""house"", ""eight"", ""marvel""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155226a36c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522750aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4610584, 'precision': 0.4843778539651614, 'recall': 0.43128324451323728, 'f1_score': 0.40548685054164242, 'confusion_matrix': array([[ 29,  58,  75,   1,   8],
       [ 15, 108,  98,   3,  10],
       [ 15,  97,  99,   3,   5],
       [ 20,  49,  67,   4,   4],
       [  7,  59,  60,   0,   6]]), 'forgetting_measure': [0.41094474, -0.5280154, 0.22468887]}","{""Every task  has these classes:"": [""no"", ""dog"", ""one"", ""sheila"", ""up""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155226a36c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522750aa90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42970301, 'precision': 0.38268983448373272, 'recall': 0.407579739442947, 'f1_score': 0.36185775755138848, 'confusion_matrix': array([[11, 36, 58,  0,  0],
       [17, 48, 89,  5,  0],
       [16, 32, 81,  3,  3],
       [15, 29, 49,  3,  0],
       [13, 34, 57,  1,  0]]), 'forgetting_measure': [0.44345905, 0.13026804, -0.104663104]}","{""Every task  has these classes:"": [""no"", ""dog"", ""one"", ""sheila"", ""up""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155221946450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155222152a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49113078, 'precision': 0.25519553072625698, 'recall': 0.39839357429718876, 'f1_score': 0.28636363636363635, 'confusion_matrix': array([[247,   1,   0,   1,   0],
       [129,   0,   0,   0,   0],
       [217,   0,   0,   0,   2],
       [137,   0,   0,   0,   1],
       [165,   0,   0,   0,   0]]), 'forgetting_measure': [0.54532884, 0.5314832, -1.2638339]}","{""Every task  has these classes:"": [""three"", ""two"", ""marvel"", ""no"", ""house""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155221946450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155222152a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5316281, 'precision': 0.2657762938230384, 'recall': 0.398989898989899, 'f1_score': 0.29887076537013803, 'confusion_matrix': array([[197,   0,   0,   0,   1],
       [ 92,   0,   0,   0,   0],
       [133,   0,   0,   0,   0],
       [ 69,   0,   0,   0,   0],
       [108,   0,   0,   0,   0]]), 'forgetting_measure': [0.6014401, 0.5047824, -0.9851288]}","{""Every task  has these classes:"": [""three"", ""two"", ""marvel"", ""no"", ""house""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dbba97d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c52a3ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4767835, 'precision': 0.51531145213705636, 'recall': 0.4938581223628692, 'f1_score': 0.4942601532682684, 'confusion_matrix': array([[109,  48,  37,  26,  17],
       [ 61,  69,  45,  11,   6],
       [ 71,  43,  68,  29,   5],
       [ 48,  25,  29,  25,   8],
       [ 51,  16,  23,  12,  18]]), 'forgetting_measure': [0.48743953, 0.29835498, -0.69193566]}","{""Every task  has these classes:"": [""off"", ""house"", ""dog"", ""five"", ""on""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dbba97d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c52a3ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44560069, 'precision': 0.45342698449433004, 'recall': 0.44499151823579307, 'f1_score': 0.4308739364122193, 'confusion_matrix': array([[74, 30, 34, 13,  9],
       [53, 30, 28,  2,  7],
       [57, 25, 49,  6,  7],
       [61, 30, 24,  8,  8],
       [16, 10, 14,  0,  5]]), 'forgetting_measure': [0.43540938, -0.3671243, 0.44207615]}","{""Every task  has these classes:"": [""off"", ""house"", ""dog"", ""five"", ""on""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521ba2e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521bf97110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51157592, 'precision': 0.30335375685262818, 'recall': 0.39920289855072465, 'f1_score': 0.30120995709918565, 'confusion_matrix': array([[  0,   0, 177,   0,   0],
       [  0,   0, 182,   1,   0],
       [  0,   0, 268,   8,   0],
       [  0,   0, 117,   3,   0],
       [  0,   0, 142,   2,   0]]), 'forgetting_measure': [0.5567492, 0.5502233, -1.602067]}","{""Every task  has these classes:"": [""nine"", ""two"", ""on"", ""up"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521ba2e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521bf97110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42028218, 'precision': 0.24566666666666667, 'recall': 0.4, 'f1_score': 0.27435549525101764, 'confusion_matrix': array([[  0,   0, 117,   0,   0],
       [  0,   0, 118,   0,   0],
       [  0,   0, 137,   0,   0],
       [  0,   0, 108,   0,   0],
       [  0,   0, 120,   0,   0]]), 'forgetting_measure': [0.45981933, 0.45651513, -0.8399776]}","{""Every task  has these classes:"": [""nine"", ""two"", ""on"", ""up"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155214bbe690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552155a5590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5153525, 'precision': 0.51102592853067235, 'recall': 0.454754790655645, 'f1_score': 0.39704883887678248, 'confusion_matrix': array([[  0,  99,  12,   1,  19],
       [  0, 227,  15,   0,  11],
       [  0, 131,  23,   0,  33],
       [  0, 105,  16,   5,  15],
       [  0, 120,  25,   2,  41]]), 'forgetting_measure': [0.45370046, -0.13095777, -0.41302854]}","{""Every task  has these classes:"": [""four"", ""three"", ""off"", ""seven"", ""eight""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155214bbe690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552155a5590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5156552, 'precision': 0.35229989604989608, 'recall': 0.39986869345411704, 'f1_score': 0.34526809743979024, 'confusion_matrix': array([[  0,  43,   5,   0,  13],
       [  0, 157,  19,   1,  16],
       [  0, 101,   8,   2,   9],
       [  0,  59,   8,   0,   8],
       [  0, 121,  12,   0,  18]]), 'forgetting_measure': [0.5426061, 0.005678694, 0.22591893]}","{""Every task  has these classes:"": [""four"", ""three"", ""off"", ""seven"", ""eight""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521581e190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552065d2a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4544774, 'precision': 0.31454846977235036, 'recall': 0.43080645161290322, 'f1_score': 0.3513112263907598, 'confusion_matrix': array([[  0,   0,  52, 122,   0],
       [  0,   0,  57,  91,   0],
       [  0,   0,  78, 117,   0],
       [  0,   0,  61, 187,   0],
       [  0,   0,  49,  86,   0]]), 'forgetting_measure': [0.50682644, 0.43261823, -0.6228491]}","{""Every task  has these classes:"": [""zero"", ""one"", ""stop"", ""on"", ""two""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521581e190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552065d2a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46803765, 'precision': 0.32306975178361021, 'recall': 0.44064935064935064, 'f1_score': 0.35477354923557457, 'confusion_matrix': array([[  0,   0,  32,  69,   0],
       [  0,   0,  37,  74,   0],
       [  0,   0,  63, 102,   0],
       [  0,   0,  25, 115,   0],
       [  0,   0,  30,  53,   0]]), 'forgetting_measure': [0.4506075, -0.20865473, 0.17263386]}","{""Every task  has these classes:"": [""zero"", ""one"", ""stop"", ""on"", ""two""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155203b0e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520056d550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44166903, 'precision': 0.6454723954032507, 'recall': 0.4598466007272188, 'f1_score': 0.40291293026579918, 'confusion_matrix': array([[  1,   0,  46,  95,  11],
       [  0,  15,  44,  94,   5],
       [  0,   4,  74,  91,   2],
       [  0,   4,  56, 183,   8],
       [  0,  11,  51,  99,   6]]), 'forgetting_measure': [0.47176768, 0.28756845, -0.34092072]}","{""Every task  has these classes:"": [""six"", ""right"", ""four"", ""one"", ""nine""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155203b0e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520056d550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46920903, 'precision': 0.6351323771767358, 'recall': 0.47850381161264254, 'f1_score': 0.4038888835450714, 'confusion_matrix': array([[  1,   3,  35,  71,   4],
       [  0,   6,  21,  70,   4],
       [  0,   5,  68,  61,   3],
       [  0,   3,  23, 107,   2],
       [  0,   4,  36,  69,   4]]), 'forgetting_measure': [0.44874085, -0.24180235, 0.19064483]}","{""Every task  has these classes:"": [""six"", ""right"", ""four"", ""one"", ""nine""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520bc3eb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520a532750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4283355, 'precision': 0.3519984326018809, 'recall': 0.3977228632804557, 'f1_score': 0.31706491042685996, 'confusion_matrix': array([[ 59,   2,   5, 156,   0],
       [ 63,   1,   2, 147,   0],
       [ 41,   0,   1, 115,   2],
       [ 46,   1,   3, 126,   1],
       [ 31,   0,   4,  94,   0]]), 'forgetting_measure': [0.41376818, -0.20260802, 0.16695361]}","{""Every task  has these classes:"": [""up"", ""left"", ""go"", ""no"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520bc3eb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520a532750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43481405, 'precision': 0.38527009519517829, 'recall': 0.39645089735833837, 'f1_score': 0.31421208662134652, 'confusion_matrix': array([[ 40,   0,   0, 103,   1],
       [ 39,   0,   0,  96,   0],
       [ 21,   0,   1,  65,   0],
       [ 34,   0,   1,  79,   0],
       [ 30,   0,   0,  90,   0]]), 'forgetting_measure': [0.43998798, -0.070737675, 0.19253331]}","{""Every task  has these classes:"": [""up"", ""left"", ""go"", ""no"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f3436990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f3047110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40652944, 'precision': 0.24320712694877506, 'recall': 0.4, 'f1_score': 0.27106227106227106, 'confusion_matrix': array([[  0,   0, 173,   1,   0],
       [  0,   0, 221,   0,   0],
       [  0,   0, 194,   0,   0],
       [  0,   0, 173,   0,   1],
       [  0,   0, 137,   0,   0]]), 'forgetting_measure': [0.431551, 0.32418203, -0.47968838]}","{""Every task  has these classes:"": [""cat"", ""go"", ""zero"", ""dog"", ""tree""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f3436990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f3047110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37415889, 'precision': 0.239, 'recall': 0.4, 'f1_score': 0.26527196652719666, 'confusion_matrix': array([[  0,   0, 120,   0,   0],
       [  0,   0, 154,   0,   0],
       [  0,   0, 117,   0,   0],
       [  0,   0, 125,   0,   0],
       [  0,   0,  84,   0,   0]]), 'forgetting_measure': [0.39050568, 0.25742212, -0.3466601]}","{""Every task  has these classes:"": [""cat"", ""go"", ""zero"", ""dog"", ""tree""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f72beb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f2cc4ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40550688, 'precision': 0.24133333333333333, 'recall': 0.4, 'f1_score': 0.26850828729281769, 'confusion_matrix': array([[186,   0,   0,   0,   0],
       [184,   0,   0,   0,   0],
       [243,   0,   0,   0,   0],
       [152,   0,   0,   0,   0],
       [135,   0,   0,   0,   0]]), 'forgetting_measure': [0.40550688, 0.0, 0.0]}","{""Every task  has these classes:"": [""stop"", ""five"", ""up"", ""no"", ""four""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f72beb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f2cc4ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4611617, 'precision': 0.245, 'recall': 0.4, 'f1_score': 0.27346938775510203, 'confusion_matrix': array([[135,   0,   0,   0,   0],
       [123,   0,   0,   0,   0],
       [160,   0,   0,   0,   0],
       [ 76,   0,   0,   0,   0],
       [106,   0,   0,   0,   0]]), 'forgetting_measure': [0.4611617, 0.0, 0.0]}","{""Every task  has these classes:"": [""stop"", ""five"", ""up"", ""no"", ""four""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ed7f6b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ecbd6f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51754678, 'precision': 0.266, 'recall': 0.4, 'f1_score': 0.29924812030075188, 'confusion_matrix': array([[297,   0,   0,   0,   0],
       [209,   0,   0,   0,   0],
       [127,   0,   0,   0,   0],
       [132,   0,   0,   0,   0],
       [135,   0,   0,   0,   0]]), 'forgetting_measure': [0.5175468, 0.0, 0.0]}","{""Every task  has these classes:"": [""happy"", ""house"", ""cat"", ""down"", ""no""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ed7f6b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ecbd6f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55365447, 'precision': 0.264, 'recall': 0.4, 'f1_score': 0.29696969696969697, 'confusion_matrix': array([[192,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [111,   0,   0,   0,   0],
       [ 84,   0,   0,   0,   0],
       [111,   0,   0,   0,   0]]), 'forgetting_measure': [0.55365447, 0.0, 0.0]}","{""Every task  has these classes:"": [""happy"", ""house"", ""cat"", ""down"", ""no""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c96cebd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c9ca67d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46850873, 'precision': 0.4651960864302062, 'recall': 0.42201076764277244, 'f1_score': 0.35489751229457954, 'confusion_matrix': array([[197,   7,  17,   0,   4],
       [156,  19,   6,   4,   3],
       [161,   9,  18,   1,   6],
       [122,  15,   5,   3,   5],
       [118,   7,  11,   3,   3]]), 'forgetting_measure': [0.51732342, 0.4407251, -0.75088733]}","{""Every task  has these classes:"": [""on"", ""six"", ""house"", ""bird"", ""right""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c96cebd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c9ca67d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45044128, 'precision': 0.38863429200062862, 'recall': 0.3967531804667662, 'f1_score': 0.3301870786466422, 'confusion_matrix': array([[122,   7,  14,   2,   6],
       [ 91,   9,   3,   1,   4],
       [139,  10,  16,   4,   4],
       [ 80,   4,   0,   0,   1],
       [ 73,   5,   3,   2,   0]]), 'forgetting_measure': [0.45846872, 0.21036628, -0.41482475]}","{""Every task  has these classes:"": [""on"", ""six"", ""house"", ""bird"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317907710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b431690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47773884, 'precision': 0.252222222222222225, 'recall': 0.4, 'f1_score': 0.28281938325991191, 'confusion_matrix': array([[  0,   0,   0, 142,   0],
       [  0,   0,   0, 164,   0],
       [  0,   0,   0, 213,   0],
       [  0,   0,   0, 235,   0],
       [  0,   0,   0, 146,   0]]), 'forgetting_measure': [0.44758573, -0.36536568, 0.26759547]}","{""Every task  has these classes:"": [""stop"", ""house"", ""zero"", ""happy"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317907710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b431690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35855822, 'precision': 0.235333333333333335, 'recall': 0.4, 'f1_score': 0.26005665722379603, 'confusion_matrix': array([[  0,   0,   0, 109,   0],
       [  0,   0,   0, 119,   0],
       [  0,   0,   0, 184,   0],
       [  0,   0,   0, 106,   0],
       [  0,   0,   0,  82,   0]]), 'forgetting_measure': [0.30588536, -1.4923561, 0.5987732]}","{""Every task  has these classes:"": [""stop"", ""house"", ""zero"", ""happy"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531bb6a2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531811f3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53454075, 'precision': 0.5185705333665144, 'recall': 0.39578019619321307, 'f1_score': 0.31304784936786734, 'confusion_matrix': array([[  2,   2,   0, 166,   2],
       [  0,   3,   1, 141,   7],
       [  0,   3,   0,  87,   2],
       [  0,   6,   3, 281,  10],
       [  0,   3,   1, 178,   2]]), 'forgetting_measure': [0.4537941, -0.49581578, 0.024841024]}","{""Every task  has these classes:"": [""nine"", ""bed"", ""six"", ""four"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531bb6a2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531811f3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43039398, 'precision': 0.3536082474226804, 'recall': 0.3939625260235947, 'f1_score': 0.29266836514943987, 'confusion_matrix': array([[  1,   1,   0, 107,   1],
       [  1,   0,   0,  88,   3],
       [  0,   0,   0, 102,   0],
       [  1,   2,   0, 156,   6],
       [  0,   0,   0, 129,   2]]), 'forgetting_measure': [0.42701085, -0.023243979, 0.0017387122]}","{""Every task  has these classes:"": [""nine"", ""bed"", ""six"", ""four"", ""stop""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c3c09890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c3a0bc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4532575, 'precision': 0.3112351434762624, 'recall': 0.44412711182622687, 'f1_score': 0.35173974540311175, 'confusion_matrix': array([[  0, 112,  61,   0,   1],
       [  0, 168,  56,   0,   2],
       [  0,  92,  84,   0,   0],
       [  0,  99,  56,   0,   1],
       [  0, 111,  57,   0,   0]]), 'forgetting_measure': [0.4574333, 0.08508146, -0.13279916]}","{""Every task  has these classes:"": [""seven"", ""house"", ""stop"", ""nine"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c3c09890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c3a0bc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46247218, 'precision': 0.3291010101010101, 'recall': 0.46486785804178203, 'f1_score': 0.36988432236160095, 'confusion_matrix': array([[  0,  72,  36,   0,   0],
       [  0, 119,  25,   0,   1],
       [  0,  67,  69,   0,   1],
       [  0,  74,  38,   0,   2],
       [  0,  64,  32,   0,   0]]), 'forgetting_measure': [0.45340003, -0.11863228, 0.11608789]}","{""Every task  has these classes:"": [""seven"", ""house"", ""stop"", ""nine"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b8976610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c8512990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35784724, 'precision': 0.236, 'recall': 0.4, 'f1_score': 0.261016949152542375, 'confusion_matrix': array([[  0,   0,   0,   0, 205],
       [  0,   0,   0,   0, 178],
       [  0,   0,   0,   0, 199],
       [  0,   0,   0,   0, 156],
       [  0,   0,   0,   0, 162]]), 'forgetting_measure': [0.35784726, 0.0, 0.0]}","{""Every task  has these classes:"": [""zero"", ""eight"", ""three"", ""marvel"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b8976610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c8512990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45851268, 'precision': 0.248, 'recall': 0.4, 'f1_score': 0.27741935483870968, 'confusion_matrix': array([[  0,   0,   0,   0, 109],
       [  0,   0,   0,   0,  98],
       [  0,   0,   0,   0, 133],
       [  0,   0,   0,   0, 116],
       [  0,   0,   0,   0, 144]]), 'forgetting_measure': [0.45851268, 0.0, 0.0]}","{""Every task  has these classes:"": [""zero"", ""eight"", ""three"", ""marvel"", ""yes""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531835b6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553198b38d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41253563, 'precision': 0.24444444444444444, 'recall': 0.4, 'f1_score': 0.27272727272727272, 'confusion_matrix': array([[  0,   0,   0, 153,   0],
       [  0,   0,   0, 196,   0],
       [  0,   0,   0, 198,   0],
       [  0,   0,   0, 200,   0],
       [  0,   0,   0, 153,   0]]), 'forgetting_measure': [0.40504552, -0.109587155, 0.0987639]}","{""Every task  has these classes:"": [""eight"", ""down"", ""happy"", ""up"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531835b6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553198b38d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39495526, 'precision': 0.246, 'recall': 0.4, 'f1_score': 0.27479674796747968, 'confusion_matrix': array([[  0,   0,   0, 116,   0],
       [  0,   0,   0, 123,   0],
       [  0,   0,   0, 142,   0],
       [  0,   0,   0, 138,   0],
       [  0,   0,   0,  81,   0]]), 'forgetting_measure': [0.38367225, -0.18429023, 0.1556124]}","{""Every task  has these classes:"": [""eight"", ""down"", ""happy"", ""up"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155314449bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f447ff50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39714946, 'precision': 0.30653228816722657, 'recall': 0.3987080103359173, 'f1_score': 0.2681908735689185, 'confusion_matrix': array([[178,   1,   1,   0,   0],
       [196,   0,   0,   1,   1],
       [192,   1,   0,   0,   1],
       [113,   0,   0,   0,   0],
       [214,   0,   0,   0,   1]]), 'forgetting_measure': [0.42836462, 0.48959383, -1.1150289]}","{""Every task  has these classes:"": [""three"", ""off"", ""four"", ""on"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155314449bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f447ff50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37007169, 'precision': 0.23584589614740368, 'recall': 0.39814814814814813, 'f1_score': 0.26070921985815603, 'confusion_matrix': array([[107,   0,   0,   0,   1],
       [115,   0,   0,   1,   0],
       [119,   0,   0,   0,   0],
       [ 91,   0,   0,   0,   1],
       [165,   0,   0,   0,   0]]), 'forgetting_measure': [0.39784684, 0.43912354, -0.8149492]}","{""Every task  has these classes:"": [""three"", ""off"", ""four"", ""on"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ead79bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea98c990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42009777, 'precision': 0.28678909612625538, 'recall': 0.39513697519857348, 'f1_score': 0.28943455170259293, 'confusion_matrix': array([[  0,   0,   7,   0, 174],
       [  1,   0,   6,   2, 135],
       [  0,   0,   8,   3, 188],
       [  1,   0,   8,   0, 150],
       [  1,   0,  12,   1, 203]]), 'forgetting_measure': [0.39898383, -0.10815265, -0.09206393]}","{""Every task  has these classes:"": [""down"", ""up"", ""eight"", ""bed"", ""two""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ead79bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea98c990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40454212, 'precision': 0.29646145119769622, 'recall': 0.40456956344349245, 'f1_score': 0.29123678000174809, 'confusion_matrix': array([[  0,   0,   7,   0, 130],
       [  0,   0,   9,   0, 107],
       [  0,   0,  12,   0, 117],
       [  0,   0,   5,   0,  99],
       [  0,   0,   8,   0, 106]]), 'forgetting_measure': [0.44365877, 0.25796142, -0.046233155]}","{""Every task  has these classes:"": [""down"", ""up"", ""eight"", ""bed"", ""two""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f42b1e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4767250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43921278, 'precision': 0.49278972626094923, 'recall': 0.4509792470243991, 'f1_score': 0.40707992997361346, 'confusion_matrix': array([[  2,  65,  67,   2,  14],
       [  2, 116,  81,   7,   8],
       [  4,  84, 118,   2,  13],
       [  1,  77,  50,   7,   9],
       [  2,  75,  74,   0,  20]]), 'forgetting_measure': [0.43708405, 0.33276537, -1.0378165]}","{""Every task  has these classes:"": [""tree"", ""off"", ""six"", ""stop"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f42b1e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4767250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46714745, 'precision': 0.4877193296178186, 'recall': 0.42184539953669735, 'f1_score': 0.37561716527533985, 'confusion_matrix': array([[ 2, 43, 38,  0, 13],
       [ 1, 70, 47,  1, 10],
       [ 1, 57, 71,  4, 23],
       [ 1, 34, 48,  4,  6],
       [ 0, 56, 63,  1,  6]]), 'forgetting_measure': [0.43381099, -0.19565542, -0.0304643]}","{""Every task  has these classes:"": [""tree"", ""off"", ""six"", ""stop"", ""marvel""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ecc24c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551c8dd0510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39609386, 'precision': 0.30501672240802676, 'recall': 0.40106382978723403, 'f1_score': 0.2664534550565925, 'confusion_matrix': array([[  0,   0,   0,   1, 252],
       [  0,   0,   0,   1, 105],
       [  0,   0,   0,   0, 181],
       [  0,   0,   0,   1, 187],
       [  0,   0,   0,   0, 172]]), 'forgetting_measure': [0.40285416, -0.0032600444, 0.10615176]}","{""Every task  has these classes:"": [""yes"", ""up"", ""house"", ""off"", ""seven""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ecc24c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551c8dd0510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34748052, 'precision': 0.235666666666666666, 'recall': 0.4, 'f1_score': 0.26053748231966055, 'confusion_matrix': array([[  0,   0,   0,   0, 157],
       [  0,   0,   0,   0,  82],
       [  0,   0,   0,   0, 140],
       [  0,   0,   0,   0, 114],
       [  0,   0,   0,   0, 107]]), 'forgetting_measure': [0.34609723, -0.028404845, 0.027620295]}","{""Every task  has these classes:"": [""yes"", ""up"", ""house"", ""off"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0391450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e02705d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6296943, 'precision': 0.706652157731605, 'recall': 0.46951484426674555, 'f1_score': 0.44036404356124746, 'confusion_matrix': array([[ 46, 133,   0,   3,   1],
       [ 18, 292,   1,   6,   1],
       [  6, 107,   6,   2,   2],
       [  6, 126,   2,  11,   1],
       [  5, 114,   2,   2,   7]]), 'forgetting_measure': [0.61691074, 0.122912295, -0.3851522]}","{""Every task  has these classes:"": [""off"", ""down"", ""stop"", ""go"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0391450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e02705d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4997079, 'precision': 0.3899869425526497, 'recall': 0.39449006351200887, 'f1_score': 0.33184987273460472, 'confusion_matrix': array([[  9, 118,   2,   7,   2],
       [ 19, 166,   2,   6,   2],
       [  8,  62,   1,   0,   1],
       [ 10,  77,   2,   3,   1],
       [  5,  94,   0,   2,   1]]), 'forgetting_measure': [0.44843377, -0.2497407, -0.095769726]}","{""Every task  has these classes:"": [""off"", ""down"", ""stop"", ""go"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f18adb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e7f19e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41139492, 'precision': 0.29321354072776905, 'recall': 0.39034968691119308, 'f1_score': 0.29222248230671393, 'confusion_matrix': array([[  4,  10, 150,   0,   0],
       [  5,   3, 181,   0,   5],
       [  6,  12, 207,   0,   2],
       [  6,   7, 142,   0,   1],
       [  8,   7, 144,   0,   0]]), 'forgetting_measure': [0.36398372, -0.31499502, -0.1805135]}","{""Every task  has these classes:"": [""three"", ""left"", ""dog"", ""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f18adb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e7f19e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42382604, 'precision': 0.27275355336063599, 'recall': 0.40017976373908578, 'f1_score': 0.27547586206896552, 'confusion_matrix': array([[  0,   4, 123,   0,   0],
       [  0,   1, 117,   0,   0],
       [  0,   1, 131,   0,   0],
       [  0,   0, 100,   0,   0],
       [  0,   1, 122,   0,   0]]), 'forgetting_measure': [0.41999633, -0.046541978, 0.039042935]}","{""Every task  has these classes:"": [""three"", ""left"", ""dog"", ""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ecb31450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e8eb4990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43485656, 'precision': 0.40261613235666825, 'recall': 0.40819307555330338, 'f1_score': 0.34015898622927664, 'confusion_matrix': array([[  3,  34,  17, 117,   0],
       [  3,  34,  18, 124,   0],
       [  0,  29,  16, 133,   0],
       [  1,  36,  13, 145,   0],
       [  1,  26,  15, 135,   0]]), 'forgetting_measure': [0.47014393, 0.14451423, 0.12021752]}","{""Every task  has these classes:"": [""five"", ""go"", ""right"", ""wow"", ""three""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ecb31450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e8eb4990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41816015, 'precision': 0.5726630234274119, 'recall': 0.38625657554772485, 'f1_score': 0.3357431692989889, 'confusion_matrix': array([[  2,  16,  10,  69,   0],
       [  2,  23,  22, 115,   0],
       [  1,  20,  14,  81,   0],
       [  1,  24,  21,  81,   0],
       [  2,  13,  11,  71,   1]]), 'forgetting_measure': [0.43708059, 0.23455374, -0.300073]}","{""Every task  has these classes:"": [""five"", ""go"", ""right"", ""wow"", ""three""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1aa18d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed683290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51365484, 'precision': 0.5759054414485619, 'recall': 0.5169083988704109, 'f1_score': 0.4691294416800031, 'confusion_matrix': array([[ 25,  53,  25,   0,  56],
       [ 13, 138,  14,   1,  45],
       [  2, 101,  28,   0,  58],
       [ 16,  49,  15,   1,  61],
       [  6,  44,  26,   0, 123]]), 'forgetting_measure': [0.49502872, 0.61657673, -3.7101383]}","{""Every task  has these classes:"": [""off"", ""four"", ""five"", ""two"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1aa18d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed683290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4373481, 'precision': 0.41243087557603685, 'recall': 0.42470427790624345, 'f1_score': 0.394376062053441, 'confusion_matrix': array([[ 6, 37,  6,  1, 25],
       [ 7, 52,  6,  0, 63],
       [ 6, 68, 25,  1, 34],
       [ 8, 56, 19,  0, 38],
       [ 5, 67,  6,  0, 64]]), 'forgetting_measure': [0.52468697, 0.5199979, -0.48544276]}","{""Every task  has these classes:"": [""off"", ""four"", ""five"", ""two"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddf31710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dd74c9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53435223, 'precision': 0.51875129737511715, 'recall': 0.49213769663473305, 'f1_score': 0.44552760896586773, 'confusion_matrix': array([[  6,  20,  28,  95,   0],
       [  1,  40,  14, 182,   0],
       [  4,  21,  66,  78,   0],
       [  3,  21,  11, 217,   0],
       [  1,  12,  12,  68,   0]]), 'forgetting_measure': [0.59828005, 0.62150174, -2.0118299]}","{""Every task  has these classes:"": [""wow"", ""go"", ""three"", ""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddf31710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dd74c9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5412775, 'precision': 0.61683397441911374, 'recall': 0.42375208324275758, 'f1_score': 0.38545213854433495, 'confusion_matrix': array([[  2,  15,   9,  56,   0],
       [  2,  15,  11, 104,   0],
       [  1,   8,  19,  82,   0],
       [  0,  17,  25, 162,   0],
       [  4,  11,   4,  52,   1]]), 'forgetting_measure': [0.59977548, 0.40120006, -0.6069124]}","{""Every task  has these classes:"": [""wow"", ""go"", ""three"", ""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e5eb18d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c65a1e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45678122, 'precision': 0.3424721377912867, 'recall': 0.42097971680061232, 'f1_score': 0.34212786950536815, 'confusion_matrix': array([[  0, 139,   1,  34,   0],
       [  0, 184,   5,  41,   0],
       [  0, 106,   1,  27,   0],
       [  0, 137,   0,  58,   0],
       [  0, 139,   0,  28,   0]]), 'forgetting_measure': [0.51186113, 0.15740073, 0.25522107]}","{""Every task  has these classes:"": [""bed"", ""stop"", ""three"", ""house"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e5eb18d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c65a1e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43146209, 'precision': 0.33210880319605486, 'recall': 0.4431941077754988, 'f1_score': 0.3641146201916734, 'confusion_matrix': array([[  0,  75,   0,  20,   0],
       [  0, 142,   0,  31,   0],
       [  0,  67,   0,  27,   0],
       [  0,  75,   0,  49,   0],
       [  0, 102,   0,  12,   0]]), 'forgetting_measure': [0.46620322, 0.39151794, -0.64343387]}","{""Every task  has these classes:"": [""bed"", ""stop"", ""three"", ""house"", ""no""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cb7a1550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cbdf2010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43814757, 'precision': 0.24466666666666667, 'recall': 0.4, 'f1_score': 0.27302452316076294, 'confusion_matrix': array([[201,   0,   0,   0,   0],
       [168,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [182,   0,   0,   0,   0],
       [205,   0,   0,   0,   0]]), 'forgetting_measure': [0.43814756, 0.0, 0.0]}","{""Every task  has these classes:"": [""bed"", ""nine"", ""yes"", ""left"", ""up""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cb7a1550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cbdf2010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44365008, 'precision': 0.247, 'recall': 0.4, 'f1_score': 0.27611336032388664, 'confusion_matrix': array([[141,   0,   0,   0,   0],
       [ 92,   0,   0,   0,   0],
       [128,   0,   0,   0,   0],
       [124,   0,   0,   0,   0],
       [115,   0,   0,   0,   0]]), 'forgetting_measure': [0.44365005, 0.0, 0.0]}","{""Every task  has these classes:"": [""bed"", ""nine"", ""yes"", ""left"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552de106350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dc7549d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33490027, 'precision': 0.3464478240136012, 'recall': 0.3901623644597678, 'f1_score': 0.28498491100939815, 'confusion_matrix': array([[ 91,   0,   0,  30,   2],
       [199,   0,   2,  32,   1],
       [190,   1,   2,  60,   4],
       [117,   0,   1,  29,   1],
       [102,   1,   1,  33,   1]]), 'forgetting_measure': [0.35844823, 0.20864369, 0.036091186]}","{""Every task  has these classes:"": [""four"", ""bird"", ""nine"", ""tree"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552de106350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dc7549d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33378648, 'precision': 0.36870445344129553, 'recall': 0.39421045779631194, 'f1_score': 0.29131522341230143, 'confusion_matrix': array([[ 69,   0,   0,  18,   0],
       [136,   0,   2,  23,   2],
       [131,   0,   1,  25,   4],
       [ 85,   1,   1,  14,   1],
       [ 73,   0,   0,  11,   3]]), 'forgetting_measure': [0.32102022, -0.15112123, -0.012356366]}","{""Every task  has these classes:"": [""four"", ""bird"", ""nine"", ""tree"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b7bfc410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c4baed10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41636213, 'precision': 0.34260089686098656, 'recall': 0.39899774774774776, 'f1_score': 0.27224973854016616, 'confusion_matrix': array([[  0, 184,   1,   2,   0],
       [  0, 190,   0,   1,   1],
       [  0, 183,   1,   1,   0],
       [  0, 134,   0,   0,   0],
       [  0, 201,   0,   1,   0]]), 'forgetting_measure': [0.41277125, -0.02322465, -0.0040859086]}","{""Every task  has these classes:"": [""go"", ""stop"", ""six"", ""bed"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b7bfc410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c4baed10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42346345, 'precision': 0.24466666666666667, 'recall': 0.4, 'f1_score': 0.27302452316076294, 'confusion_matrix': array([[  0, 148,   0,   0,   0],
       [  0, 134,   0,   0,   0],
       [  0, 119,   0,   0,   0],
       [  0,  93,   0,   0,   0],
       [  0, 106,   0,   0,   0]]), 'forgetting_measure': [0.42474594, 0.017118843, -0.017417]}","{""Every task  has these classes:"": [""go"", ""stop"", ""six"", ""bed"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d26b1710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d2194990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36737252, 'precision': 0.236444444444444446, 'recall': 0.4, 'f1_score': 0.261654135338345864, 'confusion_matrix': array([[164,   0,   0,   0,   0],
       [202,   0,   0,   0,   0],
       [177,   0,   0,   0,   0],
       [163,   0,   0,   0,   0],
       [194,   0,   0,   0,   0]]), 'forgetting_measure': [0.36453348, -0.051765155, 0.04921741]}","{""Every task  has these classes:"": [""one"", ""tree"", ""happy"", ""bed"", ""down""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d26b1710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d2194990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37448568, 'precision': 0.23833333333333334, 'recall': 0.4, 'f1_score': 0.26433566433566434, 'confusion_matrix': array([[115,   0,   0,   0,   0],
       [143,   0,   0,   0,   0],
       [ 97,   0,   0,   0,   0],
       [112,   0,   0,   0,   0],
       [133,   0,   0,   0,   0]]), 'forgetting_measure': [0.37010956, -0.07717571, 0.07164635]}","{""Every task  has these classes:"": [""one"", ""tree"", ""happy"", ""bed"", ""down""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddb22bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dafe5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54016493, 'precision': 0.7593495934959349, 'recall': 0.42888198693266762, 'f1_score': 0.36005806438923265, 'confusion_matrix': array([[ 19,   4,   0, 133,   0],
       [  1,   7,   0, 168,   0],
       [ 11,   4,   1,  96,   0],
       [  7,   3,   0, 278,   1],
       [  3,   3,   0, 159,   2]]), 'forgetting_measure': [0.5110436, -0.06426358, -0.14314744]}","{""Every task  has these classes:"": [""sheila"", ""bird"", ""two"", ""bed"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddb22bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dafe5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4872311, 'precision': 0.4552003035723966, 'recall': 0.39956799099794162, 'f1_score': 0.31777968870396054, 'confusion_matrix': array([[  2,   3,   0,  76,   0],
       [  5,   3,   0, 103,   0],
       [  1,   2,   0,  72,   1],
       [  9,   3,   1, 178,   0],
       [  5,   4,   0, 130,   2]]), 'forgetting_measure': [0.4990948, 0.0051747933, 0.1092116]}","{""Every task  has these classes:"": [""sheila"", ""bird"", ""two"", ""bed"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1e08b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ce5498d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47450615, 'precision': 0.25355555555555556, 'recall': 0.4, 'f1_score': 0.28448729184925503, 'confusion_matrix': array([[241,   0,   0,   0,   0],
       [153,   0,   0,   0,   0],
       [192,   0,   0,   0,   0],
       [200,   0,   0,   0,   0],
       [114,   0,   0,   0,   0]]), 'forgetting_measure': [0.51787467, 0.40929818, -0.6929015]}","{""Every task  has these classes:"": [""no"", ""four"", ""dog"", ""off"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1e08b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ce5498d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.441722, 'precision': 0.24033333333333333, 'recall': 0.4, 'f1_score': 0.26712898751733704, 'confusion_matrix': array([[121,   0,   0,   0,   0],
       [103,   0,   0,   0,   0],
       [137,   0,   0,   0,   0],
       [143,   0,   0,   0,   0],
       [ 96,   0,   0,   0,   0]]), 'forgetting_measure': [0.4742703, 0.3560169, -0.5528358]}","{""Every task  has these classes:"": [""no"", ""four"", ""dog"", ""off"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552de9e9610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552de7d5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50095926, 'precision': 0.5665033212460525, 'recall': 0.53563677651963575, 'f1_score': 0.53571420337793245, 'confusion_matrix': array([[ 59,  80,  34,  27,   9],
       [ 39, 124,  30,  29,   7],
       [ 44,  62,  61,   9,   7],
       [ 13,  55,  24,  59,   8],
       [ 15,  54,  15,  18,  18]]), 'forgetting_measure': [0.48239542, 0.020998314, -0.24433853]}","{""Every task  has these classes:"": [""go"", ""nine"", ""stop"", ""three"", ""yes""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552de9e9610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552de7d5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41624812, 'precision': 0.41134570756441312, 'recall': 0.4004695711575529, 'f1_score': 0.39237810332885932, 'confusion_matrix': array([[29, 47, 10, 20,  7],
       [28, 56, 44, 13,  7],
       [30, 53, 20, 16,  7],
       [25, 53, 23, 16,  3],
       [26, 34, 16, 10,  7]]), 'forgetting_measure': [0.37721447, -0.14589375, -0.32201827]}","{""Every task  has these classes:"": [""go"", ""nine"", ""stop"", ""three"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cbe99990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c36bc9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3995101, 'precision': 0.23937708565072302, 'recall': 0.39887640449438201, 'f1_score': 0.26573816155988857, 'confusion_matrix': array([[177,   0,   0,   1,   0],
       [187,   0,   0,   0,   0],
       [190,   0,   0,   0,   0],
       [153,   0,   0,   0,   0],
       [192,   0,   0,   0,   0]]), 'forgetting_measure': [0.40218122, 0.14321597, -0.28805074]}","{""Every task  has these classes:"": [""happy"", ""down"", ""six"", ""tree"", ""three""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cbe99990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c36bc9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40405965, 'precision': 0.24133333333333333, 'recall': 0.4, 'f1_score': 0.26850828729281769, 'confusion_matrix': array([[124,   0,   0,   0,   0],
       [117,   0,   0,   0,   0],
       [134,   0,   0,   0,   0],
       [117,   0,   0,   0,   0],
       [108,   0,   0,   0,   0]]), 'forgetting_measure': [0.41749046, 0.18526046, -0.2273861]}","{""Every task  has these classes:"": [""happy"", ""down"", ""six"", ""tree"", ""three""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d7181610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d4ed1e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43367777, 'precision': 0.44721007078220927, 'recall': 0.43042765136715188, 'f1_score': 0.42639712932705133, 'confusion_matrix': array([[107,  35,  57,  39,  11],
       [ 87,  36,  25,  35,   8],
       [ 77,  32,  42,  19,   8],
       [ 62,  41,  21,  36,   1],
       [ 48,  28,  13,  23,   9]]), 'forgetting_measure': [0.45077602, 0.24359013, -0.37365502]}","{""Every task  has these classes:"": [""on"", ""sheila"", ""house"", ""go"", ""down""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d7181610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d4ed1e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47172786, 'precision': 0.46347014226750537, 'recall': 0.47094390510591315, 'f1_score': 0.45931279895724985, 'confusion_matrix': array([[67, 29, 38, 18,  5],
       [33, 24, 19, 35,  5],
       [48, 28, 45, 19,  3],
       [24, 21, 17, 39,  5],
       [24,  7, 21, 23,  3]]), 'forgetting_measure': [0.43435254, -0.37013873, 0.19109589]}","{""Every task  has these classes:"": [""on"", ""sheila"", ""house"", ""go"", ""down""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d449af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d9ced910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52224184, 'precision': 0.264, 'recall': 0.4, 'f1_score': 0.29696969696969697, 'confusion_matrix': array([[288,   0,   0,   0,   0],
       [142,   0,   0,   0,   0],
       [167,   0,   0,   0,   0],
       [169,   0,   0,   0,   0],
       [134,   0,   0,   0,   0]]), 'forgetting_measure': [0.52224187, 0.0, 0.0]}","{""Every task  has these classes:"": [""on"", ""marvel"", ""go"", ""up"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d449af50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d9ced910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5439573, 'precision': 0.273, 'recall': 0.4, 'f1_score': 0.30695970695970695, 'confusion_matrix': array([[219,   0,   0,   0,   0],
       [ 81,   0,   0,   0,   0],
       [111,   0,   0,   0,   0],
       [119,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0]]), 'forgetting_measure': [0.54395736, 0.0, 0.0]}","{""Every task  has these classes:"": [""on"", ""marvel"", ""go"", ""up"", ""no""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c0e29990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bcf79290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40734757, 'precision': 0.3095005675368899, 'recall': 0.39781934346772417, 'f1_score': 0.27014545652647637, 'confusion_matrix': array([[174,   0,   0,   1,   3],
       [203,   0,   1,   2,   0],
       [199,   0,   1,   0,   4],
       [159,   0,   1,   0,   2],
       [146,   0,   1,   2,   1]]), 'forgetting_measure': [0.41252288, 0.01405803, 0.045580216]}","{""Every task  has these classes:"": [""three"", ""down"", ""tree"", ""eight"", ""seven""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c0e29990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bcf79290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.091806404, 'precision': 0.29031531531531531, 'recall': 0.40028387378534776, 'f1_score': 0.2481582034523211, 'confusion_matrix': array([[ 70,   0,   0,   0,   1],
       [140,   0,   0,   1,   0],
       [157,   0,   0,   0,   3],
       [ 98,   0,   1,   0,   0],
       [127,   0,   0,   0,   2]]), 'forgetting_measure': [0.283435126, -0.30099845, 0.23135957]}","{""Every task  has these classes:"": [""three"", ""down"", ""tree"", ""eight"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cb6b1610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552caced910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3653889, 'precision': 0.237333333333333336, 'recall': 0.4, 'f1_score': 0.26292134831460675, 'confusion_matrix': array([[168,   0,   0,   0,   0],
       [190,   0,   0,   0,   0],
       [218,   0,   0,   0,   0],
       [141,   0,   0,   0,   0],
       [183,   0,   0,   0,   0]]), 'forgetting_measure': [0.36357926, -0.033188622, 0.03212252]}","{""Every task  has these classes:"": [""sheila"", ""zero"", ""down"", ""tree"", ""bed""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cb6b1610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552caced910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41150637, 'precision': 0.24, 'recall': 0.4, 'f1_score': 0.26666666666666668, 'confusion_matrix': array([[120,   0,   0,   0,   0],
       [119,   0,   0,   0,   0],
       [115,   0,   0,   0,   0],
       [112,   0,   0,   0,   0],
       [134,   0,   0,   0,   0]]), 'forgetting_measure': [0.40788029, -0.052329253, 0.04972707]}","{""Every task  has these classes:"": [""sheila"", ""zero"", ""down"", ""tree"", ""bed""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b0969990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552acbb5150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50499366, 'precision': 0.25688888888888889, 'recall': 0.4, 'f1_score': 0.28858131487889273, 'confusion_matrix': array([[256,   0,   0,   0,   0],
       [184,   0,   0,   0,   0],
       [162,   0,   0,   0,   0],
       [184,   0,   0,   0,   0],
       [114,   0,   0,   0,   0]]), 'forgetting_measure': [0.54520182, 0.34943178, -0.5371178]}","{""Every task  has these classes:"": [""left"", ""two"", ""yes"", ""five"", ""house""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b0969990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552acbb5150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46431316, 'precision': 0.25033333333333333, 'recall': 0.4, 'f1_score': 0.28042609853528628, 'confusion_matrix': array([[151,   0,   0,   0,   0],
       [ 97,   0,   0,   0,   0],
       [128,   0,   0,   0,   0],
       [131,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0]]), 'forgetting_measure': [0.4998293, 0.35536364, -0.55126214]}","{""Every task  has these classes:"": [""left"", ""two"", ""yes"", ""five"", ""house""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552caec5f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c403d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45810418, 'precision': 0.3481331549013048, 'recall': 0.410261569416499, 'f1_score': 0.35815653724150455, 'confusion_matrix': array([[ 87, 109,  16,   0,   1],
       [ 88, 136,  14,   0,   0],
       [ 81,  88,  13,   0,   0],
       [ 39,  57,   6,   0,   0],
       [ 53, 100,  12,   0,   0]]), 'forgetting_measure': [0.45851673, 0.02612382, -0.048733428]}","{""Every task  has these classes:"": [""bird"", ""stop"", ""left"", ""go"", ""bed""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552caec5f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c403d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4669398, 'precision': 0.34400985192082422, 'recall': 0.4101349773480921, 'f1_score': 0.35526716766971904, 'confusion_matrix': array([[43, 77, 15,  0,  0],
       [47, 76,  7,  0,  0],
       [44, 60, 18,  0,  0],
       [26, 46,  6,  0,  0],
       [37, 79, 19,  0,  0]]), 'forgetting_measure': [0.46469192, -0.051167544, 0.07311658]}","{""Every task  has these classes:"": [""bird"", ""stop"", ""left"", ""go"", ""bed""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bc4a17d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc4b9dd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34618072, 'precision': 0.227111111111111114, 'recall': 0.4, 'f1_score': 0.247749510763209393, 'confusion_matrix': array([[122,   0,   0,   0,   0],
       [215,   0,   0,   0,   0],
       [273,   0,   0,   0,   0],
       [161,   0,   0,   0,   0],
       [129,   0,   0,   0,   0]]), 'forgetting_measure': [0.35758978, 0.21719156, -0.27745172]}","{""Every task  has these classes:"": [""eight"", ""off"", ""two"", ""no"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bc4a17d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc4b9dd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41257845, 'precision': 0.23166666666666666, 'recall': 0.4, 'f1_score': 0.25467625899280576, 'confusion_matrix': array([[ 95,   0,   0,   0,   0],
       [165,   0,   0,   0,   0],
       [160,   0,   0,   0,   0],
       [ 84,   0,   0,   0,   0],
       [ 96,   0,   0,   0,   0]]), 'forgetting_measure': [0.42776014, 0.19996965, -0.24995258]}","{""Every task  has these classes:"": [""eight"", ""off"", ""two"", ""no"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac116910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a3e51290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50773723, 'precision': 0.63635477582846, 'recall': 0.40176365807182747, 'f1_score': 0.31145207475289427, 'confusion_matrix': array([[  2, 127,   0,   3,   0],
       [  0, 233,   0,  11,   5],
       [  0, 127,   1,   3,   4],
       [  3, 201,   0,   7,   0],
       [  0, 167,   0,   3,   3]]), 'forgetting_measure': [0.53481228, 0.43764138, -1.1250536]}","{""Every task  has these classes:"": [""right"", ""seven"", ""zero"", ""nine"", ""house""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac116910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a3e51290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42812083, 'precision': 0.46999999999999996, 'recall': 0.4025324675324675, 'f1_score': 0.29814818889744625, 'confusion_matrix': array([[  2,  65,   0,   1,   2],
       [  0, 156,   0,   0,   4],
       [  0,  83,   0,   0,   3],
       [  0, 172,   0,   0,   2],
       [  0, 109,   0,   0,   1]]), 'forgetting_measure': [0.47652025, 0.46351925, -0.74922967]}","{""Every task  has these classes:"": [""right"", ""seven"", ""zero"", ""nine"", ""house""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a468ed10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552957893d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40515957, 'precision': 0.33484650516651014, 'recall': 0.3881808244111909, 'f1_score': 0.3025538962945112, 'confusion_matrix': array([[  6, 151,   4,   7,   0],
       [ 11, 188,  16,   5,   0],
       [  8, 172,   6,   5,   0],
       [  4, 142,   7,   3,   0],
       [  8, 146,   8,   3,   0]]), 'forgetting_measure': [0.36128778, -0.3537141, -0.080223456]}","{""Every task  has these classes:"": [""marvel"", ""five"", ""one"", ""sheila"", ""dog""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a468ed10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552957893d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46278156, 'precision': 0.30822251357932197, 'recall': 0.40419293820933165, 'f1_score': 0.31716419321296909, 'confusion_matrix': array([[  0, 100,  10,   0,   0],
       [  0, 171,  12,   0,   0],
       [  0,  95,   9,   0,   0],
       [  0,  92,   3,   0,   0],
       [  0, 104,   4,   0,   0]]), 'forgetting_measure': [0.4216264, -0.26396334, -0.023071595]}","{""Every task  has these classes:"": [""marvel"", ""five"", ""one"", ""sheila"", ""dog""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbda98d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c2645c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4555209, 'precision': 0.4599890213383737, 'recall': 0.49081439522505564, 'f1_score': 0.47171052197780626, 'confusion_matrix': array([[ 46,  29,   0,  57,  25],
       [ 38,  81,   2,  63,  16],
       [ 30,  15,   0,  46,  20],
       [ 28,  51,   2, 124,  42],
       [ 22,  51,   0,  65,  47]]), 'forgetting_measure': [0.50194163, 0.5603372, -1.499904]}","{""Every task  has these classes:"": [""two"", ""off"", ""zero"", ""bed"", ""four""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbda98d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c2645c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42632948, 'precision': 0.36695261634916808, 'recall': 0.408984052251379, 'f1_score': 0.38265219442313824, 'confusion_matrix': array([[ 3, 23,  0, 41, 23],
       [10, 35,  0, 74, 24],
       [10, 21,  0, 34, 21],
       [13, 41,  0, 81, 45],
       [12, 23,  0, 34, 32]]), 'forgetting_measure': [0.42365585, 0.082299694, -0.21843949]}","{""Every task  has these classes:"": [""two"", ""off"", ""zero"", ""bed"", ""four""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ecd1e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529e90d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42361018, 'precision': 0.31103706248330089, 'recall': 0.3953721923659915, 'f1_score': 0.30241690904119125, 'confusion_matrix': array([[214,  19,   0,   0,   3],
       [191,  13,   0,   0,   1],
       [179,  19,   0,   0,   3],
       [ 99,   8,   0,   0,   1],
       [137,  12,   0,   0,   1]]), 'forgetting_measure': [0.46706287, 0.38089377, -0.44204026]}","{""Every task  has these classes:"": [""sheila"", ""seven"", ""down"", ""no"", ""house""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ecd1e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529e90d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38573675, 'precision': 0.29285714285714286, 'recall': 0.40128676470588233, 'f1_score': 0.27849916956062208, 'confusion_matrix': array([[126,   2,   0,   0,   0],
       [133,   3,   0,   0,   0],
       [128,   1,   0,   0,   0],
       [ 78,   3,   0,   0,   0],
       [123,   3,   0,   0,   0]]), 'forgetting_measure': [0.40763656, 0.3164158, -0.46287757]}","{""Every task  has these classes:"": [""sheila"", ""seven"", ""down"", ""no"", ""house""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155295979f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552962cd150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5221348, 'precision': 0.40205854539808893, 'recall': 0.42203675064212844, 'f1_score': 0.35320816680608482, 'confusion_matrix': array([[  0, 128,   0,   6,   7],
       [  0, 245,   0,   4,  20],
       [  0, 123,   0,   5,  14],
       [  0, 135,   0,  14,  14],
       [  0, 160,   0,   4,  21]]), 'forgetting_measure': [0.47032375, -0.19718474, -0.15087001]}","{""Every task  has these classes:"": [""house"", ""one"", ""bed"", ""six"", ""seven""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155295979f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552962cd150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48550908, 'precision': 0.32786504759662282, 'recall': 0.40125109383980488, 'f1_score': 0.31899398161237289, 'confusion_matrix': array([[  0,  74,   0,   6,   5],
       [  0, 166,   0,   9,   6],
       [  0, 120,   0,   4,   3],
       [  0,  87,   0,   6,   4],
       [  0, 101,   0,   6,   3]]), 'forgetting_measure': [0.49133216, 0.028084438, 0.0039040323]}","{""Every task  has these classes:"": [""house"", ""one"", ""bed"", ""six"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbf20f90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a5806690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53316204, 'precision': 0.262360801781737196, 'recall': 0.39858156028368795, 'f1_score': 0.29491525423728815, 'confusion_matrix': array([[280,   0,   1,   0,   1],
       [128,   0,   0,   0,   0],
       [183,   0,   0,   0,   0],
       [130,   0,   0,   0,   0],
       [177,   0,   0,   0,   0]]), 'forgetting_measure': [0.50986872, -0.11275725, 0.0]}","{""Every task  has these classes:"": [""cat"", ""wow"", ""five"", ""up"", ""off""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbf20f90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a5806690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4719015, 'precision': 0.266, 'recall': 0.4, 'f1_score': 0.29924812030075188, 'confusion_matrix': array([[198,   0,   0,   0,   0],
       [112,   0,   0,   0,   0],
       [138,   0,   0,   0,   0],
       [ 69,   0,   0,   0,   0],
       [ 83,   0,   0,   0,   0]]), 'forgetting_measure': [0.4719015, 0.0, 0.0]}","{""Every task  has these classes:"": [""cat"", ""wow"", ""five"", ""up"", ""off""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aee26710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ae6fad90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3861873, 'precision': 0.40432834565420666, 'recall': 0.38633349325131512, 'f1_score': 0.33624082862739065, 'confusion_matrix': array([[ 11,  11,  68, 105,   1],
       [  9,   5,  83,  61,   2],
       [  9,   5, 133, 126,   1],
       [  1,   9,  55,  36,   1],
       [  7,   2,  89,  69,   1]]), 'forgetting_measure': [0.33265423, -0.2930152, -0.48308006]}","{""Every task  has these classes:"": [""marvel"", ""yes"", ""on"", ""two"", ""nine""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aee26710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ae6fad90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39592549, 'precision': 0.43812322085532117, 'recall': 0.40397969416041356, 'f1_score': 0.34201489636372874, 'confusion_matrix': array([[ 3,  9, 70, 67,  0],
       [ 4,  2, 48, 40,  0],
       [ 1,  5, 83, 62,  1],
       [ 8,  3, 52, 46,  0],
       [ 5,  3, 48, 39,  1]]), 'forgetting_measure': [0.36438705, -0.03777778, -0.48180744]}","{""Every task  has these classes:"": [""marvel"", ""yes"", ""on"", ""two"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552abc19350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ac2ad910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43809126, 'precision': 0.45325698312986444, 'recall': 0.40256687212963703, 'f1_score': 0.332414303632747, 'confusion_matrix': array([[181,  50,   0,   0,   5],
       [156,  47,   1,   0,   1],
       [166,  29,   2,   0,   4],
       [ 85,  21,   0,   0,   2],
       [120,  29,   0,   0,   1]]), 'forgetting_measure': [0.47942786, 0.42255172, -0.6949619]}","{""Every task  has these classes:"": [""tree"", ""sheila"", ""seven"", ""house"", ""no""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552abc19350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ac2ad910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38554044, 'precision': 0.2935695674830641, 'recall': 0.41194852941176473, 'f1_score': 0.31186475451878297, 'confusion_matrix': array([[114,  14,   0,   0,   0],
       [113,  23,   0,   0,   0],
       [106,  23,   0,   0,   0],
       [ 69,  12,   0,   0,   0],
       [103,  23,   0,   0,   0]]), 'forgetting_measure': [0.40763656, 0.252989, -0.24996443]}","{""Every task  has these classes:"": [""tree"", ""sheila"", ""seven"", ""house"", ""no""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528dec9710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528e6b49d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3448715, 'precision': 0.3927791570120269, 'recall': 0.39691829963025193, 'f1_score': 0.2701829730163107, 'confusion_matrix': array([[  1,   1,   4, 135,   6],
       [  0,   4,   7, 212,   5],
       [  2,   1,   2, 198,   6],
       [  2,   1,   4, 137,   1],
       [  0,   2,   2, 166,   1]]), 'forgetting_measure': [0.32919077, -0.01340739, -0.33285207]}","{""Every task  has these classes:"": [""zero"", ""bed"", ""off"", ""down"", ""no""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528dec9710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528e6b49d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3212634, 'precision': 0.36563294356888664, 'recall': 0.38699481441494498, 'f1_score': 0.25284151784027065, 'confusion_matrix': array([[  0,   1,   3,  88,   3],
       [  1,   2,   5, 190,   7],
       [  1,   0,   3, 119,   3],
       [  2,   1,   1,  64,   3],
       [  0,   0,   2, 101,   0]]), 'forgetting_measure': [0.319863845, -0.0017257741, -0.031522654]}","{""Every task  has these classes:"": [""zero"", ""bed"", ""off"", ""down"", ""no""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528e19cfd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526ff9c990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43516402, 'precision': 0.39192377807587796, 'recall': 0.3999954933788392, 'f1_score': 0.27545048920560374, 'confusion_matrix': array([[  0, 227,   2,   1,   0],
       [  1, 178,   1,   2,   0],
       [  0, 200,   0,   4,   0],
       [  0, 153,   0,   1,   1],
       [  0, 123,   1,   3,   2]]), 'forgetting_measure': [0.4299728, -0.008318423, -0.05066133]}","{""Every task  has these classes:"": [""down"", ""house"", ""sheila"", ""seven"", ""right""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528e19cfd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526ff9c990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37432192, 'precision': 0.26297277764394123, 'recall': 0.40055825242718445, 'f1_score': 0.26321839080459771, 'confusion_matrix': array([[  0, 143,   0,   3,   0],
       [  0, 102,   0,   1,   0],
       [  0, 153,   0,   1,   0],
       [  0,  79,   0,   1,   0],
       [  0, 116,   0,   1,   0]]), 'forgetting_measure': [0.3729494, 0.039425015, -0.106871344]}","{""Every task  has these classes:"": [""down"", ""house"", ""sheila"", ""seven"", ""right""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac3e8090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155299c05fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38565887, 'precision': 0.3863498146282217, 'recall': 0.4267227752523536, 'f1_score': 0.39040785633717078, 'confusion_matrix': array([[26, 78, 84, 17,  2],
       [28, 96, 74,  8,  3],
       [28, 60, 94, 17,  3],
       [16, 55, 46, 11,  4],
       [11, 62, 60, 17,  0]]), 'forgetting_measure': [0.39590461, 0.08585757, -0.016207622]}","{""Every task  has these classes:"": [""eight"", ""stop"", ""go"", ""wow"", ""on""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac3e8090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155299c05fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5142754, 'precision': 0.3699615071479596, 'recall': 0.447451645831905, 'f1_score': 0.39639938255211792, 'confusion_matrix': array([[20, 49, 78,  0,  0],
       [21, 69, 51,  0,  0],
       [27, 31, 93,  1,  0],
       [15, 27, 40,  0,  0],
       [26, 23, 29,  0,  0]]), 'forgetting_measure': [0.53096227, -0.05272749, 0.24385476]}","{""Every task  has these classes:"": [""eight"", ""stop"", ""go"", ""wow"", ""on""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280111bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155280be49d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.32786977, 'precision': 0.22822222222222222, 'recall': 0.4, 'f1_score': 0.249464459591041864, 'confusion_matrix': array([[127,   0,   0,   0,   0],
       [176,   0,   0,   0,   0],
       [199,   0,   0,   0,   0],
       [243,   0,   0,   0,   0],
       [155,   0,   0,   0,   0]]), 'forgetting_measure': [0.323421684, -0.108119234, 0.09757004]}","{""Every task  has these classes:"": [""off"", ""eight"", ""six"", ""right"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280111bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155280be49d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.32664358, 'precision': 0.230333333333333334, 'recall': 0.4, 'f1_score': 0.25267727930535456, 'confusion_matrix': array([[ 91,   0,   0,   0,   0],
       [103,   0,   0,   0,   0],
       [139,   0,   0,   0,   0],
       [169,   0,   0,   0,   0],
       [ 98,   0,   0,   0,   0]]), 'forgetting_measure': [0.31829779, -0.21164723, 0.17467727]}","{""Every task  has these classes:"": [""off"", ""eight"", ""six"", ""right"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155278209bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527887c9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37116149, 'precision': 0.23311111111111111, 'recall': 0.4, 'f1_score': 0.256816015252621546, 'confusion_matrix': array([[149,   0,   0,   0,   0],
       [182,   0,   0,   0,   0],
       [209,   0,   0,   0,   0],
       [173,   0,   0,   0,   0],
       [187,   0,   0,   0,   0]]), 'forgetting_measure': [0.37388232, 0.046942744, -0.049254905]}","{""Every task  has these classes:"": [""three"", ""bed"", ""one"", ""six"", ""cat""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155278209bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527887c9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40033546, 'precision': 0.23666666666666667, 'recall': 0.4, 'f1_score': 0.26197183098591549, 'confusion_matrix': array([[110,   0,   0,   0,   0],
       [172,   0,   0,   0,   0],
       [121,   0,   0,   0,   0],
       [ 84,   0,   0,   0,   0],
       [113,   0,   0,   0,   0]]), 'forgetting_measure': [0.40110306, 0.011451046, -0.011583691]}","{""Every task  has these classes:"": [""three"", ""bed"", ""one"", ""six"", ""cat""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a5481550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b70cbc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45323802, 'precision': 0.4724854566193077, 'recall': 0.44545893719806763, 'f1_score': 0.41777950945484198, 'confusion_matrix': array([[  5,  56,  12,  61,   4],
       [  7,  89,  23,  84,   4],
       [  4,  61,  13,  93,   9],
       [ 10,  61,  23, 125,   6],
       [  3,  57,  15,  55,  20]]), 'forgetting_measure': [0.41502459, 0.13462013, -0.9272111]}","{""Every task  has these classes:"": [""seven"", ""yes"", ""eight"", ""sheila"", ""marvel""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a5481550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b70cbc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41998218, 'precision': 0.41537154065523095, 'recall': 0.40829554156359542, 'f1_score': 0.37467781120006257, 'confusion_matrix': array([[ 5, 47, 10, 45,  4],
       [ 1, 68, 11, 41,  8],
       [ 7, 46, 10, 43,  8],
       [ 7, 65,  5, 43, 15],
       [ 1, 55,  8, 40,  7]]), 'forgetting_measure': [0.43397137, 0.10598289, -0.03645931]}","{""Every task  has these classes:"": [""seven"", ""yes"", ""eight"", ""sheila"", ""marvel""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155290b79e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155291165910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48655857, 'precision': 0.6280648544002581, 'recall': 0.44888120494232546, 'f1_score': 0.38351368961343556, 'confusion_matrix': array([[107, 109,   1,   0,   0],
       [ 73, 160,   1,   0,   0],
       [ 38,  87,   8,   0,   0],
       [ 78, 100,   3,   0,   0],
       [ 49,  83,   2,   0,   1]]), 'forgetting_measure': [0.53535233, 0.3882643, -0.5558426]}","{""Every task  has these classes:"": [""down"", ""on"", ""up"", ""six"", ""five""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155290b79e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155291165910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45421152, 'precision': 0.34618735285222065, 'recall': 0.41456054241450834, 'f1_score': 0.35518765761756415, 'confusion_matrix': array([[ 52,  87,   3,   0,   0],
       [ 52, 115,   3,   0,   1],
       [ 34,  51,   3,   0,   0],
       [ 45,  64,   3,   0,   0],
       [ 35,  47,   5,   0,   0]]), 'forgetting_measure': [0.51683308, 0.40543073, -0.36651102]}","{""Every task  has these classes:"": [""down"", ""on"", ""up"", ""six"", ""five""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526a781bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526b172090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4287815, 'precision': 0.40473855815996425, 'recall': 0.43089051196802707, 'f1_score': 0.35985703215672406, 'confusion_matrix': array([[  2,  57, 118,   1,   2],
       [  2,  76, 126,   0,   0],
       [  7,  51, 179,   0,   1],
       [  5,  56, 109,   0,   1],
       [  1,  38,  66,   0,   2]]), 'forgetting_measure': [0.4969891, 0.3907082, -0.15169325]}","{""Every task  has these classes:"": [""down"", ""four"", ""sheila"", ""go"", ""bird""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526a781bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526b172090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51150156, 'precision': 0.31965413533834586, 'recall': 0.4500150829562594, 'f1_score': 0.359433465085639, 'confusion_matrix': array([[  0,  42,  87,   0,   0],
       [  0,  58,  72,   0,   0],
       [  0,  30, 123,   0,   0],
       [  0,  32,  48,   0,   0],
       [  0,  38,  69,   1,   0]]), 'forgetting_measure': [0.5145979, 0.06053227, -0.0974358]}","{""Every task  has these classes:"": [""down"", ""four"", ""sheila"", ""go"", ""bird""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155269dc1990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265b898d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43149449, 'precision': 0.42316079867208685, 'recall': 0.42697501961270078, 'f1_score': 0.41200704982189453, 'confusion_matrix': array([[35, 50, 40, 21, 16],
       [25, 89, 49, 15, 17],
       [50, 90, 66, 10,  9],
       [24, 63, 53, 20, 20],
       [13, 59, 43, 15,  8]]), 'forgetting_measure': [0.3799681, -0.5222199, 0.121871084]}","{""Every task  has these classes:"": [""nine"", ""zero"", ""cat"", ""tree"", ""bird""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155269dc1990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265b898d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42341754, 'precision': 0.38868357412122652, 'recall': 0.39701128336335122, 'f1_score': 0.374648548017766, 'confusion_matrix': array([[16, 36, 41, 11,  1],
       [18, 49, 44, 10,  5],
       [15, 54, 47, 14,  8],
       [10, 47, 47,  7, 12],
       [17, 38, 39,  9,  5]]), 'forgetting_measure': [0.43401378, 0.26790673, -0.5463401]}","{""Every task  has these classes:"": [""nine"", ""zero"", ""cat"", ""tree"", ""bird""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155265f29310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523b0e3f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53880815, 'precision': 0.25870535714285714, 'recall': 0.39700374531835205, 'f1_score': 0.29045571797076526, 'confusion_matrix': array([[263,   0,   0,   4,   0],
       [172,   0,   0,   0,   0],
       [185,   0,   0,   0,   0],
       [143,   0,   0,   0,   0],
       [133,   0,   0,   0,   0]]), 'forgetting_measure': [0.49259187, -0.23693219, 0.0]}","{""Every task  has these classes:"": [""tree"", ""on"", ""down"", ""go"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155265f29310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523b0e3f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46230547, 'precision': 0.252000000000000005, 'recall': 0.4, 'f1_score': 0.28253968253968255, 'confusion_matrix': array([[156,   0,   0,   0,   0],
       [108,   0,   0,   0,   0],
       [134,   0,   0,   0,   0],
       [ 98,   0,   0,   0,   0],
       [104,   0,   0,   0,   0]]), 'forgetting_measure': [0.4623055, 0.0, 0.0]}","{""Every task  has these classes:"": [""tree"", ""on"", ""down"", ""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155290dec210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527bce11d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4650753, 'precision': 0.5179932189665844, 'recall': 0.5057205786530114, 'f1_score': 0.4967491862602543, 'confusion_matrix': array([[ 21,  63,  38,  16,  14],
       [ 24, 108,  27,  23,  18],
       [ 10,  72, 114,  24,  28],
       [ 12,  69,  26,  19,  12],
       [  8,  51,  51,  11,  41]]), 'forgetting_measure': [0.4823787, 0.34354892, -0.7666464]}","{""Every task  has these classes:"": [""zero"", ""down"", ""no"", ""house"", ""one""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155290dec210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527bce11d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47958578, 'precision': 0.43344972632624, 'recall': 0.44635141097033647, 'f1_score': 0.42537905776967326, 'confusion_matrix': array([[ 5, 38, 33,  9,  8],
       [ 8, 69, 35,  9, 15],
       [ 8, 49, 71, 11, 23],
       [ 7, 35, 28,  6, 10],
       [10, 46, 37, 10, 20]]), 'forgetting_measure': [0.43809858, -0.2863355, 0.038823195]}","{""Every task  has these classes:"": [""zero"", ""down"", ""no"", ""house"", ""one""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155253791450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552534818d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45449955, 'precision': 0.6172201049094336, 'recall': 0.44262913663910016, 'f1_score': 0.3874007707193434, 'confusion_matrix': array([[ 27,   9,   1,   1, 163],
       [  2,  16,   2,   0, 128],
       [ 22,  10,   4,   0, 122],
       [ 19,   9,   1,  13, 129],
       [ 13,  12,   2,   2, 193]]), 'forgetting_measure': [0.40937794, -0.10993746, -0.3843774]}","{""Every task  has these classes:"": [""marvel"", ""two"", ""one"", ""no"", ""bed""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155253791450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552534818d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36928235, 'precision': 0.36626311513822384, 'recall': 0.3937400233162945, 'f1_score': 0.31390735267634877, 'confusion_matrix': array([[ 14,   9,   1,   0, 123],
       [ 18,   7,   1,   1,  93],
       [  5,  11,   0,   2,  89],
       [  4,   2,   0,   2, 100],
       [ 12,   4,   1,   7,  94]]), 'forgetting_measure': [0.3738483, 0.045932796, -0.013703056]}","{""Every task  has these classes:"": [""marvel"", ""two"", ""one"", ""no"", ""bed""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155278f3db50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155279a512d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44871802, 'precision': 0.43515014331632145, 'recall': 0.4236410186722449, 'f1_score': 0.41520944304942485, 'confusion_matrix': array([[ 44,  32,  95,  10,  20],
       [ 33,  27,  98,  10,  12],
       [ 48,  35, 127,  11,  25],
       [ 28,  17,  59,  13,  14],
       [ 24,  24,  62,  13,  19]]), 'forgetting_measure': [0.42901128, -0.07604189, -0.098574616]}","{""Every task  has these classes:"": [""cat"", ""on"", ""off"", ""go"", ""left""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155278f3db50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155279a512d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43098603, 'precision': 0.37847430594977426, 'recall': 0.38818726564831698, 'f1_score': 0.3650954378116502, 'confusion_matrix': array([[14, 16, 34,  2,  6],
       [44, 21, 81,  9, 22],
       [34, 28, 73,  4, 11],
       [22, 25, 42,  6, 12],
       [19, 22, 34, 11,  8]]), 'forgetting_measure': [0.3952834, -0.2786245, 0.0068629305]}","{""Every task  has these classes:"": [""cat"", ""on"", ""off"", ""go"", ""left""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552536c06d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155244721b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.421137, 'precision': 0.32438634622517566, 'recall': 0.39576776778342336, 'f1_score': 0.32515269934297624, 'confusion_matrix': array([[  0,   9, 160,   0,  20],
       [  0,  10, 115,   0,  18],
       [  0,  20, 170,   0,  29],
       [  0,  14, 118,   0,  21],
       [  0,  10, 160,   0,  26]]), 'forgetting_measure': [0.41289523, 0.07898002, -0.29760325]}","{""Every task  has these classes:"": [""left"", ""five"", ""bed"", ""stop"", ""eight""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552536c06d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155244721b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39295248, 'precision': 0.30436010923815801, 'recall': 0.4081361120923113, 'f1_score': 0.32190129425083376, 'confusion_matrix': array([[  0,   0, 114,   0,  18],
       [  0,   0,  84,   0,  10],
       [  0,   0, 125,   0,  24],
       [  0,   0, 104,   0,   7],
       [  0,   0,  91,   0,  23]]), 'forgetting_measure': [0.38909572, -0.027295668, -0.0064209537]}","{""Every task  has these classes:"": [""left"", ""five"", ""bed"", ""stop"", ""eight""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155281f19610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528224d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45396484, 'precision': 0.246, 'recall': 0.4, 'f1_score': 0.27479674796747968, 'confusion_matrix': array([[207,   0,   0,   0,   0],
       [170,   0,   0,   0,   0],
       [193,   0,   0,   0,   0],
       [165,   0,   0,   0,   0],
       [165,   0,   0,   0,   0]]), 'forgetting_measure': [0.43734726, -0.21004137, 0.17358197]}","{""Every task  has these classes:"": [""left"", ""zero"", ""eight"", ""cat"", ""bird""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155281f19610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528224d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38155666, 'precision': 0.235666666666666666, 'recall': 0.4, 'f1_score': 0.26053748231966055, 'confusion_matrix': array([[107,   0,   0,   0,   0],
       [110,   0,   0,   0,   0],
       [128,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [111,   0,   0,   0,   0]]), 'forgetting_measure': [0.36924202, -0.21829006, 0.17917742]}","{""Every task  has these classes:"": [""left"", ""zero"", ""eight"", ""cat"", ""bird""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b6d5ead0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a0983c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43078817, 'precision': 0.30599478147423354, 'recall': 0.4052285875853669, 'f1_score': 0.32818136630348462, 'confusion_matrix': array([[187,   0,  50,   0,   0],
       [159,   0,  28,   0,   0],
       [147,   0,  46,   0,   1],
       [129,   0,  18,   0,   1],
       [108,   0,  26,   0,   0]]), 'forgetting_measure': [0.48691807, 0.47654164, -0.6995626]}","{""Every task  has these classes:"": [""left"", ""five"", ""house"", ""on"", ""up""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b6d5ead0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a0983c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45964808, 'precision': 0.29270449521002211, 'recall': 0.3947139303482587, 'f1_score': 0.30441598248494799, 'confusion_matrix': array([[123,   0,  21,   0,   0],
       [ 97,   0,  11,   0,   0],
       [118,   0,  16,   0,   0],
       [126,   0,  11,   0,   0],
       [ 67,   0,  10,   0,   0]]), 'forgetting_measure': [0.44632707, 0.20772156, -0.729136]}","{""Every task  has these classes:"": [""left"", ""five"", ""house"", ""on"", ""up""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155246311990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552411698d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44546358, 'precision': 0.6102051756165535, 'recall': 0.47796068444185684, 'f1_score': 0.4593644920480364, 'confusion_matrix': array([[ 37, 102,  29,   0,  24],
       [  8, 148,  43,   1,  25],
       [  5,  95,  53,   1,  27],
       [ 19,  61,  12,   6,  20],
       [ 19,  97,  32,   0,  36]]), 'forgetting_measure': [0.45197414, 0.09508384, -0.12449004]}","{""Every task  has these classes:"": [""off"", ""four"", ""cat"", ""five"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155246311990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552411698d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43132154, 'precision': 0.36370003433059527, 'recall': 0.40360494306235574, 'f1_score': 0.36289947491770163, 'confusion_matrix': array([[17, 73, 20,  0, 31],
       [12, 79, 11,  1, 26],
       [19, 66,  9,  0, 20],
       [ 8, 49, 11,  0, 17],
       [19, 62, 19,  4, 27]]), 'forgetting_measure': [0.39873598, -0.4466955, 0.27752832]}","{""Every task  has these classes:"": [""off"", ""four"", ""cat"", ""five"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524c38ca50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240c818d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39954567, 'precision': 0.37007899421450823, 'recall': 0.40385409328254797, 'f1_score': 0.30064061145746814, 'confusion_matrix': array([[122,   1,   0,  35,   1],
       [230,   0,   0,  80,   2],
       [122,   1,   1,  32,   1],
       [ 95,   0,   1,  29,   0],
       [103,   1,   3,  38,   2]]), 'forgetting_measure': [0.41527156, 0.1698889, -0.14531015]}","{""Every task  has these classes:"": [""seven"", ""wow"", ""marvel"", ""on"", ""zero""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524c38ca50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240c818d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45012213, 'precision': 0.25735917625681406, 'recall': 0.39909909909909912, 'f1_score': 0.28638059701492537, 'confusion_matrix': array([[ 90,   0,   1,  16,   1],
       [128,   0,   1,  42,   0],
       [ 83,   0,   0,  27,   2],
       [ 62,   0,   0,  12,   0],
       [105,   0,   0,  30,   0]]), 'forgetting_measure': [0.42727321, -0.24216008, 0.14709479]}","{""Every task  has these classes:"": [""seven"", ""wow"", ""marvel"", ""on"", ""zero""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521fe51990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524241d210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39891807, 'precision': 0.23745819397993311, 'recall': 0.4, 'f1_score': 0.26309859154929578, 'confusion_matrix': array([[  0,   0, 163,   1,   0],
       [  0,   0, 198,   1,   0],
       [  0,   0, 168,   0,   0],
       [  0,   1, 185,   0,   0],
       [  0,   0, 183,   0,   0]]), 'forgetting_measure': [0.411575, 0.17946717, -0.21872027]}","{""Every task  has these classes:"": [""left"", ""five"", ""tree"", ""bird"", ""zero""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521fe51990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524241d210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44699031, 'precision': 0.24833333333333333, 'recall': 0.4, 'f1_score': 0.27785234899328859, 'confusion_matrix': array([[  0,   0, 126,   0,   0],
       [  0,   0, 132,   0,   0],
       [  0,   0, 145,   0,   0],
       [  0,   0,  92,   0,   0],
       [  0,   0, 105,   0,   0]]), 'forgetting_measure': [0.4594989, 0.14460832, -0.16905509]}","{""Every task  has these classes:"": [""left"", ""five"", ""tree"", ""bird"", ""zero""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155282420d90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527e58b390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40347545, 'precision': 0.24666666666666667, 'recall': 0.4, 'f1_score': 0.27567567567567567, 'confusion_matrix': array([[210,   0,   0,   0,   0],
       [212,   0,   0,   0,   0],
       [169,   0,   0,   0,   0],
       [125,   0,   0,   0,   0],
       [184,   0,   0,   0,   0]]), 'forgetting_measure': [0.40347545, 0.0, 0.0]}","{""Every task  has these classes:"": [""sheila"", ""five"", ""nine"", ""go"", ""six""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155282420d90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527e58b390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44455848, 'precision': 0.252000000000000005, 'recall': 0.4, 'f1_score': 0.28253968253968255, 'confusion_matrix': array([[156,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [ 89,   0,   0,   0,   0],
       [119,   0,   0,   0,   0],
       [ 92,   0,   0,   0,   0]]), 'forgetting_measure': [0.44455848, 0.0, 0.0]}","{""Every task  has these classes:"": [""sheila"", ""five"", ""nine"", ""go"", ""six""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522028a210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552190c9d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41113348, 'precision': 0.24377777777777778, 'recall': 0.4, 'f1_score': 0.27183226982680037, 'confusion_matrix': array([[197,   0,   0,   0,   0],
       [178,   0,   0,   0,   0],
       [159,   0,   0,   0,   0],
       [196,   0,   0,   0,   0],
       [170,   0,   0,   0,   0]]), 'forgetting_measure': [0.4228766, 0.15806657, -0.18774237]}","{""Every task  has these classes:"": [""up"", ""right"", ""go"", ""six"", ""tree""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522028a210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552190c9d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46229554, 'precision': 0.243, 'recall': 0.4, 'f1_score': 0.27078189300411522, 'confusion_matrix': array([[129,   0,   0,   0,   0],
       [133,   0,   0,   0,   0],
       [ 96,   0,   0,   0,   0],
       [133,   0,   0,   0,   0],
       [109,   0,   0,   0,   0]]), 'forgetting_measure': [0.48118968, 0.201581, -0.2524752]}","{""Every task  has these classes:"": [""up"", ""right"", ""go"", ""six"", ""tree""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155258e55690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155258d01290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45438902, 'precision': 0.33642729819200408, 'recall': 0.41052761648831514, 'f1_score': 0.34913403547420498, 'confusion_matrix': array([[ 15,   1, 141,  43,   0],
       [ 18,   0, 124,  33,   0],
       [ 23,   2, 166,  38,   0],
       [ 25,   3, 108,  46,   0],
       [  9,   1,  77,  27,   0]]), 'forgetting_measure': [0.50655313, 0.2744947, -0.053065415]}","{""Every task  has these classes:"": [""nine"", ""seven"", ""right"", ""go"", ""down""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155258e55690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155258d01290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3955677, 'precision': 0.29992065120733291, 'recall': 0.39503983071944236, 'f1_score': 0.31096275040689915, 'confusion_matrix': array([[  9,   0,  73,  21,   0],
       [ 15,   0, 125,  22,   0],
       [  8,   0,  75,  21,   0],
       [  9,   0,  76,  17,   0],
       [ 14,   0,  94,  21,   0]]), 'forgetting_measure': [0.41223278, 0.2352039, -0.30706188]}","{""Every task  has these classes:"": [""nine"", ""seven"", ""right"", ""go"", ""down""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522fb21bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522fd249d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37616108, 'precision': 0.234666666666666665, 'recall': 0.4, 'f1_score': 0.2590909090909091, 'confusion_matrix': array([[156,   0,   0,   0,   0],
       [189,   0,   0,   0,   0],
       [209,   0,   0,   0,   0],
       [184,   0,   0,   0,   0],
       [162,   0,   0,   0,   0]]), 'forgetting_measure': [0.37616107, 0.0, 0.0]}","{""Every task  has these classes:"": [""happy"", ""up"", ""zero"", ""dog"", ""go""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522fb21bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522fd249d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40678294, 'precision': 0.238, 'recall': 0.4, 'f1_score': 0.2638655462184874, 'confusion_matrix': array([[114,   0,   0,   0,   0],
       [174,   0,   0,   0,   0],
       [110,   0,   0,   0,   0],
       [107,   0,   0,   0,   0],
       [ 95,   0,   0,   0,   0]]), 'forgetting_measure': [0.40678295, 0.0, 0.0]}","{""Every task  has these classes:"": [""happy"", ""up"", ""zero"", ""dog"", ""go""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522ff7fdd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552229f4990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4180424, 'precision': 0.242269187986651836, 'recall': 0.39895287958115185, 'f1_score': 0.26972477064220184, 'confusion_matrix': array([[  0,   0, 161,   0,   0],
       [  0,   0, 183,   0,   0],
       [  0,   0, 190,   0,   1],
       [  0,   0, 209,   0,   0],
       [  0,   0, 156,   0,   0]]), 'forgetting_measure': [0.40458633, -0.09495245, -0.00676868]}","{""Every task  has these classes:"": [""seven"", ""tree"", ""right"", ""cat"", ""nine""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522ff7fdd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552229f4990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42323267, 'precision': 0.240999999999999995, 'recall': 0.4, 'f1_score': 0.26804979253112033, 'confusion_matrix': array([[  0,   0, 118,   0,   0],
       [  0,   0, 142,   0,   0],
       [  0,   0, 123,   0,   0],
       [  0,   0, 100,   0,   0],
       [  0,   0, 117,   0,   0]]), 'forgetting_measure': [0.43304328, 0.12629355, -0.14454919]}","{""Every task  has these classes:"": [""seven"", ""tree"", ""right"", ""cat"", ""nine""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525900f5d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155267d4d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41487567, 'precision': 0.42828993995467822, 'recall': 0.4237534011677343, 'f1_score': 0.42230573681403304, 'confusion_matrix': array([[10, 32, 43, 33, 20],
       [28, 49, 61, 39, 18],
       [24, 52, 66, 41, 15],
       [26, 37, 59, 42, 28],
       [14, 26, 44, 50, 43]]), 'forgetting_measure': [0.35372914, -0.3083194, -0.44073817]}","{""Every task  has these classes:"": [""marvel"", ""down"", ""six"", ""bird"", ""eight""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525900f5d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155267d4d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37425665, 'precision': 0.39152311051408638, 'recall': 0.38619542928467414, 'f1_score': 0.37633082687308566, 'confusion_matrix': array([[ 4, 25, 31, 29, 16],
       [ 3, 25, 48, 38, 24],
       [ 7, 34, 36, 40, 27],
       [ 2, 15, 39, 24, 19],
       [ 6, 22, 29, 32, 25]]), 'forgetting_measure': [0.34471193, -0.3626137, 0.08273833]}","{""Every task  has these classes:"": [""marvel"", ""down"", ""six"", ""bird"", ""eight""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155267eee510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524afbef10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42805901, 'precision': 0.28318747121142331, 'recall': 0.39561111111111112, 'f1_score': 0.29599311046739215, 'confusion_matrix': array([[206,   0,  19,   0,   0],
       [161,   0,  11,   0,   0],
       [165,   0,  11,   0,   0],
       [174,   0,  12,   0,   0],
       [129,   0,  12,   0,   0]]), 'forgetting_measure': [0.39643414, -0.24149226, 0.0]}","{""Every task  has these classes:"": [""tree"", ""dog"", ""up"", ""down"", ""no""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155267eee510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524afbef10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40906506, 'precision': 0.246, 'recall': 0.4, 'f1_score': 0.27479674796747968, 'confusion_matrix': array([[138,   0,   0,   0,   0],
       [123,   0,   0,   0,   0],
       [129,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [108,   0,   0,   0,   0]]), 'forgetting_measure': [0.40906508, 0.0, 0.0]}","{""Every task  has these classes:"": [""tree"", ""dog"", ""up"", ""down"", ""no""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155222495610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552294b4990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4262403, 'precision': 0.241156840934371525, 'recall': 0.4, 'f1_score': 0.26826568265682656, 'confusion_matrix': array([[  0, 228,   0,   0,   0],
       [  0, 185,   0,   0,   0],
       [  0, 173,   0,   0,   0],
       [  0, 146,   0,   0,   0],
       [  0, 167,   0,   1,   0]]), 'forgetting_measure': [0.45049078, 0.29043555, -0.4093153]}","{""Every task  has these classes:"": [""go"", ""cat"", ""bed"", ""one"", ""no""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155222495610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552294b4990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45448385, 'precision': 0.25600000000000001, 'recall': 0.4, 'f1_score': 0.28750000000000001, 'confusion_matrix': array([[  0, 119,   0,   0,   0],
       [  0, 168,   0,   0,   0],
       [  0, 119,   0,   0,   0],
       [  0,  61,   0,   0,   0],
       [  0, 133,   0,   0,   0]]), 'forgetting_measure': [0.49288962, 0.39338174, -0.6484832]}","{""Every task  has these classes:"": [""go"", ""cat"", ""bed"", ""one"", ""no""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155210b89710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155211201310>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46961675, 'precision': 0.250888888888888886, 'recall': 0.4, 'f1_score': 0.28113374667847652, 'confusion_matrix': array([[  0, 209,   0,   0,   0],
       [  0, 229,   0,   0,   0],
       [  0, 174,   0,   0,   0],
       [  0, 141,   0,   0,   0],
       [  0, 147,   0,   0,   0]]), 'forgetting_measure': [0.46849508, -0.012533077, 0.012377944]}","{""Every task  has these classes:"": [""tree"", ""marvel"", ""sheila"", ""six"", ""down""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155210b89710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155211201310>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43284927, 'precision': 0.25, 'recall': 0.4, 'f1_score': 0.28, 'confusion_matrix': array([[  0, 129,   0,   0,   0],
       [  0, 150,   0,   0,   0],
       [  0, 102,   0,   0,   0],
       [  0, 105,   0,   0,   0],
       [  0, 114,   0,   0,   0]]), 'forgetting_measure': [0.43284927, 0.0, 0.0]}","{""Every task  has these classes:"": [""tree"", ""marvel"", ""sheila"", ""six"", ""down""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529c25ed10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529c8d3b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39656795, 'precision': 0.33812908610376967, 'recall': 0.4069666536709585, 'f1_score': 0.30380068731603212, 'confusion_matrix': array([[138,   1,  29,   0,   1],
       [312,   0,  68,   4,   3],
       [ 98,   1,  25,   0,   1],
       [ 91,   0,  17,   1,   1],
       [ 89,   0,  19,   0,   1]]), 'forgetting_measure': [0.38500757, -0.11462463, 0.03749339]}","{""Every task  has these classes:"": [""up"", ""no"", ""wow"", ""house"", ""eight""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529c25ed10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529c8d3b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36579165, 'precision': 0.36725806451612904, 'recall': 0.4112198912198912, 'f1_score': 0.29943078549948778, 'confusion_matrix': array([[ 70,   0,  19,   1,   0],
       [154,   0,  63,   0,   2],
       [ 75,   0,  28,   0,   1],
       [ 82,   0,  26,   1,   1],
       [ 53,   0,  24,   0,   0]]), 'forgetting_measure': [0.33821839, -0.23181246, -0.10947]}","{""Every task  has these classes:"": [""up"", ""no"", ""wow"", ""house"", ""eight""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524b3130d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526028ee50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45201917, 'precision': 0.41015118317265555, 'recall': 0.41068458436169912, 'f1_score': 0.3516589998504494, 'confusion_matrix': array([[  1,  34,   2,  73,   8],
       [  2,  38,   3, 147,  14],
       [  2,  31,   1, 129,  11],
       [  1,  42,   0, 160,  11],
       [  0,  23,   4, 143,  20]]), 'forgetting_measure': [0.4207638, 0.2131613, -1.0816162]}","{""Every task  has these classes:"": [""on"", ""yes"", ""zero"", ""right"", ""house""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524b3130d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526028ee50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39964242, 'precision': 0.32024509803921568, 'recall': 0.39490756337471665, 'f1_score': 0.31332824833220925, 'confusion_matrix': array([[  0,   5,   0,  89,   0],
       [  0,  23,   0, 109,   3],
       [  0,  15,   0,  98,   4],
       [  0,  26,   0, 109,   2],
       [  0,  11,   0, 105,   1]]), 'forgetting_measure': [0.40710339, 0.38593447, -1.0809808]}","{""Every task  has these classes:"": [""on"", ""yes"", ""zero"", ""right"", ""house""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552608d2790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155255815910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4773944, 'precision': 0.30055560787268103, 'recall': 0.39997421018697617, 'f1_score': 0.30834957511499181, 'confusion_matrix': array([[  7, 158,   0,   0,   0],
       [ 11, 270,   1,   0,   0],
       [  5, 178,   0,   0,   0],
       [  6, 111,   0,   0,   0],
       [  8, 144,   1,   0,   0]]), 'forgetting_measure': [0.44260812, -0.21507719, 0.0]}","{""Every task  has these classes:"": [""stop"", ""marvel"", ""down"", ""six"", ""house""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552608d2790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155255815910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52575697, 'precision': 0.264, 'recall': 0.4, 'f1_score': 0.29696969696969697, 'confusion_matrix': array([[  0,  93,   0,   0,   0],
       [  0, 192,   0,   0,   0],
       [  0, 108,   0,   0,   0],
       [  0,  96,   0,   0,   0],
       [  0, 111,   0,   0,   0]]), 'forgetting_measure': [0.525757, 0.0, 0.0]}","{""Every task  has these classes:"": [""stop"", ""marvel"", ""down"", ""six"", ""house""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218671990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552186418d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50117026, 'precision': 0.6645622119815668, 'recall': 0.44194547156847493, 'f1_score': 0.3938157577757407, 'confusion_matrix': array([[202,  44,   1,   4,   0],
       [139,  60,   7,   8,   0],
       [ 93,  42,   6,   3,   0],
       [137,  12,   1,   6,   0],
       [111,  18,   0,   0,   6]]), 'forgetting_measure': [0.5250011, 0.6724706, -3.4347]}","{""Every task  has these classes:"": [""house"", ""down"", ""bird"", ""tree"", ""left""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218671990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552186418d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46138663, 'precision': 0.43193580866173497, 'recall': 0.4143497929124742, 'f1_score': 0.3489669039148765, 'confusion_matrix': array([[107,  26,   3,   7,   2],
       [ 78,  27,   0,   2,   0],
       [ 92,  32,   6,   2,   3],
       [ 82,  21,   1,   4,   0],
       [ 84,  16,   3,   2,   0]]), 'forgetting_measure': [0.50177426, 0.38830414, -0.61322427]}","{""Every task  has these classes:"": [""house"", ""down"", ""bird"", ""tree"", ""left""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155297296610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528114b5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36872169, 'precision': 0.33919821826280623, 'recall': 0.39998116760828627, 'f1_score': 0.26768617429082545, 'confusion_matrix': array([[  1, 179,   0,   0,   0],
       [  1, 176,   0,   0,   0],
       [  0, 180,   0,   0,   0],
       [  0, 199,   0,   0,   0],
       [  0, 164,   0,   0,   0]]), 'forgetting_measure': [0.37335133, 0.04005996, 0.0]}","{""Every task  has these classes:"": [""sheila"", ""up"", ""stop"", ""left"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155297296610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528114b5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4273761, 'precision': 0.24566666666666667, 'recall': 0.4, 'f1_score': 0.27435549525101764, 'confusion_matrix': array([[  0, 108,   0,   0,   0],
       [  0, 137,   0,   0,   0],
       [  0, 139,   0,   0,   0],
       [  0, 139,   0,   0,   0],
       [  0,  77,   0,   0,   0]]), 'forgetting_measure': [0.42807914, 0.009246882, -0.009333185]}","{""Every task  has these classes:"": [""sheila"", ""up"", ""stop"", ""left"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552870e6b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155285a93b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41514669, 'precision': 0.24133333333333333, 'recall': 0.4, 'f1_score': 0.26850828729281769, 'confusion_matrix': array([[186,   0,   0,   0,   0],
       [139,   0,   0,   0,   0],
       [308,   0,   0,   0,   0],
       [138,   0,   0,   0,   0],
       [129,   0,   0,   0,   0]]), 'forgetting_measure': [0.42407694, 0.119560644, -0.13579656]}","{""Every task  has these classes:"": [""stop"", ""wow"", ""bed"", ""eight"", ""house""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552870e6b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155285a93b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3265715, 'precision': 0.23333333333333333, 'recall': 0.4, 'f1_score': 0.25714285714285714, 'confusion_matrix': array([[100,   0,   0,   0,   0],
       [115,   0,   0,   0,   0],
       [205,   0,   0,   0,   0],
       [ 69,   0,   0,   0,   0],
       [111,   0,   0,   0,   0]]), 'forgetting_measure': [0.32825836, 0.03945599, -0.041076716]}","{""Every task  has these classes:"": [""stop"", ""wow"", ""bed"", ""eight"", ""house""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fb5c9990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fb6c18d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4302319, 'precision': 0.32475368986007282, 'recall': 0.39864311782412955, 'f1_score': 0.3285620580795167, 'confusion_matrix': array([[  0, 147,  37,   0,  11],
       [  4, 173,  37,   1,  10],
       [  1, 150,  36,   0,   7],
       [  1, 129,  23,   0,   4],
       [  1, 106,  15,   2,   5]]), 'forgetting_measure': [0.38801348, -0.23343071, -0.16765296]}","{""Every task  has these classes:"": [""sheila"", ""go"", ""happy"", ""three"", ""six""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fb5c9990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fb6c18d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41608426, 'precision': 0.28057142857142857, 'recall': 0.39956112852664576, 'f1_score': 0.31134028708759769, 'confusion_matrix': array([[  0,  78,  43,   0,   0],
       [  1, 117,  27,   0,   0],
       [  0,  89,  21,   0,   0],
       [  0,  93,  27,   0,   0],
       [  2,  73,  29,   0,   0]]), 'forgetting_measure': [0.41032268, -0.022259353, -0.036843315]}","{""Every task  has these classes:"": [""sheila"", ""go"", ""happy"", ""three"", ""six""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552541b9610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524dcf9e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4984844, 'precision': 0.61828211204381854, 'recall': 0.5150377992855649, 'f1_score': 0.50539550320005, 'confusion_matrix': array([[ 44,  21,  30,  74,   2],
       [ 14,  53,  56,  53,   0],
       [  7,  15,  64,  90,   6],
       [ 12,  13,  61, 125,   1],
       [  9,  12,  54,  72,  12]]), 'forgetting_measure': [0.52504138, 0.5991043, -2.377423]}","{""Every task  has these classes:"": [""nine"", ""one"", ""zero"", ""down"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552541b9610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524dcf9e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40764299, 'precision': 0.38963626682640308, 'recall': 0.407957675843298, 'f1_score': 0.36361966192458088, 'confusion_matrix': array([[ 9, 15, 38, 55,  6],
       [13, 11, 37, 75,  3],
       [ 6, 10, 37, 53,  6],
       [12, 16, 22, 57,  2],
       [12, 15, 27, 59,  4]]), 'forgetting_measure': [0.40956963, 0.012736864, 0.0021334765]}","{""Every task  has these classes:"": [""nine"", ""one"", ""zero"", ""down"", ""happy""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520a1d9bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155209e893d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50035537, 'precision': 0.56431739431739435, 'recall': 0.43626744191767254, 'f1_score': 0.37541929686557406, 'confusion_matrix': array([[  9, 146,   3,   3,  19],
       [  0, 217,   8,   1,  16],
       [  2, 143,  22,   1,   3],
       [  0, 153,   9,   1,   4],
       [  2, 118,   3,   3,  14]]), 'forgetting_measure': [0.5307688, 0.08438241, 0.1169468]}","{""Every task  has these classes:"": [""no"", ""wow"", ""zero"", ""six"", ""dog""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520a1d9bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155209e893d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.439959, 'precision': 0.44302297063248254, 'recall': 0.41593890432765112, 'f1_score': 0.33904322226567695, 'confusion_matrix': array([[  2, 123,   3,   2,   5],
       [  2, 120,   6,   2,   8],
       [  2,  82,  10,   2,   3],
       [  2, 106,  10,   2,   6],
       [  2,  86,   5,   1,   8]]), 'forgetting_measure': [0.45125784, 0.095779896, -0.06265355]}","{""Every task  has these classes:"": [""no"", ""wow"", ""zero"", ""six"", ""dog""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552401f98d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523b0d5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4552822, 'precision': 0.4626330103172564, 'recall': 0.44640530930853508, 'f1_score': 0.43594478627660026, 'confusion_matrix': array([[ 38,  15,  16,  79,   8],
       [ 27,  41,  19, 102,  20],
       [ 20,  17,  22,  85,   8],
       [ 48,  27,  13, 151,  20],
       [ 10,  19,  11,  76,   8]]), 'forgetting_measure': [0.43492712, -0.11795169, -0.02149367]}","{""Every task  has these classes:"": [""cat"", ""house"", ""three"", ""dog"", ""on""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552401f98d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523b0d5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44839167, 'precision': 0.4259866029818806, 'recall': 0.42040227776681057, 'f1_score': 0.39214881412481435, 'confusion_matrix': array([[19, 29,  9, 76, 10],
       [16, 19,  8, 85, 10],
       [17, 17,  9, 57,  3],
       [17, 14,  7, 85, 11],
       [12, 15,  5, 41,  9]]), 'forgetting_measure': [0.4710291, -0.048719365, 0.3318439]}","{""Every task  has these classes:"": [""cat"", ""house"", ""three"", ""dog"", ""on""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522c735690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522c6cd910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39959629, 'precision': 0.4338927632489276, 'recall': 0.3990148580648287, 'f1_score': 0.39523331853128664, 'confusion_matrix': array([[35, 76, 66,  6, 20],
       [46, 63, 73,  4, 18],
       [59, 62, 63,  3, 27],
       [37, 40, 37,  9, 12],
       [42, 34, 41,  5, 22]]), 'forgetting_measure': [0.42120972, 0.20614521, -0.15012006]}","{""Every task  has these classes:"": [""tree"", ""no"", ""yes"", ""eight"", ""left""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522c735690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522c6cd910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44882172, 'precision': 0.41306431801027664, 'recall': 0.42544229661523688, 'f1_score': 0.4013638982383538, 'confusion_matrix': array([[23, 44, 23,  4, 14],
       [33, 80, 33,  7, 15],
       [24, 39, 33,  2,  4],
       [14, 45, 28,  2,  4],
       [34, 48, 31,  4, 12]]), 'forgetting_measure': [0.37852394, -0.47654858, -0.15456277]}","{""Every task  has these classes:"": [""tree"", ""no"", ""yes"", ""eight"", ""left""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522ca9b110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155234495910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4910827, 'precision': 0.250444444444444445, 'recall': 0.4, 'f1_score': 0.28056787932564331, 'confusion_matrix': array([[227,   0,   0,   0,   0],
       [163,   0,   0,   0,   0],
       [244,   0,   0,   0,   0],
       [155,   0,   0,   0,   0],
       [111,   0,   0,   0,   0]]), 'forgetting_measure': [0.52911718, 0.34669542, -0.53067964]}","{""Every task  has these classes:"": [""sheila"", ""cat"", ""house"", ""go"", ""no""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522ca9b110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155234495910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51512886, 'precision': 0.259, 'recall': 0.4, 'f1_score': 0.29111969111969112, 'confusion_matrix': array([[177,   0,   0,   0,   0],
       [101,   0,   0,   0,   0],
       [134,   0,   0,   0,   0],
       [ 95,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0]]), 'forgetting_measure': [0.57789634, 0.49829128, -0.9931885]}","{""Every task  has these classes:"": [""sheila"", ""cat"", ""house"", ""go"", ""no""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fc6b9450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f9944990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45021857, 'precision': 0.3898681034383193, 'recall': 0.40461621452288264, 'f1_score': 0.35481955501334183, 'confusion_matrix': array([[ 47, 134,   0,   2,  22],
       [ 42, 144,   2,   0,  35],
       [ 44, 104,   1,   2,  13],
       [ 27,  97,   1,   0,  21],
       [ 26, 109,   0,   4,  23]]), 'forgetting_measure': [0.42318555, -0.2933528, 0.17267914]}","{""Every task  has these classes:"": [""left"", ""bed"", ""wow"", ""two"", ""zero""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fc6b9450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f9944990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4803763, 'precision': 0.3406798425455142, 'recall': 0.39019263443082152, 'f1_score': 0.32931792890893096, 'confusion_matrix': array([[ 12,  92,   0,   2,   6],
       [ 29, 145,   0,   2,   7],
       [ 18,  78,   0,   2,   4],
       [ 15,  50,   0,   0,   2],
       [ 22, 104,   0,   3,   7]]), 'forgetting_measure': [0.49917777, 0.06578724, 0.060968176]}","{""Every task  has these classes:"": [""left"", ""bed"", ""wow"", ""two"", ""zero""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f9ddde90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520604d150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41258414, 'precision': 0.241824249165739714, 'recall': 0.4, 'f1_score': 0.26918123275068996, 'confusion_matrix': array([[188,   0,   0,   0,   0],
       [232,   0,   0,   0,   0],
       [162,   0,   0,   0,   1],
       [155,   0,   0,   0,   0],
       [162,   0,   0,   0,   0]]), 'forgetting_measure': [0.41613048, 0.049224813, -0.051773343]}","{""Every task  has these classes:"": [""one"", ""down"", ""three"", ""happy"", ""no""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f9ddde90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520604d150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.30011926, 'precision': 0.226666666666666665, 'recall': 0.4, 'f1_score': 0.247058823529411764, 'confusion_matrix': array([[ 80,   0,   0,   0,   0],
       [165,   0,   0,   0,   0],
       [115,   0,   0,   0,   0],
       [117,   0,   0,   0,   0],
       [123,   0,   0,   0,   0]]), 'forgetting_measure': [0.3064608, 0.17870075, -0.217583]}","{""Every task  has these classes:"": [""one"", ""down"", ""three"", ""happy"", ""no""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f09a9990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551efe34e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39630636, 'precision': 0.238, 'recall': 0.4, 'f1_score': 0.2638655462184874, 'confusion_matrix': array([[171,   0,   0,   0,   0],
       [170,   0,   0,   0,   0],
       [198,   0,   0,   0,   0],
       [184,   0,   0,   0,   0],
       [177,   0,   0,   0,   0]]), 'forgetting_measure': [0.39630636, 0.0, 0.0]}","{""Every task  has these classes:"": [""six"", ""stop"", ""one"", ""marvel"", ""dog""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f09a9990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551efe34e10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4044181, 'precision': 0.248, 'recall': 0.4, 'f1_score': 0.27741935483870968, 'confusion_matrix': array([[144,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [141,   0,   0,   0,   0],
       [129,   0,   0,   0,   0],
       [ 84,   0,   0,   0,   0]]), 'forgetting_measure': [0.4044181, 0.0, 0.0]}","{""Every task  has these classes:"": [""six"", ""stop"", ""one"", ""marvel"", ""dog""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523472b950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523b165910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43704521, 'precision': 0.24866666666666667, 'recall': 0.4, 'f1_score': 0.27828418230563003, 'confusion_matrix': array([[219,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [183,   0,   0,   0,   0],
       [195,   0,   0,   0,   0],
       [159,   0,   0,   0,   0]]), 'forgetting_measure': [0.43704524, 0.0, 0.0]}","{""Every task  has these classes:"": [""go"", ""wow"", ""stop"", ""down"", ""five""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523472b950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523b165910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43258378, 'precision': 0.247, 'recall': 0.4, 'f1_score': 0.27611336032388664, 'confusion_matrix': array([[141,   0,   0,   0,   0],
       [120,   0,   0,   0,   0],
       [114,   0,   0,   0,   0],
       [116,   0,   0,   0,   0],
       [109,   0,   0,   0,   0]]), 'forgetting_measure': [0.43258379, 0.0, 0.0]}","{""Every task  has these classes:"": [""go"", ""wow"", ""stop"", ""down"", ""five""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155227839610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522812d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.58882333, 'precision': 0.6155123478694548, 'recall': 0.5389961825145714, 'f1_score': 0.52480375378107923, 'confusion_matrix': array([[ 25,  56,  54,  10,   2],
       [  8,  78,  77,   9,   2],
       [  1,  15, 215,  10,  29],
       [  7,  22,  90,  16,   7],
       [  5,  10, 116,   8,  28]]), 'forgetting_measure': [0.5025266, -0.24120146, -0.30080327]}","{""Every task  has these classes:"": [""sheila"", ""cat"", ""dog"", ""on"", ""zero""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155227839610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522812d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42571787, 'precision': 0.38270160438636213, 'recall': 0.38012899039124539, 'f1_score': 0.35800507943862077, 'confusion_matrix': array([[ 9, 30, 48,  6,  3],
       [11, 19, 71,  8, 11],
       [16, 51, 96,  6,  8],
       [ 5, 22, 82,  3,  9],
       [ 5, 17, 56,  1,  7]]), 'forgetting_measure': [0.46063827, 0.23414634, -0.08663797]}","{""Every task  has these classes:"": [""sheila"", ""cat"", ""dog"", ""on"", ""zero""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551eff89710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551eb844990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39816527, 'precision': 0.241999999999999996, 'recall': 0.4, 'f1_score': 0.26942148760330578, 'confusion_matrix': array([[189,   0,   0,   0,   0],
       [151,   0,   0,   0,   0],
       [233,   0,   0,   0,   0],
       [199,   0,   0,   0,   0],
       [128,   0,   0,   0,   0]]), 'forgetting_measure': [0.33911018, -1.2735608, 0.5601613]}","{""Every task  has these classes:"": [""yes"", ""nine"", ""bird"", ""on"", ""happy""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551eff89710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551eb844990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.358514, 'precision': 0.228333333333333332, 'recall': 0.4, 'f1_score': 0.249635036496350364, 'confusion_matrix': array([[ 85,   0,   0,   0,   0],
       [ 87,   0,   0,   0,   0],
       [176,   0,   0,   0,   0],
       [150,   0,   0,   0,   0],
       [102,   0,   0,   0,   0]]), 'forgetting_measure': [0.32717444, -0.7392889, 0.4250524]}","{""Every task  has these classes:"": [""yes"", ""nine"", ""bird"", ""on"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dd541450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dd864a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40767246, 'precision': 0.239329608938547485, 'recall': 0.4, 'f1_score': 0.26573295985060691, 'confusion_matrix': array([[  0,   0,   0, 209,   1],
       [  0,   0,   0, 186,   0],
       [  1,   0,   0, 182,   1],
       [  0,   0,   0, 176,   0],
       [  0,   2,   0, 142,   0]]), 'forgetting_measure': [0.36074288, -0.87586313, 0.46691206]}","{""Every task  has these classes:"": [""seven"", ""wow"", ""nine"", ""left"", ""down""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dd541450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dd864a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39527471, 'precision': 0.23933333333333333, 'recall': 0.4, 'f1_score': 0.26573816155988857, 'confusion_matrix': array([[  0,   0,   0, 147,   0],
       [  0,   0,   0, 102,   0],
       [  0,   0,   0, 119,   0],
       [  0,   0,   0, 118,   0],
       [  0,   0,   0, 114,   0]]), 'forgetting_measure': [0.3731998, -0.38236028, 0.2765996]}","{""Every task  has these classes:"": [""seven"", ""wow"", ""nine"", ""left"", ""down""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522237d690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522845c350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43113853, 'precision': 0.48108089896873334, 'recall': 0.4313758505086021, 'f1_score': 0.4040758891248843, 'confusion_matrix': array([[  4,  43,   2,   0,  73],
       [  5, 100,   6,   1, 124],
       [  2,  66,  23,   0,  72],
       [  1,  52,   1,   0,  55],
       [  3, 105,  10,   1, 151]]), 'forgetting_measure': [0.46279753, 0.28164893, -0.28104684]}","{""Every task  has these classes:"": [""four"", ""eight"", ""wow"", ""five"", ""two""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522237d690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522845c350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4508026, 'precision': 0.34996050735823813, 'recall': 0.43538609763060236, 'f1_score': 0.37572974644403216, 'confusion_matrix': array([[ 0, 41, 10,  0, 44],
       [ 0, 82,  8,  0, 65],
       [ 0, 42,  4,  0, 67],
       [ 2, 25,  4,  0, 46],
       [ 0, 47, 15,  0, 98]]), 'forgetting_measure': [0.42142774, -0.46392527, 0.36194932]}","{""Every task  has these classes:"": [""four"", ""eight"", ""wow"", ""five"", ""two""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521ba85690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521b55d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5426645, 'precision': 0.2633221850613155, 'recall': 0.39929824561403509, 'f1_score': 0.2961082910321489, 'confusion_matrix': array([[284,   0,   0,   0,   1],
       [151,   0,   0,   0,   1],
       [133,   0,   0,   0,   0],
       [161,   0,   0,   0,   1],
       [168,   0,   0,   0,   0]]), 'forgetting_measure': [0.5309253, -0.05321105, 0.0]}","{""Every task  has these classes:"": [""tree"", ""marvel"", ""off"", ""five"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521ba85690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521b55d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51793377, 'precision': 0.266, 'recall': 0.4, 'f1_score': 0.29924812030075188, 'confusion_matrix': array([[198,   0,   0,   0,   0],
       [ 89,   0,   0,   0,   0],
       [103,   0,   0,   0,   0],
       [108,   0,   0,   0,   0],
       [102,   0,   0,   0,   0]]), 'forgetting_measure': [0.51793377, 0.0, 0.0]}","{""Every task  has these classes:"": [""tree"", ""marvel"", ""off"", ""five"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155215691e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521515f450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51596228, 'precision': 0.5874406150125248, 'recall': 0.43584015275504636, 'f1_score': 0.37875269285240364, 'confusion_matrix': array([[  1,  90,  39,   0,   0],
       [  0, 251,  57,   4,   0],
       [  1, 121,  65,   1,   0],
       [  1, 107,  21,   0,   0],
       [  1, 112,  22,   3,   3]]), 'forgetting_measure': [0.44072582, -0.49659458, 0.037130043]}","{""Every task  has these classes:"": [""left"", ""tree"", ""eight"", ""house"", ""five""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155215691e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521515f450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50314565, 'precision': 0.30151766004415012, 'recall': 0.38999093829804764, 'f1_score': 0.32955855897412244, 'confusion_matrix': array([[  0,  79,  20,   0,   0],
       [  0, 145,  54,   0,   0],
       [  0,  93,  27,   0,   2],
       [  0,  70,  23,   0,   0],
       [  1,  66,  20,   0,   0]]), 'forgetting_measure': [0.44061966, -0.49313822, 0.1384428]}","{""Every task  has these classes:"": [""left"", ""tree"", ""eight"", ""house"", ""five""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155215a46e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522242d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4293315, 'precision': 0.38556625858102022, 'recall': 0.4134900474021327, 'f1_score': 0.37287990140216786, 'confusion_matrix': array([[ 49,   7, 138,  11,   1],
       [ 37,   2,  90,  16,   3],
       [ 62,   2, 167,  21,   0],
       [ 24,   5, 109,  25,   0],
       [ 31,   5,  87,   8,   0]]), 'forgetting_measure': [0.43850146, 0.11357914, -0.12614036]}","{""Every task  has these classes:"": [""house"", ""off"", ""wow"", ""dog"", ""left""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155215a46e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522242d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4876009, 'precision': 0.37943722943722942, 'recall': 0.43114385614385613, 'f1_score': 0.3886067706757362, 'confusion_matrix': array([[ 24,   0,  94,  14,   0],
       [ 15,   0,  51,  10,   0],
       [ 32,   0, 135,  22,   0],
       [  7,   0,  70,  27,   0],
       [ 21,   0,  70,   8,   0]]), 'forgetting_measure': [0.47241683, -0.01027504, -0.14517331]}","{""Every task  has these classes:"": [""house"", ""off"", ""wow"", ""dog"", ""left""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552069e1610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520640d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45556117, 'precision': 0.5957511824860032, 'recall': 0.4562079026013452, 'f1_score': 0.41099739325098463, 'confusion_matrix': array([[  9,   3,   1, 124,  28],
       [  2,  18,   8, 116,  24],
       [  0,   5,  17, 142,  19],
       [  0,   5,   5, 178,  28],
       [  8,   4,   5, 117,  34]]), 'forgetting_measure': [0.43166713, 0.0036919857, -0.3179765]}","{""Every task  has these classes:"": [""left"", ""dog"", ""on"", ""sheila"", ""stop""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552069e1610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520640d910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41789058, 'precision': 0.44492442225346256, 'recall': 0.41500872245553096, 'f1_score': 0.34784606329367428, 'confusion_matrix': array([[  5,   7,   4,  83,  12],
       [  2,   5,   4,  86,  11],
       [  0,   6,   5, 114,   7],
       [  5,   5,   8, 119,   4],
       [  2,   8,   2,  85,  11]]), 'forgetting_measure': [0.47665415, 0.3195097, -0.002638289]}","{""Every task  has these classes:"": [""left"", ""dog"", ""on"", ""sheila"", ""stop""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155284ddc710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552857da990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34465767, 'precision': 0.23133333333333334, 'recall': 0.4, 'f1_score': 0.25417867435158501, 'confusion_matrix': array([[141,   0,   0,   0,   0],
       [219,   0,   0,   0,   0],
       [189,   0,   0,   0,   0],
       [165,   0,   0,   0,   0],
       [186,   0,   0,   0,   0]]), 'forgetting_measure': [0.34465769, 0.0, 0.0]}","{""Every task  has these classes:"": [""zero"", ""dog"", ""happy"", ""on"", ""marvel""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155284ddc710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552857da990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3120799, 'precision': 0.227000000000000003, 'recall': 0.4, 'f1_score': 0.24757709251101322, 'confusion_matrix': array([[ 81,   0,   0,   0,   0],
       [186,   0,   0,   0,   0],
       [150,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [ 81,   0,   0,   0,   0]]), 'forgetting_measure': [0.312079896, 0.0, 0.0]}","{""Every task  has these classes:"": [""zero"", ""dog"", ""happy"", ""on"", ""marvel""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e45ae150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e6172750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38634185, 'precision': 0.43942093541202675, 'recall': 0.40105820105820107, 'f1_score': 0.2679657282741738, 'confusion_matrix': array([[  1,   0,   0,   0, 188],
       [  0,   0,   0,   0, 150],
       [  0,   0,   0,   1, 228],
       [  0,   0,   0,   0, 155],
       [  0,   0,   0,   0, 177]]), 'forgetting_measure': [0.40030335, 0.10455248, 0.0]}","{""Every task  has these classes:"": [""eight"", ""cat"", ""five"", ""no"", ""wow""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e45ae150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e6172750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.30451713, 'precision': 0.226000000000000002, 'recall': 0.4, 'f1_score': 0.246017699115044254, 'confusion_matrix': array([[  0,   0,   0,   0, 111],
       [  0,   0,   0,   0, 137],
       [  0,   0,   0,   0, 175],
       [  0,   0,   0,   0,  99],
       [  0,   0,   0,   0,  78]]), 'forgetting_measure': [0.30451713, 0.0, 0.0]}","{""Every task  has these classes:"": [""eight"", ""cat"", ""five"", ""no"", ""wow""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552062ee190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551cf9ed910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5169879, 'precision': 0.56584156537876555, 'recall': 0.5557864979567942, 'f1_score': 0.555112654910733, 'confusion_matrix': array([[ 65,  46,  29,  36,   9],
       [ 32, 103,  27,  28,  17],
       [ 24,  43,  56,  34,  14],
       [ 37,  30,  42,  75,  12],
       [ 16,  50,  25,  19,  31]]), 'forgetting_measure': [0.49450947, 0.026276201, -0.28912446]}","{""Every task  has these classes:"": [""on"", ""marvel"", ""dog"", ""six"", ""four""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552062ee190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551cf9ed910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44413615, 'precision': 0.4263899254242537, 'recall': 0.42028956406772324, 'f1_score': 0.42123012603945535, 'confusion_matrix': array([[28, 44, 20, 25,  9],
       [20, 30, 19, 33, 18],
       [28, 32, 24, 22, 12],
       [36, 42, 24, 45, 11],
       [ 9, 22, 14, 22, 11]]), 'forgetting_measure': [0.4239477, -0.3099122, 0.26672038]}","{""Every task  has these classes:"": [""on"", ""marvel"", ""dog"", ""six"", ""four""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e1908c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551efe8a010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39793563, 'precision': 0.40231253336516491, 'recall': 0.4001219486161367, 'f1_score': 0.38498173711095606, 'confusion_matrix': array([[ 43,  18,  26,   9,  91],
       [ 33,  18,  22,  16,  78],
       [ 46,  14,  14,  13,  89],
       [ 44,  19,  17,  15,  53],
       [ 56,  21,  25,  13, 107]]), 'forgetting_measure': [0.38099508, -0.2355726, 0.1540623]}","{""Every task  has these classes:"": [""yes"", ""happy"", ""bed"", ""tree"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e1908c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551efe8a010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38415943, 'precision': 0.42833776749566223, 'recall': 0.39055722574201597, 'f1_score': 0.37394291808017298, 'confusion_matrix': array([[25,  4, 16, 13, 70],
       [42, 12,  9,  9, 45],
       [38,  4,  6,  9, 49],
       [36,  5, 10, 11, 46],
       [49,  3,  9, 10, 70]]), 'forgetting_measure': [0.40708962, 0.23071285, -0.16801015]}","{""Every task  has these classes:"": [""yes"", ""happy"", ""bed"", ""tree"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f80598d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f85312d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3780618, 'precision': 0.24133333333333333, 'recall': 0.4, 'f1_score': 0.26850828729281769, 'confusion_matrix': array([[186,   0,   0,   0,   0],
       [189,   0,   0,   0,   0],
       [219,   0,   0,   0,   0],
       [156,   0,   0,   0,   0],
       [150,   0,   0,   0,   0]]), 'forgetting_measure': [0.37806178, 0.0, 0.0]}","{""Every task  has these classes:"": [""left"", ""up"", ""sheila"", ""down"", ""happy""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f80598d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f85312d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42400147, 'precision': 0.24, 'recall': 0.4, 'f1_score': 0.26666666666666668, 'confusion_matrix': array([[120,   0,   0,   0,   0],
       [162,   0,   0,   0,   0],
       [137,   0,   0,   0,   0],
       [109,   0,   0,   0,   0],
       [ 72,   0,   0,   0,   0]]), 'forgetting_measure': [0.42400147, 0.0, 0.0]}","{""Every task  has these classes:"": [""left"", ""up"", ""sheila"", ""down"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e337d9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551cb85d590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41483493, 'precision': 0.24466666666666667, 'recall': 0.4, 'f1_score': 0.27302452316076294, 'confusion_matrix': array([[  0, 160,   0,   0,   0],
       [  0, 201,   0,   0,   0],
       [  0, 159,   0,   0,   0],
       [  0, 218,   0,   0,   0],
       [  0, 162,   0,   0,   0]]), 'forgetting_measure': [0.42974011, 0.19463532, -0.24167351]}","{""Every task  has these classes:"": [""happy"", ""six"", ""wow"", ""right"", ""zero""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e337d9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551cb85d590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41764033, 'precision': 0.244, 'recall': 0.4, 'f1_score': 0.27213114754098361, 'confusion_matrix': array([[  0, 119,   0,   0,   0],
       [  0, 132,   0,   0,   0],
       [  0, 102,   0,   0,   0],
       [  0, 125,   0,   0,   0],
       [  0, 122,   0,   0,   0]]), 'forgetting_measure': [0.42044957, 0.038229447, -0.03974903]}","{""Every task  has these classes:"": [""happy"", ""six"", ""wow"", ""right"", ""zero""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f3b25690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f82ec550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38906005, 'precision': 0.237333333333333336, 'recall': 0.4, 'f1_score': 0.26292134831460675, 'confusion_matrix': array([[168,   0,   0,   0,   0],
       [177,   0,   0,   0,   0],
       [195,   0,   0,   0,   0],
       [189,   0,   0,   0,   0],
       [171,   0,   0,   0,   0]]), 'forgetting_measure': [0.3966489, 0.11577271, -0.13093093]}","{""Every task  has these classes:"": [""right"", ""seven"", ""up"", ""bird"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f3b25690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f82ec550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42744781, 'precision': 0.243666666666666666, 'recall': 0.4, 'f1_score': 0.27168262653898769, 'confusion_matrix': array([[131,   0,   0,   0,   0],
       [164,   0,   0,   0,   0],
       [108,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0],
       [104,   0,   0,   0,   0]]), 'forgetting_measure': [0.4406202, 0.16423033, -0.19650191]}","{""Every task  has these classes:"": [""right"", ""seven"", ""up"", ""bird"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531bb63fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553179037d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36221249, 'precision': 0.235333333333333335, 'recall': 0.4, 'f1_score': 0.26005665722379603, 'confusion_matrix': array([[159,   0,   0,   0,   0],
       [222,   0,   0,   0,   0],
       [183,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [192,   0,   0,   0,   0]]), 'forgetting_measure': [0.3622125, 0.0, 0.0]}","{""Every task  has these classes:"": [""yes"", ""zero"", ""nine"", ""sheila"", ""bird""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531bb63fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553179037d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38488786, 'precision': 0.237, 'recall': 0.4, 'f1_score': 0.26244725738396624, 'confusion_matrix': array([[111,   0,   0,   0,   0],
       [141,   0,   0,   0,   0],
       [115,   0,   0,   0,   0],
       [104,   0,   0,   0,   0],
       [129,   0,   0,   0,   0]]), 'forgetting_measure': [0.38488784, 0.0, 0.0]}","{""Every task  has these classes:"": [""yes"", ""zero"", ""nine"", ""sheila"", ""bird""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186d2bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553180f0a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42152574, 'precision': 0.30568561872909699, 'recall': 0.40031291172595517, 'f1_score': 0.2680745308771721, 'confusion_matrix': array([[175,   0,   0,   1,   0],
       [181,   0,   0,   0,   0],
       [180,   0,   0,   0,   0],
       [137,   0,   0,   1,   0],
       [224,   0,   0,   1,   0]]), 'forgetting_measure': [0.41029268, -0.07695708, -0.005882268]}","{""Every task  has these classes:"": [""yes"", ""stop"", ""on"", ""nine"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186d2bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553180f0a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37074463, 'precision': 0.42604340567612685, 'recall': 0.40217391304347826, 'f1_score': 0.250386747351535074, 'confusion_matrix': array([[ 78,   0,   0,   0,   0],
       [114,   0,   0,   0,   0],
       [120,   0,   0,   0,   0],
       [ 91,   0,   0,   1,   0],
       [196,   0,   0,   0,   0]]), 'forgetting_measure': [0.3821714, 0.09408812, 0.0]}","{""Every task  has these classes:"": [""yes"", ""stop"", ""on"", ""nine"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528341e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527e24a990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4278193, 'precision': 0.34057971014492754, 'recall': 0.3999653048833377, 'f1_score': 0.26950164824510376, 'confusion_matrix': array([[  0,   0,   0,   0, 192],
       [  0,   0,   0,   1, 184],
       [  0,   0,   0,   0, 151],
       [  0,   0,   0,   1, 188],
       [  0,   0,   1,   0, 182]]), 'forgetting_measure': [0.42153269, -0.042566705, 0.0]}","{""Every task  has these classes:"": [""wow"", ""five"", ""go"", ""sheila"", ""three""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528341e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527e24a990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31627602, 'precision': 0.228000000000000004, 'recall': 0.4, 'f1_score': 0.24912280701754386, 'confusion_matrix': array([[  0,   0,   0,   0, 161],
       [  0,   0,   0,   0, 131],
       [  0,   0,   0,   0, 113],
       [  0,   0,   0,   0, 111],
       [  0,   0,   0,   0,  84]]), 'forgetting_measure': [0.316276026, 0.0, 0.0]}","{""Every task  has these classes:"": [""wow"", ""five"", ""go"", ""sheila"", ""three""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531790ca50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4119450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35059516, 'precision': 0.232, 'recall': 0.4, 'f1_score': 0.25517241379310346, 'confusion_matrix': array([[144,   0,   0,   0,   0],
       [196,   0,   0,   0,   0],
       [173,   0,   0,   0,   0],
       [193,   0,   0,   0,   0],
       [194,   0,   0,   0,   0]]), 'forgetting_measure': [0.34260289, -0.16813686, 0.14393593]}","{""Every task  has these classes:"": [""bird"", ""eight"", ""sheila"", ""three"", ""right""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531790ca50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4119450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35323944, 'precision': 0.23766666666666667, 'recall': 0.4, 'f1_score': 0.26339410939691445, 'confusion_matrix': array([[113,   0,   0,   0,   0],
       [136,   0,   0,   0,   0],
       [138,   0,   0,   0,   0],
       [109,   0,   0,   0,   0],
       [104,   0,   0,   0,   0]]), 'forgetting_measure': [0.34442214, -0.1831564, 0.1548032]}","{""Every task  has these classes:"": [""bird"", ""eight"", ""sheila"", ""three"", ""right""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186d6850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42f590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34153661, 'precision': 0.23188405797101449, 'recall': 0.39861111111111113, 'f1_score': 0.25494716618635927, 'confusion_matrix': array([[  0, 192,   2,   0,   0],
       [  0, 143,   1,   0,   0],
       [  0, 228,   0,   0,   0],
       [  0, 174,   0,   0,   0],
       [  0, 160,   0,   0,   0]]), 'forgetting_measure': [0.3088415, -0.76491266, 0.35619292]}","{""Every task  has these classes:"": [""sheila"", ""eight"", ""zero"", ""yes"", ""left""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186d6850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42f590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39688146, 'precision': 0.241999999999999996, 'recall': 0.4, 'f1_score': 0.26942148760330578, 'confusion_matrix': array([[  0,  99,   0,   0,   0],
       [  0, 126,   0,   0,   0],
       [  0, 132,   0,   0,   0],
       [  0, 106,   0,   0,   0],
       [  0, 137,   0,   0,   0]]), 'forgetting_measure': [0.3930574, -0.05942383, 0.056090705]}","{""Every task  has these classes:"": [""sheila"", ""eight"", ""zero"", ""yes"", ""left""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e51fdb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e54b5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37495626, 'precision': 0.234666666666666665, 'recall': 0.4, 'f1_score': 0.2590909090909091, 'confusion_matrix': array([[156,   0,   0,   0,   0],
       [196,   0,   0,   0,   0],
       [151,   0,   0,   0,   0],
       [235,   0,   0,   0,   0],
       [162,   0,   0,   0,   0]]), 'forgetting_measure': [0.36650902, -0.15219428, 0.1320908]}","{""Every task  has these classes:"": [""bird"", ""sheila"", ""off"", ""one"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e51fdb50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e54b5910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36471425, 'precision': 0.226666666666666665, 'recall': 0.4, 'f1_score': 0.247058823529411764, 'confusion_matrix': array([[ 80,   0,   0,   0,   0],
       [143,   0,   0,   0,   0],
       [108,   0,   0,   0,   0],
       [165,   0,   0,   0,   0],
       [104,   0,   0,   0,   0]]), 'forgetting_measure': [0.36066651, -0.07558068, 0.07026965]}","{""Every task  has these classes:"": [""bird"", ""sheila"", ""off"", ""one"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f3adfe10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e57e9990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33342305, 'precision': 0.23422222222222222, 'recall': 0.4, 'f1_score': 0.25844402277039847, 'confusion_matrix': array([[  0,   0,   0,   0, 146],
       [  0,   0,   0,   0, 251],
       [  0,   0,   0,   0, 216],
       [  0,   0,   0,   0, 133],
       [  0,   0,   0,   0, 154]]), 'forgetting_measure': [0.29858549, -1.0601219, 0.5145918]}","{""Every task  has these classes:"": [""two"", ""dog"", ""six"", ""eight"", ""five""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f3adfe10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e57e9990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37481071, 'precision': 0.24166666666666667, 'recall': 0.4, 'f1_score': 0.26896551724137931, 'confusion_matrix': array([[  0,   0,   0,   0, 110],
       [  0,   0,   0,   0, 132],
       [  0,   0,   0,   0, 138],
       [  0,   0,   0,   0,  95],
       [  0,   0,   0,   0, 125]]), 'forgetting_measure': [0.35168355, -0.45740905, 0.31385085]}","{""Every task  has these classes:"": [""two"", ""dog"", ""six"", ""eight"", ""five""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551decf1710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e7b21290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39498427, 'precision': 0.44077010192525483, 'recall': 0.40446023921433754, 'f1_score': 0.28244153114234119, 'confusion_matrix': array([[  0,   1,   1, 181,   0],
       [  0,   4,   0, 191,   0],
       [  0,   1,   0, 171,   2],
       [  2,   0,   0, 180,   1],
       [  0,   2,   0, 160,   3]]), 'forgetting_measure': [0.43575847, 0.26759204, -0.022305652]}","{""Every task  has these classes:"": [""go"", ""cat"", ""six"", ""right"", ""five""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551decf1710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e7b21290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40626244, 'precision': 0.239, 'recall': 0.4, 'f1_score': 0.26527196652719666, 'confusion_matrix': array([[  0,   0,   0, 150,   0],
       [  0,   0,   0, 113,   0],
       [  0,   0,   0, 114,   0],
       [  0,   0,   0, 117,   0],
       [  0,   0,   0, 106,   0]]), 'forgetting_measure': [0.43567383, 0.37439105, -0.5984426]}","{""Every task  has these classes:"": [""go"", ""cat"", ""six"", ""right"", ""five""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dc289990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d861d150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40780212, 'precision': 0.23459821428571429, 'recall': 0.39871794871794873, 'f1_score': 0.25893536121673004, 'confusion_matrix': array([[  0,   0,   0,   0, 225],
       [  1,   0,   0,   0, 208],
       [  0,   0,   0,   0, 134],
       [  2,   0,   0,   0, 174],
       [  1,   0,   0,   0, 155]]), 'forgetting_measure': [0.40782456, 0.0, 0.00032358515]}","{""Every task  has these classes:"": [""five"", ""up"", ""house"", ""marvel"", ""six""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dc289990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d861d150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38906362, 'precision': 0.24067226890756302, 'recall': 0.3967479674796748, 'f1_score': 0.26740947075208914, 'confusion_matrix': array([[  0,   0,   0,   0, 123],
       [  0,   0,   0,   0, 131],
       [  1,   0,   0,   0, 106],
       [  2,   0,   0,   0, 114],
       [  2,   0,   0,   0, 121]]), 'forgetting_measure': [0.38921688, 0.0, 0.002430043]}","{""Every task  has these classes:"": [""five"", ""up"", ""house"", ""marvel"", ""six""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317903290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f13b3a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4495561, 'precision': 0.30512333965844403, 'recall': 0.40173669467787114, 'f1_score': 0.30715763565972711, 'confusion_matrix': array([[188,  20,   0,   2,   0],
       [208,  27,   0,   3,   0],
       [138,  20,   0,   0,   0],
       [126,  14,   0,   0,   0],
       [139,  12,   0,   3,   0]]), 'forgetting_measure': [0.46477042, 0.0861936, 0.0]}","{""Every task  has these classes:"": [""left"", ""stop"", ""wow"", ""yes"", ""bed""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317903290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f13b3a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38080363, 'precision': 0.30031317754757889, 'recall': 0.40083056478405314, 'f1_score': 0.27548555599525128, 'confusion_matrix': array([[128,   1,   0,   0,   0],
       [166,   2,   0,   0,   0],
       [ 89,   1,   0,   0,   0],
       [ 96,   1,   0,   0,   0],
       [114,   2,   0,   0,   0]]), 'forgetting_measure': [0.40001215, 0.14405508, 0.0]}","{""Every task  has these classes:"": [""left"", ""stop"", ""wow"", ""yes"", ""bed""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e353d150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e375d690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38660396, 'precision': 0.236222222222222225, 'recall': 0.4, 'f1_score': 0.261335841956726256, 'confusion_matrix': array([[  0, 242,   0,   0,   0],
       [  0, 163,   0,   0,   0],
       [  0, 196,   0,   0,   0],
       [  0, 161,   0,   0,   0],
       [  0, 138,   0,   0,   0]]), 'forgetting_measure': [0.33160755, -1.253646, 0.5562746]}","{""Every task  has these classes:"": [""nine"", ""house"", ""down"", ""five"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e353d150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e375d690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43095249, 'precision': 0.241999999999999996, 'recall': 0.4, 'f1_score': 0.26942148760330578, 'confusion_matrix': array([[  0, 147,   0,   0,   0],
       [  0, 126,   0,   0,   0],
       [  0, 119,   0,   0,   0],
       [  0, 121,   0,   0,   0],
       [  0,  87,   0,   0,   0]]), 'forgetting_measure': [0.38343662, -0.77709436, 0.4372837]}","{""Every task  has these classes:"": [""nine"", ""house"", ""down"", ""five"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317907610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552debaf290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45410601, 'precision': 0.25873192436040044, 'recall': 0.39924528301886793, 'f1_score': 0.2907216494845361, 'confusion_matrix': array([[  0,   0,   0, 144,   0],
       [  0,   0,   0, 140,   0],
       [  0,   0,   0, 192,   0],
       [  1,   0,   0, 264,   0],
       [  0,   0,   0, 159,   0]]), 'forgetting_measure': [0.49524553, 0.48895183, -1.0955589]}","{""Every task  has these classes:"": [""down"", ""wow"", ""nine"", ""two"", ""four""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317907610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552debaf290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53472025, 'precision': 0.263, 'recall': 0.4, 'f1_score': 0.29581749049429658, 'confusion_matrix': array([[  0,   0,   0,  79,   0],
       [  0,   0,   0,  82,   0],
       [  0,   0,   0, 160,   0],
       [  0,   0,   0, 189,   0],
       [  0,   0,   0,  90,   0]]), 'forgetting_measure': [0.62267543, 0.6242747, -1.6615187]}","{""Every task  has these classes:"": [""down"", ""wow"", ""nine"", ""two"", ""four""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552deac0dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da963150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46224995, 'precision': 0.25822222222222222, 'recall': 0.4, 'f1_score': 0.2901893287435456, 'confusion_matrix': array([[  0,   0, 171,   0,   0],
       [  0,   0, 173,   0,   0],
       [  0,   0, 262,   0,   0],
       [  0,   0, 147,   0,   0],
       [  0,   0, 147,   0,   0]]), 'forgetting_measure': [0.5262117, 0.5882229, -1.4284984]}","{""Every task  has these classes:"": [""zero"", ""on"", ""go"", ""no"", ""eight""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552deac0dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da963150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45957286, 'precision': 0.256999999999999995, 'recall': 0.4, 'f1_score': 0.28871595330739299, 'confusion_matrix': array([[  0,   0, 105,   0,   0],
       [  0,   0, 168,   0,   0],
       [  0,   0, 171,   0,   0],
       [  0,   0,  76,   0,   0],
       [  0,   0,  80,   0,   0]]), 'forgetting_measure': [0.52219324, 0.58306986, -1.3984835]}","{""Every task  has these classes:"": [""zero"", ""on"", ""go"", ""no"", ""eight""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e54aad90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e6f19990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34188711, 'precision': 0.3305122494432071, 'recall': 0.399720315280956, 'f1_score': 0.2552078916240766, 'confusion_matrix': array([[  0,   0,   0,   0, 163],
       [  0,   0,   0,   0, 185],
       [  0,   0,   0,   0, 243],
       [  0,   0,   0,   1, 170],
       [  0,   0,   0,   1, 137]]), 'forgetting_measure': [0.34522046, 0.03443048, 0.0]}","{""Every task  has these classes:"": [""marvel"", ""on"", ""right"", ""yes"", ""nine""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e54aad90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e6f19990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34338325, 'precision': 0.236, 'recall': 0.4, 'f1_score': 0.261016949152542375, 'confusion_matrix': array([[  0,   0,   0,   0,  91],
       [  0,   0,   0,   0, 142],
       [  0,   0,   0,   0, 149],
       [  0,   0,   0,   0, 110],
       [  0,   0,   0,   0, 108]]), 'forgetting_measure': [0.34338325, 0.0, 0.0]}","{""Every task  has these classes:"": [""marvel"", ""on"", ""right"", ""yes"", ""nine""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7383dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e1361990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44080637, 'precision': 0.244222222222222225, 'recall': 0.4, 'f1_score': 0.2724294813466788, 'confusion_matrix': array([[199,   0,   0,   0,   0],
       [202,   0,   0,   0,   0],
       [157,   0,   0,   0,   0],
       [169,   0,   0,   0,   0],
       [173,   0,   0,   0,   0]]), 'forgetting_measure': [0.44248591, 0.020778956, -0.021219883]}","{""Every task  has these classes:"": [""down"", ""marvel"", ""bed"", ""bird"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7383dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e1361990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40064257, 'precision': 0.232, 'recall': 0.4, 'f1_score': 0.25517241379310346, 'confusion_matrix': array([[ 96,   0,   0,   0,   0],
       [162,   0,   0,   0,   0],
       [ 98,   0,   0,   0,   0],
       [138,   0,   0,   0,   0],
       [106,   0,   0,   0,   0]]), 'forgetting_measure': [0.40344418, 0.04131237, -0.04309263]}","{""Every task  has these classes:"": [""down"", ""marvel"", ""bed"", ""bird"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f09c5710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e91a5690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37310433, 'precision': 0.35763658287560348, 'recall': 0.38287645904464161, 'f1_score': 0.31579646517012306, 'confusion_matrix': array([[  0,   3,   9,   7, 163],
       [  3,  10,  25,  27, 233],
       [  2,   2,  13,  18,  89],
       [  0,   0,   3,   5,  81],
       [  0,  16,  16,  26, 149]]), 'forgetting_measure': [0.34608821, -0.24793433, -0.0472156]}","{""Every task  has these classes:"": [""four"", ""tree"", ""no"", ""up"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f09c5710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e91a5690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39290201, 'precision': 0.534524049285685, 'recall': 0.4165753903748457, 'f1_score': 0.33697232602546117, 'confusion_matrix': array([[  2,   3,   6,   7, 103],
       [  1,   9,  12,  15, 118],
       [  0,   8,  14,  14,  86],
       [  0,   0,   5,   7,  88],
       [  0,   5,   5,   8,  84]]), 'forgetting_measure': [0.39817352, 0.097351946, -0.12729496]}","{""Every task  has these classes:"": [""four"", ""tree"", ""no"", ""up"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ce326fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6c1ba10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44737807, 'precision': 0.2905118778280543, 'recall': 0.40395322641205813, 'f1_score': 0.29847018130324767, 'confusion_matrix': array([[  0, 182,  13,   0,   0],
       [  0, 193,  13,   0,   0],
       [  0, 166,  15,   0,   0],
       [  0, 137,  16,   0,   0],
       [  0, 154,  11,   0,   0]]), 'forgetting_measure': [0.46931453, 0.1152072, 0.0157601]}","{""Every task  has these classes:"": [""sheila"", ""marvel"", ""dog"", ""bird"", ""one""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ce326fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6c1ba10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45593597, 'precision': 0.30897887323943663, 'recall': 0.41174834897462635, 'f1_score': 0.30409069731324738, 'confusion_matrix': array([[  0, 103,   6,   0,   0],
       [  0, 132,   5,   0,   0],
       [  0,  95,  10,   0,   0],
       [  0, 121,   5,   0,   0],
       [  0, 117,   6,   0,   0]]), 'forgetting_measure': [0.47186406, 0.08522316, 0.005814447]}","{""Every task  has these classes:"": [""sheila"", ""marvel"", ""dog"", ""bird"", ""one""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d9586ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f123a390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40571242, 'precision': 0.3764823717948718, 'recall': 0.39781447117750833, 'f1_score': 0.33418552176091533, 'confusion_matrix': array([[  1,   4,   5,  87,  49],
       [ 13,  10,   7,  91,  45],
       [  3,   0,   0,  99,  82],
       [  1,   2,   0,  76,  54],
       [  6,   9,   2, 159,  95]]), 'forgetting_measure': [0.309944485, -1.6269515, 0.24390692]}","{""Every task  has these classes:"": [""house"", ""four"", ""stop"", ""nine"", ""zero""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d9586ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f123a390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43359258, 'precision': 0.4973597924018092, 'recall': 0.43291499023559936, 'f1_score': 0.3705657807134724, 'confusion_matrix': array([[ 4,  0,  3, 63, 44],
       [ 0,  5,  0, 44, 35],
       [ 2,  4,  2, 69, 62],
       [ 0,  1,  2, 76, 43],
       [ 5,  2,  2, 71, 61]]), 'forgetting_measure': [0.39403347, -0.6129526, 0.38083705]}","{""Every task  has these classes:"": [""house"", ""four"", ""stop"", ""nine"", ""zero""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d9864b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c18a2e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3804822, 'precision': 0.23866666666666667, 'recall': 0.4, 'f1_score': 0.26480446927374302, 'confusion_matrix': array([[174,   0,   0,   0,   0],
       [165,   0,   0,   0,   0],
       [183,   0,   0,   0,   0],
       [201,   0,   0,   0,   0],
       [177,   0,   0,   0,   0]]), 'forgetting_measure': [0.39074692, 0.16143996, -0.19252044]}","{""Every task  has these classes:"": [""stop"", ""marvel"", ""eight"", ""bird"", ""three""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d9864b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c18a2e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38347684, 'precision': 0.246, 'recall': 0.4, 'f1_score': 0.27479674796747968, 'confusion_matrix': array([[138,   0,   0,   0,   0],
       [108,   0,   0,   0,   0],
       [137,   0,   0,   0,   0],
       [103,   0,   0,   0,   0],
       [114,   0,   0,   0,   0]]), 'forgetting_measure': [0.39887345, 0.23225725, -0.30251962]}","{""Every task  has these classes:"": [""stop"", ""marvel"", ""eight"", ""bird"", ""three""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553198fa710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317910190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5264226, 'precision': 0.30332022869336303, 'recall': 0.3949811927527493, 'f1_score': 0.29987156482881986, 'confusion_matrix': array([[  1,   2, 152,   1,   0],
       [  1,   0, 130,   0,   1],
       [  2,   3, 274,   1,   5],
       [  3,   2, 179,   0,   2],
       [  4,   0, 136,   0,   1]]), 'forgetting_measure': [0.4616369, -0.3714252, 0.0]}","{""Every task  has these classes:"": [""off"", ""marvel"", ""nine"", ""left"", ""seven""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553198fa710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317910190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52829794, 'precision': 0.4646464646464647, 'recall': 0.3987749287749288, 'f1_score': 0.3010081278124673, 'confusion_matrix': array([[  0,   0,  81,   0,   0],
       [  0,   0,  80,   0,   1],
       [  0,   1, 192,   0,   2],
       [  0,   0, 107,   1,   0],
       [  1,   0, 134,   0,   0]]), 'forgetting_measure': [0.52287398, -0.041101996, 0.030551426]}","{""Every task  has these classes:"": [""off"", ""marvel"", ""nine"", ""left"", ""seven""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b4319d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317910950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45723803, 'precision': 0.42678505484957098, 'recall': 0.40559986470130814, 'f1_score': 0.35195845050986348, 'confusion_matrix': array([[ 12,   9,   1, 111,   6],
       [ 13,  13,   0, 167,   3],
       [  9,   9,   5, 143,   5],
       [ 13,  17,  10, 216,   9],
       [  8,   4,   6, 107,   4]]), 'forgetting_measure': [0.46050833, 0.17530647, -0.37947708]}","{""Every task  has these classes:"": [""cat"", ""four"", ""right"", ""wow"", ""bird""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b4319d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317910950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48087083, 'precision': 0.35729080491466743, 'recall': 0.4160341828425804, 'f1_score': 0.34991275702030576, 'confusion_matrix': array([[ 10,  10,   0,  71,   0],
       [ 10,  19,   5, 105,   3],
       [  6,  13,   0,  76,   0],
       [  8,  12,   4, 133,   2],
       [ 12,  12,   1,  88,   0]]), 'forgetting_measure': [0.54664574, 0.4276452, -0.4997775]}","{""Every task  has these classes:"": [""cat"", ""four"", ""right"", ""wow"", ""bird""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531c33c9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b432410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4665375, 'precision': 0.29598923485216611, 'recall': 0.399693865536324, 'f1_score': 0.30692992644212156, 'confusion_matrix': array([[  0, 173,   6,   1,   0],
       [  0, 275,   9,   1,   0],
       [  0, 140,   5,   4,   0],
       [  0, 136,   6,   0,   0],
       [  0, 139,   5,   0,   0]]), 'forgetting_measure': [0.43583588, -0.19527332, 0.0]}","{""Every task  has these classes:"": [""on"", ""happy"", ""cat"", ""go"", ""sheila""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531c33c9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b432410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53821744, 'precision': 0.264, 'recall': 0.4, 'f1_score': 0.29696969696969697, 'confusion_matrix': array([[  0,  78,   0,   0,   0],
       [  0, 192,   0,   0,   0],
       [  0, 140,   0,   0,   0],
       [  0, 110,   0,   0,   0],
       [  0,  80,   0,   0,   0]]), 'forgetting_measure': [0.53821744, 0.0, 0.0]}","{""Every task  has these classes:"": [""on"", ""happy"", ""cat"", ""go"", ""sheila""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553169ca8d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2f30c50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43636532, 'precision': 0.39907228963934825, 'recall': 0.40019003110285377, 'f1_score': 0.35264019633137224, 'confusion_matrix': array([[ 20, 179,   6,  13,  20],
       [ 13, 168,   2,  25,  21],
       [ 11,  85,   3,  11,  14],
       [ 12, 110,   6,   7,  13],
       [  8, 110,   8,  17,  18]]), 'forgetting_measure': [0.47232432, 0.60794026, -2.0908706]}","{""Every task  has these classes:"": [""up"", ""go"", ""six"", ""no"", ""on""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553169ca8d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2f30c50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43636724, 'precision': 0.419797849368868, 'recall': 0.39796394511464777, 'f1_score': 0.35633065494284268, 'confusion_matrix': array([[ 13, 106,   5,  10,   7],
       [ 14, 107,   6,  16,  10],
       [  8,  77,   5,   7,  10],
       [  9,  68,   2,  10,   9],
       [  6,  82,   0,   8,   5]]), 'forgetting_measure': [0.52383537, 0.64456874, -1.3471957]}","{""Every task  has these classes:"": [""up"", ""go"", ""six"", ""no"", ""on""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b432790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f6bee5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50000827, 'precision': 0.4966170948486579, 'recall': 0.4869437734907353, 'f1_score': 0.4761406151834532, 'confusion_matrix': array([[115,  19,  37,  24,   9],
       [ 69,  48,  48,  14,  26],
       [ 57,  25,  53,   9,  48],
       [ 75,  10,  28,  18,  18],
       [ 42,  15,  47,  10,  36]]), 'forgetting_measure': [0.4830269, 0.030544372, -0.24868213]}","{""Every task  has these classes:"": [""marvel"", ""sheila"", ""dog"", ""five"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b432790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f6bee5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39956578, 'precision': 0.40493028450315515, 'recall': 0.3997861060725948, 'f1_score': 0.38403671713594924, 'confusion_matrix': array([[75, 23, 29,  5, 12],
       [49, 20, 24,  3, 13],
       [68, 19,  8, 13, 13],
       [45, 15, 24, 10, 15],
       [51, 16, 24, 10, 16]]), 'forgetting_measure': [0.37680532, -0.394991, 0.28945455]}","{""Every task  has these classes:"": [""marvel"", ""sheila"", ""dog"", ""five"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f3472010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155305076150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4512745, 'precision': 0.3715829089357088, 'recall': 0.39562683794637004, 'f1_score': 0.31524461019417742, 'confusion_matrix': array([[  9,   4,   2,   3, 150],
       [ 11,   6,   9,   2, 150],
       [ 10,   8,   5,   5, 172],
       [  7,   6,   6,   1, 115],
       [ 10,   4,  12,   5, 188]]), 'forgetting_measure': [0.46354837, 0.38122895, -1.0064183]}","{""Every task  has these classes:"": [""yes"", ""sheila"", ""nine"", ""eight"", ""four""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f3472010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155305076150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44178904, 'precision': 0.4146103896103896, 'recall': 0.4030950095926444, 'f1_score': 0.31888484606485065, 'confusion_matrix': array([[  5,   1,   8,   0,  76],
       [  8,   1,   2,   1,  86],
       [  9,   3,   7,   2, 129],
       [  7,   3,   1,   1,  99],
       [ 11,   3,   2,   0, 135]]), 'forgetting_measure': [0.50510616, 0.56031513, -1.1327561]}","{""Every task  has these classes:"": [""yes"", ""sheila"", ""nine"", ""eight"", ""four""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e42312d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d8285f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40729424, 'precision': 0.3367188204207572, 'recall': 0.384708908453088, 'f1_score': 0.32354068102392488, 'confusion_matrix': array([[154,   9,  26,   0,  24],
       [113,   2,  17,   0,  21],
       [153,   9,  17,   0,  20],
       [101,   1,  19,   0,  18],
       [157,   3,  16,   0,  20]]), 'forgetting_measure': [0.3617081, -0.44871277, 0.035696723]}","{""Every task  has these classes:"": [""three"", ""bed"", ""no"", ""eight"", ""one""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e42312d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d8285f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45451925, 'precision': 0.35589449998575863, 'recall': 0.4247660843509724, 'f1_score': 0.35953361692947626, 'confusion_matrix': array([[100,   0,  17,   0,  15],
       [ 90,   0,  11,   0,  25],
       [ 84,   0,  23,   0,  21],
       [ 63,   0,   9,   0,   8],
       [ 86,   0,  23,   0,  25]]), 'forgetting_measure': [0.45347033, 0.15555859, -0.383131]}","{""Every task  has these classes:"": [""three"", ""bed"", ""no"", ""eight"", ""one""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f343f5d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e4a839d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41239671, 'precision': 0.29287518508840693, 'recall': 0.39480225988700567, 'f1_score': 0.30492073021590734, 'confusion_matrix': array([[ 19,   0, 153,   5,   0],
       [ 10,   0, 192,   2,   0],
       [ 26,   0, 195,   4,   0],
       [ 21,   0, 146,   0,   0],
       [ 10,   0, 115,   2,   0]]), 'forgetting_measure': [0.43176895, 0.5440463, -1.8364578]}","{""Every task  has these classes:"": [""on"", ""nine"", ""two"", ""cat"", ""stop""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f343f5d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e4a839d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44986155, 'precision': 0.25, 'recall': 0.4, 'f1_score': 0.28, 'confusion_matrix': array([[  0,   0, 126,   0,   0],
       [  0,   0, 116,   0,   0],
       [  0,   0, 150,   0,   0],
       [  0,   0, 113,   0,   0],
       [  0,   0,  95,   0,   0]]), 'forgetting_measure': [0.48272128, 0.34867996, -0.53534347]}","{""Every task  has these classes:"": [""on"", ""nine"", ""two"", ""cat"", ""stop""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f2bb8550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e4cf5410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46525617, 'precision': 0.30454540942435404, 'recall': 0.40874450415241816, 'f1_score': 0.32623512498495876, 'confusion_matrix': array([[  0,  31,   0, 159,   0],
       [  0,  31,   0, 147,   0],
       [  0,  19,   0, 120,   0],
       [  0,  33,   0, 220,   0],
       [  0,  17,   0, 123,   0]]), 'forgetting_measure': [0.47031454, 0.0064769983, 0.043466557]}","{""Every task  has these classes:"": [""three"", ""on"", ""right"", ""four"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f2bb8550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e4cf5410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42695923, 'precision': 0.2863157894736842, 'recall': 0.39990450725744843, 'f1_score': 0.30189107004696188, 'confusion_matrix': array([[  0,  11,   0, 132,   0],
       [  0,   4,   0, 115,   0],
       [  0,   3,   0,  81,   0],
       [  0,   6,   0, 170,   0],
       [  0,   6,   0,  72,   0]]), 'forgetting_measure': [0.41569084, -0.07467657, -0.006863789]}","{""Every task  has these classes:"": [""three"", ""on"", ""right"", ""four"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e62dae10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1e6a350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55944512, 'precision': 0.543979040761219, 'recall': 0.42794594742256075, 'f1_score': 0.3491062507195646, 'confusion_matrix': array([[259,   3,   1,   4,   0],
       [108,   1,   2,   0,   0],
       [178,   0,  28,   0,   1],
       [139,   0,  11,   2,   1],
       [124,   0,  35,   1,   2]]), 'forgetting_measure': [0.48675896, -0.27563164, -0.16396692]}","{""Every task  has these classes:"": [""on"", ""happy"", ""wow"", ""tree"", ""down""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e62dae10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1e6a350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45133118, 'precision': 0.31176966700596189, 'recall': 0.4116635397123202, 'f1_score': 0.32276129833825129, 'confusion_matrix': array([[141,   0,  13,   2,   0],
       [ 77,   0,  10,   0,   0],
       [102,   0,  19,   1,   1],
       [ 86,   0,  12,   0,   1],
       [123,   0,  11,   1,   0]]), 'forgetting_measure': [0.46146528, -0.0072595105, 0.12985322]}","{""Every task  has these classes:"": [""on"", ""happy"", ""wow"", ""tree"", ""down""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eacd9bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eac72890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52435897, 'precision': 0.5161875487299241, 'recall': 0.5217432630041997, 'f1_score': 0.4924536117615255, 'confusion_matrix': array([[ 94,  66,  18,   1,   6],
       [ 35, 128,  32,   0,   8],
       [ 54, 101,  42,   0,   4],
       [ 19,  65,  33,   0,  14],
       [ 10,  82,  41,   0,  47]]), 'forgetting_measure': [0.4475043, -0.58939785, 0.15555592]}","{""Every task  has these classes:"": [""one"", ""tree"", ""six"", ""left"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eacd9bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eac72890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43238035, 'precision': 0.37200583990239693, 'recall': 0.4074513946533465, 'f1_score': 0.37727672168479774, 'confusion_matrix': array([[25, 63, 34,  0, 13],
       [27, 67, 29,  0,  4],
       [41, 62, 26,  0, 13],
       [26, 36, 18,  0, 17],
       [25, 43, 17,  0, 14]]), 'forgetting_measure': [0.42901618, 0.16830753, -0.4577218]}","{""Every task  has these classes:"": [""one"", ""tree"", ""six"", ""left"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb2f9990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea822950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50013278, 'precision': 0.4815393683215218, 'recall': 0.43135845720100762, 'f1_score': 0.37005660468401418, 'confusion_matrix': array([[ 16,  10,   0, 166,   3],
       [ 10,  18,   0, 158,   9],
       [  9,   2,   0,  77,   2],
       [  2,  13,   1, 240,   5],
       [  1,  11,   0, 137,  10]]), 'forgetting_measure': [0.4787448, 0.0064647924, -0.24470073]}","{""Every task  has these classes:"": [""on"", ""left"", ""marvel"", ""four"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb2f9990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea822950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55380843, 'precision': 0.35570806976094986, 'recall': 0.40440694789081887, 'f1_score': 0.3315995737205541, 'confusion_matrix': array([[  6,   3,   0,  65,   4],
       [  6,   2,   0, 167,  11],
       [  4,   1,   0,  60,   1],
       [  7,   6,   0, 177,   5],
       [  6,   1,   0,  66,   2]]), 'forgetting_measure': [0.55277733, -0.031624258, 0.05280976]}","{""Every task  has these classes:"": [""on"", ""left"", ""marvel"", ""four"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e5fed610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e038e190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40925432, 'precision': 0.33434618975376358, 'recall': 0.39283223539745278, 'f1_score': 0.3374327938953967, 'confusion_matrix': array([[134,  20,   0,  53,   0],
       [140,  17,   0,  43,   0],
       [ 96,  11,   0,  38,   0],
       [147,  21,   0,  51,   1],
       [ 91,  13,   0,  24,   0]]), 'forgetting_measure': [0.39296819, -0.053085063, -0.13961224]}","{""Every task  has these classes:"": [""one"", ""seven"", ""stop"", ""zero"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e5fed610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e038e190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44784797, 'precision': 0.30110397946084723, 'recall': 0.40343859649122806, 'f1_score': 0.33098597446095878, 'confusion_matrix': array([[108,   0,   0,  44,   0],
       [ 81,   0,   0,  35,   0],
       [ 67,   0,   0,  43,   0],
       [104,   0,   0,  46,   0],
       [ 50,   0,   0,  22,   0]]), 'forgetting_measure': [0.40915823, -0.09420896, -0.334961]}","{""Every task  has these classes:"": [""one"", ""seven"", ""stop"", ""zero"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb984650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d422ff50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41434496, 'precision': 0.28662285505659, 'recall': 0.39743240172688026, 'f1_score': 0.2976596224335585, 'confusion_matrix': array([[  0,   0, 170,   0,  12],
       [  0,   0, 178,   0,  15],
       [  0,   2, 196,   0,  18],
       [  0,   0, 138,   0,   8],
       [  0,   2, 148,   0,  13]]), 'forgetting_measure': [0.38476151, -0.24017547, 0.0]}","{""Every task  has these classes:"": [""happy"", ""zero"", ""left"", ""sheila"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb984650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d422ff50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35305656, 'precision': 0.33288590604026845, 'recall': 0.40064646464646466, 'f1_score': 0.26159768289264693, 'confusion_matrix': array([[  0,   1, 110,   0,   0],
       [  0,   2, 148,   0,   0],
       [  0,   1,  98,   0,   0],
       [  0,   0, 145,   0,   0],
       [  0,   0,  95,   0,   0]]), 'forgetting_measure': [0.35911475, 0.05711139, 0.0]}","{""Every task  has these classes:"": [""happy"", ""zero"", ""left"", ""sheila"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e02b12d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f21b0710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43193577, 'precision': 0.28877613342729622, 'recall': 0.38758708565285875, 'f1_score': 0.28298569207300158, 'confusion_matrix': array([[  1, 165,   1,   7,   0],
       [  5, 208,   5,   8,   0],
       [  0, 159,   0,   4,   0],
       [  2, 162,   3,   2,   0],
       [  1, 166,   0,   1,   0]]), 'forgetting_measure': [0.35818909, -0.80272686, 0.114756174]}","{""Every task  has these classes:"": [""happy"", ""no"", ""one"", ""tree"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e02b12d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f21b0710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50335847, 'precision': 0.30434292160180485, 'recall': 0.40172575916809557, 'f1_score': 0.29922077922077922, 'confusion_matrix': array([[  2,  99,   0,   0,   0],
       [  2, 177,   0,   0,   0],
       [  1,  88,   0,   0,   0],
       [  2, 112,   0,   0,   0],
       [  2, 115,   0,   0,   0]]), 'forgetting_measure': [0.5262494, 0.2108133, -0.26753473]}","{""Every task  has these classes:"": [""happy"", ""no"", ""one"", ""tree"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552df7ef050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d13ff990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4972117, 'precision': 0.4708008212359354, 'recall': 0.4753723654307801, 'f1_score': 0.41632314441163944, 'confusion_matrix': array([[ 10,  33,   4, 110,   2],
       [  9,  87,  12,  94,   1],
       [  9,  71,  22,  88,   0],
       [ 14,  31,   2, 157,   0],
       [  7,  33,   2, 102,   0]]), 'forgetting_measure': [0.41163899, -0.39217252, -0.3079041]}","{""Every task  has these classes:"": [""left"", ""up"", ""sheila"", ""stop"", ""dog""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552df7ef050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d13ff990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36735426, 'precision': 0.43546479859549452, 'recall': 0.3886975986975987, 'f1_score': 0.33500271128130378, 'confusion_matrix': array([[ 4, 46,  3, 81,  1],
       [ 3, 34,  2, 87,  0],
       [ 3, 55, 19, 79,  0],
       [ 0, 39,  4, 47,  0],
       [ 4, 39,  4, 46,  0]]), 'forgetting_measure': [0.36503616, -0.083514355, 0.11526471]}","{""Every task  has these classes:"": [""left"", ""up"", ""sheila"", ""stop"", ""dog""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea029fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1898110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49302266, 'precision': 0.732832312085266, 'recall': 0.44267259169717326, 'f1_score': 0.4062511066027776, 'confusion_matrix': array([[  1,  69,   4,   0,  21],
       [  0, 160,  38,   1,  29],
       [  0, 149,  57,   0,  19],
       [  0, 138,  17,  10,  29],
       [  0, 115,   9,   3,  31]]), 'forgetting_measure': [0.4728129, 0.32787552, -1.3062887]}","{""Every task  has these classes:"": [""right"", ""seven"", ""on"", ""off"", ""stop""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea029fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1898110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43501678, 'precision': 0.33409320155887822, 'recall': 0.3990389347228253, 'f1_score': 0.34278694087924823, 'confusion_matrix': array([[  0,  68,  18,   5,  17],
       [  0, 102,  20,   4,  21],
       [  0,  96,  21,   2,  22],
       [  0,  73,  16,   0,  10],
       [  0,  76,  13,   0,  16]]), 'forgetting_measure': [0.41226081, 0.07114523, -0.4994466]}","{""Every task  has these classes:"": [""right"", ""seven"", ""on"", ""off"", ""stop""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1639990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d8755090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52508415, 'precision': 0.56893922318438843, 'recall': 0.4975747010604613, 'f1_score': 0.461240391113832, 'confusion_matrix': array([[  1,  28,  17,  70,  23],
       [  0,  59,  23,  87,  23],
       [  1,  18,  37,  78,  19],
       [  0,  19,  20, 158,  15],
       [  0,  19,  25, 122,  38]]), 'forgetting_measure': [0.48193063, 0.07101559, -0.6471844]}","{""Every task  has these classes:"": [""bed"", ""six"", ""marvel"", ""no"", ""eight""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1639990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d8755090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45107294, 'precision': 0.36540991464107163, 'recall': 0.40369765512025792, 'f1_score': 0.36537644262716297, 'confusion_matrix': array([[ 0, 25,  2, 77, 10],
       [ 0, 26, 13, 92, 18],
       [ 0, 17,  7, 47, 25],
       [ 1, 30, 15, 83, 11],
       [ 0, 18, 10, 55, 18]]), 'forgetting_measure': [0.40760418, -0.443335, 0.17911367]}","{""Every task  has these classes:"": [""bed"", ""six"", ""marvel"", ""no"", ""eight""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1c6fc90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d11abcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4822804, 'precision': 0.3690296386520503, 'recall': 0.39028759173920465, 'f1_score': 0.3135962691363905, 'confusion_matrix': array([[  6,   1,   1, 178,   0],
       [ 13,   1,   0, 172,   3],
       [  5,   0,   0, 110,   2],
       [ 20,   9,   2, 256,   1],
       [ 11,   0,   1, 105,   3]]), 'forgetting_measure': [0.46990846, 0.08432015, -0.33434516]}","{""Every task  has these classes:"": [""left"", ""four"", ""up"", ""sheila"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1c6fc90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d11abcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52692617, 'precision': 0.4239462016327236, 'recall': 0.39806664276240574, 'f1_score': 0.33409784820857237, 'confusion_matrix': array([[  5,   1,   0,  69,   3],
       [  6,   1,   0, 104,   0],
       [  5,   0,   1,  57,   0],
       [ 16,   3,   5, 194,   1],
       [ 11,   1,   1, 114,   2]]), 'forgetting_measure': [0.5239702, 0.023212994, -0.07555214]}","{""Every task  has these classes:"": [""left"", ""four"", ""up"", ""sheila"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d16cc750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d15320d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34464766, 'precision': 0.30756161968727414, 'recall': 0.40548318433375906, 'f1_score': 0.29834634556791974, 'confusion_matrix': array([[106,   0,  27,   0,   2],
       [196,   2,  51,   6,   6],
       [119,   3,  38,   1,   1],
       [135,   3,  42,   0,   1],
       [119,   3,  33,   6,   0]]), 'forgetting_measure': [0.34676036, 0.057648752, -0.07652225]}","{""Every task  has these classes:"": [""cat"", ""up"", ""sheila"", ""seven"", ""on""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d16cc750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d15320d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37340639, 'precision': 0.42356394129979035, 'recall': 0.394671423642935, 'f1_score': 0.30260937961580016, 'confusion_matrix': array([[ 88,   3,  17,   0,   3],
       [136,   3,  30,   0,   2],
       [ 97,   1,  18,   0,   1],
       [ 83,   0,  23,   1,   2],
       [ 73,   0,  17,   2,   0]]), 'forgetting_measure': [0.39702083, 0.20301919, -0.058302134]}","{""Every task  has these classes:"": [""cat"", ""up"", ""sheila"", ""seven"", ""on""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c2dc2010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c2f486d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50033308, 'precision': 0.5307598357668872, 'recall': 0.49788797690275526, 'f1_score': 0.4962375701902602, 'confusion_matrix': array([[ 64,  56,  30,   6,   9],
       [ 30, 145,  30,  15,  39],
       [ 24, 113,  40,   5,  21],
       [  8,  76,  12,  16,  14],
       [ 20,  62,  26,   7,  32]]), 'forgetting_measure': [0.47581263, 0.33348456, -1.4008332]}","{""Every task  has these classes:"": [""house"", ""up"", ""bird"", ""zero"", ""five""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c2dc2010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c2f486d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4153691, 'precision': 0.391393351173218, 'recall': 0.3970711586125935, 'f1_score': 0.37446122198990563, 'confusion_matrix': array([[19, 60,  9, 12, 11],
       [27, 75, 19,  8, 13],
       [41, 63, 21,  4, 16],
       [24, 53, 12,  4, 12],
       [17, 50, 13,  7, 10]]), 'forgetting_measure': [0.44183527, 0.25007293, -0.22912847]}","{""Every task  has these classes:"": [""house"", ""up"", ""bird"", ""zero"", ""five""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d08dee90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc168e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4210577, 'precision': 0.28183445190156599, 'recall': 0.39872041796727988, 'f1_score': 0.27070674961778908, 'confusion_matrix': array([[  0,   1,   0, 147,   0],
       [  0,   1,   1, 237,   0],
       [  0,   0,   0, 195,   0],
       [  0,   2,   0, 187,   0],
       [  0,   1,   0, 128,   0]]), 'forgetting_measure': [0.41539253, -0.039452367, 0.0]}","{""Every task  has these classes:"": [""cat"", ""five"", ""zero"", ""left"", ""no""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d08dee90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc168e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31663727, 'precision': 0.228999999999999998, 'recall': 0.4, 'f1_score': 0.250655021834061134, 'confusion_matrix': array([[  0,   0,   0, 131,   0],
       [  0,   0,   0, 136,   0],
       [  0,   0,   0, 126,   0],
       [  0,   0,   0,  87,   0],
       [  0,   0,   0, 120,   0]]), 'forgetting_measure': [0.31663727, 0.0, 0.0]}","{""Every task  has these classes:"": [""cat"", ""five"", ""zero"", ""left"", ""no""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c0f41bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155295f53410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4033459, 'precision': 0.2371523915461624, 'recall': 0.39880952380952382, 'f1_score': 0.26260543580131209, 'confusion_matrix': array([[  0, 168,   0,   0,   0],
       [  1, 167,   0,   0,   0],
       [  0, 199,   0,   0,   0],
       [  0, 185,   0,   0,   0],
       [  0, 180,   0,   0,   0]]), 'forgetting_measure': [0.39040166, -0.09396188, -0.0146511905]}","{""Every task  has these classes:"": [""cat"", ""three"", ""right"", ""stop"", ""bed""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c0f41bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155295f53410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45577965, 'precision': 0.25066666666666667, 'recall': 0.4, 'f1_score': 0.28085106382978724, 'confusion_matrix': array([[  0, 131,   0,   0,   0],
       [  0, 152,   0,   0,   0],
       [  0, 111,   0,   0,   0],
       [  0,  94,   0,   0,   0],
       [  0, 112,   0,   0,   0]]), 'forgetting_measure': [0.46806685, 0.13750891, -0.15943228]}","{""Every task  has these classes:"": [""cat"", ""three"", ""right"", ""stop"", ""bed""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c019a010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bfcf9b10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5178681, 'precision': 0.5351401178668696, 'recall': 0.4883476971410871, 'f1_score': 0.47027934152423494, 'confusion_matrix': array([[122,  75,  13,   6,  13],
       [ 72, 131,  17,   3,  11],
       [ 62,  77,  14,   9,   7],
       [ 28,  69,  10,  10,   4],
       [ 48,  61,   9,   2,  27]]), 'forgetting_measure': [0.50298316, -0.09125054, 0.032180652]}","{""Every task  has these classes:"": [""seven"", ""marvel"", ""two"", ""bird"", ""off""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c019a010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bfcf9b10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46410094, 'precision': 0.40796466572638636, 'recall': 0.43770392364989396, 'f1_score': 0.3967487494499133, 'confusion_matrix': array([[73, 45, 12,  4,  5],
       [34, 68, 12,  7, 15],
       [47, 50, 10,  5, 10],
       [20, 36,  9,  1,  2],
       [53, 58, 10,  5,  9]]), 'forgetting_measure': [0.48833118, 0.16311829, -0.08857671]}","{""Every task  has these classes:"": [""seven"", ""marvel"", ""two"", ""bird"", ""off""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ca0de350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc2e00d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41656688, 'precision': 0.244222222222222225, 'recall': 0.4, 'f1_score': 0.2724294813466788, 'confusion_matrix': array([[199,   0,   0,   0,   0],
       [233,   0,   0,   0,   0],
       [217,   0,   0,   0,   0],
       [121,   0,   0,   0,   0],
       [130,   0,   0,   0,   0]]), 'forgetting_measure': [0.45085148, 0.4100192, -0.6949704]}","{""Every task  has these classes:"": [""on"", ""bed"", ""off"", ""tree"", ""bird""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ca0de350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc2e00d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3876912, 'precision': 0.240999999999999995, 'recall': 0.4, 'f1_score': 0.26804979253112033, 'confusion_matrix': array([[123,   0,   0,   0,   0],
       [176,   0,   0,   0,   0],
       [115,   0,   0,   0,   0],
       [ 92,   0,   0,   0,   0],
       [ 94,   0,   0,   0,   0]]), 'forgetting_measure': [0.42407189, 0.48708504, -0.9496409]}","{""Every task  has these classes:"": [""on"", ""bed"", ""off"", ""tree"", ""bird""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bb3c1bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c0d25510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44086301, 'precision': 0.24822222222222222, 'recall': 0.4, 'f1_score': 0.27770814682184422, 'confusion_matrix': array([[217,   0,   0,   0,   0],
       [170,   0,   0,   0,   0],
       [145,   0,   0,   0,   0],
       [135,   0,   0,   0,   0],
       [233,   0,   0,   0,   0]]), 'forgetting_measure': [0.5021054, 0.60815567, -1.552034]}","{""Every task  has these classes:"": [""house"", ""four"", ""seven"", ""nine"", ""cat""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bb3c1bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c0d25510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46141873, 'precision': 0.24933333333333333, 'recall': 0.4, 'f1_score': 0.27914438502673797, 'confusion_matrix': array([[148,   0,   0,   0,   0],
       [ 89,   0,   0,   0,   0],
       [138,   0,   0,   0,   0],
       [101,   0,   0,   0,   0],
       [124,   0,   0,   0,   0]]), 'forgetting_measure': [0.48841445, 0.28080112, -0.39043596]}","{""Every task  has these classes:"": [""house"", ""four"", ""seven"", ""nine"", ""cat""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b59ea010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b5359450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4666466, 'precision': 0.252000000000000005, 'recall': 0.4, 'f1_score': 0.28253968253968255, 'confusion_matrix': array([[234,   0,   0,   0,   0],
       [177,   0,   0,   0,   0],
       [131,   0,   0,   0,   0],
       [182,   0,   0,   0,   0],
       [176,   0,   0,   0,   0]]), 'forgetting_measure': [0.4757849, 0.0994071, -0.110379614]}","{""Every task  has these classes:"": [""happy"", ""bed"", ""bird"", ""no"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b59ea010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b5359450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39102536, 'precision': 0.24133333333333333, 'recall': 0.4, 'f1_score': 0.26850828729281769, 'confusion_matrix': array([[124,   0,   0,   0,   0],
       [104,   0,   0,   0,   0],
       [110,   0,   0,   0,   0],
       [121,   0,   0,   0,   0],
       [141,   0,   0,   0,   0]]), 'forgetting_measure': [0.39764966, 0.100545734, -0.11178526]}","{""Every task  has these classes:"": [""happy"", ""bed"", ""bird"", ""no"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b5de2e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b5eae150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42648187, 'precision': 0.24177777777777778, 'recall': 0.4, 'f1_score': 0.26911764705882353, 'confusion_matrix': array([[188,   0,   0,   0,   0],
       [202,   0,   0,   0,   0],
       [154,   0,   0,   0,   0],
       [167,   0,   0,   0,   0],
       [189,   0,   0,   0,   0]]), 'forgetting_measure': [0.40845672, -0.2594085, 0.20597647]}","{""Every task  has these classes:"": [""no"", ""bed"", ""dog"", ""nine"", ""up""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b5de2e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b5eae150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43041397, 'precision': 0.24033333333333333, 'recall': 0.4, 'f1_score': 0.26712898751733704, 'confusion_matrix': array([[121,   0,   0,   0,   0],
       [154,   0,   0,   0,   0],
       [ 87,   0,   0,   0,   0],
       [129,   0,   0,   0,   0],
       [109,   0,   0,   0,   0]]), 'forgetting_measure': [0.41196681, -0.26108575, 0.2070325]}","{""Every task  has these classes:"": [""no"", ""bed"", ""dog"", ""nine"", ""up""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b7b801d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bb351690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4170339, 'precision': 0.24555555555555556, 'recall': 0.4, 'f1_score': 0.27420814479638008, 'confusion_matrix': array([[205,   0,   0,   0,   0],
       [133,   0,   0,   0,   0],
       [150,   0,   0,   0,   0],
       [148,   0,   0,   0,   0],
       [264,   0,   0,   0,   0]]), 'forgetting_measure': [0.37808634, -0.65610087, 0.39617205]}","{""Every task  has these classes:"": [""happy"", ""bird"", ""four"", ""yes"", ""six""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b7b801d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bb351690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37563842, 'precision': 0.23966666666666667, 'recall': 0.4, 'f1_score': 0.26620305980528512, 'confusion_matrix': array([[119,   0,   0,   0,   0],
       [119,   0,   0,   0,   0],
       [124,   0,   0,   0,   0],
       [ 97,   0,   0,   0,   0],
       [141,   0,   0,   0,   0]]), 'forgetting_measure': [0.33965942, -0.7728591, 0.43593937]}","{""Every task  has these classes:"": [""happy"", ""bird"", ""four"", ""yes"", ""six""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfa69450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cb9386d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38636312, 'precision': 0.24266666666666667, 'recall': 0.4, 'f1_score': 0.27032967032967033, 'confusion_matrix': array([[192,   0,   0,   0,   0],
       [240,   0,   0,   0,   0],
       [132,   0,   0,   0,   0],
       [198,   0,   0,   0,   0],
       [138,   0,   0,   0,   0]]), 'forgetting_measure': [0.3863631, 0.0, 0.0]}","{""Every task  has these classes:"": [""tree"", ""no"", ""left"", ""stop"", ""down""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfa69450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cb9386d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46262453, 'precision': 0.252000000000000005, 'recall': 0.4, 'f1_score': 0.28253968253968255, 'confusion_matrix': array([[156,   0,   0,   0,   0],
       [108,   0,   0,   0,   0],
       [111,   0,   0,   0,   0],
       [114,   0,   0,   0,   0],
       [111,   0,   0,   0,   0]]), 'forgetting_measure': [0.46262456, 0.0, 0.0]}","{""Every task  has these classes:"": [""tree"", ""no"", ""left"", ""stop"", ""down""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553198e0ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317910610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33231786, 'precision': 0.22984409799554566, 'recall': 0.4, 'f1_score': 0.25193798449612404, 'confusion_matrix': array([[134,   0,   0,   0,   0],
       [199,   0,   1,   0,   0],
       [268,   0,   0,   1,   0],
       [147,   0,   0,   0,   0],
       [150,   0,   0,   0,   0]]), 'forgetting_measure': [0.33676594, 0.09757004, -0.108119234]}","{""Every task  has these classes:"": [""nine"", ""marvel"", ""four"", ""one"", ""down""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553198e0ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317910610>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33648973, 'precision': 0.233, 'recall': 0.4, 'f1_score': 0.25665236051502146, 'confusion_matrix': array([[ 99,   0,   0,   0,   0],
       [117,   0,   0,   0,   0],
       [189,   0,   0,   0,   0],
       [ 96,   0,   0,   0,   0],
       [ 99,   0,   0,   0,   0]]), 'forgetting_measure': [0.3433352, 0.1432751, -0.16723582]}","{""Every task  has these classes:"": [""nine"", ""marvel"", ""four"", ""one"", ""down""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317575dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317907710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3394653, 'precision': 0.2375, 'recall': 0.39881656804733727, 'f1_score': 0.26309859154929578, 'confusion_matrix': array([[  0,   0,   1,   0, 155],
       [  0,   0,   1,   0, 165],
       [  0,   1,   0,   0, 254],
       [  0,   0,   0,   0, 154],
       [  0,   0,   0,   1, 168]]), 'forgetting_measure': [0.319630255, -0.32235035, 0.11138689]}","{""Every task  has these classes:"": [""happy"", ""six"", ""right"", ""left"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317575dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317907710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.30903699, 'precision': 0.23, 'recall': 0.4, 'f1_score': 0.25217391304347826, 'confusion_matrix': array([[  0,   0,   0,   0, 115],
       [  0,   0,   0,   0, 123],
       [  0,   0,   0,   0, 168],
       [  0,   0,   0,   0, 104],
       [  0,   0,   0,   0,  90]]), 'forgetting_measure': [0.30114227, -0.2341667, 0.18973668]}","{""Every task  has these classes:"": [""happy"", ""six"", ""right"", ""left"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531a3d8610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553169ece90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4395021, 'precision': 0.241648106904231624, 'recall': 0.39893617021276594, 'f1_score': 0.26887661141804788, 'confusion_matrix': array([[187,   0,   1,   0,   0],
       [131,   0,   0,   0,   0],
       [166,   0,   0,   0,   0],
       [270,   0,   0,   0,   0],
       [144,   0,   0,   1,   0]]), 'forgetting_measure': [0.43749258, 0.06279621, -0.16109264]}","{""Every task  has these classes:"": [""seven"", ""six"", ""on"", ""house"", ""nine""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531a3d8610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553169ece90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5032049, 'precision': 0.25533333333333333, 'recall': 0.4, 'f1_score': 0.2866840731070496, 'confusion_matrix': array([[166,   0,   0,   0,   0],
       [ 86,   0,   0,   0,   0],
       [100,   0,   0,   0,   0],
       [159,   0,   0,   0,   0],
       [ 89,   0,   0,   0,   0]]), 'forgetting_measure': [0.50566788, 0.02417313, -0.024771946]}","{""Every task  has these classes:"": [""seven"", ""six"", ""on"", ""house"", ""nine""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531fa6b6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b4322d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40391808, 'precision': 0.26241758241758242, 'recall': 0.39639318885448914, 'f1_score': 0.27015750447690103, 'confusion_matrix': array([[  0,   4,  14,   0, 196],
       [  0,   0,   7,   0, 155],
       [  0,   0,   7,   0, 163],
       [  0,   1,  13,   0, 188],
       [  0,   1,   8,   0, 143]]), 'forgetting_measure': [0.39728068, -0.09996637, 0.09000221]}","{""Every task  has these classes:"": [""three"", ""wow"", ""nine"", ""happy"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531fa6b6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b4322d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38891554, 'precision': 0.29134271099744246, 'recall': 0.38613052365861354, 'f1_score': 0.28065100883742879, 'confusion_matrix': array([[  0,   0,  12,   0, 109],
       [  0,   2,  10,   0, 114],
       [  0,   2,   2,   0,  85],
       [  0,   2,  12,   0, 120],
       [  0,   4,  10,   0, 116]]), 'forgetting_measure': [0.36969402, -0.3687045, 0.2904895]}","{""Every task  has these classes:"": [""three"", ""wow"", ""nine"", ""happy"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155546fc1bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42e8d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4544325, 'precision': 0.254626532887402456, 'recall': 0.4, 'f1_score': 0.28581436077057794, 'confusion_matrix': array([[245,   0,   0,   0,   0],
       [162,   0,   0,   0,   1],
       [203,   1,   0,   0,   0],
       [164,   0,   1,   0,   0],
       [123,   0,   0,   0,   0]]), 'forgetting_measure': [0.464223, 0.111161664, -0.12506399]}","{""Every task  has these classes:"": [""right"", ""marvel"", ""go"", ""wow"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155546fc1bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42e8d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44567175, 'precision': 0.245, 'recall': 0.4, 'f1_score': 0.27346938775510203, 'confusion_matrix': array([[135,   0,   0,   0,   0],
       [121,   0,   0,   0,   0],
       [125,   0,   0,   0,   0],
       [117,   0,   0,   0,   0],
       [102,   0,   0,   0,   0]]), 'forgetting_measure': [0.4501522, 0.053732585, -0.05678372]}","{""Every task  has these classes:"": [""right"", ""marvel"", ""go"", ""wow"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531699f310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42ecd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38447958, 'precision': 0.43251670378619155, 'recall': 0.3996920873612603, 'f1_score': 0.25797940830181116, 'confusion_matrix': array([[  0,   0, 214,   0,   0],
       [  0,   1, 189,   0,   0],
       [  0,   0, 146,   1,   0],
       [  0,   0, 148,   0,   0],
       [  0,   0, 201,   0,   0]]), 'forgetting_measure': [0.38824477, 0.07771229, -0.103459895]}","{""Every task  has these classes:"": [""zero"", ""tree"", ""two"", ""bed"", ""wow""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531699f310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42ecd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33336548, 'precision': 0.23, 'recall': 0.4, 'f1_score': 0.25217391304347826, 'confusion_matrix': array([[  0,   0, 161,   0,   0],
       [  0,   0,  88,   0,   0],
       [  0,   0,  90,   0,   0],
       [  0,   0, 129,   0,   0],
       [  0,   0, 132,   0,   0]]), 'forgetting_measure': [0.33451949, 0.025736282, -0.026416136]}","{""Every task  has these classes:"": [""zero"", ""tree"", ""two"", ""bed"", ""wow""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531448d9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f27f1b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3107371, 'precision': 0.4279017857142857, 'recall': 0.4008, 'f1_score': 0.25056522197205302, 'confusion_matrix': array([[125,   0,   0,   0,   0],
       [200,   0,   0,   1,   0],
       [206,   0,   0,   0,   0],
       [117,   0,   1,   0,   0],
       [248,   1,   0,   0,   1]]), 'forgetting_measure': [0.32021492, 0.103907645, 0.0320353]}","{""Every task  has these classes:"": [""eight"", ""four"", ""three"", ""cat"", ""on""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531448d9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f27f1b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.08914447, 'precision': 0.218666666666666668, 'recall': 0.4, 'f1_score': 0.23414634146341464, 'confusion_matrix': array([[ 56,   0,   0,   0,   0],
       [192,   0,   0,   0,   0],
       [127,   0,   0,   0,   0],
       [ 91,   0,   0,   0,   0],
       [134,   0,   0,   0,   0]]), 'forgetting_measure': [0.28477046, -0.15479474, 0.13404524]}","{""Every task  has these classes:"": [""eight"", ""four"", ""three"", ""cat"", ""on""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0119c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db6ad2d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49683954, 'precision': 0.25644444444444444, 'recall': 0.4, 'f1_score': 0.2880415944540728, 'confusion_matrix': array([[  0, 163,   0,   0,   0],
       [  0, 254,   0,   0,   0],
       [  0, 167,   0,   0,   0],
       [  0, 172,   0,   0,   0],
       [  0, 144,   0,   0,   0]]), 'forgetting_measure': [0.5270312, 0.27696133, -0.3830519]}","{""Every task  has these classes:"": [""go"", ""dog"", ""on"", ""happy"", ""eight""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0119c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db6ad2d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5684929, 'precision': 0.26166666666666667, 'recall': 0.4, 'f1_score': 0.29426751592356689, 'confusion_matrix': array([[  0, 119,   0,   0,   0],
       [  0, 185,   0,   0,   0],
       [  0, 142,   0,   0,   0],
       [  0,  91,   0,   0,   0],
       [  0,  63,   0,   0,   0]]), 'forgetting_measure': [0.61632816, 0.344694, -0.5260046]}","{""Every task  has these classes:"": [""go"", ""dog"", ""on"", ""happy"", ""eight""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0cade90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0dcef10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.436288, 'precision': 0.248660714285714286, 'recall': 0.39818181818181818, 'f1_score': 0.27813620071684588, 'confusion_matrix': array([[  0,   0, 166,   0,   0],
       [  0,   0, 172,   0,   0],
       [  1,   0, 218,   0,   1],
       [  0,   1, 185,   0,   0],
       [  1,   0, 155,   0,   0]]), 'forgetting_measure': [0.41313186, -0.16852155, 0.009501055]}","{""Every task  has these classes:"": [""one"", ""dog"", ""no"", ""happy"", ""yes""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0cade90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0dcef10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40312601, 'precision': 0.25033333333333333, 'recall': 0.4, 'f1_score': 0.28042609853528628, 'confusion_matrix': array([[  0,   0, 114,   0,   0],
       [  0,   0, 122,   0,   0],
       [  0,   0, 151,   0,   0],
       [  0,   0, 103,   0,   0],
       [  0,   0, 110,   0,   0]]), 'forgetting_measure': [0.40095949, -0.032342855, 0.031329565]}","{""Every task  has these classes:"": [""one"", ""dog"", ""no"", ""happy"", ""yes""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0e0f590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e12adfd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4548975, 'precision': 0.29933333333333333, 'recall': 0.4, 'f1_score': 0.3304097266146602, 'confusion_matrix': array([[158,  79,   0,   0,   0],
       [140,  70,   0,   0,   0],
       [121,  69,   0,   0,   0],
       [103,  43,   0,   0,   0],
       [ 78,  39,   0,   0,   0]]), 'forgetting_measure': [0.43800108, -0.1064896, 0.0]}","{""Every task  has these classes:"": [""left"", ""no"", ""yes"", ""bird"", ""go""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0e0f590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e12adfd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5046788, 'precision': 0.30400000000000001, 'recall': 0.4, 'f1_score': 0.33468719292499182, 'confusion_matrix': array([[112,  56,   0,   0,   0],
       [ 96,  48,   0,   0,   0],
       [ 61,  33,   0,   0,   0],
       [ 57,  26,   0,   0,   0],
       [ 74,  37,   0,   0,   0]]), 'forgetting_measure': [0.5005148, -0.020784535, 0.0]}","{""Every task  has these classes:"": [""left"", ""no"", ""yes"", ""bird"", ""go""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b42e490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2c31ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31311892, 'precision': 0.25816554809843401, 'recall': 0.40085470085470086, 'f1_score': 0.2458457711442786, 'confusion_matrix': array([[  0,   0,   1, 224,   0],
       [  0,   0,   2, 190,   0],
       [  0,   0,   1, 233,   0],
       [  0,   0,   0, 111,   0],
       [  0,   0,   2, 136,   0]]), 'forgetting_measure': [0.32485817, 0.14103113, 0.0]}","{""Every task  has these classes:"": [""no"", ""dog"", ""down"", ""house"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b42e490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2c31ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31312697, 'precision': 0.227000000000000003, 'recall': 0.4, 'f1_score': 0.24757709251101322, 'confusion_matrix': array([[  0,   0,   0, 153,   0],
       [  0,   0,   0, 131,   0],
       [  0,   0,   0, 145,   0],
       [  0,   0,   0,  81,   0],
       [  0,   0,   0,  90,   0]]), 'forgetting_measure': [0.31312696, 0.0, 0.0]}","{""Every task  has these classes:"": [""no"", ""dog"", ""down"", ""house"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e1bce590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f7fc8550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41406601, 'precision': 0.31732686738061562, 'recall': 0.39785441298226022, 'f1_score': 0.33751930565518453, 'confusion_matrix': array([[ 11, 106,   0,  34,   0],
       [ 26, 148,   0,  49,   0],
       [ 22, 137,   0,  42,   0],
       [ 20, 116,   0,  46,   0],
       [ 19,  93,   0,  31,   0]]), 'forgetting_measure': [0.35889683, -0.5340155, 0.01722744]}","{""Every task  has these classes:"": [""yes"", ""bed"", ""dog"", ""eight"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e1bce590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f7fc8550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43524968, 'precision': 0.33754742547425475, 'recall': 0.40691262806492458, 'f1_score': 0.34483389504092442, 'confusion_matrix': array([[ 7, 68,  0, 23,  0],
       [12, 90,  0, 34,  0],
       [ 3, 89,  0, 37,  0],
       [ 7, 95,  0, 44,  0],
       [ 7, 58,  0, 26,  0]]), 'forgetting_measure': [0.44047628, 0.10243852, -0.15561485]}","{""Every task  has these classes:"": [""yes"", ""bed"", ""dog"", ""eight"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ecb9d510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9f6d0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4727673, 'precision': 0.4121004507851599, 'recall': 0.4192323017560438, 'f1_score': 0.38961929541331587, 'confusion_matrix': array([[  8,   9,  45,  74,  14],
       [  4,   6,  29,  85,  20],
       [ 13,   9,  51,  96,  35],
       [  4,  18,  49, 161,  17],
       [  8,   6,  37,  86,  16]]), 'forgetting_measure': [0.46438615, 0.03232177, -0.1650808]}","{""Every task  has these classes:"": [""dog"", ""zero"", ""six"", ""four"", ""marvel""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ecb9d510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9f6d0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45642404, 'precision': 0.38284794362432416, 'recall': 0.39446908831343934, 'f1_score': 0.36380668179093397, 'confusion_matrix': array([[  0,   1,  20,  56,  10],
       [  5,   9,  28,  67,  11],
       [  4,   7,  33,  90,  17],
       [  5,  12,  35, 100,  15],
       [  1,   2,  19,  47,   6]]), 'forgetting_measure': [0.49069856, 0.3294162, -0.45500702]}","{""Every task  has these classes:"": [""dog"", ""zero"", ""six"", ""four"", ""marvel""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bb7559d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bbda9b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37368445, 'precision': 0.3358591458702341, 'recall': 0.39573183772405248, 'f1_score': 0.31798868493547339, 'confusion_matrix': array([[  0, 103,   5,  30,   0],
       [  0, 125,   4,  50,   0],
       [  0, 129,   6,  55,   0],
       [  0, 149,   2,  50,   0],
       [  0, 136,   5,  51,   0]]), 'forgetting_measure': [0.37940347, 0.11299397, -0.14695953]}","{""Every task  has these classes:"": [""down"", ""three"", ""five"", ""wow"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bb7559d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bbda9b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44181718, 'precision': 0.3467297084318361, 'recall': 0.39982108778625954, 'f1_score': 0.3223135276154587, 'confusion_matrix': array([[ 0, 93,  0, 35,  0],
       [ 0, 91,  3, 34,  0],
       [ 0, 88,  5, 38,  0],
       [ 0, 85,  5, 30,  0],
       [ 0, 66,  2, 25,  0]]), 'forgetting_measure': [0.45922167, -0.03836832, 0.2678826]}","{""Every task  has these classes:"": [""down"", ""three"", ""five"", ""wow"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553175c8090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531ce38110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43898783, 'precision': 0.241379310344827586, 'recall': 0.39893048128342244, 'f1_score': 0.26850828729281769, 'confusion_matrix': array([[186,   0,   0,   1,   0],
       [197,   0,   0,   0,   0],
       [198,   0,   0,   0,   0],
       [178,   0,   0,   0,   0],
       [140,   0,   0,   0,   0]]), 'forgetting_measure': [0.43095794, -0.013627561, -0.076012075]}","{""Every task  has these classes:"": [""eight"", ""zero"", ""stop"", ""six"", ""up""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553175c8090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531ce38110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36142108, 'precision': 0.234999999999999996, 'recall': 0.4, 'f1_score': 0.25957446808510638, 'confusion_matrix': array([[105,   0,   0,   0,   0],
       [144,   0,   0,   0,   0],
       [103,   0,   0,   0,   0],
       [131,   0,   0,   0,   0],
       [117,   0,   0,   0,   0]]), 'forgetting_measure': [0.37806877, 0.2804708, -0.38979766]}","{""Every task  has these classes:"": [""eight"", ""zero"", ""stop"", ""six"", ""up""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552daf4b090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f15f2f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36420749, 'precision': 0.26678334195139414, 'recall': 0.3879593336599706, 'f1_score': 0.2726660544842363, 'confusion_matrix': array([[140,   2,  12,   1,   2],
       [202,   0,  31,   0,   7],
       [196,   1,  10,   0,   1],
       [139,   1,   5,   0,   7],
       [134,   3,   4,   2,   0]]), 'forgetting_measure': [0.36921072, 0.0032015212, 0.082565494]}","{""Every task  has these classes:"": [""cat"", ""zero"", ""right"", ""off"", ""go""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552daf4b090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f15f2f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35375817, 'precision': 0.5897883597883598, 'recall': 0.39650050542551162, 'f1_score': 0.29703074817416954, 'confusion_matrix': array([[101,   0,   6,   0,   8],
       [139,   2,   9,   0,   3],
       [143,   0,  11,   0,   1],
       [ 85,   2,  10,   2,   0],
       [ 72,   0,   6,   0,   0]]), 'forgetting_measure': [0.3452025, 0.019471541, -0.2199934]}","{""Every task  has these classes:"": [""cat"", ""zero"", ""right"", ""off"", ""go""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553198a73d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531815bfd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42109321, 'precision': 0.24449388209121245, 'recall': 0.39900497512437812, 'f1_score': 0.27272727272727272, 'confusion_matrix': array([[  0,   0,   0,   0, 228],
       [  0,   0,   0,   0, 198],
       [  0,   0,   0,   0, 148],
       [  0,   0,   0,   0, 125],
       [  0,   1,   0,   0, 200]]), 'forgetting_measure': [0.4071317, -0.10110592, 0.0]}","{""Every task  has these classes:"": [""nine"", ""tree"", ""wow"", ""left"", ""five""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553198a73d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531815bfd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37088948, 'precision': 0.232, 'recall': 0.4, 'f1_score': 0.25517241379310346, 'confusion_matrix': array([[  0,   0,   0,   0, 141],
       [  0,   0,   0,   0, 144],
       [  0,   0,   0,   0, 135],
       [  0,   0,   0,   0,  84],
       [  0,   0,   0,   0,  96]]), 'forgetting_measure': [0.3708895, 0.0, 0.0]}","{""Every task  has these classes:"": [""nine"", ""tree"", ""wow"", ""left"", ""five""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552da3c54d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1176390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46955497, 'precision': 0.254727474972191326, 'recall': 0.39919028340080971, 'f1_score': 0.28586387434554973, 'confusion_matrix': array([[  0,   0,   0, 150,   0],
       [  0,   0,   0, 184,   0],
       [  0,   0,   0, 152,   0],
       [  1,   0,   0, 246,   0],
       [  0,   0,   0, 167,   0]]), 'forgetting_measure': [0.52643682, 0.55016863, -1.2840041]}","{""Every task  has these classes:"": [""happy"", ""four"", ""right"", ""zero"", ""five""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552da3c54d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1176390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4534907, 'precision': 0.257666666666666665, 'recall': 0.4, 'f1_score': 0.28952134540750324, 'confusion_matrix': array([[  0,   0,   0, 101,   0],
       [  0,   0,   0, 115,   0],
       [  0,   0,   0, 124,   0],
       [  0,   0,   0, 173,   0],
       [  0,   0,   0,  87,   0]]), 'forgetting_measure': [0.50781096, 0.52941865, -1.125031]}","{""Every task  has these classes:"": [""happy"", ""four"", ""right"", ""zero"", ""five""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186fbad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b431950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40447384, 'precision': 0.24177777777777778, 'recall': 0.4, 'f1_score': 0.26911764705882353, 'confusion_matrix': array([[  0,   0,   0,   0, 150],
       [  0,   0,   0,   0, 186],
       [  0,   0,   0,   0, 231],
       [  0,   0,   0,   0, 145],
       [  0,   0,   0,   0, 188]]), 'forgetting_measure': [0.4509907, 0.55599886, -1.2522465]}","{""Every task  has these classes:"": [""left"", ""four"", ""stop"", ""five"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553186fbad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b431950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42649066, 'precision': 0.248, 'recall': 0.4, 'f1_score': 0.27741935483870968, 'confusion_matrix': array([[  0,   0,   0,   0, 102],
       [  0,   0,   0,   0,  90],
       [  0,   0,   0,   0, 153],
       [  0,   0,   0,   0, 111],
       [  0,   0,   0,   0, 144]]), 'forgetting_measure': [0.48202653, 0.5907514, -1.4435027]}","{""Every task  has these classes:"": [""left"", ""four"", ""stop"", ""five"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1b71a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531ed78090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3610648, 'precision': 0.336741246451264, 'recall': 0.40299406952513493, 'f1_score': 0.3076234692940593, 'confusion_matrix': array([[  1, 103,   0,   0, 146],
       [  4,  51,   1,   1,  88],
       [  5,  68,   1,   1, 148],
       [  1,  36,   0,   0,  77],
       [  2,  54,   2,   0, 110]]), 'forgetting_measure': [0.34254312, -0.27301866, 0.122720055]}","{""Every task  has these classes:"": [""six"", ""bed"", ""go"", ""house"", ""seven""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1b71a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531ed78090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43602508, 'precision': 0.36923711340206188, 'recall': 0.4169651156785788, 'f1_score': 0.33086675874884843, 'confusion_matrix': array([[ 2, 48,  0,  0, 78],
       [ 0, 40,  1,  0, 62],
       [ 0, 36,  0,  0, 99],
       [ 2, 26,  0,  0, 65],
       [ 1, 44,  0,  0, 96]]), 'forgetting_measure': [0.39362034, -0.41340706, 0.120124504]}","{""Every task  has these classes:"": [""six"", ""bed"", ""go"", ""house"", ""seven""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddb61a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f254f0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43542671, 'precision': 0.2875644129881418, 'recall': 0.39515584673416714, 'f1_score': 0.32045970308817452, 'confusion_matrix': array([[  0,   0,  97,  61,   0],
       [  0,   0, 106,  62,   0],
       [  0,   0, 128,  91,   0],
       [  0,   0, 112,  72,   0],
       [  0,   0, 103,  68,   0]]), 'forgetting_measure': [0.3807528, -0.25005847, -0.32584053]}","{""Every task  has these classes:"": [""down"", ""left"", ""happy"", ""six"", ""one""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ddb61a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f254f0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35408368, 'precision': 0.27722513987574228, 'recall': 0.3959546925566343, 'f1_score': 0.30884410373813407, 'confusion_matrix': array([[ 0,  0, 68, 46,  0],
       [ 0,  0, 86, 51,  0],
       [ 0,  0, 58, 45,  0],
       [ 0,  0, 77, 55,  0],
       [ 0,  0, 62, 52,  0]]), 'forgetting_measure': [0.38773217, 0.4588062, -0.70197105]}","{""Every task  has these classes:"": [""down"", ""left"", ""happy"", ""six"", ""one""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e11b9b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e1830ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38806167, 'precision': 0.53482142857142855, 'recall': 0.40230792776247322, 'f1_score': 0.26389611008649548, 'confusion_matrix': array([[156,   0,   0,   0,   0],
       [132,   1,   0,   1,   1],
       [193,   0,   0,   0,   0],
       [241,   0,   0,   1,   0],
       [174,   0,   0,   0,   0]]), 'forgetting_measure': [0.41042906, 0.15944137, 0.0]}","{""Every task  has these classes:"": [""bird"", ""four"", ""sheila"", ""down"", ""nine""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e11b9b50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e1830ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35000682, 'precision': 0.231, 'recall': 0.4, 'f1_score': 0.25367965367965368, 'confusion_matrix': array([[ 93,   0,   0,   0,   0],
       [102,   0,   0,   0,   0],
       [147,   0,   0,   0,   0],
       [162,   0,   0,   0,   0],
       [ 96,   0,   0,   0,   0]]), 'forgetting_measure': [0.35000683, 0.0, 0.0]}","{""Every task  has these classes:"": [""bird"", ""four"", ""sheila"", ""down"", ""nine""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd4e1690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552de9f0410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45622174, 'precision': 0.28333333333333334, 'recall': 0.38944844124700239, 'f1_score': 0.31572178770356448, 'confusion_matrix': array([[  0, 107,   0,   0,  56],
       [  0, 172,   0,   0,  86],
       [  0, 112,   0,   0,  65],
       [  0, 109,   0,   0,  54],
       [  0, 100,   0,   0,  39]]), 'forgetting_measure': [0.34451078, -1.1744614, 0.013721661]}","{""Every task  has these classes:"": [""three"", ""six"", ""one"", ""house"", ""no""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd4e1690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552de9f0410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46115954, 'precision': 0.2905, 'recall': 0.38951142985208427, 'f1_score': 0.32248512522485125, 'confusion_matrix': array([[  0,  59,   0,   0,  30],
       [  0, 129,   0,   0,  65],
       [  0,  69,   0,   0,  42],
       [  0,  77,   0,   0,  37],
       [  0,  66,   0,   0,  26]]), 'forgetting_measure': [0.33186616, -1.4513413, -0.015822342]}","{""Every task  has these classes:"": [""three"", ""six"", ""one"", ""house"", ""no""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1575650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2235090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38814076, 'precision': 0.23642458100558659, 'recall': 0.39757575757575757, 'f1_score': 0.261509433962264146, 'confusion_matrix': array([[  0,   0,   0,   0, 160],
       [  0,   0,   1,   0, 156],
       [  0,   1,   0,   1, 170],
       [  0,   0,   0,   0, 246],
       [  0,   0,   0,   2, 163]]), 'forgetting_measure': [0.37425095, -0.027460404, -0.17929047]}","{""Every task  has these classes:"": [""off"", ""seven"", ""one"", ""left"", ""eight""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1575650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2235090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4054405, 'precision': 0.239, 'recall': 0.4, 'f1_score': 0.26527196652719666, 'confusion_matrix': array([[  0,   0,   0,   0,  64],
       [  0,   0,   0,   0, 152],
       [  0,   0,   0,   0, 104],
       [  0,   0,   0,   0, 163],
       [  0,   0,   0,   0, 117]]), 'forgetting_measure': [0.40969202, 0.06082506, -0.06476436]}","{""Every task  has these classes:"": [""off"", ""seven"", ""one"", ""left"", ""eight""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f186e010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552df6f8cd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4584411, 'precision': 0.33040368306299013, 'recall': 0.39876196715892858, 'f1_score': 0.34382142870983622, 'confusion_matrix': array([[  0, 104,   0,  47,   5],
       [  0, 175,   0,  70,  19],
       [  0, 106,   0,  44,   9],
       [  0, 111,   0,  45,  14],
       [  0, 103,   0,  38,  10]]), 'forgetting_measure': [0.38416192, -0.55719626, -0.061402857]}","{""Every task  has these classes:"": [""bird"", ""sheila"", ""five"", ""cat"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f186e010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552df6f8cd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4579279, 'precision': 0.30700000000000001, 'recall': 0.40589970501474925, 'f1_score': 0.3406904805154562, 'confusion_matrix': array([[  0,  60,   0,  30,   0],
       [  0, 132,   0,  66,   0],
       [  0,  74,   0,  37,   0],
       [  0,  72,   0,  41,   0],
       [  0,  62,   0,  26,   0]]), 'forgetting_measure': [0.39747981, -0.4591465, 0.0]}","{""Every task  has these classes:"": [""bird"", ""sheila"", ""five"", ""cat"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd5a1750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dcd21b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39426651, 'precision': 0.43073926540313092, 'recall': 0.40915766640294722, 'f1_score': 0.3409014293119757, 'confusion_matrix': array([[ 38,   0, 181,  29,   1],
       [ 58,   6, 116,  39,   4],
       [ 27,   5, 105,  11,   1],
       [ 36,   2,  76,  19,   2],
       [ 37,   4,  62,  38,   3]]), 'forgetting_measure': [0.36806693, -0.30346543, 0.10684426]}","{""Every task  has these classes:"": [""bird"", ""five"", ""go"", ""no"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd5a1750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dcd21b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36756634, 'precision': 0.42043881353517633, 'recall': 0.3926344998232591, 'f1_score': 0.3347518414697467, 'confusion_matrix': array([[27,  3, 92, 15,  1],
       [30,  0, 79, 18,  0],
       [27,  2, 70, 12,  1],
       [36,  2, 50, 11,  1],
       [25,  4, 74, 16,  4]]), 'forgetting_measure': [0.35971752, -0.23280013, 0.2580909]}","{""Every task  has these classes:"": [""bird"", ""five"", ""go"", ""no"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552da9bdc10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d67d44d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3821279, 'precision': 0.23688888888888889, 'recall': 0.4, 'f1_score': 0.262288930581613514, 'confusion_matrix': array([[  0,   0,   0, 150,   0],
       [  0,   0,   0, 194,   0],
       [  0,   0,   0, 208,   0],
       [  0,   0,   0, 166,   0],
       [  0,   0,   0, 182,   0]]), 'forgetting_measure': [0.35503281, -0.52430964, 0.3439653]}","{""Every task  has these classes:"": [""five"", ""bed"", ""two"", ""wow"", ""bird""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552da9bdc10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d67d44d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.32292777, 'precision': 0.219666666666666666, 'recall': 0.4, 'f1_score': 0.23581183611532625, 'confusion_matrix': array([[  0,   0,   0, 119,   0],
       [  0,   0,   0, 151,   0],
       [  0,   0,   0, 125,   0],
       [  0,   0,   0,  59,   0],
       [  0,   0,   0, 146,   0]]), 'forgetting_measure': [0.29385757, -0.92917985, 0.48164502]}","{""Every task  has these classes:"": [""five"", ""bed"", ""two"", ""wow"", ""bird""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1a4d6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea501e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.32578152, 'precision': 0.37702340535080938, 'recall': 0.36642524871532022, 'f1_score': 0.3434146612495199, 'confusion_matrix': array([[ 27,  27,  57,   6,  51],
       [ 29,  21,  72,  12,  39],
       [ 48,   9,  36,   3,  17],
       [ 19,  58, 122,  10,  38],
       [ 31,  16, 105,   9,  38]]), 'forgetting_measure': [0.36024412, 0.46680504, -0.54092926]}","{""Every task  has these classes:"": [""sheila"", ""off"", ""house"", ""two"", ""zero""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1a4d6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea501e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3375196, 'precision': 0.4068330665920768, 'recall': 0.40579111029815253, 'f1_score': 0.37263004738776808, 'confusion_matrix': array([[14, 10, 25,  2, 15],
       [29, 22, 52,  7, 32],
       [16, 15, 38,  8, 18],
       [28, 21, 87, 11, 42],
       [20, 19, 41,  6, 22]]), 'forgetting_measure': [0.36448152, 0.13845485, 0.24938023]}","{""Every task  has these classes:"": [""sheila"", ""off"", ""house"", ""two"", ""zero""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c7f35c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c83561d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.321073835, 'precision': 0.253647586980920314, 'recall': 0.3998010724788099, 'f1_score': 0.25657570461979657, 'confusion_matrix': array([[140,   0,   1,   0,   0],
       [191,   0,   2,   0,   0],
       [163,   0,   1,   0,   0],
       [209,   0,   4,   0,   0],
       [188,   0,   1,   0,   0]]), 'forgetting_measure': [0.32096143, -0.00278796, 0.002780209]}","{""Every task  has these classes:"": [""yes"", ""zero"", ""up"", ""nine"", ""right""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c7f35c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c83561d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41474487, 'precision': 0.28050625096465505, 'recall': 0.39763345434987228, 'f1_score': 0.27847992200077092, 'confusion_matrix': array([[130,   0,   4,   0,   0],
       [120,   0,   4,   0,   0],
       [109,   0,   2,   0,   0],
       [ 93,   0,   0,   0,   0],
       [137,   0,   1,   0,   0]]), 'forgetting_measure': [0.4271704, 0.16409104, -0.19630252]}","{""Every task  has these classes:"": [""yes"", ""zero"", ""up"", ""nine"", ""right""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317907710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42e9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4769941, 'precision': 0.25422222222222223, 'recall': 0.4, 'f1_score': 0.28531468531468532, 'confusion_matrix': array([[244,   0,   0,   0,   0],
       [203,   0,   0,   0,   0],
       [150,   0,   0,   0,   0],
       [162,   0,   0,   0,   0],
       [141,   0,   0,   0,   0]]), 'forgetting_measure': [0.51192586, 0.33596218, -0.50593835]}","{""Every task  has these classes:"": [""three"", ""down"", ""house"", ""marvel"", ""bird""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317907710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42e9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48114748, 'precision': 0.256999999999999995, 'recall': 0.4, 'f1_score': 0.28871595330739299, 'confusion_matrix': array([[171,   0,   0,   0,   0],
       [118,   0,   0,   0,   0],
       [104,   0,   0,   0,   0],
       [ 90,   0,   0,   0,   0],
       [117,   0,   0,   0,   0]]), 'forgetting_measure': [0.54269944, 0.5388273, -1.1683851]}","{""Every task  has these classes:"": [""three"", ""down"", ""house"", ""marvel"", ""bird""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553179073d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531699b690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3314628, 'precision': 0.22777777777777778, 'recall': 0.4, 'f1_score': 0.24878048780487805, 'confusion_matrix': array([[125,   0,   0,   0,   0],
       [208,   0,   0,   0,   0],
       [154,   0,   0,   0,   0],
       [147,   0,   0,   0,   0],
       [266,   0,   0,   0,   0]]), 'forgetting_measure': [0.32447693, -0.16836506, 0.14410312]}","{""Every task  has these classes:"": [""three"", ""four"", ""happy"", ""yes"", ""eight""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553179073d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531699b690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3693355, 'precision': 0.228000000000000004, 'recall': 0.4, 'f1_score': 0.24912280701754386, 'confusion_matrix': array([[ 84,   0,   0,   0,   0],
       [139,   0,   0,   0,   0],
       [104,   0,   0,   0,   0],
       [ 85,   0,   0,   0,   0],
       [188,   0,   0,   0,   0]]), 'forgetting_measure': [0.36579771, -0.06401404, 0.06016278]}","{""Every task  has these classes:"": [""three"", ""four"", ""happy"", ""yes"", ""eight""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553175c8050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42e650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38450423, 'precision': 0.230666666666666665, 'recall': 0.4, 'f1_score': 0.25317919075144508, 'confusion_matrix': array([[138,   0,   0,   0,   0],
       [239,   0,   0,   0,   0],
       [148,   0,   0,   0,   0],
       [252,   0,   0,   0,   0],
       [123,   0,   0,   0,   0]]), 'forgetting_measure': [0.38450424, 0.0, 0.0]}","{""Every task  has these classes:"": [""off"", ""stop"", ""yes"", ""down"", ""house""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553175c8050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15533b42e650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.308776055, 'precision': 0.228000000000000004, 'recall': 0.4, 'f1_score': 0.24912280701754386, 'confusion_matrix': array([[ 84,   0,   0,   0,   0],
       [136,   0,   0,   0,   0],
       [105,   0,   0,   0,   0],
       [182,   0,   0,   0,   0],
       [ 93,   0,   0,   0,   0]]), 'forgetting_measure': [0.308776055, 0.0, 0.0]}","{""Every task  has these classes:"": [""off"", ""stop"", ""yes"", ""down"", ""house""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531bb64a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531757ff10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47150923, 'precision': 0.50450265166213947, 'recall': 0.4028846332159243, 'f1_score': 0.30364306080150569, 'confusion_matrix': array([[  1, 162,   1,   5,   0],
       [  3, 215,   0,   8,   1],
       [  0, 178,   1,   4,   0],
       [  0, 154,   1,   6,   1],
       [  1, 150,   1,   4,   3]]), 'forgetting_measure': [0.48992298, 0.2892177, -0.5457337]}","{""Every task  has these classes:"": [""cat"", ""bird"", ""tree"", ""yes"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531bb64a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531757ff10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39032285, 'precision': 0.40645905420991925, 'recall': 0.4001165280485467, 'f1_score': 0.2815860604345276, 'confusion_matrix': array([[  0, 100,   1,   3,   1],
       [  2, 115,   0,   2,   1],
       [  1, 137,   1,   2,   0],
       [  0, 106,   1,   3,   1],
       [  0, 120,   0,   2,   1]]), 'forgetting_measure': [0.41365386, 0.32080746, -0.4623355]}","{""Every task  has these classes:"": [""cat"", ""bird"", ""tree"", ""yes"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d89f16d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d68dce10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41243443, 'precision': 0.239822024471635145, 'recall': 0.3988888888888889, 'f1_score': 0.26635773864689527, 'confusion_matrix': array([[179,   1,   0,   0,   0],
       [120,   0,   0,   0,   0],
       [205,   0,   0,   0,   0],
       [193,   0,   0,   0,   0],
       [202,   0,   0,   0,   0]]), 'forgetting_measure': [0.39847295, -0.10551685, 0.0]}","{""Every task  has these classes:"": [""cat"", ""happy"", ""seven"", ""left"", ""nine""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d89f16d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d68dce10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36233109, 'precision': 0.240999999999999995, 'recall': 0.4, 'f1_score': 0.26804979253112033, 'confusion_matrix': array([[123,   0,   0,   0,   0],
       [108,   0,   0,   0,   0],
       [125,   0,   0,   0,   0],
       [123,   0,   0,   0,   0],
       [121,   0,   0,   0,   0]]), 'forgetting_measure': [0.36233109, 0.0, 0.0]}","{""Every task  has these classes:"": [""cat"", ""happy"", ""seven"", ""left"", ""nine""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316fe8dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553186d3a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5444469, 'precision': 0.38359550561797755, 'recall': 0.4026249854555327, 'f1_score': 0.30413263332412268, 'confusion_matrix': array([[  2,   0,   0, 136,   0],
       [  0,   0,   1, 152,   0],
       [  1,   0,   1, 175,   0],
       [  0,   0,   2, 283,   0],
       [  2,   0,   1, 144,   0]]), 'forgetting_measure': [0.53806705, -0.022604017, -0.011154253]}","{""Every task  has these classes:"": [""down"", ""zero"", ""dog"", ""stop"", ""four""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316fe8dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553186d3a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42871047, 'precision': 0.24916387959866221, 'recall': 0.4, 'f1_score': 0.2789261744966443, 'confusion_matrix': array([[  0,   0,   0,  88,   0],
       [  0,   0,   0,  95,   0],
       [  2,   0,   0, 163,   0],
       [  0,   0,   0, 147,   0],
       [  0,   0,   0, 105,   0]]), 'forgetting_measure': [0.42871047, 0.0, 0.0]}","{""Every task  has these classes:"": [""down"", ""zero"", ""dog"", ""stop"", ""four""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b42edd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d3ce3810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55872445, 'precision': 0.26770949720670391, 'recall': 0.3973941368078176, 'f1_score': 0.30083194675540766, 'confusion_matrix': array([[  0, 105,   0,   0,   1],
       [  0, 303,   2,   2,   0],
       [  0, 175,   0,   0,   0],
       [  0, 138,   0,   0,   0],
       [  0, 174,   0,   0,   0]]), 'forgetting_measure': [0.51196856, -0.24111715, 0.026277399]}","{""Every task  has these classes:"": [""wow"", ""tree"", ""four"", ""up"", ""right""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533b42edd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d3ce3810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49993474, 'precision': 0.258666666666666666, 'recall': 0.4, 'f1_score': 0.29072164948453607, 'confusion_matrix': array([[  0,  75,   0,   0,   0],
       [  0, 176,   0,   0,   0],
       [  0, 124,   0,   0,   0],
       [  0, 111,   0,   0,   0],
       [  0, 114,   0,   0,   0]]), 'forgetting_measure': [0.4886511, -0.117272645, 0.10496332]}","{""Every task  has these classes:"": [""wow"", ""tree"", ""four"", ""up"", ""right""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ef85d990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea761990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41935563, 'precision': 0.3886062941554271, 'recall': 0.4032344507700131, 'f1_score': 0.28938302578980546, 'confusion_matrix': array([[  2, 208,   0,   3,   3],
       [  0, 191,   3,   2,   1],
       [  2, 189,   0,   2,   0],
       [  2, 161,   1,   5,   2],
       [  3, 116,   1,   2,   1]]), 'forgetting_measure': [0.45484747, 0.2722762, -0.17417532]}","{""Every task  has these classes:"": [""sheila"", ""house"", ""bird"", ""marvel"", ""three""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ef85d990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea761990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3922489, 'precision': 0.29304029304029304, 'recall': 0.39398601398601398, 'f1_score': 0.26627107073465315, 'confusion_matrix': array([[  0, 143,   0,   1,   3],
       [  2, 105,   0,   3,   0],
       [  2, 129,   0,   1,   0],
       [  1, 127,   0,   2,   0],
       [  0,  81,   0,   0,   0]]), 'forgetting_measure': [0.39455275, 0.06811921, -0.10807494]}","{""Every task  has these classes:"": [""sheila"", ""house"", ""bird"", ""marvel"", ""three""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea6a2850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ddd91990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39828403, 'precision': 0.23892013498312711, 'recall': 0.39548022598870057, 'f1_score': 0.26491557223264541, 'confusion_matrix': array([[  0,   0,   0,   2, 197],
       [  0,   0,   1,   1, 209],
       [  0,   0,   0,   3, 190],
       [  0,   0,   0,   0, 120],
       [  0,   0,   1,   3, 173]]), 'forgetting_measure': [0.36478294, -0.30495661, 0.0]}","{""Every task  has these classes:"": [""right"", ""left"", ""tree"", ""marvel"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea6a2850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ddd91990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33135633, 'precision': 0.233, 'recall': 0.4, 'f1_score': 0.25665236051502146, 'confusion_matrix': array([[  0,   0,   0,   0, 110],
       [  0,   0,   0,   0, 132],
       [  0,   0,   0,   0, 130],
       [  0,   0,   0,   0, 129],
       [  0,   0,   0,   0,  99]]), 'forgetting_measure': [0.33135633, 0.0, 0.0]}","{""Every task  has these classes:"": [""right"", ""left"", ""tree"", ""marvel"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfa8d450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ddd51bd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3803629, 'precision': 0.23666666666666667, 'recall': 0.4, 'f1_score': 0.26197183098591549, 'confusion_matrix': array([[165,   0,   0,   0,   0],
       [230,   0,   0,   0,   0],
       [190,   0,   0,   0,   0],
       [150,   0,   0,   0,   0],
       [165,   0,   0,   0,   0]]), 'forgetting_measure': [0.39140694, 0.17309788, -0.20933299]}","{""Every task  has these classes:"": [""tree"", ""up"", ""marvel"", ""bird"", ""cat""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfa8d450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ddd51bd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39783193, 'precision': 0.235333333333333335, 'recall': 0.4, 'f1_score': 0.26005665722379603, 'confusion_matrix': array([[106,   0,   0,   0,   0],
       [137,   0,   0,   0,   0],
       [129,   0,   0,   0,   0],
       [111,   0,   0,   0,   0],
       [117,   0,   0,   0,   0]]), 'forgetting_measure': [0.4007481, 0.04357957, -0.04556529]}","{""Every task  has these classes:"": [""tree"", ""up"", ""marvel"", ""bird"", ""cat""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d2abfdd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c58c7b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4101947, 'precision': 0.4882554301941822, 'recall': 0.41325868980403415, 'f1_score': 0.33107837155781393, 'confusion_matrix': array([[  5,   0,   0,  71,  98],
       [  0,   0,   0,  68,  97],
       [  0,   0,   0,  79, 109],
       [  0,   1,   0, 111, 123],
       [  0,   1,   1,  58,  78]]), 'forgetting_measure': [0.4978661, 0.49313232, -0.20374154]}","{""Every task  has these classes:"": [""on"", ""stop"", ""nine"", ""down"", ""left""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d2abfdd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c58c7b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40796593, 'precision': 0.28995455632623775, 'recall': 0.40098039215686275, 'f1_score': 0.31891028485224955, 'confusion_matrix': array([[  0,   0,   0,  27,  51],
       [  1,   0,   0,  61, 103],
       [  1,   0,   0,  31,  67],
       [  2,   0,   0,  65,  89],
       [  0,   0,   0,  42,  60]]), 'forgetting_measure': [0.46624912, 0.34218794, -0.042051043]}","{""Every task  has these classes:"": [""on"", ""stop"", ""nine"", ""down"", ""left""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea6bd550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c853a290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45194582, 'precision': 0.3077587585986242, 'recall': 0.40026581605528976, 'f1_score': 0.28454472269968018, 'confusion_matrix': array([[  0,   0,   0, 141,   0],
       [  0,   2,   0, 196,   0],
       [  0,   1,   0, 245,   0],
       [  0,   2,   0, 226,   0],
       [  0,   2,   0,  85,   0]]), 'forgetting_measure': [0.44889028, -0.018415058, 0.0]}","{""Every task  has these classes:"": [""zero"", ""on"", ""go"", ""sheila"", ""dog""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea6bd550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c853a290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35804507, 'precision': 0.247, 'recall': 0.4, 'f1_score': 0.27611336032388664, 'confusion_matrix': array([[  0,   0,   0, 108,   0],
       [  0,   0,   0, 111,   0],
       [  0,   0,   0, 162,   0],
       [  0,   0,   0, 141,   0],
       [  0,   0,   0,  78,   0]]), 'forgetting_measure': [0.35804507, 0.0, 0.0]}","{""Every task  has these classes:"": [""zero"", ""on"", ""go"", ""sheila"", ""dog""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c89aab10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0d6fbd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38639727, 'precision': 0.23266666666666666, 'recall': 0.4, 'f1_score': 0.256160458452722065, 'confusion_matrix': array([[147,   0,   0,   0,   0],
       [312,   0,   0,   0,   0],
       [174,   0,   0,   0,   0],
       [150,   0,   0,   0,   0],
       [117,   0,   0,   0,   0]]), 'forgetting_measure': [0.37736539, -0.15276738, 0.1325223]}","{""Every task  has these classes:"": [""one"", ""dog"", ""no"", ""house"", ""five""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (DIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c89aab10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0d6fbd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 5, 'Class Incremental Case': (False, 50, 1, (True, 0.9), (10, 0.01), 0.4, 6), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36224346, 'precision': 0.23833333333333334, 'recall': 0.4, 'f1_score': 0.26433566433566434, 'confusion_matrix': array([[115,   0,   0,   0,   0],
       [208,   0,   0,   0,   0],
       [104,   0,   0,   0,   0],
       [ 95,   0,   0,   0,   0],
       [ 78,   0,   0,   0,   0]]), 'forgetting_measure': [0.35581283, -0.12381396, 0.110173]}","{""Every task  has these classes:"": [""one"", ""dog"", ""no"", ""house"", ""five""]}"
