Hyperparameters,Results,Additional classes
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e012d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316b52790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43793525, 'precision': 0.19713887029738148, 'recall': 0.22864961621662038, 'f1_score': 0.19903230503868668, 'confusion_matrix': array([[ 14,  56, 114,   0,   0,   0,   0],
       [ 23,  47, 149,   0,   0,   0,   0],
       [ 26,  77, 161,   0,   0,   0,   0],
       [  0,  27,  42,   0,   0,   0,   0],
       [  0,  26,  38,   0,   0,   0,   0],
       [  0,  19,  29,   0,   0,   0,   0],
       [  0,  20,  32,   0,   0,   0,   0]]), 'forgetting_measure': [0.4470276, 0.40980121, 0.20922472]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e012d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316b52790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4482844, 'precision': 0.21965811965811965, 'recall': 0.24711937502439282, 'f1_score': 0.21188110494701209, 'confusion_matrix': array([[ 18,  23, 103,   0,   0,   0,   0],
       [ 18,  29,  92,   0,   0,   0,   0],
       [ 18,  30, 110,   0,   0,   0,   0],
       [  0,   6,  32,   0,   0,   0,   0],
       [  0,   9,  45,   0,   0,   0,   0],
       [  0,   8,  17,   0,   0,   0,   0],
       [  0,  12,  30,   0,   0,   0,   0]]), 'forgetting_measure': [0.40124417, 0.28760678, -0.06710221]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d65bd910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d67c77d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60032065, 'precision': 0.32990773623395575, 'recall': 0.29119669778377002, 'f1_score': 0.2976350066116266, 'confusion_matrix': array([[ 54,  96,  16,   5,   8,   5,   1,   1,   0],
       [ 33, 257,  24,  14,   2,  11,  11,   3,   0],
       [  9,  70,  21,   6,   2,   5,   0,   0,   0],
       [ 12,  42,   6,  14,   4,   2,   3,   0,   0],
       [ 12,  28,   2,   5,  11,   4,   1,   0,   0],
       [  5,  22,   4,   1,   1,   5,   1,   0,   0],
       [  3,  31,   5,   3,   4,   9,   3,   1,   2],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.6091711, 0.18887748, 0.32496238]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d65bd910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d67c77d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4900464, 'precision': 0.22548182062403507, 'recall': 0.21742731541703025, 'f1_score': 0.21334150960898781, 'confusion_matrix': array([[ 14, 102,  13,   5,   4,   7,   3,   0,   0],
       [ 20, 139,  32,  13,   4,  15,   6,   1,   1],
       [  8,  48,   3,   5,   1,   3,   1,   0,   0],
       [  7,  30,   2,   9,   3,   3,   1,   0,   0],
       [  7,  12,   2,   6,   1,   2,   0,   0,   0],
       [  4,  22,   2,   0,   1,   2,   4,   0,   1],
       [  3,  15,   5,   0,   0,   6,   2,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5512532, 0.43835777, 0.3472172]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e9be5410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f83ffcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4853488, 'precision': 0.17771263274982444, 'recall': 0.22807268553321854, 'f1_score': 0.19502914455045752, 'confusion_matrix': array([[  0,  77,  53,   1,   0,   0,   0],
       [  0, 149, 125,   0,   0,   0,   0],
       [  0, 166,  91,   1,   0,   0,   0],
       [  0,  59,  18,   0,   0,   0,   0],
       [  0,  44,  16,   0,   0,   0,   0],
       [  0,  37,   7,   0,   0,   0,   0],
       [  0,  50,   6,   0,   0,   0,   0]]), 'forgetting_measure': [0.45224062, 0.16890182, 0.27903762]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e9be5410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f83ffcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50571383, 'precision': 0.18208225819063257, 'recall': 0.2496030540974361, 'f1_score': 0.20588810429114612, 'confusion_matrix': array([[ 0, 57, 56,  0,  0,  0,  0],
       [ 0, 95, 83,  0,  0,  0,  0],
       [ 0, 72, 76,  0,  0,  0,  0],
       [ 0, 45, 12,  0,  0,  0,  0],
       [ 0, 26, 11,  0,  0,  0,  0],
       [ 0, 22,  9,  0,  0,  0,  0],
       [ 0, 31,  5,  0,  0,  0,  0]]), 'forgetting_measure': [0.53031543, 0.37613502, 0.18658862]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dbf4da50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3dadf90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.602678, 'precision': 0.36589462465751124, 'recall': 0.32506814600638367, 'f1_score': 0.31528919938548044, 'confusion_matrix': array([[ 94,  82,   3,   7,   3,   2,   0],
       [ 53, 292,  11,  12,   3,   1,   0],
       [ 21,  65,   8,   5,   3,   1,   0],
       [ 10,  59,   1,  10,   4,   0,   0],
       [  7,  30,   2,   8,   3,   0,   0],
       [ 17,  26,   0,   3,   0,   2,   0],
       [ 14,  28,   1,   5,   2,   2,   0]]), 'forgetting_measure': [0.6083844, 0.25657853, 0.14880018]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dbf4da50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3dadf90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4941478, 'precision': 0.33894075360640707, 'recall': 0.27855546787528692, 'f1_score': 0.27045484285274076, 'confusion_matrix': array([[ 32, 104,   5,   8,   1,   1,   0],
       [ 45, 143,   5,   9,   2,   2,   0],
       [ 20,  51,   6,   3,   3,   0,   0],
       [ 10,  30,   0,   7,   0,   1,   0],
       [  9,  32,   1,   2,   1,   0,   0],
       [  7,  19,   0,   0,   0,   3,   0],
       [ 18,  17,   1,   1,   0,   1,   0]]), 'forgetting_measure': [0.57990838, 0.4839675, 0.37457016]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c6235410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d01dfcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46676738, 'precision': 0.24977981088032807, 'recall': 0.2897005547950424, 'f1_score': 0.26096314522025415, 'confusion_matrix': array([[ 45, 120,  25,   0,   0,   8,   7],
       [ 64, 146,  23,   0,   0,  18,   6],
       [ 47, 126,  11,   0,   1,  15,   3],
       [  6,  37,  13,   0,   0,   6,   2],
       [  9,  48,   7,   0,   0,   5,   2],
       [ 20,   6,   7,   0,   0,  24,   7],
       [ 15,   2,   5,   0,   0,  10,   4]]), 'forgetting_measure': [0.44108207, 0.2179967, 0.278316]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c6235410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d01dfcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41688128, 'precision': 0.2060242682146519, 'recall': 0.23280236967016026, 'f1_score': 0.20417002261589678, 'confusion_matrix': array([[ 17,  93,  23,   0,   0,   2,   5],
       [ 24, 101,  21,   0,   0,   3,  12],
       [ 22,  99,  15,   0,   0,   2,   5],
       [  8,  30,   9,   0,   0,   1,   0],
       [  7,  23,  10,   0,   0,   0,   1],
       [ 29,   7,   6,   0,   0,   1,   6],
       [  9,   2,   6,   0,   0,   0,   1]]), 'forgetting_measure': [0.45270157, 0.500117, 0.31011826]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c64dc210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c8e177d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5850614, 'precision': 0.37306933903739866, 'recall': 0.33386221402295793, 'f1_score': 0.3215152774944225, 'confusion_matrix': array([[138,  59,  15,   1,   0,   9,   0,   0],
       [ 40, 110,  66,  13,   4,   9,   1,   0],
       [ 24,  63,  90,   6,   5,   7,   0,   1],
       [ 17,  20,  20,   6,   5,   2,   0,   1],
       [ 15,  16,  29,   5,   0,   3,   0,   0],
       [ 19,  13,   3,   1,   0,  11,   0,   0],
       [ 21,  21,   2,   0,   0,   7,   1,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5259035, 0.17748477, -0.0818028]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c64dc210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c8e177d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41294616, 'precision': 0.23388697104048916, 'recall': 0.25723227684139082, 'f1_score': 0.2383653914168645, 'confusion_matrix': array([[46, 39, 38,  4,  4,  8,  0,  0],
       [60, 38, 43,  5,  1, 16,  0,  0],
       [46, 37, 35, 11,  2,  6,  0,  1],
       [15, 15,  4,  2,  1,  2,  0,  0],
       [22, 16,  7,  5,  1,  2,  1,  0],
       [ 5,  9,  2,  0,  1, 10,  0,  0],
       [13, 14,  5,  0,  2,  5,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.3857576, 0.41929016, -0.12773347]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c8d0f150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b4203e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6462298, 'precision': 0.4444936427055354, 'recall': 0.4367553211785181, 'f1_score': 0.43361181929712913, 'confusion_matrix': array([[142,  22,  20,  10,   4,  15,  10],
       [ 44, 124,  36,  20,   5,   4,   5],
       [ 28,  55,  71,  28,  11,   3,   4],
       [ 10,  17,  14,  18,   3,   2,   0],
       [  9,  17,  20,  20,   6,   3,   0],
       [ 13,   5,   5,   2,   2,   8,   6],
       [ 20,   9,   4,   0,   1,   8,  17]]), 'forgetting_measure': [0.6423017, 0.215632, 0.12775078]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c8d0f150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b4203e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3982211, 'precision': 0.29292615255742254, 'recall': 0.28576046871149307, 'f1_score': 0.28124500623323886, 'confusion_matrix': array([[33, 43, 30, 21,  5,  7,  5],
       [56, 41, 37, 12,  6, 10,  4],
       [42, 32, 28, 17,  6,  6,  4],
       [10, 10,  4,  9,  2,  1,  1],
       [20,  9,  9, 11,  2,  0,  0],
       [ 7,  4,  5,  2,  1,  3,  2],
       [ 7,  9,  4,  1,  2, 11,  9]]), 'forgetting_measure': [0.3650739, 0.1837619, 0.47668597]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528abb5910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc63dc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50392727, 'precision': 0.30482411522818428, 'recall': 0.33466286097578268, 'f1_score': 0.29187312050244623, 'confusion_matrix': array([[150,  29,  29,   5,   5,  32,   0],
       [112,  21,  24,   8,   9,  41,   0],
       [110,  22,  23,   6,   8,  35,   0],
       [ 22,   8,   5,   5,   7,  12,   0],
       [ 33,  13,   2,   4,   8,  12,   0],
       [ 10,  16,   1,   1,   0,  49,   0],
       [  3,   5,   2,   0,   0,  13,   0]]), 'forgetting_measure': [0.47320378, 0.17647532, 0.24762943]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528abb5910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bc63dc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50888346, 'precision': 0.29212883740740533, 'recall': 0.356178094545417, 'f1_score': 0.29309675993689698, 'confusion_matrix': array([[97, 14, 33,  9, 10, 30,  0],
       [57, 13, 18,  6,  6, 24,  0],
       [68, 11, 18,  7,  6, 21,  0],
       [15,  9,  0,  2,  7,  3,  0],
       [21,  8,  4,  3,  7,  6,  0],
       [ 3,  2,  1,  0,  0, 34,  0],
       [ 6,  0,  2,  0,  0, 19,  0]]), 'forgetting_measure': [0.41588843, 0.037069257, -0.007905126]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a75bd910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a76e1fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43545688, 'precision': 0.13047619047619048, 'recall': 0.24285714285714285, 'f1_score': 0.15023547880690738, 'confusion_matrix': array([[192,   0,   0,   0,   0,   0,   0],
       [366,   0,   0,   0,   0,   0,   0],
       [107,   0,   0,   0,   0,   0,   0],
       [ 85,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [ 55,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42029897, 0.40875292, -0.03865307]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a75bd910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a76e1fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45184363, 'precision': 0.134523809523809526, 'recall': 0.24285714285714285, 'f1_score': 0.15560882070949185, 'confusion_matrix': array([[145,   0,   0,   0,   0,   0,   0],
       [214,   0,   0,   0,   0,   0,   0],
       [ 78,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 29,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43520648, 0.41280606, -0.1354565]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ecb5910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529f647350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4144948, 'precision': 0.13253968253968254, 'recall': 0.24285714285714285, 'f1_score': 0.15300581771170006, 'confusion_matrix': array([[205,   0,   0,   0,   0,   0,   0],
       [253,   0,   0,   0,   0,   0,   0],
       [211,   0,   0,   0,   0,   0,   0],
       [ 58,   0,   0,   0,   0,   0,   0],
       [ 73,   0,   0,   0,   0,   0,   0],
       [ 35,   0,   0,   0,   0,   0,   0],
       [ 65,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3862887, 0.34498724, 0.095187634]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529ecb5910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529f647350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40729095, 'precision': 0.130238095238095238, 'recall': 0.24285714285714285, 'f1_score': 0.14991157398310081, 'confusion_matrix': array([[127,   0,   0,   0,   0,   0,   0],
       [171,   0,   0,   0,   0,   0,   0],
       [147,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 15,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38786135, 0.37301564, 0.14936253]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529efb8bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ce37350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.462371, 'precision': 0.24515880087920827, 'recall': 0.28987176787573792, 'f1_score': 0.23646068927535016, 'confusion_matrix': array([[  8,  30, 112,   2,   4,  23,   0],
       [ 18,  25, 130,   4,   6,  45,   0],
       [ 20,  33, 152,   9,  14,  34,   0],
       [  0,  15,  52,   2,   1,  10,   0],
       [  0,   9,  29,   1,   1,  11,   0],
       [  0,   1,  23,   2,   0,  33,   1],
       [  0,   0,  23,   0,   0,  17,   0]]), 'forgetting_measure': [0.5067785, 0.6335865, -0.5517388]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529efb8bd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ce37350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44087776, 'precision': 0.29942003154302926, 'recall': 0.33028077546395112, 'f1_score': 0.25796396819010722, 'confusion_matrix': array([[18, 12, 68,  3,  6, 22,  0],
       [14, 20, 78,  1,  7, 29,  0],
       [15, 22, 81,  3,  8, 34,  0],
       [ 0,  3, 40,  2,  4,  7,  0],
       [ 0,  2, 22,  0,  0, 12,  0],
       [ 0,  0,  7,  0,  0, 29,  0],
       [ 0,  0,  6,  0,  0, 25,  0]]), 'forgetting_measure': [0.4288612, 0.327875, 0.2185149]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528c60d410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529094df50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54802485, 'precision': 0.25380575714824532, 'recall': 0.26928129068969952, 'f1_score': 0.2410174372100464, 'confusion_matrix': array([[ 98, 180,   5,   0,   3,   0,   0],
       [ 63, 194,   4,   2,   2,   0,   0],
       [ 23,  89,  14,   0,   1,   0,   0],
       [  8,  53,   1,   0,   0,   0,   0],
       [  4,  53,   3,   0,   0,   0,   0],
       [  9,  27,   6,   0,   2,   0,   0],
       [ 13,  32,  11,   0,   0,   0,   0]]), 'forgetting_measure': [0.51027856, 0.09220578, 0.29829895]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528c60d410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529094df50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4776973, 'precision': 0.2369762190590522, 'recall': 0.23639050045643925, 'f1_score': 0.20540979731222584, 'confusion_matrix': array([[ 57, 132,   8,   0,   0,   0,   0],
       [ 51, 103,   9,   0,   0,   0,   0],
       [ 24,  54,   1,   0,   0,   0,   0],
       [  6,  39,   1,   0,   0,   0,   0],
       [  7,  37,   3,   0,   1,   0,   0],
       [ 12,  18,   4,   0,   1,   0,   0],
       [ 14,   9,   8,   0,   1,   0,   0]]), 'forgetting_measure': [0.53081704, 0.43369013, 0.35117006]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528498d410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528cb20390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44669558, 'precision': 0.25423366958915816, 'recall': 0.26921954443357037, 'f1_score': 0.2552527131797518, 'confusion_matrix': array([[ 24,  97,  58,  14,   9,   1,   0],
       [ 17,  97,  68,  20,   7,   3,   0],
       [ 32, 111,  78,  12,   7,   4,   0],
       [  6,  23,  21,  16,   8,   1,   0],
       [ 10,  25,  19,   7,   5,   0,   0],
       [ 19,  14,  12,   3,   0,   0,   0],
       [ 22,  10,  12,   5,   0,   3,   0]]), 'forgetting_measure': [0.4209674, 0.22514877, 0.3147731]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528498d410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528cb20390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44197912, 'precision': 0.26567532996104423, 'recall': 0.27568992901714675, 'f1_score': 0.26263590200429198, 'confusion_matrix': array([[17, 47, 63,  9,  7,  3,  0],
       [13, 65, 56, 16,  6,  4,  0],
       [15, 42, 59, 14, 10,  2,  0],
       [ 5, 11, 14,  6,  8,  0,  0],
       [ 2, 10, 13, 11,  5,  0,  0],
       [ 6,  7, 16,  0,  0,  1,  0],
       [12,  7, 15,  0,  0,  3,  0]]), 'forgetting_measure': [0.45616294, 0.5080016, -0.110204324]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 10 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317063e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316e91310>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4720603, 'precision': 0.22699328671504945, 'recall': 0.24774087507266936, 'f1_score': 0.2290254692500317, 'confusion_matrix': array([[ 21, 119,  47,   0,   9,   0,   0],
       [ 44, 139,  54,   0,  21,   0,   0],
       [ 34, 105,  58,   0,  14,   0,   0],
       [  2,  16,  10,   0,  10,   0,   0],
       [  2,  43,  41,   0,  11,   0,   0],
       [  1,  31,  27,   0,   1,   0,   0],
       [  0,  23,  17,   0,   0,   0,   0]]), 'forgetting_measure': [0.45163832, 0.2601743, 0.21433528]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 10 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317063e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316e91310>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4827119, 'precision': 0.25049939041123173, 'recall': 0.26881435145398088, 'f1_score': 0.25712595717424627, 'confusion_matrix': array([[24, 49, 25,  0, 11,  0,  0],
       [30, 82, 61,  0, 16,  0,  0],
       [32, 46, 52,  0, 17,  0,  0],
       [ 0,  3,  7,  0,  9,  0,  0],
       [ 2, 26, 29,  0, 12,  0,  0],
       [ 0, 12, 29,  0,  0,  0,  0],
       [ 0, 12, 14,  0,  0,  0,  0]]), 'forgetting_measure': [0.4526201, 0.34742558, -0.15337771]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155284968410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265b47cd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54753716, 'precision': 0.35648104861625387, 'recall': 0.329626695440707, 'f1_score': 0.3072448416322827, 'confusion_matrix': array([[148,  38,  51,   1,   1,   5,   2],
       [ 21,  40, 122,   5,   2,   3,   0],
       [ 20,  34, 154,   5,   7,   3,   0],
       [ 10,  11,  45,   0,   1,   2,   0],
       [ 37,   9,  20,   0,   1,   2,   0],
       [ 13,   0,  39,   0,   1,   4,   0],
       [ 17,   0,  21,   1,   1,   2,   1]]), 'forgetting_measure': [0.5197345, 0.1787748, 0.19297045]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL)', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155284968410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265b47cd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44903107, 'precision': 0.2803893027031458, 'recall': 0.25069310325855567, 'f1_score': 0.23638697427804355, 'confusion_matrix': array([[43, 15, 93,  4,  3,  1,  0],
       [38, 10, 75,  1,  1,  6,  2],
       [46, 16, 83,  2,  2,  4,  1],
       [ 5,  7, 16,  1,  0,  0,  0],
       [13, 10, 30,  1,  1,  3,  0],
       [10,  0, 19,  0,  2,  3,  0],
       [ 7,  0, 16,  0,  3,  6,  1]]), 'forgetting_measure': [0.45554206, 0.4228634, 0.0918222]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 50 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a1ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553168cca10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43335889, 'precision': 0.23059507197560197, 'recall': 0.24319573342718184, 'f1_score': 0.23039510098099208, 'confusion_matrix': array([[126,  52,  52,   8,   5,  16,   0],
       [ 76,  40,  58,   6,   2,   7,   0],
       [112,  41,  49,   4,   4,   9,   0],
       [ 46,  12,   6,   1,   1,   1,   0],
       [ 51,   5,   5,   3,   0,   2,   0],
       [ 42,   6,   9,   0,   0,   4,   0],
       [ 23,   0,   9,   0,   0,   7,   0]]), 'forgetting_measure': [0.42199624, 0.27137312, 0.38850775]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 50 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a1ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553168cca10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45055298, 'precision': 0.23999785713350685, 'recall': 0.25678275602887665, 'f1_score': 0.2384068127843817, 'confusion_matrix': array([[103,  19,  38,   5,   0,   6,   0],
       [ 68,  15,  39,   5,   0,   6,   0],
       [ 73,  27,  31,   6,   0,   4,   0],
       [ 16,   6,   7,   2,   0,   1,   0],
       [ 33,  11,   8,   3,   0,   1,   0],
       [ 25,   0,  11,   0,   0,   4,   0],
       [ 17,   0,   8,   0,   0,   2,   0]]), 'forgetting_measure': [0.42306084, 0.3514616, -0.045644484]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f79f3490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4464190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51890818, 'precision': 0.31839263759905786, 'recall': 0.30822447717423584, 'f1_score': 0.30685344506398962, 'confusion_matrix': array([[131,  27,  63,  10,  19,   5,   0,   0],
       [ 84,  39,  46,  16,   6,   6,   0,   0],
       [ 64,  24,  97,  14,   5,   4,   0,   1],
       [ 23,  11,  17,  12,   3,   5,   0,   0],
       [ 21,  21,   7,   8,  10,   1,   0,   0],
       [ 27,   9,  11,   4,   6,  12,   0,   0],
       [ 12,   5,   8,   1,   1,   4,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4724222, 0.043036584, 0.3605177]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f79f3490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4464190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45545603, 'precision': 0.27614303842008108, 'recall': 0.278139774515955, 'f1_score': 0.2712543839921106, 'confusion_matrix': array([[88, 16, 60,  3, 10,  4,  0],
       [58, 15, 30,  7,  3,  3,  0],
       [58, 23, 46, 14,  8,  5,  0],
       [14,  3,  8,  7,  5,  0,  0],
       [19,  3, 10, 10,  3,  0,  0],
       [14,  9,  9,  0,  4,  3,  0],
       [12,  4,  6,  0,  3,  3,  0]]), 'forgetting_measure': [0.42434133, 0.35307553, -0.10665167]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 10 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316be6cd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316d71690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5752625, 'precision': 0.1965174531351002, 'recall': 0.24397562665971333, 'f1_score': 0.18263565122790341, 'confusion_matrix': array([[321,   6,   0,   0,   0,   0,   0],
       [186,   5,   0,   0,   0,   0,   0],
       [148,   5,   0,   0,   0,   0,   0],
       [ 66,   0,   0,   0,   0,   0,   0],
       [ 63,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.56989268, 0.21671751, 0.21796176]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 10 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316be6cd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316d71690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6260207, 'precision': 0.157857142857142864, 'recall': 0.24285714285714285, 'f1_score': 0.18235892221657347, 'confusion_matrix': array([[243,   0,   0,   0,   0,   0,   0],
       [ 98,   0,   0,   0,   0,   0,   0],
       [104,   0,   0,   0,   0,   0,   0],
       [ 51,   0,   0,   0,   0,   0,   0],
       [ 37,   0,   0,   0,   0,   0,   0],
       [ 27,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.66311727, 0.26888037, 0.2634581]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed1354d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecbb43d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49037747, 'precision': 0.2641579689695148, 'recall': 0.26527811942843984, 'f1_score': 0.23713278160556958, 'confusion_matrix': array([[ 17,  26, 105,  32,   4,   1,  14,   1],
       [ 19,  19, 124,  19,   5,   1,  15,   0],
       [ 22,  30, 157,  38,   2,   3,  12,   1],
       [  6,   0,  42,  19,   3,   0,   5,   1],
       [  7,   0,  32,  12,   2,   1,   2,   1],
       [  6,   0,  40,   0,   0,   1,  17,   0],
       [  3,   0,  24,   0,   0,   0,   9,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4840459, 0.41846254, -0.1809474]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed1354d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecbb43d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46373714, 'precision': 0.25902039598529324, 'recall': 0.2813365588691763, 'f1_score': 0.25361781768913668, 'confusion_matrix': array([[18, 23, 58, 15,  3,  3, 11,  0],
       [19, 24, 70, 18,  5,  0, 12,  1],
       [18, 23, 82, 10,  3,  5, 16,  1],
       [12,  0, 34, 11,  4,  0,  6,  0],
       [ 5,  2, 11,  5,  1,  1,  3,  0],
       [ 4,  0, 20,  0,  0,  0, 12,  1],
       [ 1,  1, 12,  1,  0,  1, 13,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.38826976, 0.15323469, -0.060418613]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed44e850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3800790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5071009, 'precision': 0.2794425087108014, 'recall': 0.24937692119733476, 'f1_score': 0.21953678163786705, 'confusion_matrix': array([[ 14, 146,  24,   3,   1,   1,   0],
       [ 17, 226,  49,   2,   2,   0,   0],
       [  8, 135,  31,   3,   0,   1,   0],
       [ 10,  52,   4,   0,   0,   1,   0],
       [  5,  50,  14,   0,   1,   0,   0],
       [ 16,  33,   1,   0,   0,   1,   0],
       [ 12,  36,   0,   1,   0,   0,   0]]), 'forgetting_measure': [0.50524638, 0.34251672, 0.06316246]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed44e850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3800790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50887508, 'precision': 0.35646464396896773, 'recall': 0.24703044602157503, 'f1_score': 0.21978234287111764, 'confusion_matrix': array([[ 11,  82,   8,   0,   0,   0,   0],
       [ 16, 175,  30,   0,   2,   1,   0],
       [  8,  94,  14,   0,   1,   1,   0],
       [  2,  33,  12,   1,   1,   0,   0],
       [  2,  33,   4,   0,   0,   2,   0],
       [  6,  29,   1,   0,   0,   0,   0],
       [  4,  26,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.5371353, 0.3500014, 0.27727678]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d08ab490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1011a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49284796, 'precision': 0.18788789879227579, 'recall': 0.2421031798390289, 'f1_score': 0.20799948642108907, 'confusion_matrix': array([[128, 154,   4,   0,   0,   0,   0],
       [117, 145,   3,   0,   0,   0,   0],
       [ 57,  60,   0,   0,   0,   0,   0],
       [ 27,  41,   0,   0,   0,   0,   0],
       [ 29,  35,   0,   0,   0,   0,   0],
       [ 15,  37,   0,   0,   0,   0,   0],
       [ 22,  26,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5018958, 0.2773085, 0.35891345]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d08ab490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1011a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48043878, 'precision': 0.18408996668430158, 'recall': 0.23845366103430617, 'f1_score': 0.20457927045495051, 'confusion_matrix': array([[ 79, 107,   0,   0,   0,   0,   0],
       [ 82,  98,   0,   0,   0,   0,   0],
       [ 41,  29,   0,   0,   0,   0,   0],
       [ 24,  14,   0,   0,   0,   0,   0],
       [ 33,  26,   0,   0,   0,   0,   0],
       [ 14,  17,   0,   0,   0,   0,   0],
       [ 18,  18,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51529256, 0.3470589, 0.42889366]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f406ac90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4109650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6641391, 'precision': 0.3133108120530125, 'recall': 0.34001827618510838, 'f1_score': 0.31778229466886928, 'confusion_matrix': array([[ 47,  79,  20,   4,   0,   0,   0],
       [ 24, 322,  19,   5,   0,   0,   0],
       [ 29,  54,  64,   5,   0,   0,   0],
       [  6,  26,  17,   4,   0,   0,   0],
       [  5,  53,  16,   1,   0,   0,   0],
       [ 13,  24,  17,   2,   0,   0,   0],
       [ 11,  28,   5,   0,   0,   0,   0]]), 'forgetting_measure': [0.5521581, -0.015084524, -0.04859004]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f406ac90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4109650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52327732, 'precision': 0.20116820116820116, 'recall': 0.23909481350478162, 'f1_score': 0.21389502095018235, 'confusion_matrix': array([[ 14,  82,  18,   7,   0,   0,   0],
       [ 21, 162,  44,   2,   0,   0,   0],
       [ 20,  55,  14,   4,   0,   0,   0],
       [  5,  18,   3,   0,   0,   0,   0],
       [  9,  40,  13,   2,   0,   0,   0],
       [  8,  18,  11,   0,   0,   0,   0],
       [  7,  15,   8,   0,   0,   0,   0]]), 'forgetting_measure': [0.6322073, 0.54114264, 0.20797841]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d914fa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d91d4950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6467748, 'precision': 0.28087262621234745, 'recall': 0.31720534126081542, 'f1_score': 0.26875986232840054, 'confusion_matrix': array([[291,  27,   4,   0,   0,   0,   0],
       [ 77, 113,   2,   0,   0,   0,   0],
       [ 95,  43,   4,   0,   0,   0,   0],
       [ 52,  18,   1,   0,   0,   0,   0],
       [ 68,   5,   0,   0,   0,   0,   0],
       [ 49,   6,   0,   0,   0,   0,   0],
       [ 24,  19,   1,   1,   0,   0,   0]]), 'forgetting_measure': [0.6137046, 0.16703817, 0.06817728]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d914fa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d91d4950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50888245, 'precision': 0.17458544781819108, 'recall': 0.2349994543271854, 'f1_score': 0.19583334724109041, 'confusion_matrix': array([[173,  54,   4,   0,   0,   0,   0],
       [ 81,  20,   1,   0,   0,   0,   0],
       [ 80,  31,   0,   0,   0,   0,   0],
       [ 31,   9,   0,   0,   0,   0,   0],
       [ 34,  15,   0,   0,   0,   0,   0],
       [ 26,  15,   0,   0,   0,   0,   0],
       [ 18,   8,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57041398, 0.40240586, 0.3770673]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d9b09b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d98a0950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56881152, 'precision': 0.3881657619960361, 'recall': 0.3740155303474042, 'f1_score': 0.3668096831452104, 'confusion_matrix': array([[ 91,  35,  82,   5,   5,   7,   0],
       [ 47,  89,  43,   3,   1,  19,   0],
       [ 77,  25, 118,   5,   2,  12,   0],
       [ 21,  14,  15,   9,   3,   3,   0],
       [ 25,   8,  19,  10,   5,   2,   0],
       [ 20,  14,   2,   0,   0,  21,   0],
       [ 18,   3,   7,   1,   2,  12,   0]]), 'forgetting_measure': [0.53033162, 0.10511538, 0.24433126]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d9b09b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d98a0950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43981364, 'precision': 0.23481426517928233, 'recall': 0.247208192405864, 'f1_score': 0.23419440454705603, 'confusion_matrix': array([[32, 29, 64,  4,  1,  3,  0],
       [41, 19, 37,  8,  4, 15,  0],
       [50, 45, 67,  4,  5, 24,  0],
       [12,  8, 11,  3,  2,  3,  0],
       [13,  9, 11,  6,  1,  2,  0],
       [10,  6,  4,  0,  1,  5,  0],
       [13,  5,  5,  0,  0, 18,  0]]), 'forgetting_measure': [0.41015798, 0.2355854, 0.27371815]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ef314610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ebc7c090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54350115, 'precision': 0.29825865469204024, 'recall': 0.29957245475193347, 'f1_score': 0.28045598737908142, 'confusion_matrix': array([[  9,   8, 105,  10,   3,   8,   0],
       [ 13,  11, 102,   8,   4,  11,   0],
       [ 18,  18, 290,  24,   2,  24,   0],
       [  2,   8,  35,  15,   2,   8,   0],
       [  0,   9,  34,  12,   2,   5,   0],
       [  1,   0,  44,   0,   5,  16,   0],
       [  0,   0,  24,   0,   2,   8,   0]]), 'forgetting_measure': [0.51244584, 0.21611811, 0.08833672]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ef314610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ebc7c090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5834051, 'precision': 0.26818588679490934, 'recall': 0.2985336427954541, 'f1_score': 0.25755617239228079, 'confusion_matrix': array([[  2,   3,  68,   9,   2,  11,   0],
       [  0,   2,  59,   6,   3,   4,   0],
       [  2,  12, 202,  22,   3,  22,   0],
       [  3,   1,  34,   9,   3,   9,   0],
       [  1,   0,  26,  10,   0,   5,   0],
       [  0,   0,  16,   0,   6,  16,   0],
       [  1,   0,  13,   0,   2,  13,   0]]), 'forgetting_measure': [0.6954985, 0.63542354, -0.5550655]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e08372d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cfdef390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5956938, 'precision': 0.2135503130915975, 'recall': 0.24273378288645158, 'f1_score': 0.19057974992040928, 'confusion_matrix': array([[  3, 127,   5,   1,   0,   0,   0],
       [ 11, 354,   2,   0,   0,   0,   0],
       [  4, 154,   2,   0,   0,   0,   0],
       [  0,  52,   0,   0,   0,   0,   0],
       [  0,  85,   0,   0,   0,   0,   0],
       [  0,  60,   0,   0,   0,   0,   0],
       [  0,  40,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5738452, 0.1683802, 0.19002713]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e08372d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cfdef390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6249877, 'precision': 0.157857142857142864, 'recall': 0.24285714285714285, 'f1_score': 0.18235892221657347, 'confusion_matrix': array([[  0, 110,   0,   0,   0,   0,   0],
       [  0, 243,   0,   0,   0,   0,   0],
       [  0,  89,   0,   0,   0,   0,   0],
       [  0,  39,   0,   0,   0,   0,   0],
       [  0,  52,   0,   0,   0,   0,   0],
       [  0,  32,   0,   0,   0,   0,   0],
       [  0,  35,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.70011995, 0.36346284, 0.23338898]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552af895fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552beac4a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49645532, 'precision': 0.138571428571428576, 'recall': 0.24285714285714285, 'f1_score': 0.16074240719910012, 'confusion_matrix': array([[243,   0,   0,   0,   0,   0,   0],
       [249,   0,   0,   0,   0,   0,   0],
       [174,   0,   0,   0,   0,   0,   0],
       [ 61,   0,   0,   0,   0,   0,   0],
       [ 73,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42239068, 0.049646985, 0.14946726]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552af895fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552beac4a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40184869, 'precision': 0.127857142857142858, 'recall': 0.24285714285714285, 'f1_score': 0.1466228332337119, 'confusion_matrix': array([[117,   0,   0,   0,   0,   0,   0],
       [198,   0,   0,   0,   0,   0,   0],
       [135,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0],
       [ 25,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4100948, 0.5068705, 0.067896865]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552be905f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c7b72810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44341993, 'precision': 0.139523809523809524, 'recall': 0.24285714285714285, 'f1_score': 0.161917195076464, 'confusion_matrix': array([[249,   0,   0,   0,   0,   0,   0],
       [227,   0,   0,   0,   0,   0,   0],
       [188,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 74,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42239068, 0.33494875, 0.09768132]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552be905f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c7b72810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43148403, 'precision': 0.132857142857142856, 'recall': 0.24285714285714285, 'f1_score': 0.15342624854819977, 'confusion_matrix': array([[138,   0,   0,   0,   0,   0,   0],
       [170,   0,   0,   0,   0,   0,   0],
       [136,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [ 28,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4100948, 0.4344744, -0.19173668]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e97d2790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9d14b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54688705, 'precision': 0.33392167550619927, 'recall': 0.29755872707993613, 'f1_score': 0.2845421473172583, 'confusion_matrix': array([[ 32,  79,  42,   2,   0,   0,   0],
       [  2, 169,  93,   0,   0,   0,   0],
       [  7, 136, 108,   3,   0,   0,   0],
       [  6,  37,  13,   7,   0,   0,   0],
       [  1,  44,  18,   1,   0,   0,   0],
       [  9,  21,  10,   2,   0,   0,   0],
       [ 10,  43,   5,   0,   0,   0,   0]]), 'forgetting_measure': [0.51553992, 0.18937919, 0.14418899]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e97d2790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9d14b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51336775, 'precision': 0.23172565986920234, 'recall': 0.252044233063184, 'f1_score': 0.2306264025911795, 'confusion_matrix': array([[ 10,  38,  46,   2,   0,   0,   0],
       [ 14, 101,  82,   4,   0,   0,   0],
       [ 10,  70,  59,   2,   0,   0,   0],
       [  7,  28,  14,   2,   0,   0,   0],
       [  5,  22,  14,   3,   0,   0,   0],
       [  4,  13,  12,   0,   0,   0,   0],
       [  3,  21,  13,   1,   0,   0,   0]]), 'forgetting_measure': [0.56777606, 0.40489197, 0.30328408]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c803e810>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c10ac510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4697668, 'precision': 0.2106642066212985, 'recall': 0.21724223275947414, 'f1_score': 0.20198324816805057, 'confusion_matrix': array([[ 36,  61, 101,   2,   1,   2,   0,   0],
       [ 43,  43, 120,   0,   2,   2,   0,   0],
       [ 52,  66, 134,   2,   3,   1,   0,   1],
       [ 11,  16,  48,   0,   0,   0,   0,   0],
       [ 12,   7,  34,   0,   0,   0,   0,   0],
       [  8,   6,  36,   0,   0,   2,   0,   0],
       [ 11,   6,  28,   0,   0,   3,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43163887, 0.40965626, -0.4397755]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c803e810>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c10ac510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44438034, 'precision': 0.20314891361352499, 'recall': 0.2328385035281587, 'f1_score': 0.21368678537747863, 'confusion_matrix': array([[30, 47, 67,  0,  0,  1,  0],
       [39, 47, 59,  1,  0,  2,  0],
       [41, 42, 60,  0,  2,  3,  0],
       [ 9,  5, 29,  0,  3,  1,  0],
       [ 8,  4, 32,  0,  0,  1,  0],
       [ 8,  6, 14,  0,  0,  0,  0],
       [12,  3, 21,  1,  0,  2,  0]]), 'forgetting_measure': [0.43777314, 0.4525608, -0.13816108]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e98d3750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db594fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5125814, 'precision': 0.21836552442468473, 'recall': 0.23696423342405012, 'f1_score': 0.20700243540069938, 'confusion_matrix': array([[213,  81,   5,  12,   0,   0,   0],
       [140,  48,   6,  11,   3,   0,   0],
       [106,  36,   4,   7,   0,   0,   0],
       [ 30,  27,   0,   1,   1,   0,   0],
       [ 34,  33,   1,   1,   0,   0,   0],
       [ 34,  20,   0,   0,   0,   0,   0],
       [ 28,  17,   0,   0,   1,   0,   0]]), 'forgetting_measure': [0.5378503, 0.43618634, -0.024960682]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e98d3750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552db594fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53561662, 'precision': 0.2435011496651545, 'recall': 0.24423921046281826, 'f1_score': 0.21781726153857792, 'confusion_matrix': array([[168,  50,   5,   4,   2,   0,   0],
       [ 92,  23,   4,   0,   1,   0,   0],
       [ 75,  19,   1,   2,   0,   0,   0],
       [ 23,  27,   0,   4,   0,   0,   0],
       [ 14,  17,   1,   1,   0,   0,   0],
       [ 29,   2,   0,   0,   0,   0,   0],
       [ 32,   4,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.53854573, 0.234066, 0.30810058]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c076eed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b456f790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55546705, 'precision': 0.367132024666228, 'recall': 0.2949684392084235, 'f1_score': 0.29455361428558002, 'confusion_matrix': array([[ 24, 106,   6,  13,   1,   1,   9,   0],
       [ 11, 290,  23,  14,   1,   3,   6,   6],
       [  5, 106,  16,   9,   0,   1,   3,   1],
       [  3,  61,   4,  21,   0,   1,   1,   0],
       [  4,  30,   1,  12,   4,   0,   3,   0],
       [  4,  26,   7,   8,   1,   1,   0,   0],
       [  2,  27,   2,   6,   5,   2,   8,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.58076314, 0.34995115, 0.12607549]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c076eed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b456f790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60140453, 'precision': 0.27461509844322345, 'recall': 0.262830948242387, 'f1_score': 0.24829109616407538, 'confusion_matrix': array([[  6,  70,   4,   8,   2,   1,   1,   0],
       [ 11, 193,  10,  19,   3,   4,   9,   0],
       [  7,  77,   5,   8,   0,   2,   1,   2],
       [  2,  42,   3,  13,   0,   1,   3,   0],
       [  0,  20,   0,   6,   0,   0,   0,   0],
       [  0,  27,   3,   2,   0,   1,   5,   2],
       [  1,  19,   1,   0,   0,   0,   5,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.7300679, 0.47308347, 0.27061015]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529f5a7a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ef90c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4799479, 'precision': 0.27663508874330872, 'recall': 0.27489540177734672, 'f1_score': 0.2518182242764703, 'confusion_matrix': array([[181,  13,  54,   9,   0,  11,   0],
       [142,   8,  32,   2,   0,  10,   0],
       [131,  15,  46,   3,   0,   6,   0],
       [ 52,   1,   2,   4,   0,   3,   0],
       [ 58,   1,   8,   4,   0,   4,   0],
       [ 42,   0,  13,   0,   0,  15,   0],
       [ 17,   0,   6,   0,   0,   7,   0]]), 'forgetting_measure': [0.44370783, 0.21934894, 0.15092605]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529f5a7a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ef90c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46202098, 'precision': 0.28495426655532024, 'recall': 0.2824005528581341, 'f1_score': 0.252550072334245, 'confusion_matrix': array([[117,   1,  55,   8,   0,  13,   0],
       [ 64,   1,  32,   1,   0,  10,   0],
       [ 88,   0,  38,   6,   0,   8,   0],
       [ 28,   0,   8,   4,   0,   3,   0],
       [ 38,   1,   3,   3,   0,   3,   0],
       [ 16,   0,  12,   0,   0,  12,   0],
       [ 11,   0,   9,   0,   0,   7,   0]]), 'forgetting_measure': [0.38382087, 0.098092, 0.037965957]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dc72c610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d0961410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41921694, 'precision': 0.2714577388470608, 'recall': 0.24838717730161408, 'f1_score': 0.25271578292379134, 'confusion_matrix': array([[58, 58, 76,  6,  9,  5,  5,  1,  0],
       [51, 68, 67,  4,  6,  6,  6,  2,  1],
       [48, 77, 81,  2, 11,  7,  7,  2,  0],
       [10, 25, 21,  5,  4,  4,  2,  0,  0],
       [18, 16, 20,  5,  2,  1,  1,  2,  0],
       [16,  9, 14,  0,  0,  7,  4,  2,  0],
       [18,  5, 10,  1,  0,  3,  8,  3,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.42037464, 0.37770444, 0.30827078]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dc72c610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d0961410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42041951, 'precision': 0.29391539735041347, 'recall': 0.26586025301122637, 'f1_score': 0.2667126608060801, 'confusion_matrix': array([[40, 55, 34,  0,  6,  2,  1],
       [44, 45, 51,  2,  5,  7,  7],
       [46, 39, 42,  1,  9,  8,  3],
       [12, 14, 11,  1,  4,  1,  1],
       [12, 16, 11,  1,  1,  0,  1],
       [13,  8, 10,  0,  0,  6,  1],
       [10,  7,  5,  0,  0,  4,  3]]), 'forgetting_measure': [0.3650721, 0.26204282, -0.025370203]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529854bf90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552987d9390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59582825, 'precision': 0.37268447589687084, 'recall': 0.35108267954912844, 'f1_score': 0.3447065763243883, 'confusion_matrix': array([[ 43,  81,   8,  20,   1,   2,  10,   0],
       [ 16, 261,  24,  28,   4,   8,   3,   0],
       [  1,  99,  19,  25,   4,  10,   1,   0],
       [ 11,  35,   3,  30,   2,   3,   3,   0],
       [  1,  13,   6,  19,   0,   4,   2,   0],
       [  0,  17,   1,   5,   4,  19,   2,   1],
       [ 12,  18,   1,   5,   5,   3,   7,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57492313, 0.18172036, 0.16643038]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529854bf90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552987d9390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54440613, 'precision': 0.31055839765584425, 'recall': 0.30726292819796072, 'f1_score': 0.30225928961188439, 'confusion_matrix': array([[ 11,  46,   8,  11,   2,   9,   2],
       [ 34, 124,  30,  37,   8,  13,   3],
       [ 18,  53,   9,  19,   2,   4,   2],
       [  2,  28,   3,  17,   1,   7,   1],
       [  3,  10,   3,  10,   1,   2,   0],
       [  4,  15,   0,   4,   2,   7,   5],
       [  3,  10,   2,   3,   3,   2,   7]]), 'forgetting_measure': [0.691964, 0.62942195, -0.011472466]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dc975290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c6114090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6643603, 'precision': 0.32111696329763775, 'recall': 0.3059488646326994, 'f1_score': 0.27519553249498612, 'confusion_matrix': array([[ 91,  99,   1,   0,   0,   0,   0],
       [ 16, 344,   3,   0,   0,   0,   0],
       [  9, 103,   2,   0,   0,   0,   0],
       [  0,  84,   0,   0,   0,   0,   0],
       [  0,  48,   0,   0,   0,   0,   0],
       [  2,  45,   0,   0,   0,   0,   0],
       [  0,  53,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.6795827, 0.27434257, 0.06576347]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dc975290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c6114090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.58320023, 'precision': 0.19558823529411765, 'recall': 0.24869359114883413, 'f1_score': 0.20326852817163523, 'confusion_matrix': array([[ 20, 117,   1,   0,   0,   0,   0],
       [ 21, 198,   2,   0,   0,   0,   0],
       [ 12,  71,   0,   0,   0,   0,   0],
       [  8,  55,   0,   0,   0,   0,   0],
       [  1,  27,   0,   0,   0,   0,   0],
       [  4,  32,   0,   0,   0,   0,   0],
       [  2,  28,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.58192665, 0.28697407, 0.05697603]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552adc3d4d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529d9c1390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5232624, 'precision': 0.24790770028519576, 'recall': 0.28194710432057626, 'f1_score': 0.2476795032442903, 'confusion_matrix': array([[  9,   1, 132,   6,   1,  14,   1],
       [ 10,   0, 112,  12,   0,  10,   0],
       [ 17,   1, 308,  19,   1,  14,   0],
       [  2,   0,  64,  12,   0,   4,   2],
       [  1,   0,  38,   8,   0,   1,   0],
       [  3,   0,  42,   0,   0,  13,   1],
       [  3,   0,  29,   0,   0,   9,   0]]), 'forgetting_measure': [0.50950948, 0.22285318, 0.23949887]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552adc3d4d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529d9c1390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60311977, 'precision': 0.22113393005531944, 'recall': 0.26058978615369593, 'f1_score': 0.22337548236335795, 'confusion_matrix': array([[  0,   0,  85,   3,   0,   3,   0],
       [  0,   0,  80,   3,   0,   3,   0],
       [  0,   0, 249,   7,   1,   9,   0],
       [  1,   0,  43,   6,   1,   4,   0],
       [  0,   0,  30,   3,   0,   2,   0],
       [  0,   0,  32,   0,   0,   3,   3],
       [  0,   0,  28,   0,   0,   1,   0]]), 'forgetting_measure': [0.7108951, 0.4603987, 0.18449046]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552deaeac90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c64135d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47929276, 'precision': 0.25692622612296275, 'recall': 0.23424736583801156, 'f1_score': 0.23008415017230623, 'confusion_matrix': array([[136,  94,  31,  12,   2,  15,   1,   0,   0],
       [ 79,  74,  29,   5,   1,   7,   2,   0,   0],
       [ 67,  58,  33,   7,   0,   3,   3,   1,   1],
       [ 53,  30,   8,   4,   0,   2,   0,   0,   0],
       [ 20,  15,   6,   0,   0,   0,   0,   0,   1],
       [ 21,   3,  10,   0,   0,   2,   3,   0,   0],
       [ 33,   3,  13,   0,   2,   5,   5,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47507764, 0.25348407, 0.34714913]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552deaeac90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c64135d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42391932, 'precision': 0.2993938803271283, 'recall': 0.29780226286825667, 'f1_score': 0.284817476410819, 'confusion_matrix': array([[74, 68, 21,  8,  0,  2,  2],
       [53, 42, 20,  4,  0,  6,  3],
       [52, 52, 25,  8,  0,  5,  2],
       [10, 25,  9,  6,  0,  3,  2],
       [ 9, 12,  5,  3,  0,  1,  1],
       [ 7,  2,  5,  0,  0,  6,  1],
       [22,  0, 10,  0,  0, 11,  3]]), 'forgetting_measure': [0.3706074, 0.3649398, -0.3342795]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ba606890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ba437890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42336778, 'precision': 0.133174603174603176, 'recall': 0.24285714285714285, 'f1_score': 0.15384516295246684, 'confusion_matrix': array([[209,   0,   0,   0,   0,   0,   0],
       [236,   0,   0,   0,   0,   0,   0],
       [224,   0,   0,   0,   0,   0,   0],
       [ 68,   0,   0,   0,   0,   0,   0],
       [ 63,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 66,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3862887, 0.3364033, -0.020287374]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ba606890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ba437890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4541266, 'precision': 0.1319047619047619, 'recall': 0.24285714285714285, 'f1_score': 0.15216037368625924, 'confusion_matrix': array([[134,   0,   0,   0,   0,   0,   0],
       [178,   0,   0,   0,   0,   0,   0],
       [131,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 14,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38786135, -0.014719396, 0.37548476]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfa32790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bae0ee90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42897017, 'precision': 0.132857142857142856, 'recall': 0.24285714285714285, 'f1_score': 0.15342624854819977, 'confusion_matrix': array([[207,   0,   0,   0,   0,   0,   0],
       [232,   0,   0,   0,   0,   0,   0],
       [231,   0,   0,   0,   0,   0,   0],
       [ 68,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 37,   0,   0,   0,   0,   0,   0],
       [ 63,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3820933, 0.29007468, -0.02140612]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfa32790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bae0ee90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41465896, 'precision': 0.13214285714285715, 'recall': 0.24285714285714285, 'f1_score': 0.15247813411078717, 'confusion_matrix': array([[135,   0,   0,   0,   0,   0,   0],
       [159,   0,   0,   0,   0,   0,   0],
       [154,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0],
       [ 37,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38841233, 0.3918219, -0.02709386]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155291ba1cd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528165c790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60231535, 'precision': 0.38530776665240976, 'recall': 0.33465604291541678, 'f1_score': 0.32194892739041322, 'confusion_matrix': array([[ 80, 103,  23,   1,   5,   5,   0],
       [ 22, 219,  28,   1,   2,   1,   0],
       [ 25, 101,  45,   0,   2,   0,   0],
       [ 44,  11,   5,   2,   2,   0,   0],
       [ 44,  22,   3,   1,   1,   2,   0],
       [ 12,  20,  10,   1,   2,   9,   0],
       [ 28,  11,   4,   1,   1,   1,   0]]), 'forgetting_measure': [0.51922292, -0.0130830165, 0.14525786]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155291ba1cd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528165c790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43384278, 'precision': 0.238658523225241, 'recall': 0.23325005854446065, 'f1_score': 0.2275162528793178, 'confusion_matrix': array([[ 11,  73,  14,   0,   2,   2,   0],
       [ 62, 121,  31,   3,   4,   2,   0],
       [ 24,  75,  18,   0,   2,   4,   0],
       [ 22,  16,   5,   0,   1,   3,   0],
       [ 18,  15,   3,   0,   2,   0,   0],
       [ 16,  13,   3,   0,   1,   3,   0],
       [ 10,   7,   6,   1,   3,   4,   0]]), 'forgetting_measure': [0.43629966, 0.3203546, 0.40207663]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c1668210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c16dc090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.58577595, 'precision': 0.21566671000966366, 'recall': 0.25051907283585317, 'f1_score': 0.21665460863147989, 'confusion_matrix': array([[ 12, 148,   2,  10,   0,   1,   0],
       [ 31, 342,   0,  17,   0,   1,   0],
       [  5, 101,   0,   3,   0,   0,   0],
       [  3,  62,   0,   8,   0,   0,   0],
       [  3,  43,   0,   8,   0,   0,   0],
       [  2,  49,   0,   0,   0,   0,   0],
       [  3,  46,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.6000821, 0.24621981, 0.25642055]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c1668210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c16dc090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.57976065, 'precision': 0.3635175683379842, 'recall': 0.26097800170989304, 'f1_score': 0.2181473644541382, 'confusion_matrix': array([[  6, 129,   0,   7,   0,   0,   0],
       [ 14, 197,   0,  13,   0,   0,   0],
       [  2,  66,   1,   9,   0,   0,   0],
       [  0,  42,   0,  10,   0,   0,   0],
       [  0,  30,   0,   6,   0,   1,   0],
       [  1,  34,   0,   0,   0,   0,   0],
       [  1,  31,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.56613076, 0.13765994, 0.32534117]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155283cafa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155279811fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.61201776, 'precision': 0.34718430297034152, 'recall': 0.38625969204886254, 'f1_score': 0.36383271080494647, 'confusion_matrix': array([[179,  31,  21,   3,  14,   0,   0],
       [ 28,  70,  84,   9,   1,   0,   0],
       [ 28,  58, 141,   4,   4,   0,   0],
       [  7,  15,  34,   0,   6,   0,   0],
       [ 26,   3,  12,   2,  20,   0,   0],
       [ 15,  17,  15,   1,   6,   0,   0],
       [ 26,   3,  10,   1,   6,   0,   0]]), 'forgetting_measure': [0.56761104, 0.25125167, -0.19477804]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155283cafa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155279811fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4106377, 'precision': 0.22776385630445533, 'recall': 0.23880164860557018, 'f1_score': 0.23059315243820957, 'confusion_matrix': array([[52, 42, 56,  3,  9,  0,  0],
       [52, 28, 41,  6,  5,  0,  0],
       [56, 37, 45,  4,  8,  0,  0],
       [ 4, 10, 14,  1,  5,  0,  0],
       [15,  7, 25,  2,  6,  0,  0],
       [14, 13, 10,  0,  3,  0,  0],
       [ 9,  7,  8,  0,  3,  0,  0]]), 'forgetting_measure': [0.39854587, 0.5084087, -0.2714734]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c146fd50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b3b0cb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41841793, 'precision': 0.129523809523809525, 'recall': 0.24285714285714285, 'f1_score': 0.1489344909234412, 'confusion_matrix': array([[186,   0,   0,   0,   0,   0,   0],
       [359,   0,   0,   0,   0,   0,   0],
       [120,   0,   0,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42029897, 0.39732346, 0.26481265]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c146fd50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b3b0cb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45039873, 'precision': 0.134523809523809526, 'recall': 0.24285714285714285, 'f1_score': 0.15560882070949185, 'confusion_matrix': array([[145,   0,   0,   0,   0,   0,   0],
       [225,   0,   0,   0,   0,   0,   0],
       [ 71,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43520648, 0.3571323, 0.06959428]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155279696b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155273c0a190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55648254, 'precision': 0.152598124900683295, 'recall': 0.24242685025817556, 'f1_score': 0.17682488104908901, 'confusion_matrix': array([[331,   1,   0,   0,   0,   0,   0],
       [181,   0,   0,   0,   0,   0,   0],
       [146,   0,   0,   0,   0,   0,   0],
       [ 81,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57022066, 0.26258788, 0.2718585]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155279696b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155273c0a190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6210053, 'precision': 0.155714285714285716, 'recall': 0.24285714285714285, 'f1_score': 0.18016443987667009, 'confusion_matrix': array([[234,   0,   0,   0,   0,   0,   0],
       [102,   0,   0,   0,   0,   0,   0],
       [112,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 43,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 25,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.66311727, 0.3300547, 0.14477326]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155266f09b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155267cb4790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40787463, 'precision': 0.128095238095238093, 'recall': 0.24285714285714285, 'f1_score': 0.1469558296856347, 'confusion_matrix': array([[177,   0,   0,   0,   0,   0,   0],
       [353,   0,   0,   0,   0,   0,   0],
       [131,   0,   0,   0,   0,   0,   0],
       [ 87,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 58,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42029897, 0.47184426, 0.20695803]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155266f09b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155267cb4790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43490694, 'precision': 0.13214285714285715, 'recall': 0.24285714285714285, 'f1_score': 0.15247813411078717, 'confusion_matrix': array([[135,   0,   0,   0,   0,   0,   0],
       [231,   0,   0,   0,   0,   0,   0],
       [ 76,   0,   0,   0,   0,   0,   0],
       [ 61,   0,   0,   0,   0,   0,   0],
       [ 30,   0,   0,   0,   0,   0,   0],
       [ 27,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43520648, 0.354229, 0.292973]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b3cdba10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a988f290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42126234, 'precision': 0.2698487153307045, 'recall': 0.25505698674997045, 'f1_score': 0.2543637085690724, 'confusion_matrix': array([[64, 48, 74,  9,  5,  0,  4],
       [67, 52, 90, 10,  6,  0, 12],
       [84, 52, 65,  9,  8,  0,  5],
       [24,  1, 21,  3,  2,  0,  0],
       [42,  8, 28,  1,  3,  0,  3],
       [ 1,  4, 12,  6,  2,  0,  3],
       [ 2, 13, 29, 12,  4,  0, 12]]), 'forgetting_measure': [0.4260284, 0.43973374, 0.15091628]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b3cdba10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a988f290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4062881, 'precision': 0.2706305258638352, 'recall': 0.27224333792909022, 'f1_score': 0.26548445279372728, 'confusion_matrix': array([[39, 21, 53,  3,  4,  0,  2],
       [58, 37, 50,  7,  8,  0, 11],
       [45, 26, 61,  8,  7,  0,  6],
       [17,  3, 15,  1,  0,  0,  3],
       [22,  6, 16,  1,  1,  0,  2],
       [ 1,  3,  3,  3,  3,  0,  5],
       [ 1,  9, 17,  5,  6,  0, 11]]), 'forgetting_measure': [0.41858736, 0.3561545, 0.53609884]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155270ead310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155271754c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4328935, 'precision': 0.137460317460317465, 'recall': 0.24285714285714285, 'f1_score': 0.159356136820925554, 'confusion_matrix': array([[236,   0,   0,   0,   0,   0,   0],
       [204,   0,   0,   0,   0,   0,   0],
       [221,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 79,   0,   0,   0,   0,   0,   0],
       [ 54,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.41484348, 0.23709443, 0.40198314]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155270ead310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155271754c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4920896, 'precision': 0.14071428571428571, 'recall': 0.24285714285714285, 'f1_score': 0.16336853807670928, 'confusion_matrix': array([[171,   0,   0,   0,   0,   0,   0],
       [135,   0,   0,   0,   0,   0,   0],
       [135,   0,   0,   0,   0,   0,   0],
       [ 26,   0,   0,   0,   0,   0,   0],
       [ 66,   0,   0,   0,   0,   0,   0],
       [ 43,   0,   0,   0,   0,   0,   0],
       [ 24,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.46459395, 0.22715239, 0.18410468]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155257135a10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552627769d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37415355, 'precision': 0.29515725959250457, 'recall': 0.32307120535423117, 'f1_score': 0.28512813630025882, 'confusion_matrix': array([[25, 72, 33, 26, 34, 14, 19],
       [31, 46, 43, 28, 25, 18, 23],
       [21, 71, 34, 38, 30, 16, 20],
       [ 0, 20,  0, 20, 19,  9,  2],
       [ 1, 19,  0, 15, 15, 10,  3],
       [ 0,  8,  0,  7,  7,  8, 16],
       [ 0, 12,  0,  2,  9, 10, 21]]), 'forgetting_measure': [0.37506408, 0.50558865, 0.18083857]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155257135a10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552627769d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3557502, 'precision': 0.2917614673720263, 'recall': 0.32517128610810785, 'f1_score': 0.28443376956495808, 'confusion_matrix': array([[19, 35, 23, 27, 18, 13, 15],
       [22, 27, 27, 19, 21, 12, 15],
       [21, 42, 22, 21, 22, 11, 12],
       [ 0, 17,  0, 17, 10,  6,  5],
       [ 0, 11,  0,  9,  6,  2,  6],
       [ 0,  7,  0,  2,  2, 10, 14],
       [ 0,  4,  0,  3,  3, 11, 11]]), 'forgetting_measure': [0.33335403, 0.3583402, 0.4379185]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a9673f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a5fc38d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56867514, 'precision': 0.2881052624595799, 'recall': 0.33018069944896996, 'f1_score': 0.30499384801054527, 'confusion_matrix': array([[164,  42,  29,   1,  21,   0,   0],
       [ 44,  61,  82,   0,  13,   1,   0],
       [ 26,  52, 106,   0,  12,   1,   0],
       [ 34,   9,  21,   0,   5,   0,   0],
       [ 57,   3,   6,   0,  10,   0,   0],
       [ 16,   5,  11,   1,  19,   0,   0],
       [ 26,   0,   5,   4,  13,   0,   0]]), 'forgetting_measure': [0.51866577, -0.047961034, 0.43335187]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a9673f50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a5fc38d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41216293, 'precision': 0.21179402923271455, 'recall': 0.22785240835537365, 'f1_score': 0.21587094800054427, 'confusion_matrix': array([[54, 22, 64,  0, 18,  0,  0],
       [51, 23, 42,  0, 12,  0,  0],
       [72, 21, 48,  2, 12,  0,  0],
       [22,  5, 14,  0,  4,  0,  0],
       [28,  4, 10,  2,  3,  0,  0],
       [ 9,  5,  9,  1, 15,  0,  0],
       [ 9,  5,  6,  1,  6,  1,  0]]), 'forgetting_measure': [0.4836088, 0.5513942, 0.53052855]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524a1afa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524a6e0790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5717477, 'precision': 0.41191271625437783, 'recall': 0.4092126219955102, 'f1_score': 0.4006621443930843, 'confusion_matrix': array([[ 71,  48,  46,   2,  19,   6,  13],
       [ 12, 134,  36,   3,  23,   8,   3],
       [ 20,  60, 114,   5,  16,  10,   5],
       [  6,  24,  17,   2,  10,   4,   1],
       [ 12,  32,   2,   2,  22,   7,   5],
       [  0,  12,  11,   4,   6,   6,  14],
       [  1,  11,   5,   3,   6,   7,  14]]), 'forgetting_measure': [0.58555106, 0.10743028, 0.5470481]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524a1afa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524a6e0790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46182556, 'precision': 0.3663471375877391, 'recall': 0.3383175604511424, 'f1_score': 0.31184423715401055, 'confusion_matrix': array([[25, 62, 45,  6, 18,  0,  6],
       [15, 67, 41,  6, 15,  0,  8],
       [22, 47, 37,  4, 10,  1,  6],
       [ 6, 14,  9,  0, 18,  0,  7],
       [ 6,  7,  7,  2, 15,  0,  1],
       [ 0, 12,  6,  2,  0,  1,  6],
       [ 1, 13,  9,  3,  0,  0, 14]]), 'forgetting_measure': [0.4549817, 0.31725818, 0.22374363]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbfae890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b0598490>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47053323, 'precision': 0.26673393765881173, 'recall': 0.29602135480618452, 'f1_score': 0.25288917864629784, 'confusion_matrix': array([[178,  17,  38,   0,   8,  25,   0],
       [129,   4,  27,   0,   3,  24,   0],
       [137,   7,  33,   0,   8,  23,   0],
       [ 48,   1,   6,   0,   1,   7,   0],
       [ 54,   1,   6,   0,   5,  10,   0],
       [ 37,   1,   0,   0,   0,  32,   0],
       [ 19,   0,   0,   0,   0,  11,   0]]), 'forgetting_measure': [0.44983626, 0.26085514, 0.21423124]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bbfae890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b0598490>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47627048, 'precision': 0.2113462692428161, 'recall': 0.2945442908346134, 'f1_score': 0.22848482700817374, 'confusion_matrix': array([[131,   3,  30,   0,   0,  36,   0],
       [ 81,   0,  16,   0,   0,  28,   0],
       [ 92,   0,  16,   0,   0,  16,   0],
       [ 34,   0,   0,   0,   0,   3,   0],
       [ 40,   0,   0,   0,   0,   7,   0],
       [ 19,   0,   0,   0,   0,  26,   0],
       [  5,   0,   0,   0,   0,  17,   0]]), 'forgetting_measure': [0.42068455, 0.1441529, 0.14860976]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525bb5b490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525b3a0790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4248958, 'precision': 0.24214972476040985, 'recall': 0.25430135102667028, 'f1_score': 0.23856151306795245, 'confusion_matrix': array([[ 62,  12,  90,  21,  17,  10,   2],
       [ 56,  11,  74,  20,  20,   6,   3],
       [ 72,  18, 104,  22,  31,   6,   2],
       [ 24,   6,  26,   8,  16,   1,   0],
       [ 11,   7,  17,  11,  11,   3,   0],
       [ 20,   0,  16,   0,   9,   2,   0],
       [ 15,   0,  22,   0,  12,   4,   0]]), 'forgetting_measure': [0.4601024, 0.48930007, 0.28940886]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525bb5b490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525b3a0790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45154436, 'precision': 0.2568712257727567, 'recall': 0.2645976423747891, 'f1_score': 0.251718502498199, 'confusion_matrix': array([[55,  5, 44, 19, 13,  7,  1],
       [38, 12, 58, 10, 18,  2,  4],
       [46,  9, 58, 24, 15,  3,  0],
       [13, 15, 13,  5,  4,  2,  0],
       [ 6,  5, 12, 11,  4,  2,  0],
       [11,  0,  7,  0,  5,  3,  0],
       [12,  0, 13,  0, 10,  6,  0]]), 'forgetting_measure': [0.46275375, 0.49578953, -0.14253807]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155248cdb490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552480b4190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56172235, 'precision': 0.4256985002856977, 'recall': 0.37032814166126534, 'f1_score': 0.3533850869827922, 'confusion_matrix': array([[ 56,  90,  36,   5,  20,   0,  10],
       [ 20, 167,  40,  13,  15,   0,   5],
       [ 18, 102,  28,  19,  19,   0,   6],
       [  2,  17,   9,   7,   5,   0,   2],
       [ 14,  30,  10,   7,  17,   0,  11],
       [  7,   8,   1,  10,  21,   7,  12],
       [  5,   5,   0,   2,   6,   3,  13]]), 'forgetting_measure': [0.55118886, 0.4932628, -0.7728934]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155248cdb490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552480b4190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45369546, 'precision': 0.29644217875051084, 'recall': 0.30040849898088017, 'f1_score': 0.27891010983271677, 'confusion_matrix': array([[17, 74, 12,  5, 11,  1, 17],
       [14, 96, 15, 12, 24,  1,  5],
       [20, 83, 18,  3, 14,  2,  3],
       [ 5,  4,  5,  4,  4,  0,  3],
       [19,  9,  4, 11, 12,  0,  6],
       [ 5, 16,  0,  3,  5,  1,  6],
       [ 5,  8,  0,  6,  3,  3,  6]]), 'forgetting_measure': [0.48374823, 0.3588785, 0.46628755]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a66f82d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527c990490>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5380418, 'precision': 0.30622737839022162, 'recall': 0.2996165246893578, 'f1_score': 0.2859254373394201, 'confusion_matrix': array([[230,  46,  30,  26,   2,   0,   0],
       [125,  34,  15,  13,   4,   0,   0],
       [ 90,  13,  20,  14,   4,   0,   0],
       [ 39,   6,   8,  23,   0,   0,   0],
       [ 31,   7,   2,  13,   5,   0,   0],
       [ 25,  10,   5,   2,   1,   0,   0],
       [ 27,  21,   8,   1,   0,   0,   0]]), 'forgetting_measure': [0.5075143, 0.22774692, 0.07244008]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a66f82d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527c990490>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48493264, 'precision': 0.23256802721088437, 'recall': 0.27242657747864448, 'f1_score': 0.24324174744008408, 'confusion_matrix': array([[120,  24,  26,  25,   7,   0,   0],
       [ 70,  21,  25,  16,   1,   0,   0],
       [ 69,  18,  12,  13,   1,   0,   0],
       [ 23,   2,   3,  15,   0,   0,   0],
       [ 22,   6,   3,  11,   0,   0,   0],
       [ 17,  11,   6,   0,   2,   0,   0],
       [ 15,   8,   5,   0,   3,   0,   0]]), 'forgetting_measure': [0.43259514, 0.087380864, 0.27958304]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155247d75310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155247a67e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41838565, 'precision': 0.27184610373206022, 'recall': 0.27505725749203793, 'f1_score': 0.26700618018894087, 'confusion_matrix': array([[44, 34, 66, 21, 32, 10, 10,  2],
       [45, 28, 59, 12, 33,  8,  7,  0],
       [65, 31, 82, 22, 26, 13, 16,  0],
       [18,  2, 16, 13, 15,  4,  5,  5],
       [16,  2,  9,  5, 13,  3,  7,  1],
       [22,  1,  1,  3,  7,  6,  5,  0],
       [20,  0,  5,  3,  5, 11, 11,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.42982692, 0.40011322, 0.3557464]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155247d75310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155247a67e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40601386, 'precision': 0.25340906171486893, 'recall': 0.25217505265026438, 'f1_score': 0.2459209379750379, 'confusion_matrix': array([[39, 28, 41,  7, 21,  2, 11,  1],
       [38, 30, 41,  9, 10,  3,  6,  1],
       [36, 34, 38,  6, 29,  5,  8,  3],
       [13,  3, 10,  5, 13,  0,  5,  2],
       [14,  3,  4,  3,  9,  1,  1,  0],
       [ 8,  0,  0,  1,  6,  0,  4,  0],
       [31,  0,  0,  1,  5,  4,  7,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.412197, 0.3015209, 0.59744895]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155236869b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155237364190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51539267, 'precision': 0.3081648843750909, 'recall': 0.34641480216314532, 'f1_score': 0.3131811937168062, 'confusion_matrix': array([[ 25,  88,  38,   6,   8,   0,  27],
       [ 26, 178,  49,  11,   5,   0,  22],
       [  9,  98,  49,   8,   4,   1,  13],
       [ 10,  22,  12,  10,   4,   0,   5],
       [ 14,  38,   4,   6,   2,   0,   8],
       [  6,   1,  19,   8,   1,   0,  10],
       [  7,   0,  10,   7,   2,   0,  29]]), 'forgetting_measure': [0.52684463, 0.21899317, 0.44216454]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155236869b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155237364190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4753539, 'precision': 0.2775802585085917, 'recall': 0.32905607404956788, 'f1_score': 0.28171894923505866, 'confusion_matrix': array([[  9,  60,  20,   5,   4,   1,   7],
       [ 14, 106,  50,  13,   3,   0,  22],
       [ 12,  57,  35,   5,   3,   0,  13],
       [  7,  18,   8,   3,   2,   0,   6],
       [ 12,  17,   8,   4,   2,   0,   7],
       [  0,   3,  13,   9,   0,   0,  13],
       [  0,   1,   7,   3,   0,   0,  18]]), 'forgetting_measure': [0.51595113, 0.38995627, 0.38379022]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528c038b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527ca830d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6333477, 'precision': 0.4629139036352615, 'recall': 0.4112426345029179, 'f1_score': 0.4223387474900023, 'confusion_matrix': array([[ 49,  11,  62,   8,   9,   7,   3],
       [ 23,  31,  66,   2,   3,  10,   1],
       [ 40,  27, 279,   8,   3,  20,   1],
       [ 19,   2,  34,  27,   5,   5,   1],
       [  8,   2,  26,   4,   4,   0,   0],
       [  6,   4,  23,   3,   0,  28,   5],
       [  5,   1,  15,   0,   0,   7,   3]]), 'forgetting_measure': [0.5859679, 0.1114846, 0.11465002]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528c038b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527ca830d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5184098, 'precision': 0.29453373704968852, 'recall': 0.30934395200859918, 'f1_score': 0.29670458424631837, 'confusion_matrix': array([[ 19,  10,  42,   5,   4,   7,   2],
       [ 13,  12,  46,   6,   2,   7,   3],
       [ 48,  27, 143,  17,   8,  17,   6],
       [  4,   3,  23,   6,   0,   4,   0],
       [  6,   2,  29,   7,   1,   4,   0],
       [  1,   0,  23,   1,   0,  18,   1],
       [  3,   1,  11,   3,   0,   5,   0]]), 'forgetting_measure': [0.57569126, 0.44174406, 0.19422056]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520bd77a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520c18c510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.62843205, 'precision': 0.409115306878565, 'recall': 0.3535662518118659, 'f1_score': 0.345069856421533, 'confusion_matrix': array([[274,  33,  14,   3,   0,   0,   0],
       [102,  84,   3,   1,   0,   0,   0],
       [ 74,  29,  50,   3,   0,   0,   0],
       [ 55,   7,   8,  14,   0,   0,   0],
       [ 38,   4,   4,   0,   0,   0,   0],
       [ 39,  14,   1,   0,   0,   0,   0],
       [ 21,  23,   2,   0,   0,   0,   0]]), 'forgetting_measure': [0.5378955, -0.024732234, 0.111539595]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520bd77a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520c18c510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47733114, 'precision': 0.26058690461111622, 'recall': 0.26047061286325567, 'f1_score': 0.23945607794111323, 'confusion_matrix': array([[119,  47,  18,   1,   0,   0,   0],
       [ 79,  41,  15,   2,   0,   0,   0],
       [ 85,  29,  10,   3,   0,   0,   0],
       [ 35,   6,   3,   5,   0,   0,   0],
       [ 23,   5,   5,   2,   0,   0,   0],
       [ 20,  10,   6,   0,   0,   0,   0],
       [ 22,   8,   0,   1,   0,   0,   0]]), 'forgetting_measure': [0.5426594, 0.5044913, 0.22498791]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552348dfa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155234caca90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50929294, 'precision': 0.22175820974703658, 'recall': 0.24470158480557624, 'f1_score': 0.20464749044452573, 'confusion_matrix': array([[  8, 147,  18,   5,   2,   0,   0],
       [ 11, 219,  36,   2,   4,   0,   0],
       [ 12, 161,  28,   5,   0,   0,   0],
       [  1,  66,   3,   2,   1,   0,   0],
       [  1,  61,   5,   2,   0,   0,   0],
       [  3,  36,  14,   5,   1,   0,   0],
       [  1,  26,  13,   1,   0,   0,   0]]), 'forgetting_measure': [0.51959253, 0.24863194, 0.38776672]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552348dfa50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155234caca90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42725677, 'precision': 0.20415982950654948, 'recall': 0.2307104165944816, 'f1_score': 0.17850613843248593, 'confusion_matrix': array([[  5, 130,  10,   3,   2,   0,   0],
       [  3, 125,  18,   6,   3,   0,   0],
       [  4, 117,  10,   2,   0,   0,   0],
       [  0,  32,   3,   0,   1,   0,   0],
       [  0,  49,   5,   5,   0,   0,   0],
       [  1,  19,  13,   3,   0,   0,   0],
       [  2,  11,  14,   2,   2,   0,   0]]), 'forgetting_measure': [0.42305518, 0.25123504, 0.51704675]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525d8dc610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526b764090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46506642, 'precision': 0.137619047619047614, 'recall': 0.24285714285714285, 'f1_score': 0.15955522050508858, 'confusion_matrix': array([[  0,   0, 205,   0,   0,   0,   0],
       [  0,   0, 221,   0,   0,   0,   0],
       [  0,   0, 237,   0,   0,   0,   0],
       [  0,   0,  72,   0,   0,   0,   0],
       [  0,   0,  65,   0,   0,   0,   0],
       [  0,   0,  49,   0,   0,   0,   0],
       [  0,   0,  51,   0,   0,   0,   0]]), 'forgetting_measure': [0.50463975, 0.51799804, -0.0024877142]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525d8dc610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526b764090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4523716, 'precision': 0.13785714285714286, 'recall': 0.24285714285714285, 'f1_score': 0.15985319028797289, 'confusion_matrix': array([[  0,   0, 144,   0,   0,   0,   0],
       [  0,   0, 134,   0,   0,   0,   0],
       [  0,   0, 159,   0,   0,   0,   0],
       [  0,   0,  55,   0,   0,   0,   0],
       [  0,   0,  41,   0,   0,   0,   0],
       [  0,   0,  30,   0,   0,   0,   0],
       [  0,   0,  37,   0,   0,   0,   0]]), 'forgetting_measure': [0.42820424, 0.32165122, 0.07349745]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155234c1cfd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155223939a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40724572, 'precision': 0.132857142857142856, 'recall': 0.24285714285714285, 'f1_score': 0.15342624854819977, 'confusion_matrix': array([[207,   0,   0,   0,   0,   0,   0],
       [223,   0,   0,   0,   0,   0,   0],
       [242,   0,   0,   0,   0,   0,   0],
       [ 76,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 55,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3820933, 0.41629705, -0.06271488]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155234c1cfd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155223939a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43270611, 'precision': 0.13333333333333333, 'recall': 0.24285714285714285, 'f1_score': 0.15405405405405405, 'confusion_matrix': array([[140,   0,   0,   0,   0,   0,   0],
       [144,   0,   0,   0,   0,   0,   0],
       [166,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38841233, 0.2694639, 0.05545999]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155277d20b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155277c97210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43145996, 'precision': 0.129805352798053526, 'recall': 0.21502347417840375, 'f1_score': 0.14734299516908212, 'confusion_matrix': array([[196,   0,   0,   0,   0,   0,   0,  17],
       [187,   0,   0,   0,   0,   0,   0,  19],
       [234,   0,   0,   0,   0,   0,   0,  14],
       [ 68,   0,   0,   0,   0,   0,   0,   5],
       [ 57,   0,   0,   0,   0,   0,   0,   3],
       [ 37,   0,   0,   0,   0,   0,   0,  11],
       [ 43,   0,   0,   0,   0,   0,   0,   9],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4190681, 0.408035, 0.012931813]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155277d20b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155277c97210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45455374, 'precision': 0.13017241379310345, 'recall': 0.21170212765957446, 'f1_score': 0.14751131221719457, 'confusion_matrix': array([[126,   0,   0,   0,   0,   0,   0,  15],
       [141,   0,   0,   0,   0,   0,   0,  17],
       [142,   0,   0,   0,   0,   0,   0,  10],
       [ 41,   0,   0,   0,   0,   0,   0,   3],
       [ 34,   0,   0,   0,   0,   0,   0,   4],
       [ 14,   0,   0,   0,   0,   0,   0,  14],
       [ 24,   0,   0,   0,   0,   0,   0,  15],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.46236942, 0.37165478, 0.23757595]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552285fb490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155228438790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38517466, 'precision': 0.129206349206349208, 'recall': 0.24285714285714285, 'f1_score': 0.148497627833421195, 'confusion_matrix': array([[184,   0,   0,   0,   0,   0,   0],
       [285,   0,   0,   0,   0,   0,   0],
       [199,   0,   0,   0,   0,   0,   0],
       [ 55,   0,   0,   0,   0,   0,   0],
       [ 77,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.37220678, 0.4759581, 0.013868587]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552285fb490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155228438790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44927424, 'precision': 0.13261904761904762, 'recall': 0.24285714285714285, 'f1_score': 0.153111068036441174, 'confusion_matrix': array([[137,   0,   0,   0,   0,   0,   0],
       [163,   0,   0,   0,   0,   0,   0],
       [140,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 37,   0,   0,   0,   0,   0,   0],
       [ 30,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.50302894, 0.6652129, -0.5553737]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521f61f1d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552202ac790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4423439, 'precision': 0.22515599610146702, 'recall': 0.23705402439885706, 'f1_score': 0.22674856825721365, 'confusion_matrix': array([[66, 81, 33, 22,  7,  5, 16,  0,  2,  0],
       [73, 82, 30, 22,  5, 17, 11,  1,  1,  0],
       [63, 69, 23, 14,  6, 11, 10,  2,  1,  0],
       [ 8,  6, 12, 12,  3,  3,  0,  0,  0,  1],
       [17, 20, 22, 13,  2,  4,  4,  0,  0,  0],
       [ 8, 11, 11,  0,  0,  8,  7,  1,  0,  0],
       [ 5, 12, 13,  0,  0, 11,  9,  4,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.47440252, 0.47158533, 0.21760231]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521f61f1d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552202ac790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40533569, 'precision': 0.26208574533734946, 'recall': 0.27730927851482808, 'f1_score': 0.25549336746018183, 'confusion_matrix': array([[47, 45, 11, 11,  3, 11,  3,  1],
       [60, 49, 19, 28,  6, 11,  6,  1],
       [40, 45, 13, 11,  9,  7,  3,  0],
       [ 9,  8,  4,  8,  1,  4,  1,  0],
       [12, 14,  8, 17,  3,  3,  1,  0],
       [ 1, 13,  2,  0,  0,  9,  2,  0],
       [ 4, 14,  5,  1,  0, 13,  3,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.41748033, 0.493683, 0.1428631]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522004c6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520e059fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48949222, 'precision': 0.20358281895513452, 'recall': 0.20010629712731359, 'f1_score': 0.19884889574132624, 'confusion_matrix': array([[ 19,  82,  12,   8,   7,  10,   2,   0,   0,   1,   2,   2,   0],
       [ 44, 191,  48,   8,  26,  21,   8,   2,   0,   3,   2,   2,   0],
       [ 26,  84,  23,   5,   8,  12,   7,   1,   1,   1,   0,   1,   0],
       [  5,  21,   5,   3,   5,   3,   1,   0,   0,   0,   1,   1,   0],
       [  9,  39,  15,   7,   8,   5,   1,   1,   1,   0,   0,   0,   0],
       [  2,  23,   2,   0,   2,  13,   7,   0,   0,   1,   0,   0,   1],
       [  3,  28,   1,   2,   3,   6,   4,   0,   0,   1,   1,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4827247, 0.38278693, -0.056330696]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522004c6d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520e059fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52732326, 'precision': 0.20388680593884712, 'recall': 0.19239351363658899, 'f1_score': 0.1909629911613602, 'confusion_matrix': array([[  8,  58,  13,   2,   1,   4,   1,   0,   0,   0,   0,   0],
       [ 26, 139,  35,   1,  13,  32,   9,   0,   1,   2,   2,   0],
       [ 13,  57,  15,   0,   2,   5,   3,   0,   0,   3,   1,   2],
       [  3,  10,   7,   1,   0,   5,   0,   1,   0,   0,   0,   2],
       [  7,  22,  14,   0,   2,   5,   2,   1,   0,   0,   1,   2],
       [  2,  20,   2,   2,   2,   6,   2,   0,   0,   0,   0,   0],
       [  0,  14,   2,   0,   0,  10,   3,   0,   0,   2,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.6120451, 0.3919197, 0.49075696]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521404bf90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155211400950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49401922, 'precision': 0.21847712551906196, 'recall': 0.21802387474970191, 'f1_score': 0.21383290924473619, 'confusion_matrix': array([[ 64,  28,  85,  13,   4,  12,  11,   1,   2,   0,   1],
       [ 46,  21,  77,  16,   2,  13,   8,   2,   1,   4,   3],
       [ 59,  31, 119,  10,   5,  10,  11,   0,   3,   4,   2],
       [ 17,   2,  33,   5,   3,   2,   4,   0,   0,   1,   0],
       [ 16,   4,  28,  10,   1,   3,   2,   0,   0,   1,   0],
       [ 13,   7,   6,   0,   0,   9,   6,   1,   3,   2,   1],
       [  8,   4,  13,   1,   0,  10,   8,   1,   3,   2,   2],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42931176, -0.10061857, 0.4749593]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521404bf90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155211400950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41983294, 'precision': 0.23605022070599002, 'recall': 0.23067441598417817, 'f1_score': 0.22631608137176334, 'confusion_matrix': array([[38, 13, 67,  8,  3,  4, 11,  1,  1,  2],
       [32, 21, 55, 10,  3,  3,  9,  0,  3,  0],
       [42, 20, 66, 14,  2,  3,  5,  1,  1,  0],
       [ 3,  3, 23,  8,  0,  0,  7,  0,  2,  1],
       [ 9,  2, 26,  7,  0,  0,  2,  1,  1,  0],
       [ 9,  5,  6,  0,  0,  3,  7,  0,  1,  2],
       [ 8,  4,  5,  0,  0,  2,  7,  1,  4,  3],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.37705562, 0.15534951, 0.36573306]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fc21bf90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fbae8ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51051883, 'precision': 0.22827316645802053, 'recall': 0.2377154050321087, 'f1_score': 0.2287202833466574, 'confusion_matrix': array([[145,  42,   6,  25,   9,   3,  24,   1,   1,   0,   4,   1],
       [ 73,  64,  33,  20,  12,   4,  16,   0,   1,   0,   0,   0],
       [ 65,  53,  19,  24,  13,   0,   9,   0,   1,   0,   1,   1],
       [ 29,  14,   6,  24,  12,   1,   7,   0,   1,   0,   0,   0],
       [ 13,   3,   1,   9,   3,   1,   3,   1,   0,   0,   0,   2],
       [  8,   6,   8,   0,   3,   0,   7,   0,   1,   1,   1,   0],
       [ 14,  12,   6,   2,   4,   1,  24,   0,   0,   0,   2,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.56988007, 0.34903, 0.490651]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fc21bf90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fbae8ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43996872, 'precision': 0.2290563732346088, 'recall': 0.2280904160845276, 'f1_score': 0.22183391568259606, 'confusion_matrix': array([[70, 38, 10, 12, 12,  1, 12,  1,  0,  1,  0],
       [57, 40,  9,  8, 11,  1,  9,  0,  0,  1,  0],
       [52, 38, 16, 16, 11,  3, 12,  0,  1,  0,  0],
       [22,  8,  6,  8,  8,  2,  3,  0,  0,  0,  0],
       [15,  1,  3,  5,  5,  1,  4,  0,  0,  0,  0],
       [ 2,  7,  4,  0,  0,  1,  5,  0,  2,  3,  0],
       [ 4, 13,  6,  0,  5,  2, 10,  0,  0,  2,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.45616192, 0.3530408, 0.4214011]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f8cc54d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f97a4590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4788879, 'precision': 0.27309595185737706, 'recall': 0.26212232595355996, 'f1_score': 0.2562836540347938, 'confusion_matrix': array([[  4,  94,  31,   1,  14,   8,   5,   1],
       [ 21, 214,  58,   3,  22,   7,  13,   9],
       [  8,  88,  30,   1,  17,  10,  12,   2],
       [  2,  18,   5,   2,   7,   2,   3,   0],
       [  6,  34,  18,   2,  16,   2,   6,   4],
       [  2,  22,  11,   0,   1,   5,  10,   2],
       [  2,  23,   7,   0,   1,   7,   7,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4862321, 0.4449455, -0.10109115]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f8cc54d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f97a4590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5812912, 'precision': 0.3174252174451538, 'recall': 0.3096125241118252, 'f1_score': 0.2953872586556727, 'confusion_matrix': array([[  3,  74,  15,   2,   9,   5,   4,   0],
       [  7, 172,  27,   3,  13,   9,  16,   1],
       [  2,  60,  10,   0,   9,   5,   5,   0],
       [  1,   9,   2,   2,   7,   0,   0,   0],
       [  3,  24,   2,   1,  19,   2,  10,   0],
       [  0,  14,   4,   0,   1,   7,  10,   5],
       [  0,  11,   2,   0,   0,   6,   7,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.6745226, 0.43601048, 0.24287802]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f99bd610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e9f79a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43316099, 'precision': 0.24168564064595948, 'recall': 0.20709514866485156, 'f1_score': 0.20632963613281454, 'confusion_matrix': array([[ 35, 106,  37,   6,   0,  13,   6,   4,   2,   2,   1,   0,   0],
       [ 23, 113,  69,  11,   0,   5,   2,   3,   2,   3,   0,   0,   0],
       [ 25, 105,  85,  11,   0,   2,   0,   3,   0,   0,   1,   1,   0],
       [  4,  21,  34,   8,   0,   0,   0,   5,   1,   0,   0,   0,   0],
       [  6,  14,  18,   4,   1,   1,   1,   4,   1,   0,   1,   0,   0],
       [  3,  21,  14,   1,   0,  12,   1,   1,   0,   1,   0,   0,   0],
       [  3,  18,   4,   3,   2,  11,   1,   1,   0,   1,   0,   1,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42743958, 0.41400722, 0.06103398]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f99bd610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e9f79a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42314791, 'precision': 0.21385595255673701, 'recall': 0.20841799306059734, 'f1_score': 0.1988337994361229, 'confusion_matrix': array([[20, 81, 44, 11,  1,  5,  1,  0,  0,  0],
       [27, 58, 48,  5,  1,  4,  1,  0,  0,  1],
       [13, 61, 48,  0,  0,  4,  1,  0,  2,  2],
       [ 1, 12, 26,  2,  0,  2,  0,  1,  1,  0],
       [ 4, 14, 25,  5,  0,  1,  0,  0,  0,  0],
       [ 4, 13,  8,  0,  0,  4,  2,  2,  0,  0],
       [ 4, 12, 10,  1,  0,  6,  1,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.4577681, 0.44047895, 0.44301358]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551cdfd3f90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551cdaa69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47924392, 'precision': 0.2451360247706185, 'recall': 0.2320146845977327, 'f1_score': 0.23647534845530998, 'confusion_matrix': array([[ 56,  59,  51,  13,   2,   5,   6,   2,   3,   1,   0,   1],
       [ 48, 109,  56,  17,  13,  12,   6,   1,   1,   0,   0,   0],
       [ 46,  58,  64,  12,   7,  10,   6,   3,   3,   1,   0,   0],
       [ 15,  13,  17,   8,   2,   3,   2,   1,   0,   1,   0,   0],
       [  6,  18,  16,   3,   7,   2,   5,   5,   3,   1,   0,   0],
       [ 12,  15,   9,   3,   0,  15,   5,   0,   0,   0,   2,   0],
       [ 12,   6,  12,   1,   0,   4,   4,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47755334, 0.31805864, 0.21268587]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551cdfd3f90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551cdaa69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4696559, 'precision': 0.22649974294711136, 'recall': 0.2291927147539885, 'f1_score': 0.22697082654096636, 'confusion_matrix': array([[39, 41, 39,  6,  3, 11,  1,  1,  2,  0],
       [36, 54, 45,  7,  1,  9,  5,  1,  1,  0],
       [33, 46, 38, 12,  8,  3,  1,  0,  1,  0],
       [ 1, 16, 10,  7,  1,  3,  3,  0,  0,  0],
       [10,  7, 13,  7,  0,  3,  3,  1,  4,  0],
       [11, 12,  8,  5,  0,  9,  7,  0,  0,  1],
       [ 3,  4,  3,  1,  0,  2,  1,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.47656775, 0.55222416, -0.5643772]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ce42e090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dc872810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45345337, 'precision': 0.2602683441297081, 'recall': 0.26009622764185535, 'f1_score': 0.25233811503151687, 'confusion_matrix': array([[ 30,  51,  79,   5,   5,  21,   5,   0],
       [ 25,  47, 104,   8,  10,  21,   3,   0],
       [ 36,  60, 115,  14,   5,  24,   3,   0],
       [  8,  14,  35,  12,   0,   6,   1,   0],
       [  5,  15,  20,   3,   1,   8,   1,   0],
       [  9,  11,  20,   0,   3,  19,   3,   1],
       [  8,   1,  15,   0,   1,   9,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43383343, 0.2520241, 0.291839]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ce42e090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dc872810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45284174, 'precision': 0.3107842070839882, 'recall': 0.28699749596036389, 'f1_score': 0.28048750471366357, 'confusion_matrix': array([[20, 30, 60,  5,  3, 13,  0],
       [30, 45, 54,  0,  4, 14,  3],
       [35, 41, 66,  4,  1, 15,  2],
       [ 6, 12, 32,  1,  0,  5,  1],
       [ 1,  8, 18,  0,  1,  3,  0],
       [10,  6, 15,  0,  0, 12,  0],
       [ 5,  1,  4,  0,  0, 11,  3]]), 'forgetting_measure': [0.4788567, 0.45788786, 0.15141086]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551c1577a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551c1e5e9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5901686, 'precision': 0.15650793650793651, 'recall': 0.24285714285714285, 'f1_score': 0.18098271155595996, 'confusion_matrix': array([[356,   0,   0,   0,   0,   0,   0],
       [187,   0,   0,   0,   0,   0,   0],
       [120,   0,   0,   0,   0,   0,   0],
       [ 81,   0,   0,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 54,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57332218, 0.1623279, 0.24160573]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551c1577a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551c1e5e9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48371155, 'precision': 0.145714285714285714, 'recall': 0.24285714285714285, 'f1_score': 0.16926406926406926, 'confusion_matrix': array([[192,   0,   0,   0,   0,   0,   0],
       [127,   0,   0,   0,   0,   0,   0],
       [133,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.52781693, 0.50852484, -0.0132928165]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551c1eab190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d0802d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4032272, 'precision': 0.19714285714285713, 'recall': 0.3857142857142857, 'f1_score': 0.23957797884254372, 'confusion_matrix': array([[152,   0,   0,   0,   0,   0,   0],
       [267,   0,   0,   0,   0,   0,   0],
       [246,   0,   0,   0,   0,   0,   0],
       [ 65,   0,   0,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  49,   0],
       [  0,   0,   0,   0,   0,  51,   0]]), 'forgetting_measure': [0.29633001, 0.32003015, -1.0963012]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551c1eab190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d0802d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40915617, 'precision': 0.2086059917512411, 'recall': 0.3857142857142857, 'f1_score': 0.2469012446703131, 'confusion_matrix': array([[ 87,   0,   0,   0,   0,   0,   0],
       [194,   0,   0,   0,   0,   0,   0],
       [165,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  40,   0],
       [  0,   0,   0,   0,   0,  27,   0]]), 'forgetting_measure': [0.33375812, 0.47598985, -1.2141824]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316afbc10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316e01790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55317838, 'precision': 0.14968253968253968, 'recall': 0.24285714285714285, 'f1_score': 0.17372512071605229, 'confusion_matrix': array([[313,   0,   0,   0,   0,   0,   0],
       [210,   0,   0,   0,   0,   0,   0],
       [143,   0,   0,   0,   0,   0,   0],
       [100,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57332218, 0.3096969, 0.20585012]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316afbc10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316e01790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50450448, 'precision': 0.14285714285714286, 'recall': 0.24285714285714285, 'f1_score': 0.16593406593406594, 'confusion_matrix': array([[180,   0,   0,   0,   0,   0,   0],
       [140,   0,   0,   0,   0,   0,   0],
       [123,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.52781693, 0.38493693, 0.15418851]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea2195d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9d57390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4712564, 'precision': 0.312519388066066, 'recall': 0.28066833165279525, 'f1_score': 0.28160504787313722, 'confusion_matrix': array([[ 34, 113,  43,   5,   7,   9,   4],
       [ 47, 125,  50,   4,   8,   1,   5],
       [ 45,  94,  51,   9,  12,   4,   7],
       [  8,  13,  32,   9,   8,   1,   1],
       [  4,  13,  25,   2,   5,   0,   2],
       [ 10,  15,   1,   0,   0,   1,   1],
       [ 28,  23,   3,   0,   1,  10,   7]]), 'forgetting_measure': [0.4632205, 0.30439162, 0.21677369]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea2195d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9d57390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4558922, 'precision': 0.27506761914340468, 'recall': 0.2669035835471859, 'f1_score': 0.26338347464034877, 'confusion_matrix': array([[23, 64, 24,  0,  4,  3,  7],
       [38, 83, 32,  1, 11,  6,  0],
       [30, 72, 21,  0, 15,  5,  3],
       [ 3,  9, 20,  0,  5,  0,  2],
       [ 6, 22, 16,  2,  4,  1,  1],
       [ 7,  4,  1,  0,  0,  1,  3],
       [20,  8,  1,  0,  2,  9, 11]]), 'forgetting_measure': [0.45946748, 0.38813558, 0.1440431]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea4adf10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea85f950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56117154, 'precision': 0.4159439737920131, 'recall': 0.379347206595394, 'f1_score': 0.36582452427819314, 'confusion_matrix': array([[156,  39,   8,  26,  24,  24,   2],
       [ 36,  49,  38,  33,   6,   8,   0],
       [ 48,  55,  60,  34,  10,  13,   0],
       [ 18,  14,   4,  18,   9,   1,   0],
       [ 35,   1,   3,  10,  11,   7,   0],
       [ 12,   1,   1,   6,  15,  19,   1],
       [ 13,   0,   2,  10,   8,  10,   2]]), 'forgetting_measure': [0.48557708, -0.1325388, 0.40172255]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ea4adf10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ea85f950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46186913, 'precision': 0.29202707789664308, 'recall': 0.31955333231883412, 'f1_score': 0.28814955814606688, 'confusion_matrix': array([[62, 16, 32, 24,  8, 17,  2],
       [43, 23, 17, 24, 22, 14,  0],
       [51, 23, 17, 30, 13,  8,  3],
       [11,  4,  3, 11,  4,  4,  0],
       [14,  6,  5,  8, 10,  3,  1],
       [ 4,  0,  0, 14, 10, 16,  0],
       [ 1,  0,  0, 10,  5,  7,  0]]), 'forgetting_measure': [0.50036175, 0.49198747, 0.10586628]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eaf54510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0ccfd50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4898806, 'precision': 0.19742332584454934, 'recall': 0.24108796863513845, 'f1_score': 0.21060806512861639, 'confusion_matrix': array([[156, 122,   8,   0,   0,   0,   0],
       [149, 119,   7,   0,   0,   0,   0],
       [ 57,  48,   1,   0,   0,   0,   0],
       [ 43,  26,   0,   0,   0,   0,   0],
       [ 47,  17,   0,   0,   0,   0,   0],
       [ 11,  35,   0,   0,   0,   0,   0],
       [ 15,  39,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.49424887, 0.3063178, 0.2617118]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eaf54510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0ccfd50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48241628, 'precision': 0.18425274871853504, 'recall': 0.24322403118550792, 'f1_score': 0.20609123382916753, 'confusion_matrix': array([[85, 90,  0,  0,  0,  0,  0],
       [86, 92,  0,  0,  0,  0,  0],
       [44, 41,  0,  0,  0,  0,  0],
       [29, 23,  0,  0,  0,  0,  0],
       [24, 19,  0,  0,  0,  0,  0],
       [17, 17,  0,  0,  0,  0,  0],
       [ 9, 24,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.49675736, 0.36975527, 0.1984251]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df29d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43856574, 'precision': 0.2391768947459416, 'recall': 0.2520839851091952, 'f1_score': 0.23797016135063486, 'confusion_matrix': array([[ 53,  40, 119,   8,   0,   0,   0],
       [ 51,  42, 103,   4,   0,   0,   0],
       [ 71,  43, 125,  13,   0,   0,   0],
       [ 17,   9,  34,   8,   0,   0,   0],
       [ 10,  15,  29,   6,   0,   0,   0],
       [  7,   5,  40,   0,   0,   0,   0],
       [  5,   4,  39,   0,   0,   0,   0]]), 'forgetting_measure': [0.42883012, 0.27781713, 0.3709179]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df29d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42009039, 'precision': 0.22039349539349539, 'recall': 0.22457619831294672, 'f1_score': 0.2094724362812141, 'confusion_matrix': array([[41, 22, 76,  6,  0,  0,  0],
       [47, 11, 80,  4,  0,  0,  0],
       [62, 29, 64,  2,  0,  0,  0],
       [16,  2, 25,  5,  0,  0,  0],
       [15,  0, 25,  1,  0,  0,  0],
       [ 4,  4, 17,  0,  0,  0,  0],
       [13,  4, 25,  0,  0,  0,  0]]), 'forgetting_measure': [0.35555074, 0.11882106, 0.20272748]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d5c2e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da9d7250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51294715, 'precision': 0.349619566027348, 'recall': 0.3157813847420298, 'f1_score': 0.31398409546278296, 'confusion_matrix': array([[ 78,  97,  20,   7,  11,   1,   4],
       [ 52, 147,  22,   6,  15,   1,   6],
       [ 63,  94,  20,   4,  13,   1,   8],
       [ 29,  13,   8,   7,   4,   0,   0],
       [ 31,  13,  14,   3,   3,   1,   4],
       [ 13,   9,   2,   5,   3,   2,   2],
       [ 12,  17,   0,   6,  10,   3,  16]]), 'forgetting_measure': [0.46059606, 0.08294707, 0.25137487]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d5c2e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da9d7250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4104509, 'precision': 0.2811621348983134, 'recall': 0.26692938576830066, 'f1_score': 0.26166923366433256, 'confusion_matrix': array([[32, 66, 10,  9,  7,  1,  4],
       [48, 93, 12,  6, 13,  3,  8],
       [35, 67,  8,  3, 10,  0,  7],
       [11, 15,  6,  3,  4,  0,  0],
       [23, 13,  5,  3,  5,  1,  2],
       [ 5,  3,  0,  2,  6,  1,  2],
       [11, 17,  0,  6,  7,  1,  6]]), 'forgetting_measure': [0.41499553, 0.3366472, 0.48599005]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b6e41e50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b70abcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45911433, 'precision': 0.136349206349206346, 'recall': 0.24285714285714285, 'f1_score': 0.1579526761989118, 'confusion_matrix': array([[229,   0,   0,   0,   0,   0,   0],
       [210,   0,   0,   0,   0,   0,   0],
       [233,   0,   0,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 51,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4190681, 0.1616839, 0.2866945]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b6e41e50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b70abcd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4619684, 'precision': 0.136190476190476197, 'recall': 0.24285714285714285, 'f1_score': 0.157750759878419454, 'confusion_matrix': array([[152,   0,   0,   0,   0,   0,   0],
       [152,   0,   0,   0,   0,   0,   0],
       [135,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.46236942, 0.36350027, 0.16371383]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552df5fea50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ce377250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40112671, 'precision': 0.2881795164039231, 'recall': 0.309905043314883, 'f1_score': 0.29161085566438232, 'confusion_matrix': array([[53, 46, 35, 25, 32, 14, 15],
       [62, 32, 46, 24, 22,  9, 15],
       [46, 64, 46, 24, 27, 11,  9],
       [18, 14, 11, 10, 13,  4,  5],
       [ 6,  8, 14, 15, 15,  2,  8],
       [ 8,  0,  5,  5, 16, 10, 12],
       [ 2,  0,  8,  4,  8,  7, 15]]), 'forgetting_measure': [0.33111825, 0.29465547, -0.28356332]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552df5fea50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ce377250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38027492, 'precision': 0.27893208256431495, 'recall': 0.30853358164413574, 'f1_score': 0.28385956931247624, 'confusion_matrix': array([[32, 33, 16, 15, 13,  8,  6],
       [34, 23, 28, 19, 22, 12,  7],
       [42, 32, 18, 31, 20, 12, 12],
       [ 5,  0, 13, 11, 17,  4,  3],
       [10,  7,  6,  8,  8,  3,  3],
       [ 2,  0,  8,  2, 10, 13,  6],
       [ 3,  0,  3,  0,  5,  9,  6]]), 'forgetting_measure': [0.3091774, 0.12743151, 0.18296933]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552be2c6150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d58af950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54832665, 'precision': 0.33330717332585094, 'recall': 0.33133898276917497, 'f1_score': 0.32202810461216724, 'confusion_matrix': array([[193,  24,  32,   7,  11,   0,  18],
       [ 78,  79,  32,   8,   4,   3,   9],
       [ 75,  38,  29,   7,   8,   3,   5],
       [ 34,  23,  10,   7,   4,   4,   6],
       [ 23,  13,   5,   3,   1,   0,   4],
       [ 20,   4,   6,   0,   1,   1,   9],
       [ 22,   9,   5,   3,   0,   4,  16]]), 'forgetting_measure': [0.56020985, 0.42581207, -0.21296833]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552be2c6150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d58af950>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45480053, 'precision': 0.29194810576048388, 'recall': 0.2971263616833237, 'f1_score': 0.277540275834953, 'confusion_matrix': array([[95, 22, 13,  2,  4,  3,  4],
       [81, 25, 21,  0,  6,  1,  9],
       [81, 39, 20,  2,  4,  1, 11],
       [21, 18, 13,  0,  3,  1,  3],
       [13,  7,  4,  3,  1,  0,  2],
       [ 7,  4,  4,  1,  0,  3,  3],
       [21,  7,  2,  1,  1,  2, 11]]), 'forgetting_measure': [0.4314292, 0.40175277, -0.18367882]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f024ba50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b72209d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42706693, 'precision': 0.1334920634920635, 'recall': 0.24285714285714285, 'f1_score': 0.15426256911405426, 'confusion_matrix': array([[211,   0,   0,   0,   0,   0,   0],
       [229,   0,   0,   0,   0,   0,   0],
       [227,   0,   0,   0,   0,   0,   0],
       [ 66,   0,   0,   0,   0,   0,   0],
       [ 67,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42869673, 0.41299826, 0.17303856]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 10 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f024ba50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b72209d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 10, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4229742, 'precision': 0.13357142857142857, 'recall': 0.24285714285714285, 'f1_score': 0.15436668594563332, 'confusion_matrix': array([[141,   0,   0,   0,   0,   0,   0],
       [156,   0,   0,   0,   0,   0,   0],
       [141,   0,   0,   0,   0,   0,   0],
       [ 54,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.39805472, 0.3528071, 0.07739772]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316c2ae10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531695dd90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44713247, 'precision': 0.25699671347799, 'recall': 0.30615318798951474, 'f1_score': 0.2577098459081498, 'confusion_matrix': array([[ 13,  24,  84,  38,   0,  20,   0],
       [ 27,  27,  89,  54,   0,  21,   0],
       [ 30,  32, 116,  71,   0,  26,   0],
       [  4,   1,  26,  41,   0,   5,   0],
       [  2,   1,  13,  29,   0,   6,   0],
       [ 15,   5,  11,  15,   0,  19,   0],
       [  2,   1,  11,   6,   0,  15,   0]]), 'forgetting_measure': [0.4962283, 0.43874854, 0.44786727]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316c2ae10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531695dd90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45242066, 'precision': 0.29504082500678502, 'recall': 0.3591812306799997, 'f1_score': 0.29337575669274173, 'confusion_matrix': array([[26, 16, 46, 51,  0,  8,  0],
       [17, 31, 40, 43,  0, 17,  0],
       [21, 30, 43, 41,  0, 18,  0],
       [ 2,  1,  4, 48,  0,  4,  0],
       [ 0,  1,  1, 19,  0,  5,  0],
       [ 6,  6, 12,  0,  0, 12,  0],
       [ 2,  4, 12,  0,  0, 13,  0]]), 'forgetting_measure': [0.44603325, 0.36883652, 0.11711522]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b1f010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cab8fe10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60497684, 'precision': 0.454980007985968, 'recall': 0.35227465349416567, 'f1_score': 0.3541273316795632, 'confusion_matrix': array([[ 46,  10,  80,   0,   1,   5,   6],
       [ 17,  35,  87,   1,   0,   8,   0],
       [ 29,  15, 300,   4,   2,  15,  10],
       [ 40,   1,  35,   4,   0,   5,   3],
       [ 10,   3,  23,   0,   3,   2,   0],
       [  1,   3,  29,   0,   2,  15,  10],
       [  4,   1,  24,   0,   0,   9,   2]]), 'forgetting_measure': [0.54918752, -0.076318026, 0.41614738]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b1f010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cab8fe10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.565665, 'precision': 0.26934376292278544, 'recall': 0.26838767298370347, 'f1_score': 0.2518666895379352, 'confusion_matrix': array([[ 15,   5,  58,   1,   0,   3,   4],
       [ 14,   3,  70,   2,   0,   2,   5],
       [ 42,  16, 190,   1,   1,   6,   5],
       [ 11,   3,  28,   1,   0,   3,   2],
       [  7,   4,  25,   1,   0,   1,   4],
       [  2,   0,  27,   0,   0,   6,  10],
       [  1,   2,  13,   0,   0,   4,   2]]), 'forgetting_measure': [0.61224786, 0.392166, 0.12196863]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac752ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529295e710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46603326, 'precision': 0.2572104693174498, 'recall': 0.2750628180995665, 'f1_score': 0.25600729742249952, 'confusion_matrix': array([[ 30,  31, 105,  37,   1,   4,   0],
       [ 31,  22,  96,  33,   1,  10,   0],
       [ 36,  41, 125,  44,   4,   9,   0],
       [ 12,   6,  38,  25,   1,   3,   0],
       [  5,   4,  28,  12,   0,   6,   0],
       [ 21,   0,  20,  10,   0,  12,   0],
       [  6,   2,  12,  11,   0,   6,   0]]), 'forgetting_measure': [0.44978828, 0.3124234, 0.13596718]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac752ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529295e710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41785714, 'precision': 0.27121259806638806, 'recall': 0.29258218438890706, 'f1_score': 0.2733285679218354, 'confusion_matrix': array([[19, 26, 58, 23,  2,  8,  0],
       [23, 25, 70, 24,  2, 10,  0],
       [29, 27, 70, 16,  0,  8,  0],
       [ 7,  1, 26, 28,  3,  7,  0],
       [ 3,  1,  7,  7,  0,  3,  0],
       [13,  2, 18,  1,  0,  8,  0],
       [ 8,  1,  9,  0,  0,  7,  0]]), 'forgetting_measure': [0.3835432, 0.15163203, 0.46173462]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a81950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316df1150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49740024, 'precision': 0.28644607063315302, 'recall': 0.2429090909090909, 'f1_score': 0.16787804330115903, 'confusion_matrix': array([[  0,   0, 148,   0,   0,   0,   0],
       [  0,   1, 249,   0,   0,   0,   0],
       [  1,   0, 274,   0,   0,   0,   0],
       [  0,   0,  77,   0,   0,   0,   0],
       [  0,   0,  50,   0,   0,   0,   0],
       [  0,   0,  53,   0,   0,   0,   0],
       [  0,   0,  47,   0,   0,   0,   0]]), 'forgetting_measure': [0.48408792, 0.32310426, 0.045625713]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a81950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316df1150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43137496, 'precision': 0.13833333333333333, 'recall': 0.24285714285714285, 'f1_score': 0.16044678055190538, 'confusion_matrix': array([[  0,   0,  94,   0,   0,   0,   0],
       [  0,   0, 191,   0,   0,   0,   0],
       [  0,   0, 161,   0,   0,   0,   0],
       [  0,   0,  44,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0]]), 'forgetting_measure': [0.4075612, 0.30169678, 0.20011197]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df2b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316e1ca50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41055545, 'precision': 0.20194950463406839, 'recall': 0.2424008234972634, 'f1_score': 0.15222288836866514, 'confusion_matrix': array([[  0,   1, 191,   0,   0,   0,   0],
       [  1,   2, 276,   0,   0,   0,   0],
       [  1,   1, 191,   0,   0,   0,   0],
       [  0,   0,  65,   0,   0,   0,   0],
       [  0,   0,  71,   0,   0,   0,   0],
       [  0,   0,  52,   0,   0,   0,   0],
       [  0,   0,  48,   0,   0,   0,   0]]), 'forgetting_measure': [0.3795926, 0.2913438, 0.22306147]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df2b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316e1ca50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4357566, 'precision': 0.13214285714285715, 'recall': 0.24285714285714285, 'f1_score': 0.15247813411078717, 'confusion_matrix': array([[  0,   0,  98,   0,   0,   0,   0],
       [  0,   0, 209,   0,   0,   0,   0],
       [  0,   0, 135,   0,   0,   0,   0],
       [  0,   0,  46,   0,   0,   0,   0],
       [  0,   0,  45,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0]]), 'forgetting_measure': [0.42297385, 0.45448887, -0.18119645]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c7036a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ad038f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56294508, 'precision': 0.49173833611187436, 'recall': 0.3885088008048079, 'f1_score': 0.4067950542372278, 'confusion_matrix': array([[ 51,  34, 103,   4,   2,   4,   0],
       [ 12,  83,  96,  16,   4,   5,   1],
       [ 11,  61, 149,  11,   2,  14,   1],
       [  6,   9,  36,  29,   6,   3,   0],
       [  4,   7,  19,   8,   7,   1,   1],
       [  5,  11,  30,   3,   0,   8,   2],
       [ 11,   0,  11,   2,   0,  10,   7]]), 'forgetting_measure': [0.47873295, 0.2968518, -0.66649616]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c7036a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ad038f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48158593, 'precision': 0.28859336716473302, 'recall': 0.29871564208911724, 'f1_score': 0.2875907015507033, 'confusion_matrix': array([[ 3, 40, 64,  9,  0, 11,  3],
       [10, 42, 61, 15,  4,  6,  1],
       [11, 46, 98,  8,  7,  4,  1],
       [10,  6, 25, 17,  5,  0,  2],
       [ 4,  5,  9,  2,  1,  3,  0],
       [ 8, 10, 13,  2,  0,  7,  4],
       [ 2,  2,  6,  1,  1, 10,  1]]), 'forgetting_measure': [0.4528944, 0.11586211, 0.4235517]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec951e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a25f50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4688113, 'precision': 0.18407094826403183, 'recall': 0.31366004080977602, 'f1_score': 0.20186653055111956, 'confusion_matrix': array([[206,   0,   0,   0,   0,  42,   0],
       [173,   0,   4,   0,   0,  47,   0],
       [175,   0,   1,   0,   0,  25,   0],
       [ 50,   0,   1,   0,   0,  11,   0],
       [ 59,   0,   0,   0,   0,   6,   0],
       [ 15,   0,   2,   0,   0,  33,   0],
       [ 16,   0,   0,   0,   0,  34,   0]]), 'forgetting_measure': [0.41484348, 0.15598671, 0.15005273]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec951e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a25f50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44827453, 'precision': 0.17037324201503306, 'recall': 0.3452713620378291, 'f1_score': 0.2062893365178075, 'confusion_matrix': array([[129,   0,   0,   0,   0,  38,   0],
       [ 94,   0,   0,   0,   0,  39,   0],
       [110,   0,   0,   0,   0,  32,   0],
       [ 25,   0,   0,   0,   0,   7,   0],
       [ 42,   0,   0,   0,   0,  17,   0],
       [  2,   0,   0,   0,   0,  34,   0],
       [  0,   0,   0,   0,   0,  31,   0]]), 'forgetting_measure': [0.46459395, 0.32791027, 0.44829446]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a98baad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552af060f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45526002, 'precision': 0.23562175470531265, 'recall': 0.25131367414047994, 'f1_score': 0.23807241772210893, 'confusion_matrix': array([[109, 114,  42,   2,   5,   5,   0],
       [100, 114,  44,   6,   2,   9,   0],
       [ 33,  47,  16,   1,   2,   3,   0],
       [ 18,  30,  24,   0,   2,   2,   0],
       [ 18,  25,  24,   1,   1,   1,   0],
       [ 21,  23,   0,   1,   1,   4,   0],
       [ 19,  18,   0,   3,   1,   9,   0]]), 'forgetting_measure': [0.45016957, 0.3767007, 0.09580459]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a98baad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552af060f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5122485, 'precision': 0.41519513364563573, 'recall': 0.29953831795812155, 'f1_score': 0.29652757952225436, 'confusion_matrix': array([[75, 70, 37,  1,  3,  2,  0],
       [56, 76, 35,  0,  1,  4,  0],
       [26, 26, 20,  0,  1,  5,  0],
       [ 8, 12, 20,  2,  0,  0,  0],
       [12,  9, 24,  0,  4,  4,  0],
       [12, 16,  0,  0,  0,  6,  0],
       [16, 13,  0,  0,  0,  4,  0]]), 'forgetting_measure': [0.51571015, 0.35039708, 0.07057221]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155314226590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2c6fc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41133837, 'precision': 0.13031746031746032, 'recall': 0.24285714285714285, 'f1_score': 0.15001964122037449, 'confusion_matrix': array([[191,   0,   0,   0,   0,   0,   0],
       [226,   0,   0,   0,   0,   0,   0],
       [244,   0,   0,   0,   0,   0,   0],
       [ 79,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 58,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42869673, 0.5059311, 0.11994696]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155314226590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f2c6fc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42333346, 'precision': 0.1319047619047619, 'recall': 0.24285714285714285, 'f1_score': 0.15216037368625924, 'confusion_matrix': array([[134,   0,   0,   0,   0,   0,   0],
       [175,   0,   0,   0,   0,   0,   0],
       [131,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 30,   0,   0,   0,   0,   0,   0],
       [ 37,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.39805472, 0.13803092, 0.55225587]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d61f9e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0bcd910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43135519, 'precision': 0.24158308764325625, 'recall': 0.23517230795381166, 'f1_score': 0.22734162017785122, 'confusion_matrix': array([[ 38,  42, 103,   6,   1,   0,   0,   0],
       [ 45,  56, 112,  14,   0,   0,   5,   0],
       [ 38,  74, 119,  12,   1,   0,   2,   1],
       [ 13,  22,  38,  10,   0,   0,   0,   0],
       [  8,  12,  20,   7,   0,   0,   1,   0],
       [  0,  16,  29,   0,   0,   0,   2,   0],
       [  0,  21,  30,   0,   0,   0,   2,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38061542, 0.28207463, -0.052259445]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d61f9e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0bcd910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44989675, 'precision': 0.2569232932371751, 'recall': 0.2683149611998518, 'f1_score': 0.25100652850831003, 'confusion_matrix': array([[29, 27, 68,  8,  0,  0,  2],
       [25, 19, 87, 12,  0,  0,  3],
       [32, 27, 92, 12,  0,  0,  2],
       [10,  2, 23,  9,  0,  0,  1],
       [12,  4, 18,  9,  0,  0,  0],
       [ 0,  5, 33,  0,  0,  0,  2],
       [ 0,  5, 20,  0,  0,  0,  2]]), 'forgetting_measure': [0.37556902, 0.07055714, 0.14887258]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aeb61a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ad7c0f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5330698, 'precision': 0.43245190960077936, 'recall': 0.34267299290120597, 'f1_score': 0.35323947603013897, 'confusion_matrix': array([[ 34, 105,  46,   5,   3,   5,   0],
       [ 22, 176,  64,   4,   2,   4,   0],
       [ 15, 117,  56,   3,   2,   4,   0],
       [  4,  25,  17,   4,  10,   3,   0],
       [  7,  20,  19,  11,   6,   2,   5],
       [  5,  18,  13,   0,   3,  16,   0],
       [ 11,  13,   4,   2,   6,   2,   7]]), 'forgetting_measure': [0.49408743, 0.2523475, -0.053763755]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aeb61a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ad7c0f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46007053, 'precision': 0.29590660058075612, 'recall': 0.27822594066767355, 'f1_score': 0.27582868029998355, 'confusion_matrix': array([[ 10,  61,  16,   2,   4,   2,   2],
       [ 16, 125,  45,  12,   9,   4,   1],
       [ 18,  65,  29,   6,   4,   4,   3],
       [  4,  25,  11,   4,   4,   3,   3],
       [  6,  17,  10,   1,   4,   3,   0],
       [  7,   8,   9,   0,   1,   3,   0],
       [  6,  13,   9,   1,   1,   7,   2]]), 'forgetting_measure': [0.46326173, 0.46336332, -0.13886775]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e6031e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e8849d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45786647, 'precision': 0.26520788411409412, 'recall': 0.23889872509815002, 'f1_score': 0.22896901722675538, 'confusion_matrix': array([[ 42,  43, 112,   6,   6,   1,   9,   0],
       [ 35,  37, 133,   2,   1,   1,   4,   0],
       [ 37,  39, 134,  10,   3,   4,   4,   0],
       [  6,  12,  43,   4,   0,   0,   2,   1],
       [  7,  13,  43,   0,   3,   0,   3,   0],
       [  4,   1,  37,   1,   7,   1,   5,   0],
       [  7,   0,  31,   0,   4,   0,   2,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47347543, 0.501973, -0.15119441]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e6031e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e8849d10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43601003, 'precision': 0.27660722938223872, 'recall': 0.27043564777037176, 'f1_score': 0.25514127345283288, 'confusion_matrix': array([[29, 24, 71,  1,  3,  2,  2],
       [24, 37, 86,  5,  2,  1,  9],
       [30, 21, 87,  1,  3,  1,  5],
       [ 0, 13, 39,  1,  3,  0,  1],
       [ 0,  8, 20,  2,  1,  0,  1],
       [ 1,  1, 23,  0,  1,  0,  5],
       [ 8,  0, 23,  1,  0,  0,  4]]), 'forgetting_measure': [0.3858105, 0.118457586, 0.32422]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e6833f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e6831850>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42410427, 'precision': 0.24724967692461427, 'recall': 0.25945836000781613, 'f1_score': 0.23919165364505112, 'confusion_matrix': array([[ 26,  76,  97,   2,   0,  11,   0],
       [ 29,  65, 116,   0,   0,   8,   0],
       [ 29,  78, 124,   1,   0,   5,   0],
       [  5,  19,  54,   1,   0,   3,   0],
       [  0,  18,  32,   0,   0,   1,   0],
       [  8,   8,  22,   4,   0,   8,   0],
       [  7,   5,  28,   3,   0,   7,   0]]), 'forgetting_measure': [0.4011766, 0.29378733, 0.2550755]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e6833f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e6831850>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43053554, 'precision': 0.23991144625002197, 'recall': 0.28194802287386688, 'f1_score': 0.24765790422129116, 'confusion_matrix': array([[24, 38, 76,  3,  0, 12,  0],
       [33, 38, 82,  4,  0,  5,  0],
       [24, 28, 73,  2,  0,  6,  0],
       [ 1, 10, 30,  0,  0,  2,  0],
       [ 4,  9, 25,  1,  0,  3,  0],
       [ 3,  0, 14,  1,  0,  9,  0],
       [14,  0, 20,  0,  0,  6,  0]]), 'forgetting_measure': [0.4013547, 0.31392136, 0.11247289]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529532aed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a142a550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52985103, 'precision': 0.29513392821769246, 'recall': 0.2868391227770546, 'f1_score': 0.2866073693622595, 'confusion_matrix': array([[152,  35,  47,   9,   7,  24,  10,   2,   0],
       [ 36,  66,  67,  14,   3,  13,   6,   2,   0],
       [ 42,  32,  61,   7,   4,  16,   9,   1,   0],
       [ 18,  10,  28,   9,   5,   7,  15,   0,   0],
       [  5,   4,  16,  10,   3,   1,   4,   0,   0],
       [ 12,   2,  10,   3,   6,   5,   0,   0,   0],
       [  5,   7,  16,   5,   2,  13,  11,   2,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.6125443, 0.5838296, -0.23626813]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529532aed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a142a550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41821389, 'precision': 0.25040646624476392, 'recall': 0.2343097182482443, 'f1_score': 0.23685073226025524, 'confusion_matrix': array([[64, 24, 39, 12,  2, 14, 10,  1,  0],
       [51, 19, 33, 11,  3,  9,  3,  1,  0],
       [47, 28, 38,  5,  5, 10,  6,  3,  0],
       [ 5,  4, 24,  5,  0,  6,  4,  0,  0],
       [11,  2, 13,  4,  4,  6,  7,  0,  0],
       [ 3,  3,  7,  1,  2,  1,  1,  1,  1],
       [13,  3,  9,  1,  3, 10,  8,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.43430967, 0.48121858, 0.15299974]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155299216a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529d064c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45380734, 'precision': 0.27897123793957226, 'recall': 0.26768592922116632, 'f1_score': 0.26364349333906805, 'confusion_matrix': array([[108,  79,  58,  16,   0,   3,  15],
       [ 81,  67,  38,   7,   0,   1,  13],
       [ 63,  48,  40,   7,   1,   3,   9],
       [ 40,  27,  25,   5,   0,   0,   7],
       [ 16,  10,   9,   1,   0,   0,   3],
       [ 22,   3,   2,   1,   0,   2,   7],
       [ 43,   7,   1,   3,   0,   1,   8]]), 'forgetting_measure': [0.45787913, 0.38381043, 0.1700511]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155299216a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529d064c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44157833, 'precision': 0.2627795834931373, 'recall': 0.26718613099433952, 'f1_score': 0.25664622265084155, 'confusion_matrix': array([[80, 47, 28,  5,  0,  0, 10],
       [52, 42, 31,  5,  0,  0, 10],
       [59, 44, 24,  2,  0,  0,  6],
       [18, 20, 14,  3,  0,  0,  3],
       [ 8, 12,  7,  1,  0,  0,  2],
       [14,  1,  0,  1,  0,  0,  4],
       [32,  6,  1,  0,  0,  0,  8]]), 'forgetting_measure': [0.36653224, 0.049929567, 0.19052711]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529389aed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552943cb290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42382358, 'precision': 0.133174603174603176, 'recall': 0.24285714285714285, 'f1_score': 0.15384516295246684, 'confusion_matrix': array([[209,   0,   0,   0,   0,   0,   0],
       [196,   0,   0,   0,   0,   0,   0],
       [260,   0,   0,   0,   0,   0,   0],
       [ 66,   0,   0,   0,   0,   0,   0],
       [ 69,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 51,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.39670545, 0.3246598, 0.12970005]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529389aed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552943cb290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47091768, 'precision': 0.134761904761904765, 'recall': 0.24285714285714285, 'f1_score': 0.15591727307545002, 'confusion_matrix': array([[146,   0,   0,   0,   0,   0,   0],
       [127,   0,   0,   0,   0,   0,   0],
       [171,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 32,   0,   0,   0,   0,   0,   0],
       [ 35,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42776496, 0.17213236, 0.2126581]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfcd6610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d05f9d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47329287, 'precision': 0.21777614271515056, 'recall': 0.25303549865162291, 'f1_score': 0.21714208317051947, 'confusion_matrix': array([[  5,  93,  54,   1,   0,   0,   0],
       [  5, 186,  86,   0,   0,   0,   0],
       [  1, 149,  87,   0,   0,   0,   0],
       [  3,  52,  22,   0,   0,   0,   0],
       [  0,  48,   8,   0,   0,   0,   0],
       [  8,  29,  12,   0,   0,   0,   0],
       [  3,  38,  10,   0,   0,   0,   0]]), 'forgetting_measure': [0.42846528, 0.24674208, 0.0138420155]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cfcd6610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d05f9d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46220468, 'precision': 0.20815746753246754, 'recall': 0.2505078242815759, 'f1_score': 0.21280610163281958, 'confusion_matrix': array([[  3,  63,  42,   0,   0,   0,   0],
       [  6, 122,  58,   0,   0,   0,   0],
       [  2,  90,  54,   0,   0,   0,   0],
       [  1,  38,  13,   0,   0,   0,   0],
       [  2,  25,  14,   0,   0,   0,   0],
       [  1,  19,   9,   0,   0,   0,   0],
       [  3,  27,   8,   0,   0,   0,   0]]), 'forgetting_measure': [0.44515476, 0.11552771, 0.55391914]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552be496f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cafd2f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46609743, 'precision': 0.20542153636213043, 'recall': 0.24012961116650052, 'f1_score': 0.21395180497828424, 'confusion_matrix': array([[ 73, 129,  34,   0,   0,   0,   0],
       [ 87, 141,  27,   0,   0,   0,   0],
       [ 59,  97,  21,   0,   0,   0,   0],
       [ 37,  16,   5,   0,   0,   0,   0],
       [ 30,  32,  12,   0,   0,   0,   0],
       [  4,  37,   0,   0,   0,   0,   0],
       [  6,  53,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.45319656, 0.41175985, -0.14230946]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552be496f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cafd2f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45369132, 'precision': 0.21299728495016989, 'recall': 0.24175656194564976, 'f1_score': 0.2116796552042992, 'confusion_matrix': array([[51, 67, 15,  0,  0,  0,  0],
       [61, 83, 20,  0,  0,  0,  0],
       [49, 82, 15,  0,  0,  0,  0],
       [14, 18,  0,  0,  0,  0,  0],
       [27, 31,  0,  0,  0,  0,  0],
       [ 0, 30,  0,  0,  0,  0,  0],
       [ 0, 37,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.43104593, 0.35706925, -0.020432705]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529414d890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155294384110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52339668, 'precision': 0.144444444444444446, 'recall': 0.24285714285714285, 'f1_score': 0.16779661016949153, 'confusion_matrix': array([[280,   0,   0,   0,   0,   0,   0],
       [174,   0,   0,   0,   0,   0,   0],
       [224,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 64,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.50137404, 0.25615096, 0.09481219]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 50 chunk', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529414d890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155294384110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 50, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53595338, 'precision': 0.145714285714285714, 'recall': 0.24285714285714285, 'f1_score': 0.16926406926406926, 'confusion_matrix': array([[192,   0,   0,   0,   0,   0,   0],
       [122,   0,   0,   0,   0,   0,   0],
       [134,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 20,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.56770623, 0.39243987, 0.09911833]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ba0c1950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b9939f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52571146, 'precision': 0.31122240714181084, 'recall': 0.2781664104868381, 'f1_score': 0.26846503767474022, 'confusion_matrix': array([[ 78,  42,  73,   0,   0,   3,  10,   1,   0],
       [ 73,  64,  65,   1,   1,   4,  18,   0,   0],
       [ 60,  32, 125,   2,   1,   4,  10,   0,   1],
       [ 33,  12,  26,   3,   0,   0,   7,   1,   0],
       [ 35,   2,   8,   0,   0,   1,   4,   0,   0],
       [  3,  22,   8,   0,   0,   3,   4,   0,   0],
       [  5,  17,  15,   0,   0,   5,  18,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4850855, 0.13926342, 0.21379964]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ba0c1950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b9939f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50686232, 'precision': 0.388342742519771, 'recall': 0.27405091198293962, 'f1_score': 0.26828755156610994, 'confusion_matrix': array([[51, 46, 42,  0,  1,  5,  3],
       [43, 46, 45,  1,  0,  5, 15],
       [38, 43, 52,  0,  0,  5,  5],
       [16,  2, 12,  1,  0,  0,  1],
       [20,  8, 21,  0,  1,  2,  3],
       [ 3, 17,  4,  0,  0,  1,  3],
       [ 4, 21,  5,  0,  0,  4,  5]]), 'forgetting_measure': [0.51601968, 0.31661457, 0.22524025]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b9b60fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ded9510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43620869, 'precision': 0.28789286429668348, 'recall': 0.24750181827223732, 'f1_score': 0.16309068075378187, 'confusion_matrix': array([[200,   0,   1,   0,   0,   0,   0],
       [333,  10,   0,   0,   0,   0,   0],
       [116,   3,   1,   0,   0,   0,   0],
       [ 84,   0,   0,   0,   0,   0,   0],
       [ 50,   2,   0,   0,   0,   0,   0],
       [ 51,   1,   0,   0,   0,   0,   0],
       [ 47,   1,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4333996, 0.29207036, 0.41021535]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b9b60fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ded9510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42062072, 'precision': 0.20452664881966414, 'recall': 0.24580110095302762, 'f1_score': 0.161222006265450664, 'confusion_matrix': array([[136,   1,   0,   0,   0,   0,   0],
       [209,   6,   0,   0,   0,   0,   0],
       [ 82,   1,   0,   0,   0,   0,   0],
       [ 56,   2,   0,   0,   0,   0,   0],
       [ 39,   1,   0,   0,   0,   0,   0],
       [ 30,   1,   0,   0,   0,   0,   0],
       [ 35,   0,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.42629976, 0.49193856, -0.02413888]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ad139590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529d452b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59321116, 'precision': 0.22860363987759701, 'recall': 0.24601176201895627, 'f1_score': 0.19092579621580768, 'confusion_matrix': array([[  5, 134,   0,   0,   0,   0,   0],
       [  2, 355,   3,   0,   0,   0,   0],
       [  3, 170,   0,   0,   0,   0,   0],
       [  0,  46,   0,   0,   0,   0,   0],
       [  0,  82,   0,   0,   0,   0,   0],
       [  0,  57,   0,   0,   0,   0,   0],
       [  0,  43,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.6119504, 0.32947588, 0.054961886]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ad139590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529d452b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.62466834, 'precision': 0.15714285714285715, 'recall': 0.24285714285714285, 'f1_score': 0.1816326530612245, 'confusion_matrix': array([[  0, 102,   0,   0,   0,   0,   0],
       [  0, 240,   0,   0,   0,   0,   0],
       [  0, 101,   0,   0,   0,   0,   0],
       [  0,  26,   0,   0,   0,   0,   0],
       [  0,  64,   0,   0,   0,   0,   0],
       [  0,  31,   0,   0,   0,   0,   0],
       [  0,  36,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.70011995, 0.3658596, 0.22922929]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df13d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5b45a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45455466, 'precision': 0.20582306830907054, 'recall': 0.24385048313619744, 'f1_score': 0.158625458451921186, 'confusion_matrix': array([[215,   1,   0,   0,   0,   0,   0],
       [256,   3,   0,   0,   0,   0,   0],
       [187,   2,   0,   0,   0,   0,   0],
       [ 49,   0,   1,   0,   0,   0,   0],
       [ 86,   0,   0,   0,   0,   0,   0],
       [ 59,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.45495627, 0.4390861, -0.052776933]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df13d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5b45a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40832187, 'precision': 0.13124254710231338, 'recall': 0.24177489177489178, 'f1_score': 0.15120187609927691, 'confusion_matrix': array([[131,   0,   1,   0,   0,   0,   0],
       [172,   0,   0,   0,   0,   0,   0],
       [132,   0,   0,   0,   0,   0,   0],
       [ 26,   0,   0,   0,   0,   0,   0],
       [ 71,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0],
       [ 29,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.35596732, 0.22812161, 0.13236977]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b9f5e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ded9510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54222427, 'precision': 0.15142857142857143, 'recall': 0.24285714285714285, 'f1_score': 0.17563025210084033, 'confusion_matrix': array([[324,   0,   0,   0,   0,   0,   0],
       [210,   0,   0,   0,   0,   0,   0],
       [134,   0,   0,   0,   0,   0,   0],
       [ 79,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0],
       [ 51,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57332218, 0.29992965, 0.33005637]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b9f5e610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529ded9510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50227208, 'precision': 0.14476190476190477, 'recall': 0.24285714285714285, 'f1_score': 0.16816533720087019, 'confusion_matrix': array([[188,   0,   0,   0,   0,   0,   0],
       [124,   0,   0,   0,   0,   0,   0],
       [131,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.52781693, 0.3344668, 0.31768546]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155297d81590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c2e04910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43611312, 'precision': 0.13396825396825397, 'recall': 0.24285714285714285, 'f1_score': 0.15488586817132598, 'confusion_matrix': array([[214,   0,   0,   0,   0,   0,   0],
       [277,   0,   0,   0,   0,   0,   0],
       [186,   0,   0,   0,   0,   0,   0],
       [ 61,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44112647, 0.31003958, 0.43980742]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155297d81590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c2e04910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4532411, 'precision': 0.13523809523809524, 'recall': 0.24285714285714285, 'f1_score': 0.15653170359052712, 'confusion_matrix': array([[148,   0,   0,   0,   0,   0,   0],
       [148,   0,   0,   0,   0,   0,   0],
       [155,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 18,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44886697, 0.2659815, 0.39556128]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cb884c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b261d050>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42738314, 'precision': 0.18796536796536795, 'recall': 0.24339327462251053, 'f1_score': 0.17365353519199672, 'confusion_matrix': array([[  0, 195,  22,   0,   0,   0,   0],
       [  0, 167,  22,   0,   0,   0,   0],
       [  0, 227,  31,   0,   0,   0,   0],
       [  0,  65,   0,   0,   0,   0,   0],
       [  0,  71,   0,   0,   0,   0,   0],
       [  0,  48,   0,   0,   0,   0,   0],
       [  0,  52,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47922174, 0.558225, 0.19180802]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cb884c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b261d050>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35859465, 'precision': 0.124761904761904763, 'recall': 0.24285714285714285, 'f1_score': 0.14220779220779221, 'confusion_matrix': array([[  0, 142,   0,   0,   0,   0,   0],
       [  0, 104,   0,   0,   0,   0,   0],
       [  0, 198,   0,   0,   0,   0,   0],
       [  0,  37,   0,   0,   0,   0,   0],
       [  0,  52,   0,   0,   0,   0,   0],
       [  0,  29,   0,   0,   0,   0,   0],
       [  0,  38,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.34121681, 0.39530867, 0.3918527]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280d16f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a4ea1f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41790005, 'precision': 0.26959211985035721, 'recall': 0.26650318526693728, 'f1_score': 0.266140424417051, 'confusion_matrix': array([[63, 37, 63, 10,  6,  8, 10],
       [84, 48, 66, 11,  9, 11,  9],
       [62, 60, 59, 20, 13,  4, 17],
       [12, 20, 24,  5,  8,  2,  2],
       [ 9, 15, 11, 11,  7,  1,  3],
       [ 4, 15, 22,  1,  0,  3,  6],
       [ 8,  6, 24,  0,  1,  3,  7]]), 'forgetting_measure': [0.3894342, 0.18486162, 0.45603523]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280d16f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a4ea1f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43018521, 'precision': 0.32320361304329792, 'recall': 0.30728544443964672, 'f1_score': 0.31252354578809993, 'confusion_matrix': array([[35, 31, 43,  8,  3,  4,  4],
       [47, 32, 56, 11,  6,  4,  8],
       [55, 34, 43, 10,  3,  6,  4],
       [ 9, 15, 15,  8,  5,  0,  4],
       [ 7,  7,  5,  4,  5,  1,  1],
       [ 8,  4,  6,  0,  0,  7,  5],
       [10,  8,  8,  0,  0,  5,  6]]), 'forgetting_measure': [0.32790723, -0.21507081, 0.3293272]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155286131e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155281066150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53093098, 'precision': 0.28509633946971701, 'recall': 0.28045239336148497, 'f1_score': 0.27682952303145955, 'confusion_matrix': array([[107,  20,  49,   5,   4,   3,   6,   0,   1,   0],
       [ 50,  39,  94,   5,   7,  10,   7,   1,   1,   0],
       [ 47,  42, 135,   9,   7,   6,  12,   1,   1,   0],
       [ 13,  14,  27,   7,   2,   6,   3,   0,   0,   0],
       [ 15,   1,  29,   5,   3,   2,   2,   0,   1,   1],
       [  3,  11,  11,   1,   3,  12,   5,   1,   0,   0],
       [ 13,   8,  12,   4,   1,   7,   8,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4707337, 0.034975596, 0.26127288]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155286131e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155281066150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46130265, 'precision': 0.2433277840889654, 'recall': 0.23782767366064627, 'f1_score': 0.23041148772697816, 'confusion_matrix': array([[36, 12, 80,  8,  1,  7,  6,  1,  1],
       [37, 11, 69,  9,  2,  9,  2,  0,  0],
       [55, 12, 73,  2,  3,  9,  2,  0,  0],
       [13,  5, 14,  4,  3,  1,  0,  1,  0],
       [10,  7, 18,  4,  2,  1,  3,  0,  0],
       [ 4,  5,  7,  2,  2,  9,  7,  0,  0],
       [ 7,  2, 13,  1,  0,  5,  2,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.37414754, -0.2104376, 0.46382985]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155275936f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155281a89bd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46316935, 'precision': 0.1949660327499394, 'recall': 0.23946050527123902, 'f1_score': 0.20455016518348262, 'confusion_matrix': array([[ 15,  42, 149,   1,   2,   0,   0],
       [ 19,  48, 132,   1,   1,   0,   2],
       [ 22,  58, 167,   1,   0,   0,   2],
       [ 11,  20,  44,   0,   0,   0,   1],
       [  8,  19,  35,   0,   0,   0,   0],
       [  9,  35,   2,   0,   0,   0,   1],
       [  3,  47,   3,   0,   0,   0,   0]]), 'forgetting_measure': [0.46013803, 0.29682735, 0.3044887]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155275936f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155281a89bd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45094807, 'precision': 0.27771808723489396, 'recall': 0.24522558747011302, 'f1_score': 0.22000242490271402, 'confusion_matrix': array([[ 18,  20,  96,   0,   0,   0,   1],
       [ 15,  30,  90,   0,   0,   0,   2],
       [ 23,  37, 113,   0,   1,   0,   2],
       [  5,  10,  25,   0,   0,   0,   0],
       [  6,  11,  27,   0,   1,   0,   0],
       [  5,  17,   1,   0,   0,   0,   1],
       [  3,  35,   5,   0,   0,   0,   0]]), 'forgetting_measure': [0.40712646, 0.35985684, -0.26707384]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527c63ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527be71b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56060536, 'precision': 0.3799122006193481, 'recall': 0.3444597727015763, 'f1_score': 0.33473107531219897, 'confusion_matrix': array([[146,  38,  38,   0,   0,   6,   4],
       [ 67, 100,  73,   0,   0,   3,   0],
       [ 38,  71,  86,   1,   0,   0,   0],
       [ 22,  21,  15,   0,   0,   0,   0],
       [ 27,  25,  18,   0,   0,   1,   0],
       [ 14,  22,   0,   0,   0,   2,   1],
       [ 29,  18,   0,   0,   0,   3,  11]]), 'forgetting_measure': [0.55292032, 0.2048037, 0.2538463]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527c63ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527be71b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43796041, 'precision': 0.26507489501736078, 'recall': 0.26575647541535415, 'f1_score': 0.25617522046756002, 'confusion_matrix': array([[48, 38, 56,  0,  0,  1,  3],
       [62, 45, 58,  0,  0,  1,  2],
       [36, 39, 53,  0,  0,  0,  3],
       [26, 12,  3,  0,  0,  0,  0],
       [24, 20,  2,  0,  0,  0,  1],
       [ 5, 16,  0,  0,  0,  0,  2],
       [ 4, 29,  1,  0,  0,  3,  7]]), 'forgetting_measure': [0.38118905, 0.21162789, 0.04813676]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526e1f6f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526e869f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45684637, 'precision': 0.25704767701879782, 'recall': 0.27911864733532754, 'f1_score': 0.25678847028549722, 'confusion_matrix': array([[ 17, 134,  27,   6,  17,  12,   1],
       [ 26, 156,  25,   8,  22,  16,   0],
       [ 17, 123,  19,   7,  20,  22,   0],
       [  1,  15,   4,   1,  11,   1,   0],
       [  9,  43,  11,   5,  20,   4,   0],
       [ 19,  16,  14,   1,   0,  14,   0],
       [ 12,   7,   9,   1,   0,   7,   0]]), 'forgetting_measure': [0.4904614, 0.44928724, 0.2324603]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526e1f6f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526e869f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50583656, 'precision': 0.30331957761864303, 'recall': 0.31733899493504386, 'f1_score': 0.28668219850899734, 'confusion_matrix': array([[ 14,  72,   6,   3,  16,  12,   0],
       [  8, 113,   7,   6,  24,  15,   1],
       [  8,  82,  14,   6,  21,  10,   0],
       [  4,   8,   0,   3,  12,   3,   0],
       [  4,  25,   4,   8,  17,   7,   0],
       [ 10,  10,   5,   1,   0,  11,   0],
       [  7,  11,   4,   0,   0,   8,   0]]), 'forgetting_measure': [0.48488838, 0.23167557, 0.19889474]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525ec96610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525e661f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52048875, 'precision': 0.22019464720194646, 'recall': 0.25435759642656194, 'f1_score': 0.20521294204430179, 'confusion_matrix': array([[  2, 152,  11,   0,   0,   0,   0],
       [  9, 308,   8,   0,   0,   0,   0],
       [  3, 150,  21,   0,   0,   0,   0],
       [  0,  43,   4,   0,   0,   0,   0],
       [  0,  88,   1,   0,   0,   0,   0],
       [  0,  37,  15,   0,   0,   0,   0],
       [  1,  44,   3,   0,   0,   0,   0]]), 'forgetting_measure': [0.50903896, 0.34871262, -0.07366133]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525ec96610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525e661f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.648875, 'precision': 0.18514492753623189, 'recall': 0.24455514164428657, 'f1_score': 0.19967220319739227, 'confusion_matrix': array([[  0,  85,   2,   0,   0,   0,   0],
       [  0, 237,  18,   0,   0,   0,   0],
       [  0,  89,   8,   0,   0,   0,   0],
       [  0,  30,   2,   0,   0,   0,   0],
       [  0,  58,   4,   0,   0,   0,   0],
       [  0,  31,   5,   0,   0,   0,   0],
       [  0,  22,   9,   0,   0,   0,   0]]), 'forgetting_measure': [0.70011995, 0.23893407, 0.36554703]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552641c1590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525ece6e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4388626, 'precision': 0.22480519480519481, 'recall': 0.24409161500090004, 'f1_score': 0.16819482295413126, 'confusion_matrix': array([[221,   2,   5,   0,   0,   0,   0],
       [228,   3,  25,   0,   0,   0,   0],
       [176,   0,   5,   0,   0,   0,   0],
       [ 71,   0,   0,   0,   0,   0,   0],
       [ 62,   1,   1,   0,   0,   0,   0],
       [ 55,   0,   6,   0,   0,   0,   0],
       [ 37,   0,   2,   0,   0,   0,   0]]), 'forgetting_measure': [0.3999704, 0.13068496, 0.40234935]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552641c1590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525ece6e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4698034, 'precision': 0.16057971014492753, 'recall': 0.2422702414299053, 'f1_score': 0.16505341348546924, 'confusion_matrix': array([[148,   0,   5,   0,   0,   0,   0],
       [144,   0,  11,   0,   0,   0,   0],
       [135,   1,   4,   0,   0,   0,   0],
       [ 41,   0,   1,   0,   0,   0,   0],
       [ 41,   0,   2,   0,   0,   0,   0],
       [ 43,   0,   0,   0,   0,   0,   0],
       [ 23,   0,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.43356053, 0.10092684, 0.41328076]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524a751590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155251b42f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3914458, 'precision': 0.24937483373237562, 'recall': 0.2426791682297173, 'f1_score': 0.15252716209477939, 'confusion_matrix': array([[  1,   0, 176,   0,   0,   0,   0],
       [  1,   1, 282,   0,   0,   0,   0],
       [  1,   1, 190,   0,   0,   0,   0],
       [  0,   0,  74,   0,   0,   0,   0],
       [  0,   0,  73,   0,   0,   0,   0],
       [  0,   0,  49,   0,   0,   0,   0],
       [  0,   0,  51,   0,   0,   0,   0]]), 'forgetting_measure': [0.37681482, 0.45610583, 0.023867022]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524a751590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155251b42f90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41776143, 'precision': 0.13166666666666667, 'recall': 0.24285714285714285, 'f1_score': 0.151841746248294684, 'confusion_matrix': array([[  0,   0, 107,   0,   0,   0,   0],
       [  0,   0, 202,   0,   0,   0,   0],
       [  0,   0, 133,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0],
       [  0,   0,  48,   0,   0,   0,   0],
       [  0,   0,  32,   0,   0,   0,   0],
       [  0,   0,  35,   0,   0,   0,   0]]), 'forgetting_measure': [0.42297385, 0.43987286, 0.17413667]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524ab69590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524ddf7110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39971892, 'precision': 0.125396825396825397, 'recall': 0.24285714285714285, 'f1_score': 0.143126684636118594, 'confusion_matrix': array([[160,   0,   0,   0,   0,   0,   0],
       [337,   0,   0,   0,   0,   0,   0],
       [164,   0,   0,   0,   0,   0,   0],
       [ 65,   0,   0,   0,   0,   0,   0],
       [ 74,   0,   0,   0,   0,   0,   0],
       [ 57,   0,   0,   0,   0,   0,   0],
       [ 43,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3664055, 0.42382038, -0.16779728]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524ab69590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524ddf7110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36654739, 'precision': 0.123809523809523808, 'recall': 0.24285714285714285, 'f1_score': 0.14081632653061224, 'confusion_matrix': array([[100,   0,   0,   0,   0,   0,   0],
       [257,   0,   0,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0,   0,   0],
       [ 35,   0,   0,   0,   0,   0,   0],
       [ 59,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.34717468, 0.41348368, 0.25850853]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155256b21590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155257223990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44208197, 'precision': 0.20777609259409296, 'recall': 0.33950878246607404, 'f1_score': 0.23051372124810195, 'confusion_matrix': array([[137,   0,  25,   0,   0,  40,   0],
       [127,   0,  34,   0,   0,  42,   0],
       [160,   0,  49,   0,   0,  53,   0],
       [ 36,   0,  19,   0,   0,  12,   0],
       [ 31,   0,  20,   0,   0,  15,   0],
       [  0,   0,  10,   0,   0,  43,   0],
       [  0,   0,   6,   0,   0,  41,   0]]), 'forgetting_measure': [0.39638565, 0.27154776, 0.009010289]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155256b21590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155257223990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43503688, 'precision': 0.20511336152734053, 'recall': 0.3471768707482993, 'f1_score': 0.2248966940610661, 'confusion_matrix': array([[ 78,   0,  32,   0,   0,  34,   0],
       [ 76,   0,  14,   0,   0,  33,   0],
       [100,   0,  33,   0,   0,  42,   0],
       [ 18,   0,  17,   0,   0,  12,   0],
       [ 19,   0,  13,   0,   0,  12,   0],
       [  0,   0,   0,   0,   0,  33,   0],
       [  0,   0,   0,   0,   0,  34,   0]]), 'forgetting_measure': [0.45371172, 0.4503445, 0.19257434]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523b339590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523aaf4510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40993496, 'precision': 0.18641376656743972, 'recall': 0.17537265183616428, 'f1_score': 0.17513038049237612, 'confusion_matrix': array([[ 11,  50,  57,   1,   2,   4,  12,   5,   0,   1,   0,   0,   0,
          4,   1],
       [ 16,  85, 107,   0,   2,   5,  11,  12,   1,   0,   0,   4,   0,
          9,   6],
       [ 21,  98,  83,   5,   3,   4,  18,  10,   2,   0,   1,   1,   0,
          8,   7],
       [ 14,  12,  29,   2,   1,   0,   6,   2,   2,   0,   0,   3,   0,
          3,   0],
       [  6,  12,  29,   2,   0,   0,   2,   3,   1,   0,   0,   0,   0,
          3,   1],
       [  4,   3,   6,   1,   0,   3,  10,   9,   0,   0,   1,   0,   0,
          3,   2],
       [  2,   1,  11,   3,   0,   0,  18,  14,   0,   0,   0,   1,   1,
          4,   3],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0]]), 'forgetting_measure': [0.43334064, 0.42334414, 0.45770523]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523b339590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523aaf4510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4558809, 'precision': 0.19359979118664666, 'recall': 0.19214794713333135, 'f1_score': 0.17957821887635444, 'confusion_matrix': array([[11, 28, 47,  0,  0,  2, 19,  1,  0,  0,  2,  3,  0],
       [20, 43, 95,  0,  2,  3, 13,  2,  1,  0, 11,  5,  0],
       [12, 41, 60,  0,  1,  1,  9,  0,  1,  1,  6,  4,  0],
       [ 8,  4, 28,  0,  2,  0,  4,  1,  0,  0,  2,  0,  0],
       [10,  4, 15,  0,  2,  1,  5,  0,  0,  0,  3,  0,  0],
       [ 4,  1,  5,  0,  0,  0, 11,  0,  0,  1,  5,  3,  1],
       [ 2,  3,  7,  0,  0,  0, 14,  0,  0,  1,  5,  4,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.5420327, 0.6139586, 0.091863595]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523fa96f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552405b9b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49608247, 'precision': 0.19854748040608466, 'recall': 0.2025188744702034, 'f1_score': 0.19846507730814569, 'confusion_matrix': array([[ 53, 101,  27,   6,   1,   1,  10,   1,   0,   0,   0,   1,   0,
          0],
       [ 62, 117,  33,  23,   1,   0,  14,   0,   1,   2,   0,   4,   2,
          0],
       [ 46,  90,  40,  11,   0,   0,  11,   0,   0,   0,   2,   1,   1,
          0],
       [ 14,  21,   9,  17,   1,   0,   6,   0,   1,   1,   0,   1,   1,
          0],
       [ 17,  19,  17,   4,   0,   1,   8,   0,   0,   0,   0,   0,   0,
          0],
       [  0,  15,   0,   2,   1,   0,  11,   0,   0,   0,   1,   0,   0,
          0],
       [  5,  30,   5,   3,   0,   0,  20,   0,   0,   2,   0,   4,   0,
          1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0]]), 'forgetting_measure': [0.45046083, 0.08288854, 0.32679844]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523fa96f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552405b9b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46073894, 'precision': 0.18188152035069521, 'recall': 0.19152030186851727, 'f1_score': 0.18174861408446857, 'confusion_matrix': array([[38, 53, 11,  3,  0,  0, 19,  0,  0,  1,  0,  2,  3,  0],
       [50, 81, 26,  4,  1,  0, 19,  0,  0,  0,  0,  3,  0,  0],
       [29, 67, 17,  2,  2,  1, 14,  1,  0,  0,  3,  2,  1,  0],
       [14, 17,  7,  2,  1,  0,  5,  0,  0,  0,  0,  0,  0,  0],
       [ 9, 11, 12,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0],
       [ 0,  7,  0,  2,  0,  0, 10,  0,  0,  0,  0,  1,  0,  0],
       [ 3, 17,  3,  2,  0,  0, 18,  0,  1,  1,  0,  1,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.44060243, 0.3846572, -0.10706702]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522d916610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240428390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44379972, 'precision': 0.21972253676218739, 'recall': 0.2287581135189261, 'f1_score': 0.21432234077394679, 'confusion_matrix': array([[ 17,  98,  26,  27,   6,   2,  17,   0,   0,   2],
       [ 24, 113,  47,  34,   9,   1,  13,   1,   0,   3],
       [ 36,  91,  32,  26,   6,  11,  13,   1,   0,   2],
       [  1,  17,  15,  26,   3,   4,   3,   0,   0,   1],
       [  1,  19,  14,  20,   5,   5,   7,   1,   0,   0],
       [  2,  16,   6,   5,   0,   0,   4,   1,   0,   0],
       [  2,  23,  15,  10,   2,   0,  10,   0,   1,   3],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44124, 0.28829953, 0.3934853]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522d916610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240428390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43718445, 'precision': 0.23625678572861671, 'recall': 0.22921555046180785, 'f1_score': 0.22865957457392932, 'confusion_matrix': array([[20, 61, 15, 11,  6,  2,  6,  1,  1],
       [30, 75, 33, 19, 14, 10, 17,  0,  4],
       [21, 62, 20, 11,  2,  0,  4,  0,  0],
       [ 4, 14,  6,  6,  2,  4,  2,  0,  0],
       [ 2,  9, 16,  8,  4,  6,  3,  0,  2],
       [ 1,  6,  0,  6,  0,  0,  5,  0,  0],
       [ 2, 23,  1, 10,  0,  0, 11,  0,  2],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.46866063, 0.4528973, 0.29994613]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155233881590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552335e9f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43549514, 'precision': 0.18452238820362702, 'recall': 0.18431871889789312, 'f1_score': 0.17766910538436167, 'confusion_matrix': array([[ 16,  92,  62,   5,   2,   9,   0,   1,   0,   1,   0,   2,   0],
       [ 26, 135,  98,   7,   6,  11,   0,   0,   0,   2,   0,   0,   0],
       [  8, 109,  65,   6,   2,   8,   0,   4,   0,   1,   0,   0,   0],
       [  4,  19,  34,   1,   2,   1,   0,   0,   1,   1,   0,   0,   1],
       [ 10,   5,  37,   3,   1,   1,   0,   0,   0,   0,   0,   1,   0],
       [  1,  12,  28,   0,   2,  10,   0,   0,   0,   0,   0,   1,   0],
       [  0,  12,  20,   0,   0,  10,   0,   0,   0,   0,   1,   2,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.48088843, 0.54734284, 0.111516446]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155233881590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552335e9f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48432193, 'precision': 0.19142186056591119, 'recall': 0.18670037384343736, 'f1_score': 0.1775025999756458, 'confusion_matrix': array([[  9,  61,  30,   1,   2,   0,   0,   0,   1,   1,   1,   0],
       [ 15, 115,  64,   2,   5,   2,   0,   0,   1,   0,   2,   0],
       [ 15,  67,  47,   3,   3,   0,   0,   0,   0,   1,   0,   0],
       [  5,   9,  21,   0,   0,   0,   0,   0,   1,   0,   0,   0],
       [  9,  13,  23,   0,   1,   1,   0,   1,   1,   0,   0,   0],
       [  0,   9,  16,   0,   4,   1,   0,   0,   1,   0,   0,   1],
       [  0,  10,  23,   0,   1,   0,   0,   0,   0,   0,   1,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4873145, 0.30764756, 0.26352006]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552361d1590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523335f650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4612991, 'precision': 0.19977017772472319, 'recall': 0.20116905987627316, 'f1_score': 0.1968505509268483, 'confusion_matrix': array([[ 23,  58,  80,  14,   5,  12,   3,   0,   0,   0,   0,   0],
       [ 26,  56,  91,  16,   5,  14,   2,   1,   1,   0,   0,   0],
       [ 34,  59, 107,  20,   5,  23,   1,   1,   0,   0,   1,   0],
       [ 15,  19,  26,   9,   2,   9,   2,   0,   0,   1,   0,   1],
       [ 10,  12,  17,  11,   1,   5,   0,   0,   2,   0,   0,   0],
       [  2,  15,  24,   4,   2,  17,   4,   0,   0,   0,   0,   0],
       [  1,   6,  18,   0,   2,   4,   1,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47122786, 0.2714315, 0.474222]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552361d1590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523335f650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42950256, 'precision': 0.25378433478547893, 'recall': 0.26570209330470526, 'f1_score': 0.25717648266625758, 'confusion_matrix': array([[27, 44, 34,  9,  5, 15,  0,  0],
       [26, 48, 48, 13,  7, 12,  0,  0],
       [31, 46, 49, 14,  3, 12,  0,  1],
       [11, 21, 17,  8,  3,  4,  0,  0],
       [ 9,  5,  5,  3,  1,  2,  0,  0],
       [ 0, 13, 14,  2,  1, 15,  0,  0],
       [ 1,  5,  4,  1,  2,  9,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.46568844, 0.64377314, -0.4781155]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155223c3ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552250d1f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47840438, 'precision': 0.2204950560983009, 'recall': 0.20661233079851347, 'f1_score': 0.20902436170584108, 'confusion_matrix': array([[138,  53,  41,   6,   1,   9,   7,   0,   2,   0,   0,   0,   1,
          1],
       [ 61,  44,  78,   5,   1,   3,   3,   0,   0,   1,   2,   1,   1,
          0],
       [ 52,  74,  63,   6,   3,   2,   4,   1,   0,   0,   0,   0,   3,
          0],
       [ 28,  15,   7,   7,   0,   2,   1,   0,   1,   0,   0,   0,   0,
          0],
       [ 43,  17,   3,   3,   0,   3,   1,   0,   2,   0,   0,   0,   0,
          0],
       [ 10,  24,   6,   1,   0,   7,   4,   0,   0,   0,   0,   0,   0,
          0],
       [  9,  15,   7,   1,   1,   3,   9,   0,   2,   0,   0,   0,   1,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0]]), 'forgetting_measure': [0.4369954, 0.19491887, 0.16364953]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155223c3ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552250d1f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48438276, 'precision': 0.2276441886399761, 'recall': 0.21432702808178563, 'f1_score': 0.2105375622952209, 'confusion_matrix': array([[88, 31, 33,  3,  2,  1,  2,  1,  0,  0,  1],
       [71, 31, 29,  1,  1,  2,  5,  1,  0,  0,  0],
       [74, 27, 31,  1,  1,  3,  2,  0,  1,  1,  1],
       [23, 10,  6,  1,  0,  2,  2,  1,  0,  0,  1],
       [30,  6,  3,  0,  0,  0,  2,  1,  0,  0,  0],
       [13,  9,  3,  1,  1,  8,  1,  0,  0,  0,  0],
       [ 7,  8,  9,  0,  0,  5,  1,  0,  0,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.4834505, 0.35851228, 0.09049498]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b30d1490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528b3b1850>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39933441, 'precision': 0.2541084606419745, 'recall': 0.26013912278197992, 'f1_score': 0.2395974488648974, 'confusion_matrix': array([[66, 22, 32, 27, 76,  1,  0],
       [59, 22, 34, 27, 51,  1,  1],
       [61, 36, 56, 29, 58,  7,  3],
       [ 5, 12,  7, 12, 26,  4,  0],
       [12,  9,  9, 11, 20,  3,  1],
       [ 7,  1,  5,  2, 25,  0,  0],
       [ 1,  2,  5,  0, 52,  0,  0]]), 'forgetting_measure': [0.4051935, 0.26393577, 0.69654965]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b30d1490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528b3b1850>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38253094, 'precision': 0.29242582891218357, 'recall': 0.28946164596692347, 'f1_score': 0.25517217561889107, 'confusion_matrix': array([[50, 19, 10, 12, 37,  3,  2],
       [54, 18, 13, 14, 37,  5,  0],
       [54, 22, 14, 24, 48,  3,  1],
       [ 0, 14,  7,  6, 18,  1,  0],
       [ 6, 12,  3,  3, 22,  1,  0],
       [ 0,  1,  2,  0, 19,  3,  1],
       [ 3,  4,  4,  0, 28,  1,  1]]), 'forgetting_measure': [0.36635572, 0.20757009, 0.66755384]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155223941e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155213319b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48392848, 'precision': 0.21348897933039785, 'recall': 0.24212813110547343, 'f1_score': 0.18916605761730044, 'confusion_matrix': array([[  2,  31, 180,   0,   0,   0,   0],
       [  2,  30, 166,   0,   0,   0,   0],
       [  5,  37, 211,   0,   0,   0,   0],
       [  0,   0,  49,   0,   0,   0,   0],
       [  0,   0,  87,   0,   0,   0,   0],
       [  0,   0,  56,   0,   0,   0,   0],
       [  0,   0,  44,   0,   0,   0,   0]]), 'forgetting_measure': [0.47967896, 0.32016265, 0.1709803]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155223941e90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155213319b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48721344, 'precision': 0.25213024921132204, 'recall': 0.24574946150366982, 'f1_score': 0.18557637782137074, 'confusion_matrix': array([[  4,   9, 133,   0,   0,   0,   0],
       [  1,   6, 107,   0,   0,   0,   0],
       [  3,   8, 173,   0,   0,   0,   0],
       [  0,   0,  46,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0],
       [  0,   0,  35,   0,   0,   0,   0],
       [  0,   0,  32,   0,   0,   0,   0]]), 'forgetting_measure': [0.47335983, 0.38586777, -0.12951083]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155216a79590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520d59af90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3562989, 'precision': 0.12304147465437788, 'recall': 0.24187866927592954, 'f1_score': 0.139644565960355434, 'confusion_matrix': array([[145,   0,   1,   0,   0,   0,   0],
       [169,   0,   0,   0,   0,   0,   0],
       [350,   0,   0,   0,   0,   0,   0],
       [ 75,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.33601443, 0.3896344, 0.38338026]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155216a79590>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520d59af90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33941735, 'precision': 0.121666666666666667, 'recall': 0.24285714285714285, 'f1_score': 0.13762662807525326, 'confusion_matrix': array([[ 91,   0,   0,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0,   0,   0],
       [275,   0,   0,   0,   0,   0,   0],
       [ 59,   0,   0,   0,   0,   0,   0],
       [ 26,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 26,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.28243647, 0.2747068, 0.21783748]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520bb8b3d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552077d7110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4384317, 'precision': 0.20142857142857142, 'recall': 0.3857142857142857, 'f1_score': 0.24548197978718386, 'confusion_matrix': array([[176,   0,   0,   0,   0,   0,   0],
       [283,   0,   0,   0,   0,   0,   0],
       [196,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 83,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  49,   0],
       [  0,   0,   0,   0,   0,  51,   0]]), 'forgetting_measure': [0.37429304, 0.5963895, -1.9834865]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520bb8b3d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552077d7110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4781845, 'precision': 0.21423450957488088, 'recall': 0.3857142857142857, 'f1_score': 0.25494814719157524, 'confusion_matrix': array([[108,   0,   0,   0,   0,   0,   0],
       [212,   0,   0,   0,   0,   0,   0],
       [126,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  40,   0],
       [  0,   0,   0,   0,   0,  27,   0]]), 'forgetting_measure': [0.40965713, 0.55572754, -1.815427]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b1639810>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b157af90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40974827, 'precision': 0.22438536581404584, 'recall': 0.243451516727627, 'f1_score': 0.19984415956179937, 'confusion_matrix': array([[ 92,  20,  31,   6,   0,   0,   2],
       [210,  35,  81,  22,   0,   0,   0],
       [100,  20,  35,   6,   0,   0,   0],
       [ 55,   0,  17,   6,   0,   0,   0],
       [ 39,   1,  16,   6,   0,   0,   0],
       [  0,   0,  36,  10,   0,   0,   0],
       [  0,   0,  43,  11,   0,   0,   0]]), 'forgetting_measure': [0.48312128, 0.69261014, -0.089908585]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b1639810>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b157af90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34953178, 'precision': 0.14942455596746529, 'recall': 0.23985947484781489, 'f1_score': 0.16923759939466509, 'confusion_matrix': array([[ 65,   0,  15,   7,   0,   0,   2],
       [175,   0,  53,  24,   0,   0,   0],
       [ 74,   0,  20,  12,   0,   0,   0],
       [ 34,   0,  12,   3,   0,   0,   1],
       [ 24,   0,  10,   2,   0,   0,   0],
       [  0,   0,  23,   8,   0,   0,   0],
       [  0,   0,  26,  10,   0,   0,   0]]), 'forgetting_measure': [0.27452374, 0.061370943, 0.32692435]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 500 chunkss', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155206526610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155206767c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4380519, 'precision': 0.1947052947052947, 'recall': 0.23409283269479774, 'f1_score': 0.20550348472949149, 'confusion_matrix': array([[ 43, 126,  37,   0,   0,   0,   0],
       [ 56, 144,  45,   0,   0,   0,   0],
       [ 41, 134,  29,   0,   0,   0,   0],
       [ 16,  41,  13,   0,   0,   0,   0],
       [ 20,  45,  10,   0,   0,   0,   0],
       [ 11,  27,  19,   0,   0,   0,   0],
       [  8,  23,  12,   0,   0,   0,   0]]), 'forgetting_measure': [0.42371253, 0.34345585, 0.16289283]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 500 chunkss', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155206526610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155206767c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4712967, 'precision': 0.21653349675128258, 'recall': 0.25384230410786134, 'f1_score': 0.21686707633255741, 'confusion_matrix': array([[ 32, 115,  14,   0,   0,   0,   0],
       [ 27, 118,  14,   0,   0,   0,   0],
       [ 27,  81,  17,   0,   0,   0,   0],
       [  3,  36,   1,   0,   0,   0,   0],
       [  5,  36,   7,   0,   0,   0,   0],
       [ 16,  23,  10,   0,   0,   0,   0],
       [  6,   9,   3,   0,   0,   0,   0]]), 'forgetting_measure': [0.46659354, 0.21357162, 0.4485005]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd306f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155205f37650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56139107, 'precision': 0.293513623255644, 'recall': 0.25205368350658613, 'f1_score': 0.24719270610034613, 'confusion_matrix': array([[ 16, 130,  11,   4,   1,   8,   6,   0,   0],
       [ 18, 277,  23,  16,   8,  13,   1,   0,   0],
       [ 11, 111,  13,   8,   3,   2,   0,   1,   0],
       [  1,  59,   1,   1,   2,   3,   1,   0,   1],
       [  4,  42,   1,   0,   2,   1,   0,   0,   0],
       [  5,  25,   5,   3,   1,  12,   0,   0,   0],
       [ 11,  24,   1,   2,   1,   4,   6,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5013125, 0.095562145, 0.11864513]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd306f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155205f37650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.57098154, 'precision': 0.27432263928613348, 'recall': 0.25070727178119825, 'f1_score': 0.24299075028672456, 'confusion_matrix': array([[  9,  68,   3,   4,   0,   1,   3,   0],
       [ 34, 184,  12,   9,   6,  13,   2,   1],
       [  3,  81,   7,   2,   2,   2,   1,   0],
       [  3,  42,   3,   1,   2,   2,   0,   0],
       [  4,  24,   2,   0,   0,   1,   2,   0],
       [  8,  16,   0,   0,   0,   6,   0,   0],
       [ 10,  14,   0,   1,   1,   7,   4,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.66986696, 0.38957623, 0.4388058]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fb67ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155202072e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56095053, 'precision': 0.30920050148914995, 'recall': 0.26368802738571864, 'f1_score': 0.23939963476563427, 'confusion_matrix': array([[  5, 170,   8,   6,   3,   0,   6],
       [  9, 315,  11,  16,   7,   0,   8],
       [  1,  88,   9,   3,   2,   0,   1],
       [  0,  68,   0,   6,   4,   0,   1],
       [  0,  44,   0,   6,   3,   0,   0],
       [  0,  49,   0,   0,   0,   0,   2],
       [  0,  43,   0,   4,   0,   0,   2]]), 'forgetting_measure': [0.584617, 0.27744502, 0.2915509]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fb67ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155202072e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51581268, 'precision': 0.20774924201890493, 'recall': 0.24703153988868276, 'f1_score': 0.20568104524134832, 'confusion_matrix': array([[  0, 117,   8,   6,   3,   0,   0],
       [  0, 204,   9,  11,   7,   0,   0],
       [  0,  67,   3,   2,   5,   0,   0],
       [  0,  46,   0,   6,   4,   0,   0],
       [  0,  33,   0,   2,   0,   0,   0],
       [  0,  33,   0,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5074174, 0.29466254, 0.12079623]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f5e0ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522ce3c0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5373714, 'precision': 0.3726367142106149, 'recall': 0.30366092593029445, 'f1_score': 0.2839330096287881, 'confusion_matrix': array([[204,  87,   5,   1,  13,   6,   0],
       [ 94,  84,   7,   0,   8,   4,   0],
       [ 79,  48,   5,   0,   8,   4,   0],
       [ 56,   8,   0,   1,   3,   4,   0],
       [ 44,  11,   0,   0,  13,   3,   0],
       [ 22,  13,   1,   0,   0,   5,   0],
       [ 26,  26,   0,   0,   1,   6,   0]]), 'forgetting_measure': [0.5181921, 0.21777415, 0.1843943]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f5e0ef10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15522ce3c0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4736017, 'precision': 0.21592717846341791, 'recall': 0.2688757113922191, 'f1_score': 0.2363170382808024, 'confusion_matrix': array([[86, 85,  0,  1, 11,  5,  0],
       [63, 51,  1,  1,  6,  8,  0],
       [65, 48,  0,  0, 13,  4,  0],
       [35,  8,  0,  0,  5,  1,  0],
       [25,  4,  0,  0,  7,  0,  0],
       [14, 10,  1,  0,  0,  4,  0],
       [12, 17,  0,  0,  1,  8,  0]]), 'forgetting_measure': [0.47339348, 0.27685675, 0.3430241]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155235c58e50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551de919f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56393744, 'precision': 0.22356880690214024, 'recall': 0.24889653477090545, 'f1_score': 0.21203430505961758, 'confusion_matrix': array([[  9,   2, 134,   5,   0,   1,   0],
       [ 11,   0, 136,   5,   0,   0,   0],
       [ 16,   7, 323,  17,   0,   0,   4],
       [  0,   0,  68,   8,   0,   2,   0],
       [  0,   1,  49,   2,   0,   0,   0],
       [  0,   0,  69,   0,   0,   0,   0],
       [  0,   0,  31,   0,   0,   0,   0]]), 'forgetting_measure': [0.51751212, 0.13273376, 0.13777652]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155235c58e50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551de919f10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.62898884, 'precision': 0.2260184881342205, 'recall': 0.25147061295942535, 'f1_score': 0.20744065761522122, 'confusion_matrix': array([[  1,   0,  96,   6,   0,   1,   0],
       [  0,   0,  81,   8,   0,   0,   0],
       [  3,   0, 230,  12,   0,   1,   3],
       [  0,   0,  54,   8,   0,   1,   0],
       [  0,   0,  25,   3,   0,   0,   0],
       [  0,   0,  45,   0,   0,   0,   0],
       [  0,   0,  22,   0,   0,   0,   0]]), 'forgetting_measure': [0.6958475, 0.34510463, 0.22888876]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dd5f9c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f02399d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51451288, 'precision': 0.2728285804059126, 'recall': 0.25667537831768205, 'f1_score': 0.22514920608934305, 'confusion_matrix': array([[ 29, 126,   6,   8,   5,   0,   0],
       [ 31, 232,   8,  13,   4,   0,   0],
       [ 13, 167,   7,   8,   2,   0,   0],
       [ 10,  42,   2,   1,   1,   1,   0],
       [  8,  58,   8,   4,   6,   0,   0],
       [  0,  53,   0,   0,   0,   0,   0],
       [  6,  40,   0,   1,   0,   0,   0]]), 'forgetting_measure': [0.48810867, 0.29109293, -0.018769313]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dd5f9c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551f02399d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5160759, 'precision': 0.28406487860536994, 'recall': 0.26327446302957443, 'f1_score': 0.22864093699161375, 'confusion_matrix': array([[ 19,  75,   2,   7,   2,   1,   0],
       [ 29, 171,   1,   7,   2,   0,   0],
       [ 23,  93,   3,   4,   0,   0,   0],
       [  6,  36,   0,   6,   0,   0,   0],
       [  8,  34,   0,   4,   0,   0,   0],
       [  2,  36,   0,   0,   0,   0,   0],
       [  3,  26,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4752678, 0.31872565, -0.24109833]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551db406f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551db57fc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5447237, 'precision': 0.18172386272944933, 'recall': 0.24338180781294554, 'f1_score': 0.17925817325539104, 'confusion_matrix': array([[333,   0,   1,   0,   0,   0,   0],
       [181,   0,   2,   0,   0,   0,   0],
       [149,   0,   1,   0,   0,   0,   0],
       [ 86,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   1,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 58,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57332218, 0.3422638, 0.19848746]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551db406f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551db57fc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52011473, 'precision': 0.17298919567827131, 'recall': 0.24326973124627082, 'f1_score': 0.16994637376931138, 'confusion_matrix': array([[185,   0,   1,   0,   0,   0,   0],
       [135,   0,   3,   0,   0,   0,   0],
       [120,   0,   1,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 26,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5279432, 0.30222687, 0.21705304]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316c39350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316df9c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4715815, 'precision': 0.23722192413411577, 'recall': 0.2428639561820829, 'f1_score': 0.2369078100037401, 'confusion_matrix': array([[61, 85, 34,  3, 13, 14,  2,  0,  1],
       [46, 98, 53,  8, 27, 25,  3,  0,  2],
       [32, 84, 40,  5, 16, 12,  2,  1,  0],
       [15, 22,  8,  2,  7,  3,  1,  0,  0],
       [13, 31,  9,  8,  8,  6,  0,  0,  0],
       [ 8, 21,  8,  0,  2, 16,  3,  0,  0],
       [ 5, 18,  6,  0,  5,  8,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.51687247, 0.41728586, 0.3621106]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316c39350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316df9c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5183991, 'precision': 0.2948418234153294, 'recall': 0.2821884171932142, 'f1_score': 0.2758172273057252, 'confusion_matrix': array([[36, 66, 17,  3,  3,  7,  1,  0],
       [40, 76, 25,  3, 11, 11,  1,  0],
       [32, 61, 26,  3,  8,  8,  2,  1],
       [22, 14,  5,  3, 10,  3,  0,  1],
       [ 8, 14,  4,  0,  6,  2,  0,  0],
       [ 9, 19,  3,  0,  0, 15,  1,  0],
       [ 9,  6,  2,  0,  0,  3,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.45141453, 0.10334355, 0.08382599]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a23290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15534374fb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50148974, 'precision': 0.14111111111111111, 'recall': 0.24285714285714285, 'f1_score': 0.16384814495254529, 'confusion_matrix': array([[  0,   0, 190,   0,   0,   0,   0],
       [  0,   0, 214,   0,   0,   0,   0],
       [  0,   0, 259,   0,   0,   0,   0],
       [  0,   0,  82,   0,   0,   0,   0],
       [  0,   0,  55,   0,   0,   0,   0],
       [  0,   0,  61,   0,   0,   0,   0],
       [  0,   0,  39,   0,   0,   0,   0]]), 'forgetting_measure': [0.5390112, 0.36436695, 0.33199108]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a23290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15534374fb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4390575, 'precision': 0.136190476190476197, 'recall': 0.24285714285714285, 'f1_score': 0.157750759878419454, 'confusion_matrix': array([[  0,   0, 148,   0,   0,   0,   0],
       [  0,   0, 146,   0,   0,   0,   0],
       [  0,   0, 152,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0],
       [  0,   0,  25,   0,   0,   0,   0],
       [  0,   0,  40,   0,   0,   0,   0],
       [  0,   0,  27,   0,   0,   0,   0]]), 'forgetting_measure': [0.45104913, 0.3616977, 0.3660713]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ecd72110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed0833d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39162409, 'precision': 0.137870411322423705, 'recall': 0.24004788507581803, 'f1_score': 0.15879281983811302, 'confusion_matrix': array([[154,   0,   0,  25,   0,   0,   0],
       [333,   0,   0,  43,   0,   0,   0],
       [ 99,   0,   0,  14,   0,   0,   0],
       [ 66,   0,   0,   9,   0,   0,   0],
       [ 51,   0,   0,   6,   0,   0,   0],
       [ 17,   0,   0,  32,   0,   0,   0],
       [ 28,   0,   0,  23,   0,   0,   0]]), 'forgetting_measure': [0.42029897, 0.6272903, -0.13248853]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ecd72110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed0833d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47178344, 'precision': 0.154930853920515575, 'recall': 0.25114853529487676, 'f1_score': 0.18057527218006943, 'confusion_matrix': array([[131,   0,   0,  33,   0,   0,   0],
       [169,   0,   0,  35,   0,   0,   0],
       [ 63,   0,   0,  11,   0,   0,   0],
       [ 40,   0,   0,  14,   0,   0,   0],
       [ 33,   0,   0,   4,   0,   0,   0],
       [  5,   0,   0,  27,   0,   0,   0],
       [  7,   0,   0,  28,   0,   0,   0]]), 'forgetting_measure': [0.43520648, 0.19599529, 0.21844028]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316995450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eceee9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48594273, 'precision': 0.140317460317460314, 'recall': 0.24285714285714285, 'f1_score': 0.16288685318148056, 'confusion_matrix': array([[254,   0,   0,   0,   0,   0,   0],
       [217,   0,   0,   0,   0,   0,   0],
       [195,   0,   0,   0,   0,   0,   0],
       [ 72,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 71,   0,   0,   0,   0,   0,   0],
       [ 29,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.50137404, 0.36470935, 0.20990783]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316995450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eceee9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52429564, 'precision': 0.14666666666666667, 'recall': 0.24285714285714285, 'f1_score': 0.17035175879396985, 'confusion_matrix': array([[196,   0,   0,   0,   0,   0,   0],
       [108,   0,   0,   0,   0,   0,   0],
       [140,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0],
       [ 28,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.56770623, 0.53024423, -0.2993314]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed399ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1041d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36163126, 'precision': 0.19701849563148347, 'recall': 0.27868880364022852, 'f1_score': 0.20978262262113701, 'confusion_matrix': array([[ 59,   0,  35, 120,   0,   0,  26],
       [ 58,   0,  30, 111,   0,   0,  38],
       [ 40,   0,  23, 103,   0,   0,  27],
       [ 26,   0,  12,  21,   0,   0,   5],
       [ 16,   0,  13,  29,   0,   0,   8],
       [  0,   0,  22,   0,   0,   0,  26],
       [  0,   0,  23,   0,   0,   0,  29]]), 'forgetting_measure': [0.2633696, 0.026644569, -0.021951886]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed399ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f1041d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31304922, 'precision': 0.17899908506602378, 'recall': 0.29099854496555202, 'f1_score': 0.19367339197234859, 'confusion_matrix': array([[26,  0,  8, 73,  0,  0, 27],
       [35,  0, 18, 90,  0,  0, 32],
       [26,  0,  6, 75,  0,  0, 28],
       [17,  0,  4, 10,  0,  0,  8],
       [20,  0,  9, 11,  0,  0, 10],
       [ 0,  0,  7,  0,  0,  0, 22],
       [ 0,  0,  6,  0,  0,  0, 32]]), 'forgetting_measure': [0.1, 0, 0.13689893]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1da2150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed134390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42016196, 'precision': 0.15748693686686128, 'recall': 0.28875086266390614, 'f1_score': 0.18811219602172994, 'confusion_matrix': array([[170,   0,   0,  37,   0,   0,   0],
       [211,   0,   0,  61,   0,   0,   0],
       [148,   0,   0,  41,   0,   0,   0],
       [ 32,   0,   0,  32,   0,   0,   0],
       [ 44,   0,   0,  24,   0,   0,   0],
       [ 48,   0,   0,   1,   0,   0,   0],
       [ 46,   0,   0,   5,   0,   0,   0]]), 'forgetting_measure': [0.42239068, 0.38859746, 0.28474244]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552f1da2150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed134390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4130146, 'precision': 0.15250865855438634, 'recall': 0.31347642505277972, 'f1_score': 0.18267712679477386, 'confusion_matrix': array([[103,   0,   0,  37,   0,   0,   0],
       [127,   0,   0,  49,   0,   0,   0],
       [101,   0,   0,  34,   0,   0,   0],
       [  7,   0,   0,  22,   0,   0,   0],
       [ 16,   0,   0,  37,   0,   0,   0],
       [ 26,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4100948, 0.54094714, -0.3108483]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e4d02c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f10d11d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45844046, 'precision': 0.1365079365079365, 'recall': 0.24285714285714285, 'f1_score': 0.158154235145385584, 'confusion_matrix': array([[  0,   0, 228,   0,   0,   0,   0],
       [  0,   0, 208,   0,   0,   0,   0],
       [  0,   0, 230,   0,   0,   0,   0],
       [  0,   0,  68,   0,   0,   0,   0],
       [  0,   0,  66,   0,   0,   0,   0],
       [  0,   0,  38,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0]]), 'forgetting_measure': [0.50463975, 0.4827567, 0.22892192]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e4d02c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f10d11d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44326433, 'precision': 0.134999999999999996, 'recall': 0.24285714285714285, 'f1_score': 0.156224899598393566, 'confusion_matrix': array([[  0,   0, 144,   0,   0,   0,   0],
       [  0,   0, 151,   0,   0,   0,   0],
       [  0,   0, 147,   0,   0,   0,   0],
       [  0,   0,  51,   0,   0,   0,   0],
       [  0,   0,  40,   0,   0,   0,   0],
       [  0,   0,  26,   0,   0,   0,   0],
       [  0,   0,  41,   0,   0,   0,   0]]), 'forgetting_measure': [0.42820424, 0.35898593, 0.0911584]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e9b5a010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9e6fad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51367242, 'precision': 0.22281889832993613, 'recall': 0.2439461699701627, 'f1_score': 0.2069584905519455, 'confusion_matrix': array([[293,  26,  21,   3,   0,   0,   0],
       [156,  15,  12,   0,   0,   0,   0],
       [117,  13,  10,   0,   0,   0,   0],
       [ 87,   2,   0,   0,   0,   0,   0],
       [ 43,   1,   0,   1,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0],
       [ 51,   1,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43054727, -0.12432102, 0.35736737]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e9b5a010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e9e6fad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4870551, 'precision': 0.24037698412698413, 'recall': 0.24443947178047253, 'f1_score': 0.18301576601364737, 'confusion_matrix': array([[182,   5,   3,   1,   0,   0,   0],
       [131,   7,   2,   0,   0,   0,   0],
       [117,   2,   1,   2,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 37,   0,   0,   1,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51151875, 0.46537566, -0.04377444]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551db959210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ea74af90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6085282, 'precision': 0.23028953229398663, 'recall': 0.24382239382239384, 'f1_score': 0.18527564969205348, 'confusion_matrix': array([[  1,   0, 147,   0,   0,   0,   0],
       [  1,   0, 146,   0,   0,   0,   0],
       [  0,   0, 370,   0,   0,   0,   0],
       [  0,   0,  81,   0,   0,   0,   0],
       [  0,   0,  54,   0,   0,   0,   0],
       [  0,   0,  61,   0,   0,   0,   0],
       [  0,   0,  39,   0,   0,   0,   0]]), 'forgetting_measure': [0.5979006, 0.21208459, 0.14509961]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551db959210>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ea74af90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6221555, 'precision': 0.16261904761904762, 'recall': 0.24285714285714285, 'f1_score': 0.18707167687468961, 'confusion_matrix': array([[  0,   0,  84,   0,   0,   0,   0],
       [  0,   0,  93,   0,   0,   0,   0],
       [  0,   0, 263,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0],
       [  0,   0,  50,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0]]), 'forgetting_measure': [0.7108951, 0.38601026, 0.25219804]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e17d9910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e37cc990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60759963, 'precision': 0.34015577321291146, 'recall': 0.34052805061085114, 'f1_score': 0.31757881986873118, 'confusion_matrix': array([[222,  41,   5,   5,   0,   0,   0],
       [ 77, 117,  24,   4,   0,   0,   0],
       [ 82,  49,  32,  11,   0,   0,   0],
       [ 64,  12,   3,  15,   0,   0,   0],
       [ 28,   6,   2,   1,   0,   0,   0],
       [ 18,  14,   1,   0,   0,   0,   0],
       [ 40,  17,   3,   7,   0,   0,   0]]), 'forgetting_measure': [0.5077563, -0.031875532, 0.06289888]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e17d9910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e37cc990>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43387668, 'precision': 0.23548875202689306, 'recall': 0.25433320822955407, 'f1_score': 0.22409562698535666, 'confusion_matrix': array([[98, 41, 12,  7,  0,  0,  0],
       [74, 37,  5,  9,  0,  0,  0],
       [97, 39, 14,  8,  0,  0,  0],
       [30, 15,  4,  4,  0,  0,  0],
       [24,  9,  3,  3,  0,  0,  0],
       [10,  7,  2,  0,  0,  0,  0],
       [34, 10,  4,  0,  0,  0,  0]]), 'forgetting_measure': [0.40391625, 0.41042566, -0.21961758]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e1a6ca50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552caf5b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47298146, 'precision': 0.25638880142987535, 'recall': 0.2890999339099169, 'f1_score': 0.25259456523501466, 'confusion_matrix': array([[ 42, 119,  18,   2,   1,   0,  23],
       [ 45, 170,  24,   2,   1,   1,  15],
       [ 39, 113,  21,   1,   2,   1,  21],
       [ 13,  34,   2,   0,   0,   0,   8],
       [  8,  61,   4,   0,   0,   0,   9],
       [  0,  19,   0,   0,   0,   0,  16],
       [  0,  42,   0,   0,   0,   0,  23]]), 'forgetting_measure': [0.46396122, 0.29078916, 0.23735517]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e1a6ca50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552caf5b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48799006, 'precision': 0.24859598923987027, 'recall': 0.3012285609224385, 'f1_score': 0.24694235166255845, 'confusion_matrix': array([[22, 79, 13,  0,  0,  0, 18],
       [32, 99, 15,  0,  0,  0, 22],
       [23, 89,  9,  0,  0,  1, 26],
       [ 2, 35,  0,  0,  0,  0,  4],
       [ 1, 37,  0,  0,  0,  0,  6],
       [ 0,  8,  0,  0,  0,  0, 10],
       [ 0, 20,  0,  0,  0,  0, 29]]), 'forgetting_measure': [0.3795892, -0.24828862, 0.32559446]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e9d12890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eaef8910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43465958, 'precision': 0.27495630065151757, 'recall': 0.24340871483728626, 'f1_score': 0.153518779131858145, 'confusion_matrix': array([[  1, 258,   0,   0,   0,   0,   0],
       [  0, 202,   0,   0,   0,   0,   0],
       [  0, 212,   0,   0,   0,   0,   0],
       [  0,  66,   0,   0,   0,   0,   0],
       [  0,  61,   0,   0,   0,   0,   0],
       [  0,  62,   0,   0,   0,   0,   0],
       [  0,  38,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44480745, 0.3952716, 0.27747852]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e9d12890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eaef8910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41085404, 'precision': 0.129761904761904764, 'recall': 0.24285714285714285, 'f1_score': 0.14926108374384237, 'confusion_matrix': array([[  0, 174,   0,   0,   0,   0,   0],
       [  0, 125,   0,   0,   0,   0,   0],
       [  0, 147,   0,   0,   0,   0,   0],
       [  0,  36,   0,   0,   0,   0,   0],
       [  0,  51,   0,   0,   0,   0,   0],
       [  0,  46,   0,   0,   0,   0,   0],
       [  0,  21,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.39009384, 0.5502687, -0.62499666]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1971dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1ed69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44637146, 'precision': 0.22772146245612623, 'recall': 0.30541141316407557, 'f1_score': 0.2418842406759884, 'confusion_matrix': array([[153,  22,  46,   0,   0,  43,   0],
       [118,  10,  30,   0,   0,  39,   0],
       [134,  14,  26,   0,   0,  38,   0],
       [ 35,   6,  10,   0,   0,   6,   0],
       [ 41,   5,  14,   0,   0,  10,   0],
       [ 10,  13,   0,   0,   0,  50,   0],
       [  5,   5,   1,   0,   0,  16,   0]]), 'forgetting_measure': [0.46840484, 0.4881188, 0.03420022]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d1971dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1ed69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43632383, 'precision': 0.2414587191342527, 'recall': 0.33407764953570473, 'f1_score': 0.2461725700121285, 'confusion_matrix': array([[105,  10,  31,   1,   0,  36,   0],
       [ 69,   8,  14,   0,   0,  26,   0],
       [ 81,  13,  16,   0,   0,  32,   0],
       [ 27,   3,   0,   0,   0,   9,   0],
       [ 36,   3,   0,   0,   0,  13,   0],
       [  0,   5,   0,   0,   0,  38,   0],
       [  0,   2,   0,   0,   0,  22,   0]]), 'forgetting_measure': [0.41598607, 0.2723615, 0.29080045]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d455a110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552caf7f5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47730614, 'precision': 0.3718043170585297, 'recall': 0.2536217684141642, 'f1_score': 0.24668496829047534, 'confusion_matrix': array([[ 42,  31, 120,   8,   0,   0,   2,   2,   1],
       [ 29,  65, 100,  10,   0,   2,   3,   0,   1],
       [ 44,  24, 162,  16,   0,   1,   0,   1,   1],
       [ 19,  18,  36,   1,   0,   0,   0,   0,   0],
       [ 20,  14,  25,   0,   1,   0,   1,   0,   0],
       [  3,  11,  27,   0,   0,   0,   6,   0,   0],
       [  5,   9,  27,   0,   0,   2,  10,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.45602605, 0.24479552, 0.23004434]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d455a110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552caf7f5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40101558, 'precision': 0.23855090859424926, 'recall': 0.22641139751297195, 'f1_score': 0.216826272381809, 'confusion_matrix': array([[22, 41, 60, 10,  0,  1,  2,  1],
       [23, 38, 91,  5,  0,  2,  6,  0],
       [20, 36, 68, 10,  1,  0,  5,  0],
       [11, 13, 27,  0,  1,  0,  0,  0],
       [ 7, 11, 19,  0,  0,  1,  1,  0],
       [ 2,  7, 11,  0,  0,  1,  3,  0],
       [ 3, 12, 23,  1,  0,  0,  4,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.411908, 0.46048796, 0.26989585]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d47bfb10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d40c7110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4787601, 'precision': 0.22145483264268916, 'recall': 0.24627162963867532, 'f1_score': 0.21642046478112052, 'confusion_matrix': array([[163,  98,  11,   0,   0,   0,   0],
       [160, 102,   7,   0,   0,   0,   0],
       [ 73,  53,   6,   0,   0,   0,   0],
       [ 49,  12,   0,   0,   0,   0,   0],
       [ 51,  15,   0,   0,   0,   0,   0],
       [ 11,  30,   0,   0,   0,   0,   0],
       [ 14,  45,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47231007, 0.35357237, 0.07218458]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d47bfb10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d40c7110>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4920032, 'precision': 0.18094044635398019, 'recall': 0.23799228559242996, 'f1_score': 0.20169998075111186, 'confusion_matrix': array([[90, 97,  0,  0,  0,  0,  0],
       [84, 79,  0,  0,  0,  0,  0],
       [49, 39,  0,  0,  0,  0,  0],
       [26, 14,  0,  0,  0,  0,  0],
       [36, 19,  0,  0,  0,  0,  0],
       [ 0, 33,  0,  0,  0,  0,  0],
       [ 0, 34,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.51862613, 0.30439597, 0.4293041]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c5b2add0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b9a4b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.64492066, 'precision': 0.3561820751281517, 'recall': 0.3648726179478337, 'f1_score': 0.34733062042963438, 'confusion_matrix': array([[ 68,  81,  21,   0,   0,   2,   0],
       [ 32, 293,  18,   0,   1,   3,   0],
       [ 22,  54,  73,   0,   0,   4,   0],
       [ 12,  26,  11,   0,   0,   0,   0],
       [  9,  56,  12,   0,   0,   2,   0],
       [  8,  26,   9,   0,   1,   7,   0],
       [ 16,  30,   2,   0,   0,   1,   0]]), 'forgetting_measure': [0.55142737, -0.02423025, 0.089532286]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c5b2add0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b9a4b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5616984, 'precision': 0.232522847507645, 'recall': 0.26202598493316445, 'f1_score': 0.24037889548093632, 'confusion_matrix': array([[ 16,  73,  18,   0,   0,   2,   0],
       [ 32, 169,  29,   0,   1,   5,   0],
       [ 14,  58,  19,   0,   0,   0,   0],
       [  8,  18,   7,   0,   0,   0,   0],
       [  6,  41,  13,   0,   0,   4,   0],
       [  5,  21,   3,   0,   1,   2,   0],
       [  8,  21,   2,   0,   0,   4,   0]]), 'forgetting_measure': [0.6723114, 0.5450486, 0.030587072]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e2d79dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1fbfb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.57937087, 'precision': 0.34447999804553952, 'recall': 0.32090230620797377, 'f1_score': 0.31343482628809268, 'confusion_matrix': array([[ 22,  16,  82,   5,   3,   3,   3],
       [ 10,  71,  76,   4,   2,   5,   0],
       [ 24,  62, 249,   5,   1,  12,   4],
       [  3,  25,  49,   8,   1,   8,   0],
       [  2,   9,  29,   4,   0,   3,   0],
       [  0,  34,  12,   1,   0,   9,   3],
       [  5,  22,   6,   1,   3,   3,   1]]), 'forgetting_measure': [0.51623154, -0.06874242, 0.3772276]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning EWC with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e2d79dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1fbfb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.55561144, 'precision': 0.26723133744519955, 'recall': 0.2565528004748265, 'f1_score': 0.2416505450171803, 'confusion_matrix': array([[  5,  30,  53,   1,   0,   5,   1],
       [  2,  17,  69,   0,   0,   7,   1],
       [  9,  51, 171,   5,   0,  18,   2],
       [  0,  16,  29,   1,   0,   1,   2],
       [  0,  11,  23,   2,   0,   1,   0],
       [  1,  21,  13,   0,   0,   8,   2],
       [  0,  10,   9,   0,   1,   2,   0]]), 'forgetting_measure': [0.65608964, 0.46207848, 0.29258108]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b101bf10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b101a690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48968418, 'precision': 0.2919615722704229, 'recall': 0.27422248803827753, 'f1_score': 0.21919240523757184, 'confusion_matrix': array([[194,   3,   5,  26,   1,   2,   0],
       [186,   5,  13,  30,   4,   2,   0],
       [148,   3,  21,  24,   0,   0,   0],
       [ 45,   1,   0,  13,   0,   1,   0],
       [ 62,   2,   1,   7,   0,   1,   0],
       [ 32,   4,   2,  15,   1,   2,   1],
       [ 28,   2,   1,  10,   1,   1,   0]]), 'forgetting_measure': [0.4256263, 0.068068825, 0.20924054]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b101bf10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b101a690>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43942813, 'precision': 0.23848630709532964, 'recall': 0.25128333649370287, 'f1_score': 0.19314274632454185, 'confusion_matrix': array([[121,   3,   6,  20,   3,   1,   0],
       [118,   2,   5,  22,   4,   1,   0],
       [109,   2,   4,  24,   1,   1,   0],
       [ 29,   0,   0,   7,   0,   0,   1],
       [ 41,   0,   3,   4,   0,   1,   0],
       [ 19,   7,   1,  17,   1,   2,   0],
       [  7,   1,   0,  10,   1,   1,   0]]), 'forgetting_measure': [0.4069656, 0.29754058, 0.09248661]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d255a010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d2948190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4860813, 'precision': 0.2647002469788758, 'recall': 0.2766160103364288, 'f1_score': 0.26150022945245857, 'confusion_matrix': array([[156,  58,  37,  17,   0,   1,   0],
       [121,  53,  26,  18,   0,   1,   0],
       [ 87,  35,  26,  19,   0,   1,   0],
       [ 49,  22,   6,  27,   0,   0,   0],
       [ 19,   6,   6,   9,   0,   0,   0],
       [ 33,   1,   0,   0,   0,   0,   0],
       [ 65,   1,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4864801, 0.3352816, 0.16363177]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d255a010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d2948190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45306523, 'precision': 0.24488030865581886, 'recall': 0.25029761904761904, 'f1_score': 0.23224874758765226, 'confusion_matrix': array([[89, 48, 17,  6,  0,  0,  0],
       [80, 33, 25,  5,  0,  0,  1],
       [90, 40, 16,  4,  0,  0,  0],
       [21, 18,  3,  8,  0,  0,  0],
       [13,  8,  4,  4,  0,  0,  0],
       [18,  0,  0,  0,  0,  0,  0],
       [49,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.38435174, 0.2184619, -0.13670635]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b32e95d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b3817890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41243916, 'precision': 0.16652802179538926, 'recall': 0.23178378638904956, 'f1_score': 0.18783080974325215, 'confusion_matrix': array([[  0, 112, 116,   0,   0,   0,   0],
       [  0, 104, 124,   0,   0,   0,   0],
       [  0, 111,  97,   0,   0,   0,   0],
       [  0,  61,   3,   0,   0,   0,   0],
       [  0,  60,  12,   0,   0,   0,   0],
       [  0,  45,   0,   0,   0,   0,   0],
       [  1,  54,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3564922, 0.17408124, 0.20231193]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b32e95d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b3817890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43694448, 'precision': 0.1706725795600055, 'recall': 0.22952380952380954, 'f1_score': 0.18881216933982197, 'confusion_matrix': array([[ 0, 83, 60,  0,  0,  0,  0],
       [ 0, 76, 74,  0,  0,  0,  0],
       [ 0, 90, 60,  0,  0,  0,  0],
       [ 1, 32,  1,  0,  0,  0,  0],
       [ 0, 56,  0,  0,  0,  0,  0],
       [ 0, 33,  0,  0,  0,  0,  0],
       [ 0, 33,  1,  0,  0,  0,  0]]), 'forgetting_measure': [0.41929928, 0.3313468, 0.16612035]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a3021410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d2f5add0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59977401, 'precision': 0.32936492937602432, 'recall': 0.30501489852399551, 'f1_score': 0.30241217050460633, 'confusion_matrix': array([[ 44, 114,  14,   8,   1,   3,   4],
       [ 38, 281,  21,  17,   1,   9,   8],
       [ 16,  76,   6,   3,   0,   2,   1],
       [  4,  54,   3,   9,   1,   5,   3],
       [  2,  50,   0,   2,   0,   0,   0],
       [  9,  20,   1,   2,   0,   7,  10],
       [  0,  36,   0,   0,   0,   8,   7]]), 'forgetting_measure': [0.63841954, 0.35711628, 0.0906563]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a3021410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d2f5add0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56302003, 'precision': 0.4393953146590768, 'recall': 0.28944893667287288, 'f1_score': 0.28099894275103992, 'confusion_matrix': array([[ 22, 112,   6,   6,   0,   6,   5],
       [ 30, 157,   8,  13,   0,   6,   3],
       [  8,  52,   3,   4,   0,   2,   2],
       [  7,  39,   1,   4,   0,   0,   2],
       [  3,  28,   1,   0,   1,   2,   0],
       [  5,  15,   2,   0,   0,   3,   5],
       [  8,  16,   0,   0,   0,   5,   8]]), 'forgetting_measure': [0.58077142, 0.29461372, 0.20632385]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a93e9410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a9233ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40969501, 'precision': 0.1307617973908842, 'recall': 0.23992673992673993, 'f1_score': 0.15043570108265118, 'confusion_matrix': array([[191,   0,   0,   4,   0,   0,   0],
       [276,   0,   0,   3,   0,   0,   0],
       [193,   0,   0,   1,   0,   0,   0],
       [ 69,   0,   0,   0,   0,   0,   0],
       [ 63,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   2,   0,   0,   0],
       [ 46,   0,   0,   3,   0,   0,   0]]), 'forgetting_measure': [0.37220678, 0.27621013, 0.18862414]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a93e9410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a9233ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48129348, 'precision': 0.15994346369133422, 'recall': 0.24982578397212545, 'f1_score': 0.1705704743389804, 'confusion_matrix': array([[156,   0,   0,   0,   0,   0,   0],
       [151,   0,   0,   3,   0,   0,   0],
       [136,   0,   0,   2,   0,   0,   0],
       [ 39,   0,   0,   2,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 30,   0,   0,   4,   0,   0,   0],
       [ 31,   0,   0,   2,   0,   0,   0]]), 'forgetting_measure': [0.50302894, 0.4525796, 0.0018174415]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b8481dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b885e790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52143742, 'precision': 0.279901899382749, 'recall': 0.24891792223869219, 'f1_score': 0.24595874750397828, 'confusion_matrix': array([[ 31, 124,  37,   1,   3,  10,   3,   0,   0],
       [ 20, 168,  73,   0,   8,   3,   2,   1,   1],
       [ 11, 113,  49,   1,   3,   3,   1,   0,   1],
       [  3,  21,  13,   0,   3,   1,   0,   1,   0],
       [ 14,  47,  23,   0,   4,   2,   0,   0,   1],
       [ 19,  19,   8,   2,   0,  12,   4,   0,   2],
       [  6,   9,   9,   1,   0,   5,   3,   0,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4893832, 0.22145903, 0.10348827]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b8481dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b885e790>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46241836, 'precision': 0.24633588711978543, 'recall': 0.23870936365308373, 'f1_score': 0.231310496937795, 'confusion_matrix': array([[12, 66, 40,  0,  2,  6,  2,  0,  2],
       [ 7, 89, 52,  1, 11,  7,  1,  0,  2],
       [ 6, 73, 42,  1,  5,  6,  4,  1,  0],
       [ 2, 11,  7,  0,  1,  0,  0,  0,  0],
       [ 6, 35, 23,  1,  3,  2,  3,  0,  1],
       [15,  5,  8,  0,  0,  7,  2,  1,  0],
       [ 6,  9,  5,  0,  0,  5,  3,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.3963956, 0.4785674, -1.1760494]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529f1195d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529f53b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37266463, 'precision': 0.20525859269933471, 'recall': 0.2825067664107188, 'f1_score': 0.18805023361419428, 'confusion_matrix': array([[56,  0, 24, 75,  0, 88, 39],
       [41,  0, 11, 59,  0, 69, 34],
       [39,  0, 13, 39,  0, 52, 28],
       [ 5,  0, 14,  0,  0, 59, 23],
       [ 1,  0,  4,  0,  0, 14, 13],
       [ 0,  0,  0,  0,  0, 34,  5],
       [ 0,  0,  0,  0,  0, 53,  8]]), 'forgetting_measure': [0.3629196, 0.4591244, 0.20631483]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529f1195d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529f53b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.131315163, 'precision': 0.16497234109174407, 'recall': 0.2630639097744361, 'f1_score': 0.154023560643769696, 'confusion_matrix': array([[17,  0,  0, 55,  0, 53, 27],
       [18,  0,  0, 42,  0, 48, 17],
       [17,  0,  0, 51,  0, 61, 35],
       [ 0,  0,  0,  0,  0, 35, 31],
       [ 0,  0,  0,  0,  0, 16, 10],
       [ 0,  0,  0,  0,  0, 16,  3],
       [ 0,  0,  0,  0,  0, 39,  9]]), 'forgetting_measure': [0.109591327, 1.0, 0]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552928d1910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528e7a7390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4930599, 'precision': 0.28634632133747825, 'recall': 0.27127389229866577, 'f1_score': 0.25094384587472146, 'confusion_matrix': array([[  7,   2, 125,   6,   2,  10,   5],
       [  9,   3, 126,  13,   3,   4,   2],
       [ 10,  18, 265,  24,   3,  20,   4],
       [  7,   1,  63,  12,   1,   3,   0],
       [  4,   2,  38,   6,   1,   1,   0],
       [  0,   0,  49,   2,   0,   8,   2],
       [  2,   0,  26,   4,   0,   4,   3]]), 'forgetting_measure': [0.5361494, 0.42335853, 0.23846093]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552928d1910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528e7a7390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.61561645, 'precision': 0.2311255086742343, 'recall': 0.27427723743138412, 'f1_score': 0.24538659304373813, 'confusion_matrix': array([[  2,   0,  64,   6,   1,   3,   0],
       [  6,   0,  68,  10,   2,   2,   0],
       [ 13,   6, 218,  16,   6,  15,   0],
       [  3,   0,  27,  10,   0,   4,   0],
       [  4,   6,  27,   8,   0,   6,   0],
       [  1,   0,  33,   0,   0,   7,   0],
       [  0,   0,  23,   0,   0,   3,   0]]), 'forgetting_measure': [0.7108951, 0.4979723, -0.07363146]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a4e3b050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a215d710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.554443, 'precision': 0.390428596501388, 'recall': 0.3517448201964419, 'f1_score': 0.3546935125750673, 'confusion_matrix': array([[ 28, 109,  11,   0,   9,   4,   8],
       [ 32, 246,  13,   8,  24,   8,  11],
       [ 15,  91,  26,   5,   4,   6,   2],
       [  4,  20,   7,   2,   3,   1,   1],
       [ 16,  55,   4,   6,  14,   4,   3],
       [  2,  15,   1,   2,   4,  13,   6],
       [ 15,  24,   0,   0,   2,   4,  12]]), 'forgetting_measure': [0.52794943, 0.18209352, 0.18474697]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a4e3b050>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a215d710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.58005418, 'precision': 0.3267564526949021, 'recall': 0.31441860484500008, 'f1_score': 0.30548159809102318, 'confusion_matrix': array([[  6,  89,   3,   1,   6,   5,   5],
       [ 16, 190,  12,   5,  16,   6,   6],
       [  4,  58,   7,   1,   4,   2,   4],
       [  2,  18,   5,   1,   5,   1,   2],
       [  7,  21,   5,   3,  12,   0,   5],
       [  2,  21,   2,   0,   2,   8,   3],
       [  2,  13,   1,   0,   4,   5,   4]]), 'forgetting_measure': [0.69089357, 0.5757774, -0.1911999]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527c431ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527cbd1d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4663175, 'precision': 0.25258555717408329, 'recall': 0.2587008941296945, 'f1_score': 0.24430551742983377, 'confusion_matrix': array([[ 39,  48, 104,   9,   0,   2,   0],
       [ 47,  61, 107,  13,   0,   2,   0],
       [ 39,  58, 128,   7,   0,   4,   0],
       [ 35,  19,  23,   8,   0,   0,   0],
       [ 13,  13,  18,   3,   0,   0,   0],
       [ 27,  34,   0,   0,   0,   1,   0],
       [ 19,  19,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51698745, 0.5346777, 0.031449452]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527c431ed0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527cbd1d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45627217, 'precision': 0.2925357829611936, 'recall': 0.26298694526166366, 'f1_score': 0.25027212778412186, 'confusion_matrix': array([[10, 44, 77,  9,  0,  1,  0],
       [15, 52, 69,  7,  0,  0,  0],
       [15, 53, 82,  8,  0,  2,  0],
       [ 6, 31, 23,  7,  0,  1,  0],
       [ 0, 11,  6,  4,  0,  0,  0],
       [ 7, 33,  0,  0,  0,  4,  0],
       [ 7, 15,  0,  0,  0,  1,  0]]), 'forgetting_measure': [0.45547134, 0.4803353, -0.23761316]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b813ba90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b26ec550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45952882, 'precision': 0.13818152402523863, 'recall': 0.23704994192799072, 'f1_score': 0.15972415538403138, 'confusion_matrix': array([[  0, 215,   1,   0,   0,   0,   0],
       [  8, 236,   2,   0,   0,   0,   0],
       [  0, 194,   0,   0,   0,   0,   0],
       [  0,  39,   1,   0,   0,   0,   0],
       [  0, 103,   1,   0,   0,   0,   0],
       [  0,  59,   3,   0,   0,   0,   0],
       [  0,  37,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.50409154, 0.44302, 0.33610287]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b813ba90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b26ec550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5040712, 'precision': 0.21409395973154364, 'recall': 0.2451990632318501, 'f1_score': 0.1702420503084955, 'confusion_matrix': array([[  0, 137,   2,   0,   0,   0,   0],
       [  0, 178,   0,   0,   0,   0,   0],
       [  0, 120,   2,   0,   0,   0,   0],
       [  0,  29,   0,   0,   0,   0,   0],
       [  0,  65,   0,   0,   0,   0,   0],
       [  0,  40,   0,   0,   0,   0,   0],
       [  0,  27,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.48920867, 0.24660406, 0.2163895]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a68d1dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552adacfe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42168179, 'precision': 0.17079081632653061, 'recall': 0.25151476851910364, 'f1_score': 0.19624139632432487, 'confusion_matrix': array([[  0,  99, 135,   0,   0,   0,   0],
       [  0, 111, 143,   0,   0,   0,   0],
       [  0,  67, 111,   0,   0,   0,   0],
       [  0,  52,  13,   0,   0,   0,   0],
       [  0,  51,  18,   0,   0,   0,   0],
       [  0,  42,   0,   0,   0,   0,   0],
       [  0,  58,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.35971794, 0.15686677, 0.14899404]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning EWC with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a68d1dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552adacfe50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4507819, 'precision': 0.17342404117293556, 'recall': 0.24039876113046845, 'f1_score': 0.19573272319346025, 'confusion_matrix': array([[ 0, 73, 67,  0,  0,  0,  0],
       [ 0, 81, 83,  0,  0,  0,  0],
       [ 0, 69, 66,  0,  0,  0,  0],
       [ 0, 25,  2,  0,  0,  0,  0],
       [ 0, 66,  1,  0,  0,  0,  0],
       [ 0, 32,  0,  0,  0,  0,  0],
       [ 0, 35,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.41864756, 0.3164821, 0.008744151]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280c79910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552806d33d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5724579, 'precision': 0.37478196051077697, 'recall': 0.31252723266220003, 'f1_score': 0.29327014838088044, 'confusion_matrix': array([[ 15,   5, 126,   5,   2,   1,   0],
       [  8,  16, 133,   4,   1,   0,   0],
       [ 15,   6, 305,  18,   4,   0,   0],
       [  1,   0,  46,  31,   4,   0,   0],
       [  2,   0,  41,   9,   2,   0,   0],
       [  0,   3,  61,   0,   0,   0,   0],
       [  0,   0,  36,   0,   0,   0,   0]]), 'forgetting_measure': [0.5796576, 0.27752241, 0.15977181]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155280c79910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552806d33d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60624273, 'precision': 0.25208079869734006, 'recall': 0.25726374883163383, 'f1_score': 0.22676421393421125, 'confusion_matrix': array([[  1,   2,  84,   5,   2,   0,   0],
       [  2,   3,  83,   4,   0,   0,   0],
       [ 12,   6, 221,  14,   4,   1,   0],
       [  3,   2,  30,   7,   3,   0,   0],
       [  0,   0,  36,   6,   2,   0,   0],
       [  0,   1,  44,   1,   0,   0,   0],
       [  1,   0,  20,   0,   0,   0,   0]]), 'forgetting_measure': [0.6383717, 0.3382464, 0.09033121]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155261d21910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155280e22210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48061616, 'precision': 0.20919185144537256, 'recall': 0.24380879076574277, 'f1_score': 0.21363800307053727, 'confusion_matrix': array([[  0,  79,  38,   1,   0,   1,   0],
       [  2, 190,  82,   0,   0,   8,   0],
       [  6, 186,  62,   0,   0,   4,   0],
       [  0,  64,   7,   0,   0,   5,   0],
       [  0,  58,   5,   0,   0,   2,   0],
       [  4,  36,   9,   0,   0,   5,   0],
       [  1,  26,  17,   0,   0,   2,   0]]), 'forgetting_measure': [0.46478746, 0.3047732, 0.11891885]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155261d21910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155280e22210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5153968, 'precision': 0.22039200171044166, 'recall': 0.26053852370987917, 'f1_score': 0.22532456514281895, 'confusion_matrix': array([[  1,  58,  37,   0,   0,   3,   0],
       [  2, 129,  49,   0,   0,   4,   0],
       [  1, 101,  44,   0,   0,   7,   0],
       [  1,  43,   4,   0,   0,   2,   0],
       [  4,  38,   3,   0,   0,   2,   0],
       [  1,  17,  10,   0,   0,   4,   0],
       [  1,  20,  10,   0,   0,   4,   0]]), 'forgetting_measure': [0.56854103, 0.36112112, 0.4043304]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a6e45450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a11be9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34351134, 'precision': 0.123174603174603174, 'recall': 0.24285714285714285, 'f1_score': 0.139879814258399336, 'confusion_matrix': array([[146,   0,   0,   0,   0,   0,   0],
       [262,   0,   0,   0,   0,   0,   0],
       [261,   0,   0,   0,   0,   0,   0],
       [ 66,   0,   0,   0,   0,   0,   0],
       [ 65,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.29633001, 0.20841762, 0.49300602]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a6e45450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a11be9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37708336, 'precision': 0.12547619047619048, 'recall': 0.24285714285714285, 'f1_score': 0.14324105879975754, 'confusion_matrix': array([[107,   0,   0,   0,   0,   0,   0],
       [189,   0,   0,   0,   0,   0,   0],
       [154,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.33375812, 0.28303382, 0.22495314]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526bb29410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526c32a450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56681882, 'precision': 0.336919228726255, 'recall': 0.2809596846119953, 'f1_score': 0.28106919444094294, 'confusion_matrix': array([[ 70,  12, 111,  12,   3,   6,   0,   1,   0],
       [ 18,  39, 122,  13,   0,   1,   0,   0,   0],
       [ 34,  25, 185,  16,   1,   3,   1,   0,   1],
       [ 21,   9,  22,  13,   3,   2,   0,   0,   0],
       [ 18,   0,  20,   9,   8,   1,   0,   0,   0],
       [ 12,   3,  43,   2,   0,   5,   0,   0,   0],
       [ 12,   1,  18,   0,   0,   4,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5340795, 0.2648839, -0.08830906]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526bb29410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526c32a450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41325938, 'precision': 0.24311045154495905, 'recall': 0.23673999692971128, 'f1_score': 0.22441139360062786, 'confusion_matrix': array([[15, 16, 81, 11,  4,  0,  0,  0],
       [23, 20, 88, 16,  2,  1,  0,  0],
       [24, 19, 95, 22,  5,  2,  0,  0],
       [18,  9, 21, 11,  3,  2,  0,  0],
       [ 9,  2,  9,  3,  2,  0,  0,  0],
       [ 9,  1, 34,  0,  0,  1,  0,  1],
       [ 2,  1, 16,  0,  0,  2,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.44551802, 0.47740284, 0.37035277]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526b823c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552649433d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5114483, 'precision': 0.37763557740514566, 'recall': 0.37966410428671595, 'f1_score': 0.376663997309308, 'confusion_matrix': array([[76, 30, 39, 23, 12,  9,  9],
       [54, 99, 65, 19, 12,  8,  8],
       [36, 45, 69, 18, 13,  5,  9],
       [12, 13,  5, 25,  8,  4,  7],
       [12, 17, 13,  6,  9,  6,  5],
       [ 7, 19,  6,  2,  3, 15,  7],
       [11,  8,  2,  9,  5,  1,  5]]), 'forgetting_measure': [0.441977, 0.21487464, -0.20625459]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526b823c50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552649433d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38738134, 'precision': 0.2500956088332588, 'recall': 0.2393721064356807, 'f1_score': 0.24147521425184542, 'confusion_matrix': array([[37, 35, 27, 29, 11,  6,  7],
       [40, 35, 36, 17,  4,  4,  0],
       [38, 55, 21, 15, 11,  5, 13],
       [ 7, 16,  9,  5,  3,  6,  3],
       [ 9,  7,  6,  5,  4,  2,  5],
       [10, 16,  7,  6,  2,  7,  4],
       [ 3,  5,  3,  1,  1,  2,  0]]), 'forgetting_measure': [0.31922791, 0.06806245, 0.32156217]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526ca96550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527b05b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43650189, 'precision': 0.2027366841508507, 'recall': 0.2381040668072824, 'f1_score': 0.21659641723456478, 'confusion_matrix': array([[ 70,  93,  51,   2,   0,   0,   0],
       [ 87, 128,  55,   1,   0,   0,   0],
       [ 54,  96,  31,   1,   0,   0,   0],
       [ 10,  23,   2,   0,   0,   0,   0],
       [ 35,  56,   4,   1,   0,   0,   0],
       [ 17,  28,  22,   0,   0,   0,   0],
       [  4,  20,   9,   0,   0,   0,   0]]), 'forgetting_measure': [0.38709543, 0.20919165, 0.13946885]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526ca96550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527b05b3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46510686, 'precision': 0.20845070784393553, 'recall': 0.24333547672632443, 'f1_score': 0.21886743553683092, 'confusion_matrix': array([[37, 64, 23,  0,  0,  0,  0],
       [51, 88, 33,  0,  0,  0,  0],
       [52, 69, 29,  0,  0,  0,  0],
       [ 5, 20,  2,  0,  0,  0,  0],
       [13, 44,  3,  0,  0,  0,  0],
       [12, 20,  8,  0,  0,  0,  0],
       [11,  8,  8,  0,  0,  0,  0]]), 'forgetting_measure': [0.39331267, 0.110655114, 0.0755368]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529811a310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155297839dd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40480105, 'precision': 0.13657670122561164, 'recall': 0.2390116183930617, 'f1_score': 0.156556372549019615, 'confusion_matrix': array([[178,   0,   0,   0,  16,   0,   0],
       [354,   0,   0,   0,  17,   0,   0],
       [ 93,   0,   0,   0,   7,   0,   0],
       [ 78,   0,   0,   0,   3,   0,   0],
       [ 51,   0,   0,   0,   3,   0,   0],
       [ 34,   0,   0,   0,  17,   0,   0],
       [ 38,   0,   0,   0,  11,   0,   0]]), 'forgetting_measure': [0.42029897, 0.3548771, 0.5766779]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning EWC with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15529811a310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155297839dd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44587333, 'precision': 0.14720496894409938, 'recall': 0.24693264693264693, 'f1_score': 0.16627343135063699, 'confusion_matrix': array([[144,   0,   0,   0,   4,   0,   0],
       [204,   0,   0,   0,   6,   0,   0],
       [ 83,   0,   0,   0,   3,   0,   0],
       [ 52,   0,   0,   0,   1,   0,   0],
       [ 34,   0,   0,   0,   2,   0,   0],
       [ 30,   0,   0,   0,   2,   0,   0],
       [ 28,   0,   0,   0,   7,   0,   0]]), 'forgetting_measure': [0.43520648, 0.23481296, 0.43110976]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525b579910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525bdba450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44497978, 'precision': 0.13380952380952381, 'recall': 0.24285714285714285, 'f1_score': 0.15467847516365037, 'confusion_matrix': array([[213,   0,   0,   0,   0,   0,   0],
       [260,   0,   0,   0,   0,   0,   0],
       [190,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 75,   0,   0,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0,   0,   0],
       [ 30,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44112647, 0.41598275, 0.023263311]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525b579910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15525bdba450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43662052, 'precision': 0.13428571428571429, 'recall': 0.24285714285714285, 'f1_score': 0.15529953917050691, 'confusion_matrix': array([[144,   0,   0,   0,   0,   0,   0],
       [146,   0,   0,   0,   0,   0,   0],
       [145,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0],
       [ 19,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44886697, 0.4547085, 0.102367766]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528e839dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529a03b0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47393, 'precision': 0.29459792912010515, 'recall': 0.30148829298072093, 'f1_score': 0.29343667699958728, 'confusion_matrix': array([[ 96,  65,  39,   4,  10,  11,  13],
       [107,  66,  36,   8,   8,  11,   8],
       [ 68,  53,  34,   6,  13,  14,   6],
       [ 25,  15,   6,   1,   5,   2,   1],
       [ 21,  17,   9,   8,   6,   5,   3],
       [  6,   8,   8,   2,   2,  13,   5],
       [ 14,   6,   9,   2,   6,  10,   9]]), 'forgetting_measure': [0.48170126, 0.3494735, 0.22764103]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528e839dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15529a03b0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44090642, 'precision': 0.30757599181075412, 'recall': 0.30447463272800168, 'f1_score': 0.28791476816195216, 'confusion_matrix': array([[53, 37,  9,  3,  4, 10,  3],
       [86, 46,  9,  3,  8, 11,  6],
       [67, 41, 13,  4, 12, 10, 10],
       [19,  6,  3,  2,  5,  3,  2],
       [19,  8,  3,  6,  8,  1,  3],
       [10,  4,  1,  0,  2,  5,  3],
       [12,  3,  8,  3,  1,  6,  9]]), 'forgetting_measure': [0.43677724, 0.3381892, 0.268408]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525ba69910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524c6058d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44758871, 'precision': 0.20486591700528185, 'recall': 0.24450198446699522, 'f1_score': 0.22127972386807628, 'confusion_matrix': array([[ 75,  89,  43,   0,   0,   0,   0],
       [ 92, 130,  45,   0,   0,   0,   0],
       [ 63,  97,  31,   0,   0,   0,   0],
       [ 36,  26,  12,   0,   0,   0,   0],
       [ 24,  28,   9,   0,   0,   0,   0],
       [ 12,   0,  38,   0,   0,   0,   0],
       [  9,   0,  41,   0,   0,   0,   0]]), 'forgetting_measure': [0.41672296, 0.22205105, 0.27088866]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15525ba69910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524c6058d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44056211, 'precision': 0.2023676290792815, 'recall': 0.2345585358898318, 'f1_score': 0.21549723302567674, 'confusion_matrix': array([[ 24,  52,  25,   0,   0,   0,   0],
       [ 54, 107,  54,   0,   0,   0,   0],
       [ 26,  70,  25,   0,   0,   0,   0],
       [ 24,   8,   8,   0,   0,   0,   0],
       [ 27,   8,  21,   0,   0,   0,   0],
       [  0,   0,  35,   0,   0,   0,   0],
       [  0,   0,  32,   0,   0,   0,   0]]), 'forgetting_measure': [0.467369, 0.3917707, 0.4142943]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155251c52c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155252031d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46998702, 'precision': 0.2396443171850892, 'recall': 0.24416012677115014, 'f1_score': 0.22874766340924748, 'confusion_matrix': array([[ 31,  81,  37,   6,   6,   6,  19,   0,   1,   2,   0],
       [ 35, 117,  62,   8,   4,   3,  28,   2,   1,   0,   0],
       [ 23, 100,  56,   6,   7,   6,   9,   0,   1,   2,   0],
       [ 12,  13,  21,   4,   2,   2,   6,   1,   0,   0,   0],
       [ 11,  26,  23,   5,   4,   8,   3,   0,   0,   0,   0],
       [  4,  18,  13,   0,   0,   6,  17,   0,   1,   0,   0],
       [  1,   8,   9,   0,   0,   1,  20,   0,   1,   0,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.49074057, 0.3389077, 0.3770996]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155251c52c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155252031d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4748369, 'precision': 0.2477614998783351, 'recall': 0.25366693902018488, 'f1_score': 0.2382830209680999, 'confusion_matrix': array([[17, 38, 24,  2,  0,  2,  9,  0,  0,  0],
       [26, 79, 55,  8,  6,  4, 25,  0,  0,  1],
       [17, 51, 34, 10,  0, 12, 14,  0,  1,  0],
       [11,  9, 15,  6,  1,  3, 13,  1,  0,  0],
       [ 6,  8, 10,  4,  1,  2,  8,  0,  0,  0],
       [ 2,  5,  2,  0,  0,  5, 19,  0,  0,  0],
       [ 4,  7,  5,  0,  0,  2, 15,  0,  1,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.51164702, 0.5644425, -0.30269358]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528e5926d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528a3b69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53671096, 'precision': 0.3089423719752437, 'recall': 0.30026062703644198, 'f1_score': 0.28445429251934295, 'confusion_matrix': array([[241,  29,  23,   8,   4,  20,   2],
       [116,  27,  25,  18,   7,   6,   1],
       [ 97,  13,  16,   6,   0,   7,   2],
       [ 56,   1,   3,   3,   0,   0,   2],
       [ 51,   4,   2,   5,   0,   3,   2],
       [ 15,   9,   7,   0,   4,  16,   1],
       [ 16,   9,   5,   2,   4,   9,   3]]), 'forgetting_measure': [0.5042169, 0.102205016, 0.33036804]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning LWF with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15528e5926d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528a3b69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52023188, 'precision': 0.30571235179277148, 'recall': 0.2886296594095965, 'f1_score': 0.2719305551356118, 'confusion_matrix': array([[160,  18,  20,   7,   5,  21,   1],
       [ 76,  10,   4,   4,   1,   6,   2],
       [ 71,   5,   8,   7,   3,   9,   1],
       [ 42,   4,   1,   5,   1,   5,   3],
       [ 27,   2,   3,   0,   0,   1,   0],
       [  9,   4,   2,   4,   1,   8,   2],
       [ 16,   3,   3,   0,   2,   9,   4]]), 'forgetting_measure': [0.5909806, 0.3640137, 0.4957418]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aecaf990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528aaf4750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54832966, 'precision': 0.21017948729339215, 'recall': 0.2538103065407339, 'f1_score': 0.21777297145470131, 'confusion_matrix': array([[284,  56,   0,   0,   4,   0,   0],
       [144,  40,   0,   0,   7,   0,   0],
       [ 92,  35,   0,   0,   2,   0,   0],
       [ 81,   3,   0,   0,   4,   0,   0],
       [ 38,   8,   0,   0,   2,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.57584194, 0.35665607, 0.1408321]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aecaf990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528aaf4750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5261168, 'precision': 0.22699864878134462, 'recall': 0.26055074095567332, 'f1_score': 0.22050753857751942, 'confusion_matrix': array([[170,  34,   0,   0,   2,   0,   0],
       [ 88,  30,   0,   0,   1,   0,   0],
       [ 98,  20,   0,   0,   2,   0,   0],
       [ 39,   4,   0,   0,   2,   0,   0],
       [ 37,   4,   0,   0,   2,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0],
       [ 27,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.52834958, 0.3870049, -0.09463322]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523ec415d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523ebcb3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49770175, 'precision': 0.27033455832333863, 'recall': 0.26215111627432544, 'f1_score': 0.25886148057428198, 'confusion_matrix': array([[194,  72,  19,  22,   2,  11,   9,   0,   2],
       [ 91,  63,  22,  12,   0,   5,   5,   0,   1],
       [ 81,  34,  13,   7,   0,   6,   1,   0,   0],
       [ 34,  13,   2,  17,   1,   7,   0,   0,   1],
       [ 25,  15,   1,   9,   0,   3,   0,   0,   0],
       [ 24,  14,   0,   5,   0,   7,   2,   1,   0],
       [ 21,  11,   1,   1,   1,   7,   5,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.50313902, 0.32629156, 0.19598803]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523ec415d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523ebcb3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46326066, 'precision': 0.32554027897425893, 'recall': 0.25690522719391534, 'f1_score': 0.2490555069753543, 'confusion_matrix': array([[105,  51,  14,  12,   0,   4,   4,   0],
       [ 69,  22,  11,  14,   0,   1,   4,   0],
       [ 70,  36,   8,  12,   0,   3,   4,   1],
       [ 21,  15,   0,  13,   0,   0,   0,   1],
       [ 26,   5,   0,   5,   1,   0,   1,   0],
       [ 20,   5,   1,   1,   1,   2,   0,   0],
       [ 19,   7,   0,   3,   0,   4,   4,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4431471, 0.4347512, -0.30267552]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155238401910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552454f1d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.483921, 'precision': 0.2202218684461474, 'recall': 0.23469894254420323, 'f1_score': 0.22080879497606217, 'confusion_matrix': array([[179,  54,  51,  13,   6,  16,   1,   2,   0],
       [101,  30,  25,   7,   3,  18,   1,   0,   0],
       [ 87,  28,  13,   6,   3,  16,   0,   2,   0],
       [ 30,  15,  16,   8,   1,   8,   1,   0,   0],
       [ 22,  15,  10,   3,   0,   8,   0,   1,   0],
       [ 20,   1,  10,   0,   5,  17,   1,   0,   1],
       [ 21,   1,   5,   0,   0,  18,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.53994567, 0.44508857, 0.31312895]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155238401910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552454f1d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50563727, 'precision': 0.26390790257427393, 'recall': 0.279530945045149, 'f1_score': 0.2600677506516121, 'confusion_matrix': array([[127,  57,  25,   6,   9,  15,   0],
       [ 69,  15,  12,   2,   2,   9,   2],
       [ 50,  21,   7,   3,   3,  11,   0],
       [ 15,  12,   8,   5,   1,   4,   0],
       [ 21,   9,   6,   1,   0,   6,   0],
       [ 12,   1,   8,   0,   1,  15,   0],
       [  5,   3,   7,   0,   2,  13,   0]]), 'forgetting_measure': [0.56187288, 0.44288483, 0.2315972]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527ea09dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527b90f0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4369338, 'precision': 0.27802446541819508, 'recall': 0.26263769555640836, 'f1_score': 0.2620744927295482, 'confusion_matrix': array([[ 47,  98,  52,   3,   3,  14,   0,   1,   2],
       [ 39, 109,  59,   9,   5,  16,   0,   1,   2],
       [ 28,  97,  55,   6,   7,  16,   2,   0,   1],
       [ 18,  24,   5,  16,   4,   4,   1,   0,   1],
       [ 18,  18,   1,  10,   5,   3,   0,   0,   0],
       [  6,  26,   5,   0,   0,  12,   0,   0,   4],
       [  3,  26,   5,   1,   0,   7,   0,   0,   5],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3768239, 0.14988159, 0.15590134]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527ea09dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527b90f0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44284317, 'precision': 0.23323172714865766, 'recall': 0.2334778424907876, 'f1_score': 0.22838520766061792, 'confusion_matrix': array([[16, 65, 29,  4,  4, 10,  0,  0,  2],
       [24, 78, 44,  9,  6,  4,  0,  0,  0],
       [20, 63, 36,  6,  8, 13,  1,  2,  2],
       [15, 15,  3,  6,  1,  2,  0,  1,  1],
       [11, 20,  3,  5,  2,  2,  0,  0,  0],
       [ 7, 18,  4,  0,  0,  7,  0,  0,  2],
       [ 4, 10,  1,  0,  0,  9,  0,  1,  4],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.3861907, 0.22138791, 0.014918178]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527f113490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527eae5d50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4695314, 'precision': 0.34437826377767166, 'recall': 0.2921478730737082, 'f1_score': 0.29574682383704528, 'confusion_matrix': array([[100,  76,  25,   2,   4,   1,   8],
       [ 92,  96,  41,   7,   7,   3,   8],
       [ 69,  79,  34,   4,   2,   2,   4],
       [ 10,  22,  19,   2,   1,   1,   3],
       [  5,  39,  24,   1,   8,   1,   0],
       [ 10,  15,   9,   1,   0,   3,   3],
       [ 14,  19,  12,   3,   4,   0,   7]]), 'forgetting_measure': [0.47217274, 0.26365376, 0.40750006]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527f113490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527eae5d50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44047798, 'precision': 0.29684500378914635, 'recall': 0.23384963708386072, 'f1_score': 0.22872365677377146, 'confusion_matrix': array([[66, 53, 25,  3,  5,  2,  0],
       [90, 40, 14,  4,  6,  2,  1],
       [63, 50, 15,  2,  4,  2,  0],
       [ 6, 15,  9,  0,  4,  0,  0],
       [ 7, 27, 14,  3,  1,  0,  0],
       [11, 10,  2,  1,  0,  2,  1],
       [15, 19,  2,  0,  0,  2,  2]]), 'forgetting_measure': [0.40494586, 0.28957587, 0.07751839]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552388ca290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155237fc8a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4898885, 'precision': 0.27278831699052435, 'recall': 0.23635886849864418, 'f1_score': 0.23437139214838653, 'confusion_matrix': array([[ 70,  90,  51,   2,   6,   1,   0,   0,   0],
       [ 51, 138,  51,   5,  13,   3,   1,   4,   0],
       [ 39,  94,  38,   2,   8,   1,   1,   0,   0],
       [ 10,  16,  10,   2,   2,   0,   0,   0,   0],
       [ 25,  38,  19,   1,   6,   1,   0,   1,   0],
       [  1,  48,   3,   1,   3,   4,   0,   0,   0],
       [  0,  27,   7,   2,   3,   0,   0,   0,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51690263, 0.40018475, 0.18941572]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552388ca290>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155237fc8a10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41684599, 'precision': 0.24780897556390976, 'recall': 0.21707848955899719, 'f1_score': 0.21714103761109035, 'confusion_matrix': array([[27, 46, 37,  0,  9,  0,  0,  2],
       [49, 63, 59,  0,  6,  4,  0,  1],
       [39, 64, 26,  0,  8,  0,  0,  0],
       [11,  5,  4,  0,  1,  0,  0,  0],
       [31, 24, 11,  0,  5,  0,  1,  0],
       [ 3, 24,  4,  0,  2,  4,  0,  0],
       [ 0, 19,  3,  0,  7,  1,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.4287329, 0.58662426, -0.36812532]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521f641410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521f8fb3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47907035, 'precision': 0.19914305168916834, 'recall': 0.20158957735645266, 'f1_score': 0.19328539718459883, 'confusion_matrix': array([[ 32,  44, 104,   8,   8,   3,   6,   0,   0,   0],
       [ 35,  35, 111,   5,   4,   1,   4,   0,   0,   0],
       [ 44,  52, 144,   5,   7,   3,   7,   0,   0,   1],
       [  8,  10,  41,   1,   3,   0,   3,   1,   0,   0],
       [ 14,   8,  36,   6,   2,   0,   4,   0,   0,   0],
       [  5,   3,  29,   0,   0,   0,   7,   0,   0,   0],
       [  3,   9,  32,   1,   1,   4,   5,   0,   1,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4807988, 0.484023, -0.32290447]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15521f641410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521f8fb3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42591804, 'precision': 0.32765442463905394, 'recall': 0.2819759653649092, 'f1_score': 0.28947979972811044, 'confusion_matrix': array([[25, 30, 80,  5,  3,  3,  4],
       [19, 19, 66,  8,  1,  0,  3],
       [37, 40, 82,  3,  7,  3,  5],
       [ 6,  9, 24,  5,  5,  1,  1],
       [ 3,  6, 23,  2,  4,  0,  1],
       [ 0,  3, 20,  1,  0,  2,  3],
       [ 0,  5, 21,  1,  0,  3,  8]]), 'forgetting_measure': [0.38972554, 0.2918259, 0.10880232]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552705f2310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526f9ae9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52673475, 'precision': 0.35159716187382714, 'recall': 0.28799925932227127, 'f1_score': 0.25573267549339617, 'confusion_matrix': array([[ 33, 145,  11,   0,   0,   7,   0],
       [ 16, 253,  16,   0,   0,   5,   0],
       [  8, 164,   5,   1,   0,   2,   0],
       [  5,  50,   2,   1,   0,   2,   0],
       [  3,  67,   2,   0,   0,   2,   0],
       [  0,  32,   6,   0,   2,  12,   0],
       [  5,  32,   5,   0,   1,   5,   0]]), 'forgetting_measure': [0.52901725, 0.3778747, -0.06512545]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning LWF with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552705f2310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15526f9ae9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5208119, 'precision': 0.22013039463376159, 'recall': 0.25476533968657, 'f1_score': 0.21473938705700061, 'confusion_matrix': array([[ 12,  83,   5,   0,   1,   3,   0],
       [  9, 184,  11,   0,   0,  11,   0],
       [  8, 115,   2,   0,   0,   5,   0],
       [  1,  40,   2,   0,   0,   2,   0],
       [  3,  34,   0,   0,   0,   2,   0],
       [  4,  21,   3,   0,   0,   3,   0],
       [  1,  20,   7,   0,   0,   8,   0]]), 'forgetting_measure': [0.5290184, 0.21446276, 0.41720596]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a95c9810>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528ab6cc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42391056, 'precision': 0.23446861668277277, 'recall': 0.24258216873706003, 'f1_score': 0.16510227715489775, 'confusion_matrix': array([[  6,   8, 242,   0,   0,   0,   0],
       [  4,   3, 177,   0,   0,   0,   0],
       [  1,   8, 207,   0,   0,   0,   0],
       [  0,   0,  78,   0,   0,   0,   0],
       [  0,   0,  66,   0,   0,   0,   0],
       [  0,   0,  64,   0,   0,   0,   0],
       [  0,   0,  36,   0,   0,   0,   0]]), 'forgetting_measure': [0.4159699, 0.34519285, 0.28050858]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a95c9810>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15528ab6cc10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45006658, 'precision': 0.133095238095238094, 'recall': 0.24285714285714285, 'f1_score': 0.153740576068045616, 'confusion_matrix': array([[  0,   0, 199,   0,   0,   0,   0],
       [  0,   0, 113,   0,   0,   0,   0],
       [  0,   0, 139,   0,   0,   0,   0],
       [  0,   0,  40,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0],
       [  0,   0,  46,   0,   0,   0,   0],
       [  0,   0,  21,   0,   0,   0,   0]]), 'forgetting_measure': [0.3688326, 0.1555773, -0.12048203]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522a3a9910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523a902290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4879308, 'precision': 0.21122474580807337, 'recall': 0.20731336634092047, 'f1_score': 0.19921098644551182, 'confusion_matrix': array([[ 19,  45,  95,  12,   3,  13,   0,   0,   0,   0,   0,   0,   0],
       [  9,  53,  97,  21,   2,  16,   0,   1,   0,   2,   1,   0,   0],
       [ 14,  74, 132,  26,   4,  23,   0,   0,   2,   0,   2,   0,   1],
       [  0,  10,  35,  15,   8,   3,   0,   1,   1,   0,   0,   0,   0],
       [  6,  11,  29,   8,   2,   3,   0,   0,   0,   0,   0,   1,   0],
       [  1,  16,  24,   0,   0,  20,   0,   0,   0,   0,   2,   0,   0],
       [  0,   6,  16,   0,   0,  15,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47400135, 0.28742555, 0.16216151]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522a3a9910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523a902290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45850642, 'precision': 0.25337458777859173, 'recall': 0.2620981396048789, 'f1_score': 0.24713180880357232, 'confusion_matrix': array([[ 8, 37, 72, 10,  5, 13,  0,  1,  0],
       [13, 35, 53,  6,  5, 14,  0,  0,  0],
       [12, 36, 88, 12,  5, 13,  0,  0,  0],
       [ 7,  9, 35, 10,  2,  5,  0,  1,  1],
       [ 1,  5, 13,  1,  3,  2,  0,  0,  0],
       [ 1, 10, 21,  0,  0, 16,  0,  0,  0],
       [ 1,  2,  7,  0,  0,  9,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.418552, 0.4002751, -0.39195362]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526fdf0790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552653acbd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40419997, 'precision': 0.23439718315163154, 'recall': 0.2464771481715216, 'f1_score': 0.16779488002648522, 'confusion_matrix': array([[178,   1,   8,   0,   0,   0,   0],
       [332,  17,  19,   0,   0,   0,   0],
       [106,   1,   3,   0,   0,   0,   0],
       [ 73,   3,   0,   0,   0,   0,   0],
       [ 58,   1,   0,   0,   0,   0,   0],
       [ 48,   1,   0,   0,   0,   0,   0],
       [ 48,   3,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.380524, 0.4162535, -0.02788422]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15526fdf0790>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552653acbd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4611669, 'precision': 0.17693197761032124, 'recall': 0.24403357213091725, 'f1_score': 0.161839485900788575, 'confusion_matrix': array([[142,   2,   0,   0,   0,   0,   0],
       [219,   5,   2,   0,   0,   0,   0],
       [ 77,   2,   0,   0,   0,   0,   0],
       [ 52,   4,   0,   0,   0,   0,   0],
       [ 26,   2,   0,   0,   0,   0,   0],
       [ 29,   1,   0,   0,   0,   0,   0],
       [ 36,   1,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4421006, 0.34566876, 0.028117927]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552537fa010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265520b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42787324, 'precision': 0.13102131721285396, 'recall': 0.24285714285714285, 'f1_score': 0.15097372892432362, 'confusion_matrix': array([[  0,   2, 206,   0,   0,   0,   0],
       [  0,   0, 275,   0,   0,   0,   0],
       [  0,   0, 195,   0,   0,   0,   0],
       [  0,   0,  64,   0,   0,   0,   0],
       [  0,   0,  58,   0,   0,   0,   0],
       [  0,   0,  61,   0,   0,   0,   0],
       [  0,   0,  39,   0,   0,   0,   0]]), 'forgetting_measure': [0.40539495, 0.33593902, 0.13499461]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning LWF with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552537fa010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155265520b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4564702, 'precision': 0.13785714285714286, 'recall': 0.24285714285714285, 'f1_score': 0.15985319028797289, 'confusion_matrix': array([[  0,   0, 133,   0,   0,   0,   0],
       [  0,   0, 140,   0,   0,   0,   0],
       [  0,   0, 159,   0,   0,   0,   0],
       [  0,   0,  44,   0,   0,   0,   0],
       [  0,   0,  57,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0],
       [  0,   0,  24,   0,   0,   0,   0]]), 'forgetting_measure': [0.4247786, 0.19860813, 0.29168317]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522a70ad10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521d7933d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48344157, 'precision': 0.32713525859602063, 'recall': 0.28335899327914973, 'f1_score': 0.26738958793025233, 'confusion_matrix': array([[157,  19,  13,   4,   2,   1,   8,   0],
       [141,  32,  22,   6,   0,   1,   2,   0],
       [161,  19,  53,   7,   2,   2,   9,   1],
       [ 42,   7,  13,   9,   1,   1,   1,   0],
       [ 35,   7,  12,   6,   0,   0,   3,   1],
       [  8,  13,   9,   2,   2,   3,   6,   0],
       [ 21,  12,  14,   0,   2,   0,   8,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4642534, 0.4021813, -0.23216832]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15522a70ad10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15521d7933d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42235137, 'precision': 0.28024770470422644, 'recall': 0.2887479738547739, 'f1_score': 0.25854344507396764, 'confusion_matrix': array([[ 96,   9,  15,   4,   1,   1,   5],
       [ 94,  21,  17,   4,   0,   2,   8],
       [111,  20,  13,   8,   2,   4,  10],
       [ 22,   5,   7,   5,   0,   0,   4],
       [ 30,   6,   4,   3,   0,   1,   1],
       [  8,   6,   8,   0,   2,   2,   2],
       [  9,  13,   5,   0,   2,   3,   7]]), 'forgetting_measure': [0.4202384, 0.35576838, 0.3189397]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527c9a1d10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552764f05d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42740136, 'precision': 0.24745943069965417, 'recall': 0.24163681034702244, 'f1_score': 0.149537165275325944, 'confusion_matrix': array([[  1, 249,   0,   0,   0,   0,   0],
       [  2, 178,   1,   0,   0,   0,   0],
       [  0, 247,   1,   0,   0,   0,   0],
       [  0,  48,   0,   0,   0,   0,   0],
       [  0,  73,   0,   0,   0,   0,   0],
       [  0,  66,   0,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42207105, 0.5066261, -0.26639256]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527c9a1d10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552764f05d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4105972, 'precision': 0.13047619047619048, 'recall': 0.24285714285714285, 'f1_score': 0.15023547880690738, 'confusion_matrix': array([[  0, 168,   0,   0,   0,   0,   0],
       [  0, 128,   0,   0,   0,   0,   0],
       [  0, 152,   0,   0,   0,   0,   0],
       [  0,  36,   0,   0,   0,   0,   0],
       [  0,  49,   0,   0,   0,   0,   0],
       [  0,  33,   0,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.39009384, 0.39676934, 0.047368806]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155219081410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155218ed33d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47052805, 'precision': 0.21311907953737378, 'recall': 0.2146279036149425, 'f1_score': 0.2092024740697417, 'confusion_matrix': array([[98, 56, 67,  8,  7, 33,  0,  1,  1,  0,  0,  0],
       [77, 40, 43,  7,  7, 20,  3,  0,  0,  1,  1,  0],
       [76, 45, 59,  6,  2,  8,  1,  0,  0,  0,  0,  0],
       [23, 15, 10,  3,  6,  5,  1,  0,  0,  0,  0,  0],
       [17, 23, 15,  1,  5,  6,  0,  2,  0,  0,  1,  0],
       [14, 18,  5,  1,  0, 28,  4,  1,  0,  0,  0,  0],
       [ 6,  8,  3,  0,  0, 10,  0,  0,  0,  1,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.43465177, 0.305601, -0.05236487]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155219081410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155218ed33d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44456978, 'precision': 0.26157445626995628, 'recall': 0.26031037105707346, 'f1_score': 0.25586112316396372, 'confusion_matrix': array([[67, 30, 49,  7,  7, 19,  1,  0,  1],
       [41, 29, 30,  4,  6, 14,  0,  0,  0],
       [50, 26, 37,  3,  6, 12,  3,  1,  0],
       [16, 11,  5,  6,  2,  3,  1,  0,  0],
       [10, 10, 11,  4,  5,  6,  0,  0,  0],
       [ 9, 13,  4,  0,  1, 14,  2,  0,  0],
       [ 8,  8,  2,  0,  0,  6,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.46212564, 0.51245904, -0.10468079]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155267ed9510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155261fc69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4133922, 'precision': 0.155908289241622576, 'recall': 0.24424421670449594, 'f1_score': 0.16533645628168047, 'confusion_matrix': array([[173,   0,  13,   0,   0,   0,   0],
       [267,   0,  20,   0,   0,   0,   0],
       [185,   0,  16,   0,   0,   0,   0],
       [ 46,   0,   3,   0,   0,   0,   0],
       [ 73,   0,   4,   0,   0,   0,   0],
       [ 37,   0,  13,   0,   0,   0,   0],
       [ 29,   0,  21,   0,   0,   0,   0]]), 'forgetting_measure': [0.37429304, 0.2949678, 0.10800827]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155267ed9510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155261fc69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39629252, 'precision': 0.14743230625583567, 'recall': 0.2405746611770616, 'f1_score': 0.16038144353147247, 'confusion_matrix': array([[ 90,   0,  13,   0,   0,   0,   0],
       [193,   0,  17,   0,   0,   0,   0],
       [113,   0,  14,   0,   0,   0,   0],
       [ 39,   0,   4,   0,   0,   0,   0],
       [ 43,   0,   7,   0,   0,   0,   0],
       [ 16,   0,  21,   0,   0,   0,   0],
       [ 16,   0,  14,   0,   0,   0,   0]]), 'forgetting_measure': [0.40965713, 0.47923577, 0.26849014]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527cf66950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527d36e2d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4031763, 'precision': 0.1447724955678296, 'recall': 0.2271321961620469, 'f1_score': 0.16582296075143067, 'confusion_matrix': array([[162,   0,   0,  41,  13,   0,   0],
       [174,   0,   0,  33,  15,   0,   0],
       [175,   0,   0,  42,  14,   0,   0],
       [ 53,   0,   0,   8,   3,   0,   0],
       [ 49,   0,   0,  17,   1,   0,   0],
       [  2,   0,   0,  20,   6,   0,   0],
       [  6,   0,   0,  44,  22,   0,   0]]), 'forgetting_measure': [0.3862887, 0.15735279, 0.66009074]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527cf66950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15527d36e2d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39421703, 'precision': 0.14107142857142857, 'recall': 0.23970973946494142, 'f1_score': 0.1630740008668874, 'confusion_matrix': array([[ 99,   0,   0,  30,   0,   0,   0],
       [131,   0,   0,  52,   0,   0,   0],
       [103,   0,   0,  28,   0,   0,   0],
       [ 30,   0,   0,   8,   0,   0,   0],
       [ 37,   0,   0,  15,   0,   0,   0],
       [  0,   0,   0,  14,   0,   0,   0],
       [  0,   0,   0,  53,   0,   0,   0]]), 'forgetting_measure': [0.38786135, 0.13800535, 0.8119783]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218df8ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155219360090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48169563, 'precision': 0.21303571428571428, 'recall': 0.3857142857142857, 'f1_score': 0.25870797938799802, 'confusion_matrix': array([[217,   0,   0,   0,   0,   0,   0],
       [216,   0,   0,   0,   0,   0,   0],
       [234,   0,   0,   0,   0,   0,   0],
       [ 80,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  52,   0],
       [  0,   0,   0,   0,   0,  48,   0]]), 'forgetting_measure': [0.4190681, 0.3870891, -0.68980324]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218df8ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155219360090>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52400325, 'precision': 0.20097728991067179, 'recall': 0.3857142857142857, 'f1_score': 0.2482571056462116, 'confusion_matrix': array([[154,   0,   0,   0,   0,   0,   0],
       [142,   0,   0,   0,   0,   0,   0],
       [150,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [ 37,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  28,   0],
       [  0,   0,   0,   0,   0,  39,   0]]), 'forgetting_measure': [0.46236942, 0.40826195, -0.8431033]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524b5f2310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552543d7190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49004925, 'precision': 0.15847102806003429, 'recall': 0.26140848398912916, 'f1_score': 0.18564451421594277, 'confusion_matrix': array([[258,   0,   0,   0,   0,  21,   0],
       [194,   0,   0,   0,   0,  18,   0],
       [161,   0,   0,   0,   0,  13,   0],
       [ 84,   0,   0,   0,   0,   8,   0],
       [ 39,   0,   0,   0,   0,   4,   0],
       [ 31,   0,   0,   0,   0,   8,   0],
       [ 46,   0,   0,   0,   0,  15,   0]]), 'forgetting_measure': [0.52694336, 0.32074395, 0.4717292]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning LWF with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15524b5f2310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552543d7190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47937526, 'precision': 0.138339438339438335, 'recall': 0.24017857142857143, 'f1_score': 0.16021093000958772, 'confusion_matrix': array([[157,   0,   0,   0,   0,   3,   0],
       [116,   0,   0,   0,   0,   2,   0],
       [158,   0,   0,   0,   0,   4,   0],
       [ 58,   0,   0,   0,   0,   4,   0],
       [ 29,   0,   0,   0,   0,   2,   0],
       [ 19,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43141124, 0.06540102, 0.36404714]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520b9195d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520bce9d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43433523, 'precision': 0.19624999999999999, 'recall': 0.3857142857142857, 'f1_score': 0.23903656835594008, 'confusion_matrix': array([[155,   0,   0,   0,   0,   0,   0],
       [255,   0,   0,   0,   0,   0,   0],
       [245,   0,   0,   0,   0,   0,   0],
       [ 78,   0,   0,   0,   0,   0,   0],
       [ 67,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  48,   0],
       [  0,   0,   0,   0,   0,  52,   0]]), 'forgetting_measure': [0.29633001, -0.04798169, -0.4625761]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520b9195d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520bce9d90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40672637, 'precision': 0.19448469259171843, 'recall': 0.3857142857142857, 'f1_score': 0.23556065122678285, 'confusion_matrix': array([[ 90,   0,   0,   0,   0,   0,   0],
       [221,   0,   0,   0,   0,   0,   0],
       [134,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,  33,   0],
       [  0,   0,   0,   0,   0,  34,   0]]), 'forgetting_measure': [0.33375812, 0.22727315, -0.13928168]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155243be2310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552437e69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46877075, 'precision': 0.18842081545807094, 'recall': 0.20437979851392772, 'f1_score': 0.18983563567919205, 'confusion_matrix': array([[ 15,  84,  19,   9,   6,  13,  10,   2,   0,   0,   0,   0,   0],
       [ 27, 177,  18,  18,  12,  21,  21,   4,   3,   2,   2,   0,   4],
       [ 23, 112,   7,  15,   9,  19,  13,   2,   0,   1,   0,   0,   1],
       [  6,  31,   3,   4,   5,   4,   4,   1,   0,   1,   2,   0,   0],
       [  4,  33,  11,   8,   2,   4,   5,   1,   1,   1,   0,   0,   0],
       [  2,  11,   6,   0,   0,  15,  14,   0,   1,   2,   1,   1,   1],
       [  0,   5,   6,   0,   0,  13,  13,   0,   0,   6,   0,   0,   3],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.461006, 0.18428773, 0.48780632]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155243be2310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552437e69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5100986, 'precision': 0.21453673875492601, 'recall': 0.20426339713718438, 'f1_score': 0.19202530509665403, 'confusion_matrix': array([[ 11,  65,   7,   8,   2,   2,   9,   0,   0,   2,   1,   0,   0],
       [ 12, 134,  14,  15,   1,  10,  14,   4,   2,   3,   1,   0,   6],
       [  8,  73,  10,  10,   0,   6,   9,   0,   1,   3,   0,   1,   1],
       [  2,  27,   2,   6,   0,   4,   3,   1,   0,   0,   0,   0,   0],
       [  1,  26,   2,   7,   1,   1,   2,   1,   1,   0,   0,   0,   1],
       [  1,  16,   2,   0,   0,   1,  13,   0,   2,   2,   0,   0,   0],
       [  1,  10,   2,   0,   1,   5,  11,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.48894364, 0.1573878, 0.3481697]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 300 chunkss', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552043695d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fe4ea450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46862088, 'precision': 0.2587226631014731, 'recall': 0.2456868875592125, 'f1_score': 0.20881165947078426, 'confusion_matrix': array([[  1,  85,  53,   0,   0,   0,   0],
       [  1, 181, 104,   0,   0,   0,   0],
       [  0, 147,  90,   0,   0,   0,   0],
       [  0,  59,  21,   0,   0,   0,   0],
       [  0,  41,  17,   0,   0,   0,   0],
       [  0,  51,   0,   0,   0,   0,   0],
       [  0,  49,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.41810778, 0.19112836, 0.104395546]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 300 chunkss', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552043695d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fe4ea450>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59874312, 'precision': 0.19999342581026889, 'recall': 0.2564784053156146, 'f1_score': 0.21623018402288277, 'confusion_matrix': array([[  0,  60,  31,   0,   0,   0,   0],
       [  0, 171,  44,   0,   0,   0,   0],
       [  0,  98,  42,   0,   0,   0,   0],
       [  0,  50,   4,   0,   0,   0,   0],
       [  0,  31,   2,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0],
       [  0,  33,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.56336424, 0.21245897, -0.008298578]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520becac10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155204a833d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53243358, 'precision': 0.145129508978229774, 'recall': 0.24285714285714285, 'f1_score': 0.16859074990943122, 'confusion_matrix': array([[284,   0,   0,   0,   0,   0,   0],
       [262,   0,   0,   0,   0,   0,   0],
       [120,   0,   0,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0,   0,   0],
       [ 64,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.52524552, 0.35330895, -0.08018216]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520becac10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155204a833d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48223255, 'precision': 0.145075125208681135, 'recall': 0.24285714285714285, 'f1_score': 0.16852791878172589, 'confusion_matrix': array([[189,   0,   0,   0,   0,   0,   0],
       [171,   0,   1,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51268337, 0.41070986, 0.21533005]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fb056550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155204ef9ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51498984, 'precision': 0.23232583781923588, 'recall': 0.25496720633210356, 'f1_score': 0.2262269943051321, 'confusion_matrix': array([[205,  95,   9,   0,   0,   0,   0],
       [145,  89,   8,   0,   0,   0,   0],
       [ 63,  43,   6,   0,   0,   0,   0],
       [ 41,  26,   0,   0,   0,   0,   0],
       [ 50,  20,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 59,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47276056, 0.19017076, 0.10446792]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fb056550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155204ef9ed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4891096, 'precision': 0.19130804163534235, 'recall': 0.2417066723062282, 'f1_score': 0.20320037105751391, 'confusion_matrix': array([[121,  54,   0,   0,   0,   0,   0],
       [135,  58,   0,   0,   0,   0,   0],
       [ 58,  21,   0,   0,   0,   0,   0],
       [ 32,  14,   0,   0,   0,   0,   0],
       [ 28,  12,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51497123, 0.39091322, 0.21028133]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552434e2010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552433187d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44493128, 'precision': 0.18014455782312925, 'recall': 0.24264114049248539, 'f1_score': 0.15517656209489241, 'confusion_matrix': array([[204,   1,   1,   0,   0,   0,   0],
       [353,   0,   1,   0,   0,   0,   0],
       [121,   0,   1,   0,   0,   0,   0],
       [ 71,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3817479, 0.2583011, -0.16797319]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning MAS with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552434e2010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552433187d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43029879, 'precision': 0.13529692344383496, 'recall': 0.24285714285714285, 'f1_score': 0.15660738190858673, 'confusion_matrix': array([[148,   0,   0,   0,   0,   0,   0],
       [213,   0,   0,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   1,   0,   0,   0,   0],
       [ 29,   0,   0,   0,   0,   0,   0],
       [ 23,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43520648, 0.32253692, 0.43370533]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523ff26910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240357150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5038359, 'precision': 0.26256544132379458, 'recall': 0.23469303266083368, 'f1_score': 0.23258872189674878, 'confusion_matrix': array([[186,  71,   8,  31,  13,   2,  13,   1,   1],
       [107,  38,  18,  23,   3,   2,   7,   0,   1],
       [ 83,  27,   8,  12,   4,   1,   5,   0,   1],
       [ 52,   6,   2,  11,   2,   0,   2,   0,   1],
       [ 31,  10,   2,  12,   2,   0,   1,   0,   0],
       [ 25,   8,   3,   2,   1,   3,   4,   1,   0],
       [ 26,   8,   5,   2,   0,   2,   8,   1,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51251352, 0.30061156, 0.2704275]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15523ff26910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155240357150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47058244, 'precision': 0.2513507431734545, 'recall': 0.25325875366608632, 'f1_score': 0.23477714518876366, 'confusion_matrix': array([[101,  48,   4,  29,   6,   3,   9,   1],
       [ 63,  24,   5,  18,   4,   1,   1,   0],
       [ 83,  27,   2,  12,   2,   5,   1,   0],
       [ 18,   8,   1,  12,   0,   0,   1,   0],
       [ 25,   4,   1,  12,   2,   0,   0,   0],
       [ 15,   7,   6,   2,   0,   2,   4,   2],
       [ 14,   7,   2,   1,   0,   1,   3,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4929656, 0.34641612, 0.3694587]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f25da110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fb2b9390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53623827, 'precision': 0.37337068011142435, 'recall': 0.35203599634230783, 'f1_score': 0.3398113805817045, 'confusion_matrix': array([[117,  17,  46,   7,   0,   3,  21],
       [ 44,  43, 111,   6,   4,   1,   7],
       [ 53,  22, 131,  14,   5,   1,   9],
       [ 22,   6,  27,   3,   2,   2,   2],
       [ 11,   8,  35,  10,   8,   1,   1],
       [  3,   3,  27,   0,   1,   0,   9],
       [ 16,   6,  18,   0,   0,   0,  17]]), 'forgetting_measure': [0.47500694, 0.22662236, -0.18503372]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551f25da110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fb2b9390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45780818, 'precision': 0.31288248381654973, 'recall': 0.28490606845766613, 'f1_score': 0.28435957261145988, 'confusion_matrix': array([[42, 13, 70,  7,  4,  1,  6],
       [34, 22, 63,  6,  5,  1,  4],
       [50, 18, 76, 10,  2,  3,  7],
       [19,  2, 11,  9,  1,  0,  3],
       [17,  2, 13,  7,  2,  1,  2],
       [ 1,  3, 16,  0,  0,  1,  2],
       [ 6,  6, 26,  0,  1,  1,  4]]), 'forgetting_measure': [0.42793176, 0.26983494, 0.13947226]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dd44a110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dd9cbad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46396975, 'precision': 0.25066020889915296, 'recall': 0.2676002095175027, 'f1_score': 0.2364302684245056, 'confusion_matrix': array([[ 21, 145,  27,   0,   0,  15,   1],
       [ 33, 174,  42,   0,   0,  22,   2],
       [ 29, 139,  15,   1,   0,  16,   0],
       [  2,  37,   1,   0,   0,   3,   1],
       [  2,  67,   4,   0,   0,   1,   0],
       [ 10,  28,   3,   0,   0,  21,   1],
       [  4,  18,   3,   0,   0,  11,   1]]), 'forgetting_measure': [0.4571183, 0.30500498, 0.24819145]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dd44a110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dd9cbad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43199423, 'precision': 0.22368219044095599, 'recall': 0.26815707721959774, 'f1_score': 0.22584109700491355, 'confusion_matrix': array([[ 17,  73,  16,   0,   0,  19,   1],
       [ 26, 101,  20,   0,   0,  16,   1],
       [ 24, 106,  11,   0,   0,  18,   0],
       [  1,  24,   2,   0,   0,   1,   0],
       [  1,  50,   1,   0,   0,   3,   1],
       [ 11,  14,   1,   0,   0,  15,   1],
       [  3,  11,   1,   0,   0,  10,   0]]), 'forgetting_measure': [0.4363083, 0.30925345, 0.45170692]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e8ec9910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e93233d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59880762, 'precision': 0.27766374333666216, 'recall': 0.33524698051263515, 'f1_score': 0.29727215611055454, 'confusion_matrix': array([[ 67,  68,  69,   0,   0,   0,   0],
       [ 12, 209,  27,   0,   0,   0,   0],
       [ 52,  66, 107,   0,   0,   0,   0],
       [ 17,   7,  29,   0,   0,   0,   0],
       [  7,  45,  18,   0,   0,   0,   0],
       [  3,  30,   8,   0,   0,   0,   0],
       [ 14,  36,   9,   0,   0,   0,   0]]), 'forgetting_measure': [0.53972787, 0.13396633, 0.012980497]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e8ec9910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e93233d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4740816, 'precision': 0.21020742064230281, 'recall': 0.24983746614621432, 'f1_score': 0.22538524977919452, 'confusion_matrix': array([[31, 67, 39,  0,  0,  0,  0],
       [40, 90, 44,  0,  0,  0,  0],
       [24, 67, 40,  0,  0,  0,  0],
       [11, 18, 10,  0,  0,  0,  0],
       [11, 25, 16,  0,  0,  0,  0],
       [ 2,  7,  3,  0,  0,  0,  0],
       [15, 24, 16,  0,  0,  0,  0]]), 'forgetting_measure': [0.4926712, 0.38153744, 0.23113362]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155230009dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523eaab150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4866797, 'precision': 0.21545680248055572, 'recall': 0.20058747356006907, 'f1_score': 0.19884827936256792, 'confusion_matrix': array([[ 48, 102,   9,  10,  12,   2,   7,   1,   1,   0,   0,   1,   0,
          5],
       [ 51, 161,  13,  18,  10,   4,   8,   0,   0,   1,   2,   1,   0,
          2],
       [ 44, 101,  21,   9,   6,   2,  10,   0,   0,   1,   0,   2,   0,
          3],
       [ 16,  22,   3,  10,   7,   1,   2,   0,   2,   0,   0,   2,   0,
          2],
       [ 13,  27,   5,  11,   5,   1,   2,   1,   0,   0,   0,   0,   0,
          0],
       [  8,  16,   8,   1,   0,   3,   9,   1,   0,   1,   0,   0,   0,
          3],
       [ 10,  18,   3,   2,   1,   3,   9,   1,   0,   1,   0,   0,   1,
          1],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0]]), 'forgetting_measure': [0.5186354, 0.3916824, 0.26671693]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning MAS with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155230009dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15523eaab150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48540534, 'precision': 0.23027180350941772, 'recall': 0.20961146670418305, 'f1_score': 0.20378879623789787, 'confusion_matrix': array([[40, 81,  8,  5,  1,  0,  3,  0,  0,  1,  0,  5],
       [36, 90,  6, 15,  2,  6,  3,  1,  0,  2,  1,  3],
       [29, 75,  7,  7,  1,  4,  8,  1,  1,  0,  1,  3],
       [ 8, 13,  0,  6,  3,  1,  0,  1,  0,  2,  0,  0],
       [12, 27,  2,  4,  4,  0,  4,  0,  0,  0,  0,  0],
       [ 4, 15,  6,  0,  0,  1,  7,  1,  0,  0,  0,  2],
       [ 7,  8,  3,  0,  0,  3,  5,  0,  0,  2,  1,  2],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.44492207, -0.1111616, 0.6659488]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e91f9e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dc7e45d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50475587, 'precision': 0.21939136487594637, 'recall': 0.28426554608287146, 'f1_score': 0.22261789122607573, 'confusion_matrix': array([[  1,  68, 104,   0,   0,   0,   0],
       [  3, 181, 158,   0,   0,   0,   0],
       [  2,  36, 117,   0,   0,   0,   0],
       [  0,  16,  32,   0,   0,   0,   0],
       [  0,  52,  30,   0,   0,   0,   0],
       [  0,  36,  11,   0,   0,   0,   0],
       [  0,  51,   2,   0,   0,   0,   0]]), 'forgetting_measure': [0.42647496, 0.105978064, -0.013845088]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e91f9e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dc7e45d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46978368, 'precision': 0.3232905264573388, 'recall': 0.24918543938303722, 'f1_score': 0.2024831712322934, 'confusion_matrix': array([[  1,  45,  43,   0,   0,   0,   0],
       [  0, 123, 138,   0,   0,   0,   0],
       [  0,  39,  50,   0,   0,   0,   0],
       [  0,  24,   9,   0,   0,   0,   0],
       [  0,  30,  31,   0,   0,   0,   0],
       [  0,  28,   4,   0,   0,   0,   0],
       [  0,  32,   3,   0,   0,   0,   0]]), 'forgetting_measure': [0.329568, -0.109843746, -0.2755811]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218c09dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524900fc90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46619604, 'precision': 0.2322600270631791, 'recall': 0.21877715391016305, 'f1_score': 0.21681035821311035, 'confusion_matrix': array([[ 51,  31, 105,   3,   4,   4,   6,   2,   1,   1,   1],
       [ 41,  28, 111,   5,   5,   8,   8,   1,   2,   0,   0],
       [ 55,  30, 147,   4,   7,   7,   3,   0,   0,   0,   0],
       [  5,  11,  28,   2,  12,   3,   1,   2,   1,   0,   0],
       [  7,  18,  27,   4,   5,   2,   1,   0,   0,   0,   0],
       [  7,  14,  15,   2,   0,   5,   1,   0,   0,   0,   0],
       [ 12,   9,  19,   2,   0,   6,   7,   1,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.48356704, 0.38433096, 0.24255565]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218c09dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15524900fc90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42175695, 'precision': 0.2821408434576825, 'recall': 0.24846532787495456, 'f1_score': 0.2500366213218001, 'confusion_matrix': array([[36, 22, 73,  1,  7,  1,  3,  0,  1],
       [28, 27, 67,  1,  5,  5,  9,  2,  0],
       [34, 35, 63,  2,  4,  5, 12,  0,  0],
       [ 2, 13, 15,  3,  7,  2,  2,  1,  0],
       [14,  4, 24,  1,  2,  0,  0,  0,  0],
       [11,  5,  4,  0,  0,  8,  1,  0,  0],
       [10,  9, 10,  0,  0,  5,  4,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.3998361, 0.38764942, 0.009666835]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552287716d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155228be69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50498114, 'precision': 0.22785295642710953, 'recall': 0.20947626255428514, 'f1_score': 0.20152753176742395, 'confusion_matrix': array([[195,   3,  38,   7,   8,   1,  29,   0,   0,   1,   0,   1,   0,
          1,   0],
       [105,  20,  34,   6,  12,   2,  14,   0,   1,   2,   2,   0,   1,
          2,   1],
       [ 77,  14,  36,   3,   7,   2,  25,   6,   0,   2,   0,   0,   3,
          1,   0],
       [ 66,   5,   8,   2,   6,   0,   8,   1,   0,   0,   0,   0,   0,
          0,   0],
       [ 26,   0,   3,   2,   5,   1,   5,   0,   0,   0,   0,   0,   0,
          0,   0],
       [ 15,   0,   2,   0,   0,   5,  10,   0,   0,   0,   1,   0,   1,
          1,   0],
       [ 27,   1,   3,   4,   0,   3,  24,   0,   0,   0,   0,   2,   1,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0]]), 'forgetting_measure': [0.53745494, 0.4274594, 0.09355905]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning MAS with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552287716d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155228be69d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43694997, 'precision': 0.22339065229977357, 'recall': 0.19957322602534642, 'f1_score': 0.18573129196396308, 'confusion_matrix': array([[103,   7,  13,   8,   9,   0,  17,   1,   0,   0,   0,   0,   1,
          0],
       [ 91,   4,  10,   2,   4,   0,  12,   1,   1,   1,   0,   0,   2,
          0],
       [ 93,  16,  15,   2,   9,   0,  16,   3,   0,   1,   0,   0,   0,
          0],
       [ 29,   2,   2,   1,   9,   0,   8,   0,   0,   2,   0,   0,   0,
          0],
       [ 19,   3,   2,   0,   4,   1,   4,   1,   0,   1,   0,   1,   0,
          2],
       [  8,   0,   2,   0,   0,   3,   9,   0,   0,   0,   1,   0,   0,
          0],
       [ 22,   1,   0,   0,   1,   1,  16,   0,   0,   1,   1,   0,   1,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0]]), 'forgetting_measure': [0.412775, 0.2777901, 0.23774262]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155207531510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552073969d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4188076, 'precision': 0.24375563414465015, 'recall': 0.24794657430597088, 'f1_score': 0.160147933959655564, 'confusion_matrix': array([[175,   1,   1,   0,   0,   0,   0],
       [345,   8,   2,   0,   0,   0,   0],
       [116,   4,   3,   0,   0,   0,   0],
       [ 88,   0,   1,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0],
       [ 49,   2,   1,   0,   0,   0,   0],
       [ 45,   0,   3,   0,   0,   0,   0]]), 'forgetting_measure': [0.4229453, 0.36267403, 0.3797729]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155207531510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552073969d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42724251, 'precision': 0.18270065190480416, 'recall': 0.2454735944616555, 'f1_score': 0.16141482663829032, 'confusion_matrix': array([[137,   1,   0,   0,   0,   0,   0],
       [221,   3,   3,   0,   0,   0,   0],
       [ 79,   1,   1,   0,   0,   0,   0],
       [ 50,   2,   3,   0,   0,   0,   0],
       [ 31,   1,   0,   0,   0,   0,   0],
       [ 23,   2,   1,   0,   0,   0,   0],
       [ 37,   3,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.43716422, 0.53458464, -0.1957698]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155207399950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552071d56d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45696865, 'precision': 0.27992363983455298, 'recall': 0.242936773371556, 'f1_score': 0.16018230885722052, 'confusion_matrix': array([[  0,   0, 229,   0,   0,   0,   0],
       [  0,   1, 206,   0,   0,   0,   0],
       [  1,   0, 233,   0,   0,   0,   0],
       [  0,   0,  73,   0,   0,   0,   0],
       [  0,   0,  57,   0,   0,   0,   0],
       [  0,   0,  46,   0,   0,   0,   0],
       [  0,   0,  54,   0,   0,   0,   0]]), 'forgetting_measure': [0.44943143, 0.45283166, -0.20438953]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning MAS with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155207399950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552071d56d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43451546, 'precision': 0.13238095238095238, 'recall': 0.24285714285714285, 'f1_score': 0.152795031055900624, 'confusion_matrix': array([[  0,   0, 143,   0,   0,   0,   0],
       [  0,   0, 168,   0,   0,   0,   0],
       [  0,   0, 136,   0,   0,   0,   0],
       [  0,   0,  55,   0,   0,   0,   0],
       [  0,   0,  31,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0]]), 'forgetting_measure': [0.35928888, -0.0779236, 0.41049144]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218301c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155217c52a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47639002, 'precision': 0.28804087057077273, 'recall': 0.3866882846927746, 'f1_score': 0.31022412293191145, 'confusion_matrix': array([[131,   0,   0,   0,  80,   0,   0],
       [104,   0,   0,   0,  85,   0,   0],
       [175,   0,   0,   0,  92,   0,   0],
       [ 45,   0,   0,   0,  31,   0,   0],
       [ 35,   0,   0,   0,  22,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,  56]]), 'forgetting_measure': [0.34004774, 0.24263032, -1.2404096]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155218301c10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155217c52a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4175927, 'precision': 0.27735094037615046, 'recall': 0.33976917316417778, 'f1_score': 0.29339475915351403, 'confusion_matrix': array([[76,  0,  0,  0, 62,  0,  0],
       [84,  0,  0,  0, 60,  0,  0],
       [86,  0,  0,  0, 73,  0,  0],
       [36,  0,  0,  0,  9,  0,  0],
       [41,  0,  0,  0,  6,  0,  0],
       [34,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0, 33]]), 'forgetting_measure': [0.26022205, 0.11763815, -1.4840684]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520b5e2150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520b6069d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43250176, 'precision': 0.32554918664428752, 'recall': 0.3928409459021704, 'f1_score': 0.3274236686351116, 'confusion_matrix': array([[117,   0,  30,   0,   0,   0,   0],
       [202,   0,  62,   0,   0,   0,   0],
       [188,   0,  64,   0,   0,   0,   0],
       [ 67,   0,   0,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,  50]]), 'forgetting_measure': [0.33969541, 0.32864895, -0.8449571]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning MAS with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520b5e2150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520b6069d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44354665, 'precision': 0.31487904923112747, 'recall': 0.37921512144813115, 'f1_score': 0.32782165750915753, 'confusion_matrix': array([[ 62,   0,  41,   0,   0,   0,   0],
       [123,   0,  60,   0,   0,   0,   0],
       [101,   0,  55,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [ 32,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,  35]]), 'forgetting_measure': [0.38993607, 0.5898797, -1.706239]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527e8112d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155282f87010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31931359, 'precision': 0.15140663054823798, 'recall': 0.20324302134646962, 'f1_score': 0.16861957370829148, 'confusion_matrix': array([[ 94,   0,   0,   0,  21,  18,   0,  41],
       [104,   0,   0,   0,  24,  33,   0,  63],
       [126,   0,   0,   0,  36,  35,   0,  74],
       [ 10,   0,   0,   0,  21,  27,   0,  17],
       [  7,   0,   0,   0,  16,  16,   0,  17],
       [  0,   0,   0,   0,   0,   0,   0,  63],
       [  0,   0,   0,   0,   0,   0,   0,  37],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.34509577, 0.5395883, 1.0]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15527e8112d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155282f87010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.35229595, 'precision': 0.15208686440677966, 'recall': 0.20469457013574661, 'f1_score': 0.16746411483253589, 'confusion_matrix': array([[63,  0,  0,  0, 16, 23,  0, 28],
       [66,  0,  0,  0, 10, 27,  0, 55],
       [71,  0,  0,  0, 16, 32,  0, 39],
       [ 0,  0,  0,  0, 11, 39,  0, 20],
       [ 0,  0,  0,  0,  6,  8,  0,  3],
       [ 0,  0,  0,  0,  0,  0,  0, 43],
       [ 0,  0,  0,  0,  0,  0,  0, 24],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.48972297, 0.8276599, 1.0]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 700 chunkss', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520b4d4750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520170a710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49097512, 'precision': 0.14263442570792237, 'recall': 0.24179894179894179, 'f1_score': 0.1655577299412916, 'confusion_matrix': array([[  0, 195,   0,   0,   0,   0,   0],
       [  2, 268,   0,   0,   0,   0,   0],
       [  0, 198,   0,   0,   0,   0,   0],
       [  0,  77,   0,   0,   0,   0,   0],
       [  0,  60,   0,   0,   0,   0,   0],
       [  0,  63,   0,   0,   0,   0,   0],
       [  0,  37,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4885077, 0.31435105, 0.18147762]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; no TEM (CIL) with 700 chunkss', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15520b4d4750>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15520170a710>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4339492, 'precision': 0.135476190476190474, 'recall': 0.24285714285714285, 'f1_score': 0.156837688346366586, 'confusion_matrix': array([[  0, 169,   0,   0,   0,   0,   0],
       [  0, 149,   0,   0,   0,   0,   0],
       [  0, 128,   0,   0,   0,   0,   0],
       [  0,  48,   0,   0,   0,   0,   0],
       [  0,  39,   0,   0,   0,   0,   0],
       [  0,  38,   0,   0,   0,   0,   0],
       [  0,  29,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42305518, 0.38241237, 0.10143259]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fcb92010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fd75cb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40664436, 'precision': 0.1602993817116824, 'recall': 0.24218636693255982, 'f1_score': 0.15694963364482786, 'confusion_matrix': array([[195,   2,   3,   0,   0,   0,   0],
       [270,   0,   3,   0,   0,   0,   0],
       [193,   0,   4,   0,   0,   0,   0],
       [ 33,   0,   2,   0,   0,   0,   0],
       [ 90,   0,   5,   0,   0,   0,   0],
       [ 61,   0,   2,   0,   0,   0,   0],
       [ 36,   0,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.3943971, 0.46663818, -0.07321168]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning Blanco with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551fcb92010>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fd75cb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3834473, 'precision': 0.158363858363858365, 'recall': 0.2424255744255744, 'f1_score': 0.15451952219646996, 'confusion_matrix': array([[122,   0,   3,   0,   0,   0,   0],
       [166,   0,   6,   0,   0,   0,   0],
       [140,   0,   3,   0,   0,   0,   0],
       [ 23,   0,   0,   0,   0,   0,   0],
       [ 68,   0,   2,   0,   0,   0,   0],
       [ 40,   0,   1,   0,   0,   0,   0],
       [ 26,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3567137, 0.50359523, -0.304161]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e1ea1dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fcf49e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4637603, 'precision': 0.20728420865593812, 'recall': 0.24339372112481355, 'f1_score': 0.21736499430380724, 'confusion_matrix': array([[ 37, 113,  51,   2,   1,   0,   0],
       [ 44, 137,  56,   1,   0,   0,   0],
       [ 44, 126,  57,   2,   2,   0,   0],
       [  4,  43,  10,   0,   1,   0,   0],
       [  4,  49,  16,   0,   0,   0,   0],
       [  4,   6,  22,   0,   0,   0,   0],
       [ 17,  17,  34,   0,   0,   0,   0]]), 'forgetting_measure': [0.45044843, 0.32653788, 0.1321747]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e1ea1dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551fcf49e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42935115, 'precision': 0.20104136903087227, 'recall': 0.23619154381631846, 'f1_score': 0.21148346336661398, 'confusion_matrix': array([[19, 67, 39,  0,  2,  0,  0],
       [28, 89, 51,  0,  0,  0,  0],
       [25, 81, 40,  0,  0,  0,  0],
       [ 4, 38, 12,  0,  1,  0,  0],
       [ 1, 27,  9,  0,  0,  0,  0],
       [ 3,  5,  8,  0,  0,  0,  0],
       [ 7, 14, 30,  0,  0,  0,  0]]), 'forgetting_measure': [0.38907737, 0.19173063, 0.29243752]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551edb72310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551edbafad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4976029, 'precision': 0.27819380814214628, 'recall': 0.28471467554686333, 'f1_score': 0.26603424763284386, 'confusion_matrix': array([[ 24, 118,  20,   6,  16,   9,   0],
       [ 21, 208,  28,   7,  22,   8,   0],
       [ 20, 121,  24,   1,   8,   6,   0],
       [ 11,  31,   2,   2,   8,   1,   0],
       [ 11,  40,   8,   4,  10,   5,   0],
       [  2,  21,   8,   1,   9,   8,   0],
       [  2,  15,   6,   0,   7,  21,   0]]), 'forgetting_measure': [0.51779843, 0.2533786, 0.47722515]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551edb72310>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551edbafad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5028107, 'precision': 0.27188610856910508, 'recall': 0.24972402880566144, 'f1_score': 0.24175465559455203, 'confusion_matrix': array([[  7,  64,  14,   3,   0,   3,   0],
       [ 30, 137,  33,   2,   7,   7,   0],
       [ 20,  91,  16,   4,   1,   3,   0],
       [ 12,  28,   2,   3,   2,   2,   0],
       [ 10,  23,   2,   3,   3,   1,   0],
       [  0,  24,   8,   0,   0,   3,   0],
       [  0,  19,  11,   0,   0,   2,   0]]), 'forgetting_measure': [0.4421053, 0.10960473, 0.14080694]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ed5609d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ed562c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51386212, 'precision': 0.22816352353433128, 'recall': 0.26951953329111483, 'f1_score': 0.22556052234527826, 'confusion_matrix': array([[ 14,  19, 178,   0,   0,   0,   0],
       [ 15,  65, 125,   0,   0,   0,   0],
       [ 21,  28, 200,   0,   0,   0,   0],
       [  3,  14,  46,   0,   0,   0,   0],
       [  0,  11,  61,   0,   0,   0,   0],
       [  4,  37,  14,   0,   0,   0,   0],
       [  1,  11,  33,   0,   0,   0,   0]]), 'forgetting_measure': [0.47598303, 0.35242265, -0.323015]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ed5609d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ed562c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4775272, 'precision': 0.21281829589735277, 'recall': 0.240444814844368, 'f1_score': 0.21276856108584586, 'confusion_matrix': array([[ 18,  26,  87,   0,   0,   0,   0],
       [ 12,  16,  80,   0,   0,   0,   0],
       [ 18,  44, 143,   0,   0,   0,   0],
       [  1,   9,  39,   0,   0,   0,   0],
       [  1,   8,  31,   0,   0,   0,   0],
       [  2,  14,  12,   0,   0,   0,   0],
       [  4,  15,  20,   0,   0,   0,   0]]), 'forgetting_measure': [0.4557252, 0.27972654, 0.13887458]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e3889dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e429e9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59576572, 'precision': 0.4164500847755054, 'recall': 0.3934036558798306, 'f1_score': 0.3546965740736572, 'confusion_matrix': array([[197,  32,   3,   0,   0,   3,  17],
       [ 98,  91,  11,   1,  10,   0,  23],
       [ 64,  70,  26,   2,   6,   0,  19],
       [ 24,  22,   0,   0,   6,   0,   5],
       [ 23,  27,   5,   0,   8,   1,   6],
       [ 17,   6,   2,   0,   0,   3,  19],
       [ 16,   4,   0,   1,   0,   2,  30]]), 'forgetting_measure': [0.4855308, -0.104562156, 0.117224395]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e3889dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551e429e9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43391598, 'precision': 0.24613349185828176, 'recall': 0.30222263798863604, 'f1_score': 0.24519661144221777, 'confusion_matrix': array([[87, 23,  7,  0,  6,  0, 14],
       [97, 35,  7,  0,  7,  0, 20],
       [72, 36,  5,  1,  6,  0, 18],
       [27,  6,  2,  0,  3,  0,  5],
       [18, 19,  1,  0,  3,  0,  8],
       [ 6,  8,  3,  0,  0,  0, 14],
       [ 8,  9,  1,  0,  0,  1, 17]]), 'forgetting_measure': [0.3940258, 0.122701205, 0.41936603]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e3aff510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dbabe9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4586756, 'precision': 0.22759295499021525, 'recall': 0.24595011142219327, 'f1_score': 0.16524987617424592, 'confusion_matrix': array([[  1,   7, 175,   0,   0,   0,   0],
       [  0,   8, 258,   0,   0,   0,   0],
       [  0,   3, 213,   0,   0,   0,   0],
       [  3,   0,  58,   0,   0,   0,   0],
       [  0,   1,  73,   0,   0,   0,   0],
       [  0,   1,  60,   0,   0,   0,   0],
       [  0,   0,  39,   0,   0,   0,   0]]), 'forgetting_measure': [0.44403497, 0.30011103, 0.20591162]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning Blanco with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e3aff510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551dbabe9d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4229554, 'precision': 0.30208066248570736, 'recall': 0.2455357142857143, 'f1_score': 0.16533214167369615, 'confusion_matrix': array([[  3,   0, 139,   0,   0,   0,   0],
       [  0,   3, 157,   0,   0,   0,   0],
       [  1,   2, 139,   0,   0,   0,   0],
       [  0,   0,  49,   0,   0,   0,   0],
       [  0,   0,  40,   0,   0,   0,   0],
       [  0,   1,  32,   0,   0,   0,   0],
       [  0,   1,  33,   0,   0,   0,   0]]), 'forgetting_measure': [0.37582222, 0.09595348, 0.4237643]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dc1c45d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d5a87390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48522718, 'precision': 0.16862129074104102, 'recall': 0.24001671708915536, 'f1_score': 0.16788977498253568, 'confusion_matrix': array([[258,   1,   8,   0,   0,   0,   0],
       [181,   0,   5,   0,   0,   0,   0],
       [212,   2,   3,   0,   0,   0,   0],
       [ 67,   0,   0,   0,   0,   0,   0],
       [ 63,   0,   0,   0,   0,   0,   0],
       [ 71,   0,   0,   0,   0,   0,   0],
       [ 29,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42529145, 0.07421807, 0.23877776]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551dc1c45d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d5a87390>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5543865, 'precision': 0.15023809523809524, 'recall': 0.24285714285714285, 'f1_score': 0.17433503611062182, 'confusion_matrix': array([[211,   0,   0,   0,   0,   0,   0],
       [110,   0,   0,   0,   0,   0,   0],
       [125,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 20,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.56770623, 0.23903629, 0.32694355]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552826ada10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155278da7010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5058393, 'precision': 0.14497060225647544, 'recall': 0.24235412474849093, 'f1_score': 0.16834923318439802, 'confusion_matrix': array([[283,   0,   1,   0,   0,   0,   0],
       [256,   0,   0,   0,   0,   0,   0],
       [129,   0,   0,   0,   0,   0,   0],
       [ 66,   0,   0,   0,   0,   0,   0],
       [ 65,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.50430325, 0.22998531, 0.3514852]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552826ada10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155278da7010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53857772, 'precision': 0.14738095238095238, 'recall': 0.24285714285714285, 'f1_score': 0.17116037904523512, 'confusion_matrix': array([[199,   0,   0,   0,   0,   0,   0],
       [162,   0,   0,   0,   0,   0,   0],
       [ 78,   0,   0,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0],
       [ 29,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51268337, 0.2272163, 0.10905792]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e9b2e7d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d41d7c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.32765913, 'precision': 0.26129032258064516, 'recall': 0.24341517857142858, 'f1_score': 0.133764789962677684, 'confusion_matrix': array([[  1,   0, 255,   0,   0,   0,   0],
       [  0,   0, 289,   0,   0,   0,   0],
       [  0,   0, 116,   0,   0,   0,   0],
       [  0,   0,  80,   0,   0,   0,   0],
       [  0,   0,  59,   0,   0,   0,   0],
       [  0,   0,  57,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0]]), 'forgetting_measure': [0.28366584, 0.53006077, -0.30920416]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e9b2e7d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d41d7c10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3364529, 'precision': 0.118571428571428572, 'recall': 0.24285714285714285, 'f1_score': 0.13286978508217447, 'confusion_matrix': array([[  0,   0, 205,   0,   0,   0,   0],
       [  0,   0, 152,   0,   0,   0,   0],
       [  0,   0,  78,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0],
       [  0,   0,  56,   0,   0,   0,   0],
       [  0,   0,  38,   0,   0,   0,   0],
       [  0,   0,  29,   0,   0,   0,   0]]), 'forgetting_measure': [0.28564329, 0.3587333, 0.12077863]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551d4cab090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551b91faf90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46540175, 'precision': 0.259266333883452, 'recall': 0.37540385146768126, 'f1_score': 0.2687678776519517, 'confusion_matrix': array([[  0,  21,  59,  10,  26,  35,   0],
       [  0,  21,  48,  19,  25,  30,   0],
       [  0,  33, 151,  37,  69,  86,   0],
       [  0,   0,  26,   0,  38,  19,   0],
       [  0,   0,  21,   0,  20,   6,   0],
       [  0,   0,   0,   0,   3,  62,   0],
       [  0,   0,   0,   0,   8,  27,   0]]), 'forgetting_measure': [0.3713558, -0.2873617, 0.49756715]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551d4cab090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551b91faf90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50760053, 'precision': 0.23583035431467486, 'recall': 0.3962880804495711, 'f1_score': 0.25666750450287298, 'confusion_matrix': array([[  0,   0,  36,   8,  16,  16,   0],
       [  0,   0,  40,   7,  23,  22,   0],
       [  0,   0, 119,  26,  58,  73,   0],
       [  0,   0,   7,   0,  30,  10,   0],
       [  0,   0,   3,   0,  27,  12,   0],
       [  0,   0,   0,   0,   0,  39,   0],
       [  0,   0,   0,   0,   0,  28,   0]]), 'forgetting_measure': [0.3898732, -0.47904047, 0.5237278]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155546fbfd50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531689cc90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41557634, 'precision': 0.23326640026999245, 'recall': 0.22472742461675211, 'f1_score': 0.16915609992235672, 'confusion_matrix': array([[ 26,   1, 228,   0,   0,   0,   0],
       [  7,   1, 189,   0,   0,   0,   0],
       [ 51,   0, 167,   0,   0,   0,   0],
       [ 11,   0,  46,   0,   0,   0,   0],
       [ 15,   0,  58,   0,   0,   0,   0],
       [  8,   0,  58,   0,   0,   0,   0],
       [  1,   0,  33,   0,   0,   0,   0]]), 'forgetting_measure': [0.38437948, 0.351994, 0.033696767]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155546fbfd50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15531689cc90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4449022, 'precision': 0.19023508586469527, 'recall': 0.24503779802287267, 'f1_score': 0.18217914218243726, 'confusion_matrix': array([[ 32,   0, 169,   0,   0,   0,   0],
       [  8,   0, 101,   0,   0,   0,   0],
       [ 19,   0, 113,   0,   0,   0,   0],
       [  6,   0,  35,   0,   0,   0,   0],
       [  6,   0,  44,   0,   0,   0,   0],
       [  3,   0,  41,   0,   0,   0,   0],
       [  3,   0,  20,   0,   0,   0,   0]]), 'forgetting_measure': [0.37233723, 0.08849839, 0.13737848]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b1e990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41190456, 'precision': 0.20294352903535434, 'recall': 0.24374077857223924, 'f1_score': 0.154730656275765614, 'confusion_matrix': array([[  0, 197,   2,   0,   0,   0,   0],
       [  0, 197,   1,   0,   0,   0,   0],
       [  1, 263,   3,   0,   0,   0,   0],
       [  0,  62,   0,   0,   0,   0,   0],
       [  0,  74,   0,   0,   0,   0,   0],
       [  0,  41,   0,   0,   0,   0,   0],
       [  0,  59,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.41634322, 0.43289697, 0.21977791]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b1e990>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43023534, 'precision': 0.136190476190476197, 'recall': 0.24285714285714285, 'f1_score': 0.157750759878419454, 'confusion_matrix': array([[  0, 133,   0,   0,   0,   0,   0],
       [  0, 152,   0,   0,   0,   0,   0],
       [  0, 164,   0,   0,   0,   0,   0],
       [  0,  49,   0,   0,   0,   0,   0],
       [  0,  35,   0,   0,   0,   0,   0],
       [  0,  28,   0,   0,   0,   0,   0],
       [  0,  39,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.40942634, 0.36622646, 0.055749014]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a2a190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317358890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37805612, 'precision': 0.126378515811218813, 'recall': 0.2420017108639863, 'f1_score': 0.14449209327258108, 'confusion_matrix': array([[  0,   0, 301,   0,   0,   0,   0],
       [  0,   0, 205,   0,   0,   0,   0],
       [  0,   1, 166,   0,   0,   0,   0],
       [  0,   0,  90,   0,   0,   0,   0],
       [  0,   0,  37,   0,   0,   0,   0],
       [  0,   0,  41,   0,   0,   0,   0],
       [  0,   0,  59,   0,   0,   0,   0]]), 'forgetting_measure': [0.31588397, 0.1459612, 0.273696]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a2a190>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317358890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4821315, 'precision': 0.137142857142857144, 'recall': 0.24285714285714285, 'f1_score': 0.15895691609977325, 'confusion_matrix': array([[  0,   0, 175,   0,   0,   0,   0],
       [  0,   0, 117,   0,   0,   0,   0],
       [  0,   0, 156,   0,   0,   0,   0],
       [  0,   0,  59,   0,   0,   0,   0],
       [  0,   0,  26,   0,   0,   0,   0],
       [  0,   0,  17,   0,   0,   0,   0],
       [  0,   0,  50,   0,   0,   0,   0]]), 'forgetting_measure': [0.46389053, 0.24875775, 0.23497786]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e44596d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d5641ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39201833, 'precision': 0.32652604666027484, 'recall': 0.24373402734589, 'f1_score': 0.14813136208905343, 'confusion_matrix': array([[166,   0,   1,   0,   0,   0,   0],
       [155,   1,   2,   0,   0,   0,   0],
       [343,   0,   2,   0,   0,   0,   0],
       [ 84,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3777445, 0.47277886, -0.03718402]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551e44596d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551d5641ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33481769, 'precision': 0.120714285714285713, 'recall': 0.24285714285714285, 'f1_score': 0.136182158452900806, 'confusion_matrix': array([[ 87,   0,   0,   0,   0,   0,   0],
       [101,   0,   0,   0,   0,   0,   0],
       [257,   0,   0,   0,   0,   0,   0],
       [ 41,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0],
       [ 27,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.28243647, 0.2957985, 0.27186835]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ce259ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ce0bf750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44550405, 'precision': 0.1771129812078088, 'recall': 0.21857067562052277, 'f1_score': 0.18262225837763734, 'confusion_matrix': array([[  0, 124,  95,   0,   0,   0,   2,  13],
       [  0, 106,  77,   0,   0,   0,   2,   6],
       [  0, 141,  92,   0,   1,   0,   1,  11],
       [  0,  15,  36,   0,   0,   0,   1,   4],
       [  0,  20,  49,   0,   0,   0,   0,   4],
       [  0,   0,  42,   0,   0,   0,   0,   7],
       [  0,   0,  41,   0,   0,   0,   1,   9],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38886968, 0.1866985, 0.09463695]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1551ce259ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1551ce0bf750>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43800217, 'precision': 0.20298304775792927, 'recall': 0.22306773987101857, 'f1_score': 0.19883905619190744, 'confusion_matrix': array([[ 0, 64, 61,  0,  0,  0,  1, 14],
       [ 0, 56, 62,  0,  0,  0,  2,  6],
       [ 0, 87, 84,  0,  0,  0,  2, 10],
       [ 0,  1, 35,  0,  0,  0,  0,  2],
       [ 0,  3, 38,  0,  0,  0,  1,  4],
       [ 0,  0, 23,  0,  0,  0,  1,  6],
       [ 0,  0, 22,  0,  0,  0,  3, 12],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.34121681, 0.070454046, -0.10857728]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed5d6710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecc53a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4864464, 'precision': 0.23206845238095238, 'recall': 0.24253220818255138, 'f1_score': 0.160244527394660255, 'confusion_matrix': array([[  2, 315,   0,   0,   0,   0,   0],
       [  1, 231,   1,   0,   0,   0,   0],
       [  0, 120,   0,   0,   0,   0,   0],
       [  0,  73,   0,   0,   0,   0,   0],
       [  0,  57,   0,   0,   0,   0,   0],
       [  0,  53,   0,   0,   0,   0,   0],
       [  0,  47,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.50969846, 0.40389878, 0.1588833]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed5d6710>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecc53a90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49692754, 'precision': 0.14238095238095239, 'recall': 0.24285714285714285, 'f1_score': 0.16536907822254866, 'confusion_matrix': array([[  0, 196,   0,   0,   0,   0,   0],
       [  0, 178,   0,   0,   0,   0,   0],
       [  0,  72,   0,   0,   0,   0,   0],
       [  0,  45,   0,   0,   0,   0,   0],
       [  0,  42,   0,   0,   0,   0,   0],
       [  0,  31,   0,   0,   0,   0,   0],
       [  0,  36,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.50167332, 0.27651277, 0.31693023]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed885a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f6bab010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41413088, 'precision': 0.4156220171810372, 'recall': 0.2440678826521547, 'f1_score': 0.15187182298193476, 'confusion_matrix': array([[  1, 213,   0,   0,   0,   0,   0],
       [  0, 188,   0,   0,   0,   0,   0],
       [  0, 262,   1,   0,   0,   0,   0],
       [  0,  86,   0,   0,   0,   0,   0],
       [  0,  49,   0,   0,   0,   0,   0],
       [  0,  47,   0,   0,   0,   0,   0],
       [  0,  53,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4098432, 0.3985719, 0.21544273]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed885a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f6bab010>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46530725, 'precision': 0.137142857142857144, 'recall': 0.24285714285714285, 'f1_score': 0.15895691609977325, 'confusion_matrix': array([[  0, 129,   0,   0,   0,   0,   0],
       [  0, 156,   0,   0,   0,   0,   0],
       [  0, 160,   0,   0,   0,   0,   0],
       [  0,  53,   0,   0,   0,   0,   0],
       [  0,  35,   0,   0,   0,   0,   0],
       [  0,  23,   0,   0,   0,   0,   0],
       [  0,  44,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.40942634, 0.062313817, 0.32326674]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed4b8a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e78edb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37421791, 'precision': 0.21150241066328659, 'recall': 0.3380216350323336, 'f1_score': 0.19789381353359412, 'confusion_matrix': array([[  0,  23,  19, 123,   0,  34,   0],
       [  0,  15,  25, 150,   0,  37,   0],
       [  0,  20,  31, 138,   0,  42,   0],
       [  0,  10,   0,  50,   0,  12,   0],
       [  0,   6,   0,  47,   0,  18,   0],
       [  0,   8,   0,   0,   0,  27,   0],
       [  0,  25,   0,   0,   0,  40,   0]]), 'forgetting_measure': [0.31392862, 0.1829149, 0.23381704]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ed4b8a90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e78edb90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.19314181, 'precision': 0.159835004497882704, 'recall': 0.3309145880574452, 'f1_score': 0.153073502043753766, 'confusion_matrix': array([[  0,   6,   0,  92,   0,  29,   0],
       [  0,   4,   0, 125,   0,  39,   0],
       [  0,   1,   0, 105,   0,  30,   0],
       [  0,   3,   0,  32,   0,  19,   0],
       [  0,   3,   0,  29,   0,  16,   0],
       [  0,   0,   0,   0,   0,  20,   0],
       [  0,   0,   0,   0,   0,  47,   0]]), 'forgetting_measure': [0.1, 0, 0.5401097]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d4e86fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d4fdffd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43078068, 'precision': 0.25361275578459432, 'recall': 0.2777666400972218, 'f1_score': 0.26386544950709772, 'confusion_matrix': array([[ 52,  38, 121,   0,  14,   0,   7],
       [ 42,  44,  94,   0,  11,   0,  11],
       [ 54,  54, 110,   0,  17,   0,   6],
       [ 34,  10,   2,   0,  11,   0,   0],
       [ 34,  10,   9,   0,  11,   0,   4],
       [  0,  50,   0,   0,   4,   0,   8],
       [  0,  29,   0,   0,   2,   0,   7]]), 'forgetting_measure': [0.4410639, 0.33886287, 0.4421566]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d4e86fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d4fdffd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44338888, 'precision': 0.24963980644842742, 'recall': 0.2822395643873959, 'f1_score': 0.26217825807956368, 'confusion_matrix': array([[38, 41, 76,  0, 20,  0, 10],
       [36, 24, 60,  0,  6,  0,  7],
       [28, 24, 64,  0,  5,  0, 11],
       [22,  9,  0,  0,  7,  0,  2],
       [28,  4,  0,  0, 10,  0,  1],
       [ 0, 31,  0,  0,  0,  0,  7],
       [ 0, 24,  0,  0,  0,  0,  5]]), 'forgetting_measure': [0.4453122, 0.2712238, 0.47070807]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a4fcd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4581590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46281285, 'precision': 0.20929048679605471, 'recall': 0.24298827719970236, 'f1_score': 0.16124950979832248, 'confusion_matrix': array([[  0,   0, 233,   0,   0,   0,   0],
       [  0,   1, 195,   0,   0,   0,   0],
       [  0,   1, 238,   0,   0,   0,   0],
       [  0,   0,  73,   0,   0,   0,   0],
       [  0,   0,  59,   0,   0,   0,   0],
       [  0,   0,  58,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0]]), 'forgetting_measure': [0.447175, 0.26147008, 0.2789978]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a4fcd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f4581590>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46007932, 'precision': 0.136190476190476197, 'recall': 0.24285714285714285, 'f1_score': 0.157750759878419454, 'confusion_matrix': array([[  0,   0, 153,   0,   0,   0,   0],
       [  0,   0, 136,   0,   0,   0,   0],
       [  0,   0, 152,   0,   0,   0,   0],
       [  0,   0,  30,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0],
       [  0,   0,  24,   0,   0,   0,   0]]), 'forgetting_measure': [0.4453122, 0.39736092, -0.08999816]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dc81ddd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dc368650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38748806, 'precision': 0.19168793970082906, 'recall': 0.18165258528314163, 'f1_score': 0.18183536716771725, 'confusion_matrix': array([[ 35,  12,  91,   0,   0,  24,  20,  31],
       [ 35,  11,  81,   0,   0,  22,  14,  30],
       [ 47,  15, 111,   0,   0,  25,  14,  45],
       [ 10,   6,   8,   0,   0,  15,  14,  17],
       [  5,   5,  11,   0,   0,  17,  15,  14],
       [  0,  13,  24,   0,   0,   0,   0,  12],
       [  0,  14,  17,   0,   0,   0,   0,  20],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4383666, 0.6927154, -0.15530603]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dc81ddd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dc368650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36003966, 'precision': 0.19468810916179338, 'recall': 0.17494524569358535, 'f1_score': 0.16257511329485954, 'confusion_matrix': array([[ 3, 17, 72,  0,  0, 21,  3, 20],
       [ 3, 10, 83,  0,  0, 21,  7, 31],
       [ 3, 15, 79,  0,  0, 28,  6, 23],
       [ 0,  6,  3,  0,  0, 23,  4, 17],
       [ 0,  1,  5,  0,  0,  9,  5, 15],
       [ 0, 11,  8,  0,  0,  0,  0,  7],
       [ 0, 16, 20,  0,  0,  0,  0,  5],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.42773137, 1.0, 0]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7d0f950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed4bb290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43567763, 'precision': 0.23615130437557083, 'recall': 0.23821295133061579, 'f1_score': 0.21069288444364857, 'confusion_matrix': array([[ 23,  26, 119,  34,   0,   4,   0],
       [ 31,  38, 152,  41,   1,   2,   0],
       [ 27,  20, 115,  34,   3,   0,   0],
       [  1,  11,  47,   8,   0,   0,   0],
       [  1,   7,  49,   6,   0,   0,   0],
       [  1,  22,   4,  35,   3,   1,   0],
       [  2,  12,   4,  14,   1,   1,   0]]), 'forgetting_measure': [0.432178, 0.33404687, 0.3054723]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7d0f950>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed4bb290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41403107, 'precision': 0.2876394505075892, 'recall': 0.26067391376690862, 'f1_score': 0.2072248280781531, 'confusion_matrix': array([[  5,   7, 110,  36,   1,   1,   0],
       [  6,  13, 108,  32,   3,   1,   0],
       [  0,   4,  85,  25,   1,   2,   0],
       [  1,   3,  33,  11,   0,   1,   0],
       [  1,   5,  27,  10,   1,   0,   0],
       [  4,  10,   0,  34,   0,   2,   0],
       [  2,   2,   0,  13,   0,   0,   0]]), 'forgetting_measure': [0.44145364, 0.5071749, 0.21342398]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d524d150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3375b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43073891, 'precision': 0.21754475386903232, 'recall': 0.21705667847308347, 'f1_score': 0.20918893148845962, 'confusion_matrix': array([[97, 68, 19, 10,  3, 14,  2,  0,  4,  2],
       [63, 63, 24, 34,  3,  9,  0,  3,  3,  2],
       [97, 75, 35,  6, 12,  8,  3,  0,  7,  2],
       [37,  9, 15,  3,  1,  6,  1,  1,  0,  1],
       [41,  6,  0,  2,  1,  3,  1,  1,  1,  2],
       [11, 20,  0,  2,  1, 12,  0,  0,  4,  5],
       [14,  7,  2,  6,  1, 11,  0,  1,  1,  2],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.37857032, 0.31777543, -0.17654213]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d524d150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3375b90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38633354, 'precision': 0.20424921615233021, 'recall': 0.2103807091872631, 'f1_score': 0.19980662957678008, 'confusion_matrix': array([[48, 30, 22,  8,  2,  5,  2,  2,  0,  2],
       [58, 33, 33,  5,  6,  6,  0,  0,  6,  1],
       [58, 41, 28, 14,  6, 13,  1,  1,  4,  6],
       [33,  9,  1,  3,  5,  3,  0,  0,  1,  1],
       [21,  4,  1,  2,  1,  4,  1,  0,  2,  0],
       [ 0, 12,  0,  0,  1,  6,  0,  1,  3,  2],
       [ 1, 21,  1,  0,  0,  7,  0,  1,  7,  4],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.3835159, 0.5082502, 0.024050249]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552adc0d410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c3bc40d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4758407, 'precision': 0.21223528913485428, 'recall': 0.2471907953203604, 'f1_score': 0.22351772395575027, 'confusion_matrix': array([[ 24,  76,  67,   0,   0,   0,   0],
       [ 54, 185,  99,   0,   0,   0,   0],
       [ 22,  89,  57,   0,   0,   0,   0],
       [  2,  23,  22,   0,   0,   0,   0],
       [  3,  46,  31,   0,   0,   0,   0],
       [  6,  24,  21,   0,   0,   0,   0],
       [  3,  23,  23,   0,   0,   0,   0]]), 'forgetting_measure': [0.40770433, -0.1588886, 0.54227436]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552adc0d410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c3bc40d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50478022, 'precision': 0.20471212294441587, 'recall': 0.24208189367883464, 'f1_score': 0.2194146747465679, 'confusion_matrix': array([[ 18,  65,  20,   0,   0,   0,   0],
       [ 52, 149,  49,   1,   0,   0,   0],
       [ 13,  52,  19,   0,   0,   0,   0],
       [  0,  14,  14,   0,   0,   0,   0],
       [  2,  34,  31,   0,   0,   0,   0],
       [  6,  25,   7,   0,   0,   0,   0],
       [  7,  18,   4,   0,   0,   0,   0]]), 'forgetting_measure': [0.46053672, -0.034220327, 0.5147709]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e31ca1d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ca144350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46086733, 'precision': 0.25268969600736287, 'recall': 0.2623125575977243, 'f1_score': 0.23986325741653471, 'confusion_matrix': array([[ 26, 126,  16,   0,  29,   0,   4],
       [ 25, 161,  28,   0,  47,   0,   9],
       [ 24, 116,  25,   0,  17,   0,   6],
       [  0,  43,  12,   0,   8,   0,   1],
       [  0,  47,  14,   0,  16,   0,   0],
       [  0,   0,  13,   0,  38,   0,   6],
       [  0,   0,  15,   0,  25,   0,   3]]), 'forgetting_measure': [0.48530627, 0.46807313, 0.061544403]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning GEM with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e31ca1d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ca144350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39770007, 'precision': 0.17713391203557884, 'recall': 0.2387670857816811, 'f1_score': 0.18774837034843137, 'confusion_matrix': array([[  0,  99,  10,   0,  27,   0,   3],
       [  0, 110,   9,   0,  44,   0,   7],
       [  0, 101,   4,   0,  29,   0,   6],
       [  0,  30,   5,   0,   7,   0,   0],
       [  0,  28,   4,   0,   8,   0,   2],
       [  0,   0,   0,   0,  39,   0,   9],
       [  0,   0,   0,   1,  16,   0,   2]]), 'forgetting_measure': [0.42635444, 0.27271497, 0.876163]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df8410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155342ee4510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4660044, 'precision': 0.2911146325371682, 'recall': 0.28291551011454077, 'f1_score': 0.2695317182490735, 'confusion_matrix': array([[ 23,  66,  88,  10,   0,   2,  10],
       [ 23,  72,  94,  19,   0,   1,   6],
       [ 28,  81, 110,  14,   0,   2,  23],
       [  0,  41,  17,  16,   0,   0,   6],
       [  1,  27,  12,   6,   0,   0,   2],
       [  0,   1,  43,   0,   0,   1,  12],
       [  1,   2,  31,   0,   0,   1,   8]]), 'forgetting_measure': [0.5053856, 0.36659378, 0.47091997]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316df8410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155342ee4510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4641506, 'precision': 0.33436127142734084, 'recall': 0.26596299497000522, 'f1_score': 0.25748957028307053, 'confusion_matrix': array([[17, 51, 53,  1,  0,  1,  5],
       [19, 57, 63,  2,  0,  0,  5],
       [21, 65, 77,  2,  0,  1,  5],
       [ 0, 46, 13,  4,  0,  0,  3],
       [ 0, 16,  4,  1,  0,  0,  1],
       [ 0,  0, 35,  0,  0,  2,  5],
       [ 0,  0, 21,  0,  0,  2,  2]]), 'forgetting_measure': [0.39630828, 0.11068764, 0.11717829]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a0ba90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a81350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50929273, 'precision': 0.146825396825396826, 'recall': 0.24285714285714285, 'f1_score': 0.17053197848176927, 'confusion_matrix': array([[295,   0,   0,   0,   0,   0,   0],
       [251,   0,   0,   0,   0,   0,   0],
       [125,   0,   0,   0,   0,   0,   0],
       [ 59,   0,   0,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.52524552, 0.39770067, 0.03754981]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a0ba90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a81350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53134338, 'precision': 0.147142857142857146, 'recall': 0.24285714285714285, 'f1_score': 0.17089151450053706, 'confusion_matrix': array([[198,   0,   0,   0,   0,   0,   0],
       [160,   0,   0,   0,   0,   0,   0],
       [ 81,   0,   0,   0,   0,   0,   0],
       [ 35,   0,   0,   0,   0,   0,   0],
       [ 59,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51268337, 0.17934377, 0.2834477]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec79dc90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ec045a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.500672, 'precision': 0.141361756283805284, 'recall': 0.24230979748221126, 'f1_score': 0.16409466288672501, 'confusion_matrix': array([[  0,   0, 216,   0,   0,   0,   0],
       [  1,   0, 193,   0,   0,   0,   0],
       [  1,   0, 260,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0],
       [  0,   0,  67,   0,   0,   0,   0],
       [  0,   0,  54,   0,   0,   0,   0],
       [  0,   0,  46,   0,   0,   0,   0]]), 'forgetting_measure': [0.50414646, 0.30197248, 0.2351647]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec79dc90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ec045a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49251727, 'precision': 0.14476190476190477, 'recall': 0.24285714285714285, 'f1_score': 0.16816533720087019, 'confusion_matrix': array([[  0,   0, 140,   0,   0,   0,   0],
       [  0,   0, 109,   0,   0,   0,   0],
       [  0,   0, 188,   0,   0,   0,   0],
       [  0,   0,  54,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0],
       [  0,   0,  27,   0,   0,   0,   0],
       [  0,   0,  40,   0,   0,   0,   0]]), 'forgetting_measure': [0.5050715, 0.32110822, 0.2818879]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e436dc90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f28dfa50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48464702, 'precision': 0.22240163915489377, 'recall': 0.23885753653226365, 'f1_score': 0.21788792440052945, 'confusion_matrix': array([[ 24, 124,  34,   0,   1,   4,   0],
       [ 27, 179,  66,   0,   1,  15,   0],
       [ 26, 118,  34,   1,   3,  12,   0],
       [  1,  49,  13,   0,   1,   7,   0],
       [  1,  36,  17,   0,   0,   6,   0],
       [  3,  57,   1,   0,   0,   3,   0],
       [  1,  33,   1,   0,   0,   1,   0]]), 'forgetting_measure': [0.39713842, -0.112297095, 0.3153034]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e436dc90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f28dfa50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47131176, 'precision': 0.19553528723294048, 'recall': 0.25503958407184215, 'f1_score': 0.21200705163535062, 'confusion_matrix': array([[  0,  89,  42,   0,   1,   8,   0],
       [  0, 109,  37,   0,   2,   7,   0],
       [  0,  97,  44,   0,   1,  14,   0],
       [  0,  18,  14,   0,   1,   6,   0],
       [  0,  19,  17,   0,   0,   7,   0],
       [  0,  45,   0,   0,   0,   5,   0],
       [  0,  17,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42305595, 0.18673715, 0.1316167]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552edade390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552edd7f650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47858818, 'precision': 0.2899776500953103, 'recall': 0.26044572380614036, 'f1_score': 0.2487617593430821, 'confusion_matrix': array([[68, 81, 37, 24,  3,  0,  5,  1],
       [52, 98, 73, 23,  4,  0,  9,  1],
       [47, 65, 43, 18,  6,  4,  5,  2],
       [ 8, 10,  5,  7,  1,  0,  0,  0],
       [38, 29, 24,  5,  2,  0,  1,  1],
       [11,  3, 13, 16,  7,  3,  5,  1],
       [ 6,  5, 15,  7,  3,  0,  3,  2],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.44324142, -0.07893849, 0.6700655]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552edade390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552edd7f650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42884333, 'precision': 0.28834791971756965, 'recall': 0.25958507138447273, 'f1_score': 0.25742112928208024, 'confusion_matrix': array([[33, 53, 19, 13,  6,  1,  4,  2],
       [50, 66, 29, 11,  2,  1,  5,  2],
       [34, 53, 32, 11,  4,  2,  4,  1],
       [ 8, 10,  3,  4,  1,  1,  2,  0],
       [17, 16, 15, 13,  3,  0,  2,  0],
       [ 7,  2,  4, 11,  4,  2,  5,  1],
       [ 7,  6,  3,  8,  1,  0,  5,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.49364493, 0.5335777, 0.40480715]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e4d715d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e503eed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.61250062, 'precision': 0.26589413065995287, 'recall': 0.26202535948319813, 'f1_score': 0.24750459688000073, 'confusion_matrix': array([[ 90,  92,   1,   4,   2,   5,   5,   0,   3],
       [ 50, 269,   5,   1,   3,  12,  12,   1,   1],
       [ 33,  68,   2,   0,   3,   1,   2,   0,   2],
       [ 17,  47,   0,   0,   5,   1,   4,   0,   0],
       [ 18,  30,   1,   0,   2,   3,   5,   0,   0],
       [ 11,  28,   1,   0,   0,   4,   5,   0,   2],
       [  9,  29,   0,   1,   0,   4,   6,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.61529706, 0.21826297, 0.20715809]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e4d715d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e503eed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51990254, 'precision': 0.2727296691347097, 'recall': 0.25190534634262692, 'f1_score': 0.23926564710299374, 'confusion_matrix': array([[ 28,  94,   2,   1,   0,   2,   4,   2],
       [ 51, 149,   2,   0,   6,   7,   3,   2],
       [ 19,  56,   1,   2,   0,   2,   2,   1],
       [ 19,  31,   1,   1,   2,   1,   0,   1],
       [ 16,  16,   1,   1,   1,   4,   2,   0],
       [  8,   8,   0,   1,   0,   4,   6,   0],
       [ 10,  20,   0,   1,   0,   3,   5,   1],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.58974183, 0.34934, 0.52515996]}","{""Task 0 had these additional classes included:"": [""four"", ""go"", ""happy""], ""Task 1 had these additional classes included:"": [""house"", ""left""], ""Task 2 had these additional classes included:"": [""marvel"", ""nine""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cd332550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c40f3210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42996038, 'precision': 0.20453288264060331, 'recall': 0.2410867606624598, 'f1_score': 0.21443483015288518, 'confusion_matrix': array([[ 45, 131,  45,   0,   0,   0,   0],
       [ 52, 142,  50,   0,   0,   0,   0],
       [ 49, 109,  40,   0,   0,   0,   0],
       [ 19,  43,  11,   0,   0,   0,   0],
       [ 13,  47,   4,   0,   0,   0,   0],
       [ 14,  13,   1,   0,   0,   0,   0],
       [ 42,  29,   1,   0,   0,   0,   0]]), 'forgetting_measure': [0.4416234, 0.38838527, 0.33323175]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cd332550>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c40f3210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47022323, 'precision': 0.2036684525296218, 'recall': 0.23937861126769316, 'f1_score': 0.21568812140240711, 'confusion_matrix': array([[35, 69, 37,  0,  0,  0,  0],
       [40, 81, 37,  0,  0,  0,  0],
       [45, 72, 32,  0,  0,  0,  0],
       [10, 17,  9,  0,  0,  0,  0],
       [13, 27,  9,  0,  0,  0,  0],
       [ 8,  7,  0,  0,  0,  0,  0],
       [33, 19,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.47832597, 0.2088663, 0.5555148]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d97b6390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0014ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42576094, 'precision': 0.25453009336012005, 'recall': 0.251420536298757, 'f1_score': 0.24270244834813126, 'confusion_matrix': array([[ 92,  58,  59,  11,   1,   0,   0],
       [ 80,  48,  61,   8,   4,   0,   0],
       [107,  51,  56,  14,   8,   0,   0],
       [ 35,   9,  17,   8,   4,   0,   0],
       [ 28,  14,  16,   7,   4,   0,   0],
       [ 39,   3,   7,   0,   0,   0,   0],
       [ 37,   4,  10,   0,   0,   0,   0]]), 'forgetting_measure': [0.4188051, 0.44559297, -0.028187785]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d97b6390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e0014ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42597896, 'precision': 0.22494244844290457, 'recall': 0.2394996935125386, 'f1_score': 0.22568548216495531, 'confusion_matrix': array([[51, 44, 36,  6,  0,  0,  0],
       [69, 47, 37,  2,  0,  0,  0],
       [61, 51, 37,  7,  0,  0,  0],
       [22,  7, 15,  3,  0,  0,  0],
       [21,  8,  6,  3,  0,  0,  0],
       [19,  1,  7,  0,  0,  0,  0],
       [28,  4,  8,  0,  0,  0,  0]]), 'forgetting_measure': [0.4514189, 0.41813585, 0.4031644]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cdd3e650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da889910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50701596, 'precision': 0.26604912287843088, 'recall': 0.30269781920106889, 'f1_score': 0.27648685199083086, 'confusion_matrix': array([[ 35,  45,  75,  12,   0,  23,   3,   1],
       [ 23, 122,  95,  17,   3,  20,   0,   0],
       [ 31,  45,  79,  15,   1,  26,   0,   1],
       [  7,  16,  10,   5,   0,   1,   0,   0],
       [ 16,  27,  26,  13,   0,   7,   0,   0],
       [ 10,  11,  11,   1,   0,  33,   2,   1],
       [  5,   3,   4,   1,   0,  18,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.47798113, 0.18430598, 0.238609]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cdd3e650>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552da889910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48100803, 'precision': 0.24272884373690825, 'recall': 0.29476292851289595, 'f1_score': 0.25642373225242717, 'confusion_matrix': array([[18, 29, 46,  8,  0, 13,  0,  0],
       [25, 58, 63, 16,  1, 19,  0,  1],
       [21, 36, 53, 18,  1, 19,  0,  1],
       [ 3,  8,  3,  7,  1,  2,  0,  0],
       [ 5, 24, 11, 13,  0, 10,  0,  0],
       [ 2, 17,  3,  0,  0, 17,  0,  0],
       [ 3, 14,  1,  0,  0, 10,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.47683976, 0.3531033, 0.08765592]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b97f1510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b965b290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41759415, 'precision': 0.19680347641163316, 'recall': 0.24505040755040755, 'f1_score': 0.17419431933774004, 'confusion_matrix': array([[ 22, 194,   8,   0,   0,   0,   0],
       [ 15, 166,   4,   0,   0,   0,   0],
       [ 31, 216,   5,   0,   0,   0,   0],
       [  2,  59,   3,   0,   0,   0,   0],
       [  8,  64,   3,   0,   0,   0,   0],
       [  3,  53,   2,   0,   0,   0,   0],
       [  1,  41,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.40433264, 0.3355514, 0.27682152]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b97f1510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b965b290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39515145, 'precision': 0.21819727891156462, 'recall': 0.24614188862442096, 'f1_score': 0.16340864139725619, 'confusion_matrix': array([[  6, 152,   1,   0,   0,   0,   0],
       [  3, 110,   2,   0,   0,   0,   0],
       [  9, 160,   5,   0,   0,   0,   0],
       [  2,  42,   0,   0,   0,   0,   0],
       [  3,  37,   1,   0,   0,   0,   0],
       [  1,  27,   3,   0,   0,   0,   0],
       [  4,  32,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38677753, 0.38971898, 0.29342037]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d6716d90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d0c77a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.436499, 'precision': 0.13146353090735738, 'recall': 0.24285714285714285, 'f1_score': 0.15156921474150279, 'confusion_matrix': array([[  0, 245,   0,   0,   0,   0,   0],
       [  0, 198,   0,   0,   0,   0,   0],
       [  1, 217,   0,   0,   0,   0,   0],
       [  0,  69,   0,   0,   0,   0,   0],
       [  0,  70,   0,   0,   0,   0,   0],
       [  0,  55,   0,   0,   0,   0,   0],
       [  0,  45,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4440926, 0.45250586, 0.060370333]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d6716d90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d0c77a50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41971972, 'precision': 0.133095238095238094, 'recall': 0.24285714285714285, 'f1_score': 0.153740576068045616, 'confusion_matrix': array([[  0, 176,   0,   0,   0,   0,   0],
       [  0, 139,   0,   0,   0,   0,   0],
       [  0, 121,   0,   0,   0,   0,   0],
       [  0,  41,   0,   0,   0,   0,   0],
       [  0,  56,   0,   0,   0,   0,   0],
       [  0,  43,   0,   0,   0,   0,   0],
       [  0,  24,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.39009384, 0.29092062, 0.2058041]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e274c7d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e2a43b10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5755137, 'precision': 0.38194939177757783, 'recall': 0.37819334769982823, 'f1_score': 0.3620750551762822, 'confusion_matrix': array([[ 68,  13,  80,  18,   1,   0,  16],
       [ 23,  46, 106,  18,   6,   0,   7],
       [ 24,  19, 195,  16,   2,   1,  11],
       [  7,   6,  39,  10,   3,   1,   1],
       [  9,   5,  36,  10,   1,   0,   2],
       [  0,   9,  22,   0,   0,   0,   5],
       [ 13,   0,  20,   0,   0,   0,  31]]), 'forgetting_measure': [0.50603817, 0.13135497, -0.042803694]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e274c7d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e2a43b10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44964699, 'precision': 0.27511274449989028, 'recall': 0.28374174255144654, 'f1_score': 0.26497611497348588, 'confusion_matrix': array([[28, 15, 72, 16,  3,  0,  7],
       [23, 11, 78, 15,  1,  0,  8],
       [36, 17, 85, 19,  3,  2, 10],
       [ 9,  4, 11, 11,  4,  0,  0],
       [ 9,  9, 14, 11,  2,  0,  0],
       [ 2,  1, 15,  0,  0,  0,  6],
       [ 4,  4, 27,  0,  0,  0,  8]]), 'forgetting_measure': [0.4359617, 0.3271937, 0.17295817]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d5c87510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5e0f250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43351723, 'precision': 0.15032583975886378, 'recall': 0.2407144733385868, 'f1_score': 0.17272037380340629, 'confusion_matrix': array([[154,   0,   0,  52,   0,   0,   0,  24,   5],
       [158,   0,   0,  47,   0,   0,   0,  22,  12],
       [115,   0,   0,  48,   0,   0,   0,  20,  10],
       [ 14,   0,   0,  33,   0,   0,   0,   6,   1],
       [ 24,   0,   0,  43,   0,   0,   0,  10,   2],
       [ 17,   0,   0,   0,   0,   0,   0,  13,  12],
       [ 23,   0,   0,   0,   0,   0,   0,  26,   9],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42239068, 0.44608706, -0.1176433]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d5c87510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5e0f250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38878128, 'precision': 0.148623097663609394, 'recall': 0.21764705882352941, 'f1_score': 0.168580515092143, 'confusion_matrix': array([[ 76,   0,   0,  32,   0,   0,   0,  24,   4],
       [105,   0,   0,  29,   0,   0,   0,  27,  12],
       [ 81,   0,   0,  27,   0,   0,   0,  19,   7],
       [ 11,   0,   0,  24,   0,   0,   0,   8,   5],
       [ 12,   0,   0,  22,   0,   0,   0,   5,   3],
       [  3,   0,   0,   0,   0,   0,   0,  20,   8],
       [  6,   0,   0,   0,   0,   0,   0,  18,  12],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4100948, 0.3837323, 0.65909404]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d6d9c890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6c07d50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47725172, 'precision': 0.24195595449326795, 'recall': 0.2565039861828051, 'f1_score': 0.23399499157379458, 'confusion_matrix': array([[ 18, 131,  41,   0,   0,  12,   0],
       [ 21, 162,  76,   0,   0,   8,   0],
       [ 25, 126,  38,   1,   1,   9,   0],
       [  0,  31,  10,   0,   0,   2,   0],
       [  1,  75,   7,   0,   0,   5,   0],
       [  2,  25,  22,   0,   0,  13,   0],
       [  0,  22,  15,   0,   0,   1,   0]]), 'forgetting_measure': [0.4707591, 0.28578797, 0.25908232]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d6d9c890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6c07d50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4673958, 'precision': 0.2416406510219823, 'recall': 0.26945991352006387, 'f1_score': 0.24522801103841962, 'confusion_matrix': array([[ 16,  58,  31,   0,   0,   7,   0],
       [ 23, 103,  41,   0,   0,   8,   0],
       [ 16,  96,  34,   0,   0,  10,   0],
       [  0,  19,   3,   0,   0,   1,   0],
       [  1,  54,   8,   0,   0,   4,   0],
       [  1,  11,  17,   0,   0,   9,   0],
       [  1,   6,  13,   0,   0,   9,   0]]), 'forgetting_measure': [0.41523585, 0.090092614, 0.30233115]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552abdb1510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552abf79910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4510115, 'precision': 0.1334920634920635, 'recall': 0.24285714285714285, 'f1_score': 0.15426256911405426, 'confusion_matrix': array([[211,   0,   0,   0,   0,   0,   0],
       [200,   0,   0,   0,   0,   0,   0],
       [252,   0,   0,   0,   0,   0,   0],
       [ 67,   0,   0,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0],
       [ 55,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.39638565, 0.13208036, 0.22480671]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552abdb1510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552abf79910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43653427, 'precision': 0.130714285714285715, 'recall': 0.24285714285714285, 'f1_score': 0.15055849500293945, 'confusion_matrix': array([[129,   0,   0,   0,   0,   0,   0],
       [118,   0,   0,   0,   0,   0,   0],
       [197,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 29,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.45371172, 0.495873, 0.00415065]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d0fdc7d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1058510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51926847, 'precision': 0.3771339855452005, 'recall': 0.35272404269323817, 'f1_score': 0.34706666911017544, 'confusion_matrix': array([[ 68,  43,  66,   3,   2,   2,  21],
       [ 40, 140,  57,   2,  20,   5,   6],
       [ 43,  65,  59,   2,   6,   2,   8],
       [ 13,  28,   9,   3,   4,   0,   5],
       [  3,  41,  14,   0,  13,   2,   5],
       [  3,  36,   5,   3,   0,   4,   8],
       [  0,  17,   4,   2,   0,   5,  13]]), 'forgetting_measure': [0.531622, 0.28308442, 0.29954332]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d0fdc7d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d1058510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46774192, 'precision': 0.32750881357785763, 'recall': 0.33273727146793263, 'f1_score': 0.30000187369997288, 'confusion_matrix': array([[20, 54, 51,  3, 14,  7, 15],
       [18, 50, 49,  2,  7,  2, 10],
       [15, 57, 55,  2,  4,  5,  7],
       [ 3, 14,  7,  1, 10,  0,  3],
       [ 2, 15, 16,  1,  9,  0,  5],
       [ 1, 16,  5,  3,  0,  7, 18],
       [ 0,  5,  4,  1,  0,  0,  7]]), 'forgetting_measure': [0.4922657, 0.46001104, 0.059853844]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b28fccd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b291d2d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.60021485, 'precision': 0.30818706162603487, 'recall': 0.326089858076257, 'f1_score': 0.3124815451427969, 'confusion_matrix': array([[144,  39,  47,   4,  21,   0,   0],
       [ 73,  55,  33,   8,  15,   0,   0],
       [ 44,  24, 132,   2,  27,   0,   0],
       [ 31,   8,  11,   2,   6,   0,   0],
       [ 46,   6,   9,   5,   8,   0,   0],
       [ 25,   4,  11,   8,  24,   0,   0],
       [  8,   1,   4,   3,  12,   0,   0]]), 'forgetting_measure': [0.53298405, -0.07611202, 0.35244548]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552b28fccd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b291d2d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39732322, 'precision': 0.22352295056161565, 'recall': 0.23578537825672699, 'f1_score': 0.22540845302098338, 'confusion_matrix': array([[68, 25, 59,  8, 29,  0,  0],
       [43, 15, 26,  9, 16,  0,  0],
       [62, 17, 39,  6, 24,  0,  0],
       [16,  9,  8,  1,  4,  0,  0],
       [19,  5, 16,  1,  8,  0,  0],
       [10,  0,  7,  4, 25,  0,  0],
       [ 4,  0,  2,  4, 11,  0,  0]]), 'forgetting_measure': [0.45570306, 0.4728303, 0.7400181]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c665c390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c6f9bb50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.401638, 'precision': 0.19630102040816325, 'recall': 0.2428457697863, 'f1_score': 0.14579357965232402, 'confusion_matrix': array([[156,   0,   2,   0,   0,   0,   0],
       [346,   0,   0,   0,   0,   0,   0],
       [157,   0,   2,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0],
       [ 85,   0,   0,   0,   0,   0,   0],
       [ 55,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3708499, 0.43347913, -0.17713393]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c665c390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c6f9bb50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4013109, 'precision': 0.126190476190476188, 'recall': 0.24285714285714285, 'f1_score': 0.14426559356136821, 'confusion_matrix': array([[110,   0,   0,   0,   0,   0,   0],
       [256,   0,   0,   0,   0,   0,   0],
       [ 82,   0,   0,   0,   0,   0,   0],
       [ 28,   0,   0,   0,   0,   0,   0],
       [ 57,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.34717468, 0.3531398, -0.23130699]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bf646390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bfd3ff10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4293551, 'precision': 0.16135991140642304, 'recall': 0.23388600549540874, 'f1_score': 0.17385174914698078, 'confusion_matrix': array([[132,   0,   3, 181,   0,   0,   0],
       [ 87,   0,   2, 123,   0,   0,   0],
       [ 57,   0,   0,  88,   0,   0,   0],
       [ 37,   0,   0,  40,   0,   0,   0],
       [ 19,   0,   0,  31,   0,   0,   0],
       [ 24,   0,   1,  24,   0,   0,   0],
       [ 19,   0,   3,  29,   0,   0,   0]]), 'forgetting_measure': [0.4055224, 0.30295622, 0.20370802]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552bf646390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bfd3ff10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.31309817, 'precision': 0.14841597895333151, 'recall': 0.20904928304615014, 'f1_score': 0.160632674366579944, 'confusion_matrix': array([[ 80,   0,   0, 113,   0,   0,   0],
       [ 48,   0,   0,  78,   0,   0,   0],
       [ 48,   0,   0,  83,   0,   0,   0],
       [ 28,   0,   0,  15,   0,   0,   0],
       [ 29,   0,   0,  11,   0,   0,   0],
       [ 23,   0,   0,  17,   0,   0,   0],
       [ 17,   0,   0,  10,   0,   0,   0]]), 'forgetting_measure': [0.1, 0, 0.56809026]}","{""Task 0 had these additional classes included:"": [""house"", ""left"", ""marvel""], ""Task 1 had these additional classes included:"": [""nine"", ""no""], ""Task 2 had these additional classes included:"": [""off"", ""on""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552af0d4390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552aefb7650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.32633725, 'precision': 0.146753246753246755, 'recall': 0.2564967695620962, 'f1_score': 0.139483378330983414, 'confusion_matrix': array([[ 19,   0,   0, 180,   0,   0,   0],
       [ 25,   0,   0, 218,   0,   0,   0],
       [ 31,   0,   0, 194,   0,   0,   0],
       [  0,   0,   0,  61,   0,   0,   0],
       [  0,   0,   0,  72,   0,   0,   0],
       [  0,   0,   0,  31,   0,   0,   0],
       [  0,   0,   0,  69,   0,   0,   0]]), 'forgetting_measure': [0.25531127, -0.2366929, 0.8353323]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552af0d4390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552aefb7650>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.18159547, 'precision': 0.111190476190476192, 'recall': 0.24285714285714285, 'f1_score': 0.120755133583572533, 'confusion_matrix': array([[  0,   0,   0, 138,   0,   0,   0],
       [  0,   0,   0, 178,   0,   0,   0],
       [  0,   0,   0, 130,   0,   0,   0],
       [  0,   0,   0,  47,   0,   0,   0],
       [  0,   0,   0,  40,   0,   0,   0],
       [  0,   0,   0,  18,   0,   0,   0],
       [  0,   0,   0,  49,   0,   0,   0]]), 'forgetting_measure': [0.1, 0, 0.69809604]}","{""Task 0 had these additional classes included:"": [""bird"", ""cat"", ""dog""], ""Task 1 had these additional classes included:"": [""down"", ""eight""], ""Task 2 had these additional classes included:"": [""five"", ""four""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac0f1c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a7beb210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.59995706, 'precision': 0.15609407277927857, 'recall': 0.24285714285714285, 'f1_score': 0.18055682336832497, 'confusion_matrix': array([[  0, 138,   0,   0,   0,   0,   0],
       [  0, 353,   0,   0,   0,   0,   0],
       [  1, 172,   0,   0,   0,   0,   0],
       [  0,  39,   0,   0,   0,   0,   0],
       [  0,  97,   0,   0,   0,   0,   0],
       [  0,  56,   0,   0,   0,   0,   0],
       [  0,  44,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5999713, 0.26324078, 0.09994871]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ac0f1c90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a7beb210>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.6441458, 'precision': 0.158095238095238096, 'recall': 0.24285714285714285, 'f1_score': 0.18259986459038592, 'confusion_matrix': array([[  0, 101,   0,   0,   0,   0,   0],
       [  0, 244,   0,   0,   0,   0,   0],
       [  0,  98,   0,   0,   0,   0,   0],
       [  0,  26,   0,   0,   0,   0,   0],
       [  0,  64,   0,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0],
       [  0,  33,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.70011995, 0.2215614, 0.4323936]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a0f2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553168d0350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5336699, 'precision': 0.19978830052435941, 'recall': 0.2414563329287703, 'f1_score': 0.1880250870452249, 'confusion_matrix': array([[  6, 156,   5,   0,   0,   0,   0],
       [ 15, 328,   3,   0,   0,   0,   0],
       [  8, 150,   1,   0,   0,   0,   0],
       [  0,  51,   0,   0,   0,   0,   0],
       [  0,  77,   0,   0,   0,   0,   0],
       [  0,  52,   0,   0,   0,   0,   0],
       [  0,  48,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5092934, 0.22819364, 0.12685913]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a0f2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553168d0350>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.64312307, 'precision': 0.30414977343191035, 'recall': 0.2441326530612245, 'f1_score': 0.18830948639483914, 'confusion_matrix': array([[  1, 111,   0,   0,   0,   0,   0],
       [  0, 257,   0,   0,   0,   0,   0],
       [  0,  72,   0,   0,   0,   0,   0],
       [  0,  31,   0,   0,   0,   0,   0],
       [  0,  61,   0,   0,   0,   0,   0],
       [  0,  35,   0,   0,   0,   0,   0],
       [  0,  32,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.70877615, 0.39587566, 0.040676937]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316be5fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb8fc490>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37044485, 'precision': 0.30699088145896655, 'recall': 0.2462081611667486, 'f1_score': 0.145553925521252314, 'confusion_matrix': array([[133,   0,   1,   0,   0,   0,   0],
       [137,   4,   0,   0,   0,   0,   0],
       [390,   1,   1,   0,   0,   0,   0],
       [ 80,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0],
       [ 64,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38828117, 0.5671565, 0.21243642]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning REPLAY with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316be5fd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb8fc490>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3336794, 'precision': 0.122380952380952383, 'recall': 0.24285714285714285, 'f1_score': 0.138699053108275004, 'confusion_matrix': array([[ 94,   0,   0,   0,   0,   0,   0],
       [ 88,   0,   0,   0,   0,   0,   0],
       [269,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0],
       [ 27,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.28243647, 0.41730836, -0.05637925]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec5e7890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5f71ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50996904, 'precision': 0.27602642964702397, 'recall': 0.28869899953194813, 'f1_score': 0.27896269237084025, 'confusion_matrix': array([[ 18,  20,  93,  14,   1,   5,   0],
       [ 20,  26,  99,  13,   0,  10,   0],
       [ 29,  57, 216,  29,   0,  13,   0],
       [  9,  39,  26,  17,   0,   5,   0],
       [  3,  16,  11,   9,   0,   2,   0],
       [ 13,   3,  28,   3,   0,  15,   0],
       [  7,   3,  18,   1,   0,   9,   0]]), 'forgetting_measure': [0.5237154, 0.2999646, 0.29344332]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec5e7890>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d5f71ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5150645, 'precision': 0.2442023046859417, 'recall': 0.28721012456483205, 'f1_score': 0.25749449100769328, 'confusion_matrix': array([[  2,  10,  59,  10,   0,   6,   0],
       [  6,   7,  60,  11,   0,   5,   0],
       [  8,  36, 162,  33,   0,  22,   0],
       [  0,  21,  12,  11,   0,   4,   0],
       [  2,  10,  18,  14,   0,   4,   0],
       [  2,   4,  19,   0,   0,  14,   0],
       [  1,   4,  18,   0,   0,   5,   0]]), 'forgetting_measure': [0.68854073, 0.7840459, -0.80612844]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb616690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e392c0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.58682547, 'precision': 0.25404420099386648, 'recall': 0.30986965225105075, 'f1_score': 0.27610721958548045, 'confusion_matrix': array([[ 76,  68,  33,   0,   0,   0,   0],
       [ 37, 214,  35,   0,   0,   0,   0],
       [ 44,  97,  58,   0,   0,   0,   0],
       [ 21,  16,  32,   0,   0,   0,   0],
       [  2,  42,  25,   0,   0,   0,   0],
       [ 24,  27,  15,   0,   0,   0,   0],
       [ 15,   9,  10,   0,   0,   0,   0]]), 'forgetting_measure': [0.486104, -0.03266497, 0.05783503]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb616690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e392c0d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47878025, 'precision': 0.19880534475824933, 'recall': 0.23979617699568567, 'f1_score': 0.20932080654324558, 'confusion_matrix': array([[ 20,  88,  31,   0,   0,   0,   0],
       [ 21, 105,  38,   0,   0,   0,   0],
       [ 30,  86,  28,   0,   0,   0,   0],
       [ 12,  22,  10,   0,   0,   0,   0],
       [  6,  21,  15,   0,   0,   0,   0],
       [ 12,  21,   7,   0,   0,   0,   0],
       [  2,  19,   6,   0,   0,   0,   0]]), 'forgetting_measure': [0.44524563, 0.13362701, 0.35815352]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e3f110d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3f5dbd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43388621, 'precision': 0.21606777280690324, 'recall': 0.21993173405613512, 'f1_score': 0.20286783337687155, 'confusion_matrix': array([[ 27,  36, 120,   6,   1,   0,  18],
       [ 34,  15, 124,   4,   1,   0,  21],
       [ 38,  36, 149,  12,   3,   1,  19],
       [  3,  23,  35,   5,   0,   0,  22],
       [  0,   5,  24,   6,   0,   0,  12],
       [  1,   0,  63,   0,   0,   0,   0],
       [  1,   0,  35,   0,   0,   0,   0]]), 'forgetting_measure': [0.47524292, 0.7381357, -1.3218677]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e3f110d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3f5dbd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36913262, 'precision': 0.29701204649050066, 'recall': 0.23551836505211404, 'f1_score': 0.22904619820076665, 'confusion_matrix': array([[26, 14, 58,  7,  1,  1, 17],
       [26, 18, 90,  8,  0,  0, 26],
       [32, 14, 78,  7,  1,  0, 21],
       [ 1,  3, 26,  5,  0,  0, 19],
       [ 0,  2, 15,  5,  1,  0, 11],
       [ 1,  0, 31,  0,  0,  0,  0],
       [ 0,  0, 35,  0,  0,  0,  0]]), 'forgetting_measure': [0.436216, 0.761694, -0.13650669]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cf4e5090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cc261ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5206196, 'precision': 0.4191902625470839, 'recall': 0.32041563289021515, 'f1_score': 0.30962748201726653, 'confusion_matrix': array([[123,  24,  68,   1,   3,   1,   1],
       [104,  39,  50,   3,   1,   3,   0],
       [ 77,  16, 145,   2,   0,   1,   0],
       [ 40,   1,  23,   6,   0,   0,   0],
       [ 53,   0,  14,   0,   0,   1,   0],
       [ 34,   0,   6,   2,   0,   4,   1],
       [ 42,   0,   4,   1,   1,   4,   1]]), 'forgetting_measure': [0.48739574, 0.3028251, -0.12699057]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with GRU Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cf4e5090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cc261ad0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43708652, 'precision': 0.27984403254972875, 'recall': 0.21855291742630505, 'f1_score': 0.20815906716305713, 'confusion_matrix': array([[61, 29, 43,  4,  0,  3,  0,  0],
       [72, 20, 48,  3,  1,  5,  0,  0],
       [79, 26, 43,  2,  0,  1,  3,  0],
       [35,  0, 14,  2,  0,  1,  0,  0],
       [24,  1, 12,  0,  1,  0,  0,  0],
       [16,  2,  9,  1,  0,  1,  0,  0],
       [29,  0,  6,  0,  0,  2,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.4172393, 0.3389029, 0.12126195]}","{""Task 0 had these additional classes included:"": [""seven"", ""sheila"", ""six""], ""Task 1 had these additional classes included:"": [""stop"", ""three""], ""Task 2 had these additional classes included:"": [""tree"", ""two""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cd9d6690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cd681910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54027797, 'precision': 0.14883868915049316, 'recall': 0.2419325011558021, 'f1_score': 0.17267132204994674, 'confusion_matrix': array([[307,   1,   1,   0,   0,   0,   0],
       [257,   0,   0,   0,   0,   0,   0],
       [110,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 64,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 53,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51595262, 0.2688354, 0.011108189]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552cd9d6690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552cd681910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51391016, 'precision': 0.14459813975673742, 'recall': 0.24209726443768997, 'f1_score': 0.16788890905790525, 'confusion_matrix': array([[187,   0,   1,   0,   0,   0,   0],
       [178,   0,   0,   0,   0,   0,   0],
       [ 81,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51268337, 0.41747063, -0.20069364]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aa87d090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552aab65810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46200542, 'precision': 0.16656025538707103, 'recall': 0.24117939476791153, 'f1_score': 0.16114162183996721, 'confusion_matrix': array([[  1,   0, 208,   0,   0,   0,   0],
       [  0,   0, 226,   0,   0,   0,   0],
       [  4,   0, 238,   0,   0,   0,   0],
       [  0,   0,  57,   0,   0,   0,   0],
       [  0,   0,  66,   0,   0,   0,   0],
       [  0,   0,  56,   0,   0,   0,   0],
       [  0,   0,  44,   0,   0,   0,   0]]), 'forgetting_measure': [0.43909616, 0.31187525, 0.08468657]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning REPLAY with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552aa87d090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552aab65810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44009153, 'precision': 0.13357142857142857, 'recall': 0.24285714285714285, 'f1_score': 0.15436668594563332, 'confusion_matrix': array([[  0,   0, 142,   0,   0,   0,   0],
       [  0,   0, 166,   0,   0,   0,   0],
       [  0,   0, 141,   0,   0,   0,   0],
       [  0,   0,  47,   0,   0,   0,   0],
       [  0,   0,  37,   0,   0,   0,   0],
       [  0,   0,  31,   0,   0,   0,   0],
       [  0,   0,  36,   0,   0,   0,   0]]), 'forgetting_measure': [0.47623155, 0.43819374, 0.37231252]}","{""Task 0 had these additional classes included:"": [""bed"", ""bird"", ""cat""], ""Task 1 had these additional classes included:"": [""dog"", ""down""], ""Task 2 had these additional classes included:"": [""eight"", ""five""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c1925b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c1043b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3966803, 'precision': 0.20721573857498409, 'recall': 0.29100141996716655, 'f1_score': 0.2186056202925934, 'confusion_matrix': array([[137,   0,  17,  27,   0,   0,  13],
       [197,   0,  21,  57,   0,   0,  14],
       [123,   0,  19,  31,   0,   0,  13],
       [ 32,   0,   9,  19,   0,   0,   2],
       [ 43,   0,   5,  17,   0,   0,   4],
       [  7,   0,   0,  34,   0,   0,  14],
       [  9,   0,   0,  26,   0,   0,  10]]), 'forgetting_measure': [0.37429304, 0.16728166, 0.6176197]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c1925b90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c1043b50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41525249, 'precision': 0.19224267631261318, 'recall': 0.29681928743117272, 'f1_score': 0.21853230360970299, 'confusion_matrix': array([[ 72,   0,   6,  16,   0,   0,  14],
       [134,   0,  24,  32,   0,   0,  12],
       [ 90,   0,   8,  19,   0,   0,  12],
       [ 18,   0,  20,  14,   0,   0,   7],
       [ 14,   0,  13,   7,   0,   0,   1],
       [ 11,   0,   0,  12,   0,   0,  10],
       [  9,   0,   0,  11,   0,   0,  14]]), 'forgetting_measure': [0.40965713, 0.45049044, 0.024793038]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316d730d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317358c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44046685, 'precision': 0.20618622448979591, 'recall': 0.2439954467842914, 'f1_score': 0.15815266860783811, 'confusion_matrix': array([[218,   0,   0,   0,   0,   0,   0],
       [190,   0,   2,   0,   0,   0,   0],
       [249,   0,   2,   0,   0,   0,   0],
       [ 61,   0,   0,   0,   0,   0,   0],
       [ 78,   0,   0,   0,   0,   0,   0],
       [ 58,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.43327007, 0.38732606, 0.099131465]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316d730d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155317358c90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4503356, 'precision': 0.133095238095238094, 'recall': 0.24285714285714285, 'f1_score': 0.153740576068045616, 'confusion_matrix': array([[139,   0,   0,   0,   0,   0,   0],
       [126,   0,   0,   0,   0,   0,   0],
       [177,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.45371172, 0.38168558, 0.18342073]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c6fd2450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bf1c4150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42337389, 'precision': 0.1319047619047619, 'recall': 0.24285714285714285, 'f1_score': 0.15216037368625924, 'confusion_matrix': array([[201,   0,   0,   0,   0,   0,   0],
       [260,   0,   0,   0,   0,   0,   0],
       [210,   0,   0,   0,   0,   0,   0],
       [ 38,   0,   0,   0,   0,   0,   0],
       [ 91,   0,   0,   0,   0,   0,   0],
       [ 64,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42603085, 0.4610239, 0.041855033]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning REPLAY with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c6fd2450>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bf1c4150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.36589417, 'precision': 0.124523809523809524, 'recall': 0.24285714285714285, 'f1_score': 0.141861410282462916, 'confusion_matrix': array([[103,   0,   0,   0,   0,   0,   0],
       [197,   0,   0,   0,   0,   0,   0],
       [145,   0,   0,   0,   0,   0,   0],
       [ 24,   0,   0,   0,   0,   0,   0],
       [ 64,   0,   0,   0,   0,   0,   0],
       [ 33,   0,   0,   0,   0,   0,   0],
       [ 34,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.35704888, 0.4888853, 0.1684353]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a7e59490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a74dfa50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4128336, 'precision': 0.13178134435086604, 'recall': 0.24214641080312723, 'f1_score': 0.15194805194805195, 'confusion_matrix': array([[200,   0,   1,   0,   0,   0,   0],
       [274,   0,   0,   0,   0,   0,   0],
       [198,   0,   0,   0,   0,   0,   0],
       [ 44,   0,   0,   0,   0,   0,   0],
       [ 83,   0,   0,   0,   0,   0,   0],
       [ 57,   0,   0,   0,   0,   0,   0],
       [ 43,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.40508864, 0.40548077, 0.16181386]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552a7e59490>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552a74dfa50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3934031, 'precision': 0.128333333333333332, 'recall': 0.24285714285714285, 'f1_score': 0.14728789986091795, 'confusion_matrix': array([[119,   0,   0,   0,   0,   0,   0],
       [189,   0,   0,   0,   0,   0,   0],
       [143,   0,   0,   0,   0,   0,   0],
       [ 21,   0,   0,   0,   0,   0,   0],
       [ 61,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0],
       [ 25,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.35704888, 0.3065331, 0.18708825]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553169af0d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40327847, 'precision': 0.150163402427040246, 'recall': 0.24212665200087324, 'f1_score': 0.15068058675829259, 'confusion_matrix': array([[  1,   0, 180,   0,   0,   0,   0],
       [  3,   0, 292,   0,   0,   0,   0],
       [  2,   0, 186,   0,   0,   0,   0],
       [  0,   0,  67,   0,   0,   0,   0],
       [  0,   0,  69,   0,   0,   0,   0],
       [  1,   0,  56,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0]]), 'forgetting_measure': [0.36642323, 0.3442857, 0.03424663]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553169af0d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4303953, 'precision': 0.131746031746031744, 'recall': 0.24072494669509594, 'f1_score': 0.15180533751962323, 'confusion_matrix': array([[  0,   0,  99,   0,   0,   0,   0],
       [  1,   0, 208,   0,   0,   0,   0],
       [  2,   0, 132,   0,   0,   0,   0],
       [  1,   0,  38,   0,   0,   0,   0],
       [  1,   0,  51,   0,   0,   0,   0],
       [  1,   0,  34,   0,   0,   0,   0],
       [  0,   0,  32,   0,   0,   0,   0]]), 'forgetting_measure': [0.42297385, 0.3535254, 0.23648486]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531697ad10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316b52b10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47489078, 'precision': 0.18690075356742023, 'recall': 0.24128159343008104, 'f1_score': 0.16483788461180598, 'confusion_matrix': array([[  0,   0, 187,   0,   0,   0,   0],
       [  0,   3, 230,   0,   0,   0,   0],
       [  0,   6, 245,   0,   0,   0,   0],
       [  0,   0,  92,   0,   0,   0,   0],
       [  0,   0,  37,   0,   0,   0,   0],
       [  0,   0,  59,   0,   0,   0,   0],
       [  0,   0,  41,   0,   0,   0,   0]]), 'forgetting_measure': [0.4908314, 0.37773836, 0.21611014]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15531697ad10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316b52b10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45823665, 'precision': 0.13976190476190476, 'recall': 0.24285714285714285, 'f1_score': 0.16220897746321475, 'confusion_matrix': array([[  0,   0, 133,   0,   0,   0,   0],
       [  0,   0, 145,   0,   0,   0,   0],
       [  0,   0, 167,   0,   0,   0,   0],
       [  0,   0,  68,   0,   0,   0,   0],
       [  0,   0,  20,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0],
       [  0,   0,  25,   0,   0,   0,   0]]), 'forgetting_measure': [0.45104913, 0.27636462, 0.3322513]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317349a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a07fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52392198, 'precision': 0.145129508978229774, 'recall': 0.24235588972431076, 'f1_score': 0.16853281853281853, 'confusion_matrix': array([[  0,   0, 196,   0,   0,   0,   0],
       [  0,   0, 194,   0,   0,   0,   0],
       [  0,   1, 284,   0,   0,   0,   0],
       [  0,   0,  87,   0,   0,   0,   0],
       [  0,   0,  38,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0],
       [  0,   0,  38,   0,   0,   0,   0]]), 'forgetting_measure': [0.518069, 0.2939394, 0.12421852]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155317349a50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a07fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46729953, 'precision': 0.13595238095238095, 'recall': 0.24285714285714285, 'f1_score': 0.157447213239490195, 'confusion_matrix': array([[  0,   0, 140,   0,   0,   0,   0],
       [  0,   0, 157,   0,   0,   0,   0],
       [  0,   0, 151,   0,   0,   0,   0],
       [  0,   0,  58,   0,   0,   0,   0],
       [  0,   0,  27,   0,   0,   0,   0],
       [  0,   0,  37,   0,   0,   0,   0],
       [  0,   0,  30,   0,   0,   0,   0]]), 'forgetting_measure': [0.45104913, 0.46507704, -0.40089083]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a57690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a61e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39720237, 'precision': 0.20248447204968944, 'recall': 0.24276039113496222, 'f1_score': 0.15222686175640382, 'confusion_matrix': array([[  0,   1, 241,   0,   0,   0,   0],
       [  0,   1, 225,   0,   0,   0,   0],
       [  1,   0, 195,   0,   0,   0,   0],
       [  0,   0,  66,   0,   0,   0,   0],
       [  0,   0,  70,   0,   0,   0,   0],
       [  0,   0,  41,   0,   0,   0,   0],
       [  0,   0,  59,   0,   0,   0,   0]]), 'forgetting_measure': [0.3563846, 0.22220917, 0.31895882]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a57690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a61e90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40570175, 'precision': 0.13047619047619048, 'recall': 0.24285714285714285, 'f1_score': 0.15023547880690738, 'confusion_matrix': array([[  0,   0, 136,   0,   0,   0,   0],
       [  0,   0, 182,   0,   0,   0,   0],
       [  0,   0, 128,   0,   0,   0,   0],
       [  0,   0,  32,   0,   0,   0,   0],
       [  0,   0,  55,   0,   0,   0,   0],
       [  0,   0,  24,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0]]), 'forgetting_measure': [0.41864756, 0.58388436, -0.25090972]}","{""Task 0 had these additional classes included:"": [""six"", ""stop"", ""three""], ""Task 1 had these additional classes included:"": [""tree"", ""two""], ""Task 2 had these additional classes included:"": [""up"", ""wow""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b1ea10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155314467e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40129529, 'precision': 0.18752986488713133, 'recall': 0.24065556046980196, 'f1_score': 0.159373927869670544, 'confusion_matrix': array([[  0,   8, 177,   0,   0,   0,   0],
       [  1,  13, 292,   0,   0,   0,   0],
       [  0,  11, 179,   0,   0,   0,   0],
       [  0,   0,  61,   0,   0,   0,   0],
       [  0,   0,  58,   0,   0,   0,   0],
       [  0,   0,  48,   0,   0,   0,   0],
       [  0,   0,  52,   0,   0,   0,   0]]), 'forgetting_measure': [0.40159673, 0.38683966, 0.36536115]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b1ea10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155314467e50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44846652, 'precision': 0.13333333333333333, 'recall': 0.24285714285714285, 'f1_score': 0.15405405405405405, 'confusion_matrix': array([[  0,   0,  97,   0,   0,   0,   0],
       [  0,   0, 210,   0,   0,   0,   0],
       [  0,   0, 140,   0,   0,   0,   0],
       [  0,   0,  39,   0,   0,   0,   0],
       [  0,   0,  47,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0]]), 'forgetting_measure': [0.42297385, 0.5037714, -0.63573164]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb380b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb227550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42493066, 'precision': 0.16919693856527516, 'recall': 0.23066115662673813, 'f1_score': 0.17821477245811213, 'confusion_matrix': array([[155,   0,  20,  32,   0,   0,   0],
       [158,   0,  24,  27,   0,   0,   0],
       [191,   0,  25,  39,   0,   0,   0],
       [ 50,   0,   5,   4,   0,   0,   0],
       [ 51,   0,   8,  11,   0,   0,   0],
       [  2,   0,  14,  29,   0,   0,   0],
       [  3,   0,  25,  27,   0,   0,   0]]), 'forgetting_measure': [0.39670545, 0.20508759, 0.39695245]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb380b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb227550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4332813, 'precision': 0.17785400703514847, 'recall': 0.25014750911451055, 'f1_score': 0.17924662402274342, 'confusion_matrix': array([[104,   0,   5,  27,   0,   0,   0],
       [110,   0,   5,  26,   0,   0,   0],
       [119,   0,   7,  39,   0,   0,   0],
       [ 30,   0,   1,  10,   0,   0,   0],
       [ 37,   0,   1,  12,   0,   0,   0],
       [  0,   0,   3,  25,   0,   0,   0],
       [  0,   0,   9,  30,   0,   0,   0]]), 'forgetting_measure': [0.42776496, 0.33191147, 0.3008234]}","{""Task 0 had these additional classes included:"": [""sheila"", ""six"", ""stop""], ""Task 1 had these additional classes included:"": [""three"", ""tree""], ""Task 2 had these additional classes included:"": [""two"", ""up""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e77eb690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e78bda10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46099434, 'precision': 0.23130799972905235, 'recall': 0.24646154890714183, 'f1_score': 0.184848779453096, 'confusion_matrix': array([[ 36,   0, 143,   0,   0,   0,   0],
       [ 52,   3, 217,   0,   0,   0,   0],
       [ 37,   3, 174,   0,   0,   0,   0],
       [ 15,   0,  50,   0,   0,   0,   0],
       [ 15,   0,  55,   0,   0,   0,   0],
       [ 40,   0,  12,   0,   0,   0,   0],
       [ 33,   0,  15,   0,   0,   0,   0]]), 'forgetting_measure': [0.381972, -0.0032481416, 0.22894163]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e77eb690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e78bda10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41460302, 'precision': 0.15238095238095238, 'recall': 0.2490044429817344, 'f1_score': 0.17674020779351463, 'confusion_matrix': array([[ 28,   0,  75,   0,   0,   0,   0],
       [ 69,   0, 159,   0,   0,   0,   0],
       [ 27,   0,  91,   0,   0,   0,   0],
       [  8,   0,  36,   0,   0,   0,   0],
       [ 11,   0,  29,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42888272, 0.54505867, -0.10480823]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7bb1ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e7bd1890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4845846, 'precision': 0.23111697983188103, 'recall': 0.24973396442757592, 'f1_score': 0.22870906094200088, 'confusion_matrix': array([[ 20, 105,  23,   0,  21,   0,   0],
       [ 35, 216,  61,   0,  40,   0,   0],
       [ 20,  93,  22,   0,  15,   0,   0],
       [  0,  66,   0,   0,   4,   0,   0],
       [  0,  49,   0,   0,  10,   0,   0],
       [  0,  28,   0,   0,  14,   0,   0],
       [  0,  35,   0,   0,  23,   0,   0]]), 'forgetting_measure': [0.37706745, -0.21448457, 0.28619185]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7bb1ad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e7bd1890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49349324, 'precision': 0.19513212088946897, 'recall': 0.2344666368114644, 'f1_score': 0.2070982459420038, 'confusion_matrix': array([[  0,  64,  13,   0,  20,   0,   0],
       [  0, 164,  49,   0,  37,   0,   0],
       [  0,  65,  18,   0,  16,   0,   0],
       [  0,  48,   0,   0,  10,   0,   0],
       [  0,  26,   0,   0,   3,   0,   0],
       [  0,  10,   0,   0,  27,   0,   0],
       [  0,  16,   0,   0,  14,   0,   0]]), 'forgetting_measure': [0.36182014, -0.4477811, 0.36790326]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a0c390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eee99fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43849262, 'precision': 0.27777423469387754, 'recall': 0.24286612005506014, 'f1_score': 0.157378204315167915, 'confusion_matrix': array([[  0,   0, 237,   0,   0,   0,   0],
       [  2,   1, 214,   0,   0,   0,   0],
       [  1,   0, 219,   0,   0,   0,   0],
       [  0,   0,  65,   0,   0,   0,   0],
       [  0,   0,  61,   0,   0,   0,   0],
       [  0,   0,  50,   0,   0,   0,   0],
       [  0,   0,  50,   0,   0,   0,   0]]), 'forgetting_measure': [0.4485981, 0.40365303, 0.23518299]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a0c390>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eee99fd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42486363, 'precision': 0.13119047619047619, 'recall': 0.24285714285714285, 'f1_score': 0.15120187609927692, 'confusion_matrix': array([[  0,   0, 148,   0,   0,   0,   0],
       [  0,   0, 163,   0,   0,   0,   0],
       [  0,   0, 131,   0,   0,   0,   0],
       [  0,   0,  47,   0,   0,   0,   0],
       [  0,   0,  44,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0]]), 'forgetting_measure': [0.35928888, 0.22795203, -0.07460762]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ee13e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d60ccfd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45256655, 'precision': 0.17844155844155844, 'recall': 0.2395232473154551, 'f1_score': 0.17855533867470928, 'confusion_matrix': array([[ 22,   0, 188,   0,   0,   0,   0],
       [ 22,   0, 191,   0,   0,   0,   0],
       [ 31,   0, 211,   0,   0,   0,   0],
       [  0,   0,  64,   0,   0,   0,   0],
       [  0,   0,  71,   0,   0,   0,   0],
       [  0,   0,  50,   0,   0,   0,   0],
       [  0,   0,  50,   0,   0,   0,   0]]), 'forgetting_measure': [0.42142887, 0.12994732, 0.4399959]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ee13e150>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d60ccfd0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46111397, 'precision': 0.14357142857142857, 'recall': 0.24285714285714285, 'f1_score': 0.16677613574165299, 'confusion_matrix': array([[  0,   0, 146,   0,   0,   0,   0],
       [  0,   0, 117,   0,   0,   0,   0],
       [  0,   0, 183,   0,   0,   0,   0],
       [  0,   0,  49,   0,   0,   0,   0],
       [  0,   0,  38,   0,   0,   0,   0],
       [  0,   0,  32,   0,   0,   0,   0],
       [  0,   0,  35,   0,   0,   0,   0]]), 'forgetting_measure': [0.5050715, 0.4650744, 0.25426897]}","{""Task 0 had these additional classes included:"": [""marvel"", ""nine"", ""no""], ""Task 1 had these additional classes included:"": [""off"", ""on""], ""Task 2 had these additional classes included:"": [""one"", ""right""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dcf2c510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dd2cf550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.52514897, 'precision': 0.26062696287939704, 'recall': 0.2487210776849139, 'f1_score': 0.2325536919246872, 'confusion_matrix': array([[ 22, 130,   9,   0,  12,   0,   0],
       [ 42, 240,  32,   2,  31,   0,   0],
       [ 29,  93,  16,   1,   7,   0,   0],
       [  2,  39,   3,   1,   1,   0,   0],
       [  1,  72,   7,   0,   8,   0,   0],
       [  2,  43,   1,   0,  11,   0,   0],
       [  1,  29,   1,   1,  11,   0,   0]]), 'forgetting_measure': [0.5563741, 0.37171227, 0.18970785]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dcf2c510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552dd2cf550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.522385, 'precision': 0.20564298446651388, 'recall': 0.2351277012130986, 'f1_score': 0.20839440816373214, 'confusion_matrix': array([[  4,  79,  12,   0,  12,   0,   0],
       [ 15, 192,  21,   2,  17,   0,   0],
       [  8,  69,   6,   0,   7,   0,   0],
       [  3,  21,   0,   0,   3,   0,   0],
       [  3,  52,   2,   1,   4,   0,   0],
       [  0,  17,   3,   1,  11,   0,   0],
       [  1,  20,   0,   0,  14,   0,   0]]), 'forgetting_measure': [0.6206876, 0.44053084, 0.4673732]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd42ec10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e4415810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39706398, 'precision': 0.19012777147503903, 'recall': 0.24190842531541112, 'f1_score': 0.18426658455699078, 'confusion_matrix': array([[ 44,  83,   6,   0,   0,   0,   0],
       [ 47,  86,  13,   0,   0,   0,   0],
       [144, 208,  28,   0,   1,   0,   0],
       [ 54,  30,   6,   0,   0,   0,   0],
       [ 28,  20,   2,   0,   0,   0,   0],
       [ 38,   0,  22,   0,   0,   0,   0],
       [ 28,   0,  12,   0,   0,   0,   0]]), 'forgetting_measure': [0.37131367, 0.3116548, 0.28719938]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dd42ec10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e4415810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38460959, 'precision': 0.21039391407812461, 'recall': 0.25729685977880922, 'f1_score': 0.19733607045741073, 'confusion_matrix': array([[ 35,  41,   4,   0,   0,   0,   0],
       [ 34,  49,   7,   0,   0,   0,   0],
       [115, 129,  33,   0,   0,   0,   0],
       [ 46,   6,   2,   0,   0,   0,   0],
       [ 27,   3,   2,   0,   0,   0,   0],
       [ 25,   0,  17,   0,   0,   0,   0],
       [ 15,   0,  10,   0,   0,   0,   0]]), 'forgetting_measure': [0.31479088, 0.28102398, -0.1954218]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b525d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316872290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4710319, 'precision': 0.13940886699507389, 'recall': 0.24228341939185313, 'f1_score': 0.16172224987555998, 'confusion_matrix': array([[  0,   0, 162,   0,   0,   0,   0],
       [  0,   0, 255,   0,   0,   0,   0],
       [  0,   1, 248,   0,   0,   0,   0],
       [  0,   0,  72,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0],
       [  0,   0,  58,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0]]), 'forgetting_measure': [0.4631457, 0.22663951, 0.39785683]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316b525d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316872290>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45908378, 'precision': 0.136190476190476197, 'recall': 0.24285714285714285, 'f1_score': 0.157750759878419454, 'confusion_matrix': array([[  0,   0, 109,   0,   0,   0,   0],
       [  0,   0, 185,   0,   0,   0,   0],
       [  0,   0, 152,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0],
       [  0,   0,  53,   0,   0,   0,   0],
       [  0,   0,  31,   0,   0,   0,   0],
       [  0,   0,  36,   0,   0,   0,   0]]), 'forgetting_measure': [0.4075612, 0.033567213, 0.41981387]}","{""Task 0 had these additional classes included:"": [""off"", ""on"", ""one""], ""Task 1 had these additional classes included:"": [""right"", ""seven""], ""Task 2 had these additional classes included:"": [""sheila"", ""six""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e1a2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3715664, 'precision': 0.129079930081042427, 'recall': 0.24285714285714285, 'f1_score': 0.14832321098494851, 'confusion_matrix': array([[  0,   1, 220,   0,   0,   0,   0],
       [  0,   0, 270,   0,   0,   0,   0],
       [  0,   0, 183,   0,   0,   0,   0],
       [  0,   0,  46,   0,   0,   0,   0],
       [  0,   0,  80,   0,   0,   0,   0],
       [  0,   0,  57,   0,   0,   0,   0],
       [  0,   0,  43,   0,   0,   0,   0]]), 'forgetting_measure': [0.33914063, 0.49471644, -0.28047565]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e1a2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44465309, 'precision': 0.13571428571428571, 'recall': 0.24285714285714285, 'f1_score': 0.15714285714285715, 'confusion_matrix': array([[  0,   0, 124,   0,   0,   0,   0],
       [  0,   0, 167,   0,   0,   0,   0],
       [  0,   0, 150,   0,   0,   0,   0],
       [  0,   0,  29,   0,   0,   0,   0],
       [  0,   0,  63,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0]]), 'forgetting_measure': [0.45806277, 0.465019, 0.03767577]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533c659d50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4541588, 'precision': 0.133688225011918004, 'recall': 0.24218645204560698, 'f1_score': 0.154470709146968145, 'confusion_matrix': array([[212,   0,   1,   0,   0,   0,   0],
       [265,   0,   0,   0,   0,   0,   0],
       [191,   0,   0,   0,   0,   0,   0],
       [ 47,   0,   0,   0,   0,   0,   0],
       [ 84,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.40508864, 0.15728651, 0.22098924]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533c659d50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155546fbf5d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37742527, 'precision': 0.128095238095238093, 'recall': 0.24285714285714285, 'f1_score': 0.1469558296856347, 'confusion_matrix': array([[118,   0,   0,   0,   0,   0,   0],
       [173,   0,   0,   0,   0,   0,   0],
       [158,   0,   0,   0,   0,   0,   0],
       [ 24,   0,   0,   0,   0,   0,   0],
       [ 60,   0,   0,   0,   0,   0,   0],
       [ 35,   0,   0,   0,   0,   0,   0],
       [ 32,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.35704888, 0.43195707, 0.11507511]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec98dc50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ec75de90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38879858, 'precision': 0.160135674381484434, 'recall': 0.24235849950135665, 'f1_score': 0.14252015787659456, 'confusion_matrix': array([[  0,   2, 186,   0,   0,   0,   0],
       [  1,   1, 331,   0,   0,   0,   0],
       [  0,   1, 153,   0,   0,   0,   0],
       [  0,   0,  72,   0,   0,   0,   0],
       [  0,   0,  53,   0,   0,   0,   0],
       [  0,   0,  63,   0,   0,   0,   0],
       [  0,   0,  37,   0,   0,   0,   0]]), 'forgetting_measure': [0.3295466, 0.08430579, 0.39744088]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec98dc50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ec75de90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.34338623, 'precision': 0.12428571428571429, 'recall': 0.24285714285714285, 'f1_score': 0.14151404151404152, 'confusion_matrix': array([[  0,   0,  86,   0,   0,   0,   0],
       [  0,   0, 255,   0,   0,   0,   0],
       [  0,   0, 102,   0,   0,   0,   0],
       [  0,   0,  65,   0,   0,   0,   0],
       [  0,   0,  25,   0,   0,   0,   0],
       [  0,   0,  40,   0,   0,   0,   0],
       [  0,   0,  27,   0,   0,   0,   0]]), 'forgetting_measure': [0.28471065, 0.24394448, 0.24242488]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec76a9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ec374550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49112345, 'precision': 0.24534938017018656, 'recall': 0.26496403926106895, 'f1_score': 0.2397448927139479, 'confusion_matrix': array([[143,  12,  79,   0,  16,   0,   0],
       [117,  21,  52,   0,  12,   0,   0],
       [117,  14,  65,   0,  24,   0,   0],
       [ 37,  12,   0,   0,  19,   0,   0],
       [ 36,  13,   0,   0,  11,   0,   0],
       [ 75,   0,   0,   0,   0,   0,   0],
       [ 25,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4848424, 0.26589903, 0.27077803]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec76a9d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ec374550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4344194, 'precision': 0.23973702246138833, 'recall': 0.27150162390537613, 'f1_score': 0.23603664154646086, 'confusion_matrix': array([[93,  2, 77,  0, 32,  0,  0],
       [50,  2, 46,  0,  7,  0,  0],
       [65,  3, 54,  0, 13,  0,  0],
       [28,  2,  0,  0, 16,  0,  0],
       [29,  0,  0,  0, 14,  0,  0],
       [44,  0,  0,  0,  0,  0,  0],
       [23,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.37143222, 0.27557212, -0.19610047]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a12b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb750410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4300833, 'precision': 0.2744795804862546, 'recall': 0.24354066985645933, 'f1_score': 0.15314300583621427, 'confusion_matrix': array([[  1,   0, 208,   0,   0,   0,   0],
       [  0,   0, 259,   0,   0,   0,   0],
       [  0,   0, 199,   0,   0,   0,   0],
       [  0,   0,  56,   0,   0,   0,   0],
       [  0,   0,  77,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0],
       [  0,   0,  38,   0,   0,   0,   0]]), 'forgetting_measure': [0.42300386, 0.2951837, 0.38685492]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316a12b10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb750410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4219863, 'precision': 0.13595238095238095, 'recall': 0.24285714285714285, 'f1_score': 0.157447213239490195, 'confusion_matrix': array([[  0,   0, 141,   0,   0,   0,   0],
       [  0,   0, 153,   0,   0,   0,   0],
       [  0,   0, 151,   0,   0,   0,   0],
       [  0,   0,  53,   0,   0,   0,   0],
       [  0,   0,  35,   0,   0,   0,   0],
       [  0,   0,  48,   0,   0,   0,   0],
       [  0,   0,  19,   0,   0,   0,   0]]), 'forgetting_measure': [0.4247786, 0.36054644, 0.35718936]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb6b78d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e30b0410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50029684, 'precision': 0.24532834735763922, 'recall': 0.32364681944295597, 'f1_score': 0.26127001564022272, 'confusion_matrix': array([[110,  84,  23,   0,   0,  41,   0],
       [ 68,  86,   9,   0,   0,  29,   0],
       [ 89,  83,  14,   0,   0,  39,   0],
       [ 10,  47,   5,   0,   0,   6,   0],
       [  7,  38,   4,   0,   0,   8,   0],
       [  0,   6,  17,   0,   0,  39,   0],
       [  0,   5,   8,   0,   0,  25,   0]]), 'forgetting_measure': [0.50379664, 0.30356428, 0.23235664]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb6b78d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e30b0410>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47638274, 'precision': 0.24536963036963038, 'recall': 0.34847326317914556, 'f1_score': 0.24699022819853033, 'confusion_matrix': array([[76, 41,  2,  0,  0, 34,  0],
       [60, 45,  2,  0,  0, 41,  0],
       [64, 47,  3,  0,  0, 39,  0],
       [ 0, 25,  1,  0,  0,  5,  0],
       [ 0, 42,  1,  0,  0,  5,  0],
       [ 0,  0,  3,  0,  0, 34,  0],
       [ 0,  0,  1,  0,  0, 29,  0]]), 'forgetting_measure': [0.46459395, 0.28485632, 0.21830362]}","{""Task 0 had these additional classes included:"": [""stop"", ""three"", ""tree""], ""Task 1 had these additional classes included:"": [""two"", ""up""], ""Task 2 had these additional classes included:"": [""wow"", ""yes""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb619410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb975f50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44139757, 'precision': 0.1353968253968254, 'recall': 0.24285714285714285, 'f1_score': 0.15673578425136751, 'confusion_matrix': array([[  0,   0, 220,   0,   0,   0,   0],
       [  0,   0, 230,   0,   0,   0,   0],
       [  0,   0, 223,   0,   0,   0,   0],
       [  0,   0,  76,   0,   0,   0,   0],
       [  0,   0,  51,   0,   0,   0,   0],
       [  0,   0,  53,   0,   0,   0,   0],
       [  0,   0,  47,   0,   0,   0,   0]]), 'forgetting_measure': [0.44665364, 0.38456026, 0.23037776]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with Dense Model; with TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552eb619410>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552eb975f50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40556414, 'precision': 0.134523809523809526, 'recall': 0.24285714285714285, 'f1_score': 0.15560882070949185, 'confusion_matrix': array([[  0,   0, 129,   0,   0,   0,   0],
       [  0,   0, 168,   0,   0,   0,   0],
       [  0,   0, 145,   0,   0,   0,   0],
       [  0,   0,  51,   0,   0,   0,   0],
       [  0,   0,  40,   0,   0,   0,   0],
       [  0,   0,  30,   0,   0,   0,   0],
       [  0,   0,  37,   0,   0,   0,   0]]), 'forgetting_measure': [0.35928888, 0.14263386, 0.3922865]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c9249910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f0c6ad10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.50157277, 'precision': 0.19694739821890157, 'recall': 0.25973630892437538, 'f1_score': 0.21670259620168134, 'confusion_matrix': array([[203,  51,   0,   8,  69,   0,   0],
       [113,  29,   0,   5,  33,   0,   0],
       [ 98,  19,   0,   5,  27,   0,   0],
       [ 38,  17,   0,   0,  21,   0,   0],
       [ 29,  13,   0,   0,  22,   0,   0],
       [  0,  37,   0,   0,  14,   0,   0],
       [  0,  25,   0,   0,  24,   0,   0]]), 'forgetting_measure': [0.5575971, 0.26009196, 0.6794214]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c9249910>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f0c6ad10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.56417854, 'precision': 0.20855853438973642, 'recall': 0.2800365893245265, 'f1_score': 0.22733367000366377, 'confusion_matrix': array([[147,  26,   0,   0,  68,   0,   0],
       [ 53,  19,   0,   0,  24,   0,   0],
       [ 67,  18,   0,   0,  26,   0,   0],
       [ 15,   6,   0,   0,  22,   0,   0],
       [ 17,   6,   0,   0,  19,   0,   0],
       [  0,  24,   0,   0,  11,   0,   0],
       [  0,  15,   0,   0,  17,   0,   0]]), 'forgetting_measure': [0.66311727, 0.33983168, 0.57588375]}","{""Task 0 had these additional classes included:"": [""go"", ""happy"", ""house""], ""Task 1 had these additional classes included:"": [""left"", ""marvel""], ""Task 2 had these additional classes included:"": [""nine"", ""no""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e8531dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e773c150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41979634, 'precision': 0.23421620050067723, 'recall': 0.23986117307143348, 'f1_score': 0.2344097003942659, 'confusion_matrix': array([[78, 89, 31, 48, 10,  8, 19,  2,  1],
       [55, 75, 21, 35, 10, 10, 10,  1,  0],
       [46, 63, 13, 18,  6,  6, 11,  3,  0],
       [33,  8, 12, 24,  4,  8,  7,  0,  0],
       [14,  1,  5,  9,  2,  2,  2,  0,  0],
       [11,  1,  4, 10,  1,  3,  4,  0,  1],
       [24,  2,  5, 16,  3,  3, 11,  1,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.4429474, 0.45837793, 0.2963916]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e8531dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e773c150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43172928, 'precision': 0.24010847582276154, 'recall': 0.25077809670200973, 'f1_score': 0.23578249314831012, 'confusion_matrix': array([[39, 64, 10, 27,  3,  6, 13,  2,  1],
       [37, 53,  8, 15,  6,  6, 13,  2,  0],
       [30, 59, 11, 20,  4, 10,  6,  0,  0],
       [13,  4,  7, 15,  3,  4,  9,  1,  0],
       [ 9,  0,  4, 15,  1,  2,  1,  0,  0],
       [ 8,  1,  0,  0,  0,  4,  6,  2,  0],
       [20,  4,  2,  6,  1,  4,  8,  0,  1],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.443733, 0.5079767, -0.07808137]}","{""Task 0 had these additional classes included:"": [""left"", ""marvel"", ""nine""], ""Task 1 had these additional classes included:"": [""no"", ""off""], ""Task 2 had these additional classes included:"": [""on"", ""one""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7630f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b6ce4150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41657158, 'precision': 0.1926618731294255, 'recall': 0.24216573422913448, 'f1_score': 0.17134174381561141, 'confusion_matrix': array([[  0,  19, 180,   0,   0,   0,   0],
       [  0,  35, 258,   0,   0,   0,   0],
       [  0,  22, 155,   0,   0,   0,   0],
       [  0,   0,  67,   0,   0,   0,   0],
       [  0,   0,  64,   0,   0,   0,   0],
       [  0,   0,  47,   0,   0,   0,   0],
       [  0,   0,  53,   0,   0,   0,   0]]), 'forgetting_measure': [0.48315618, 0.6572954, -0.030004347]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e7630f10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552b6ce4150>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40078067, 'precision': 0.124999999999999998, 'recall': 0.24285714285714285, 'f1_score': 0.1425531914893617, 'confusion_matrix': array([[  0,   0, 113,   0,   0,   0,   0],
       [  0,   0, 229,   0,   0,   0,   0],
       [  0,   0, 105,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0],
       [  0,   0,  44,   0,   0,   0,   0],
       [  0,   0,  33,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0]]), 'forgetting_measure': [0.42297385, 0.57054305, -0.014141042]}","{""Task 0 had these additional classes included:"": [""on"", ""one"", ""right""], ""Task 1 had these additional classes included:"": [""seven"", ""sheila""], ""Task 2 had these additional classes included:"": [""six"", ""stop""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e2ec5610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552df3cfb10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44266425, 'precision': 0.21835385307202517, 'recall': 0.23149882382264932, 'f1_score': 0.21555744719236248, 'confusion_matrix': array([[ 17,  35,  60,  26,   8,   4,   4,   2],
       [ 22,  33,  55,  31,   7,   1,   0,   0],
       [ 36,  72, 154,  82,  14,   4,   0,   1],
       [  0,  23,  24,  22,   4,   1,   0,   0],
       [  0,  15,  26,  17,   0,   0,   0,   0],
       [  0,  53,   1,   6,   0,   0,   0,   2],
       [  1,  27,   0,   9,   1,   0,   0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4498321, 0.10905014, 0.7867133]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with LSTM Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e2ec5610>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552df3cfb10>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4557955, 'precision': 0.31761283307335938, 'recall': 0.26818541519337604, 'f1_score': 0.25474131496104712, 'confusion_matrix': array([[ 8, 19, 28, 19,  5,  1,  0,  0],
       [ 6, 24, 36, 28,  5,  0,  2,  0],
       [22, 71, 92, 56, 10,  0,  1,  2],
       [ 0, 20,  5, 30,  4,  1,  0,  0],
       [ 0, 13,  4, 18,  2,  1,  0,  0],
       [ 0, 37,  0,  1,  0,  4,  0,  1],
       [ 0, 24,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0,  0]]), 'forgetting_measure': [0.47758368, 0.36855242, 0.36508754]}","{""Task 0 had these additional classes included:"": [""eight"", ""five"", ""four""], ""Task 1 had these additional classes included:"": [""go"", ""happy""], ""Task 2 had these additional classes included:"": [""house"", ""left""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dfac9110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c213a550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.49955485, 'precision': 0.27216028297470218, 'recall': 0.27220709851122692, 'f1_score': 0.24435692859032415, 'confusion_matrix': array([[184,  33,  75,   1,  28,   0,   0],
       [131,  30,  38,   3,  30,   0,   0],
       [ 59,  12,  25,   1,  13,   0,   0],
       [ 26,   0,  32,   1,  21,   0,   0],
       [ 20,   0,  22,   0,  15,   0,   0],
       [ 27,   0,  32,   0,   0,   0,   0],
       [ 15,   0,  26,   0,   0,   0,   0]]), 'forgetting_measure': [0.5009998, 0.21901737, 0.41089952]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with GRU Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552dfac9110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552c213a550>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46278865, 'precision': 0.19601689756961, 'recall': 0.2726959035155196, 'f1_score': 0.22333915580285816, 'confusion_matrix': array([[109,   0,  43,   2,  27,   0,   0],
       [100,   0,  45,   0,  25,   0,   0],
       [ 53,   0,  29,   0,  15,   0,   0],
       [  5,   0,  18,   0,  10,   0,   0],
       [  9,   0,  26,   1,  16,   0,   0],
       [ 19,   0,  13,   0,   0,   0,   0],
       [ 18,   0,  17,   0,   0,   0,   0]]), 'forgetting_measure': [0.51268337, 0.5700879, -0.117504686]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533fd3df90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15534374ff50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.47631423, 'precision': 0.17896103896103897, 'recall': 0.24236168775810717, 'f1_score': 0.18481731191134856, 'confusion_matrix': array([[ 19, 168,   0,   0,   0,   0,   0],
       [ 29, 247,   0,   0,   0,   0,   0],
       [ 27, 182,   0,   0,   0,   0,   0],
       [  0,  77,   0,   0,   0,   0,   0],
       [  0,  51,   0,   0,   0,   0,   0],
       [  0,  56,   0,   0,   0,   0,   0],
       [  0,  44,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4369369, 0.11021459, 0.35889503]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 300 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x15533fd3df90>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x15534374ff50>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 300, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43340352, 'precision': 0.13404761904761905, 'recall': 0.24285714285714285, 'f1_score': 0.15498942511055566, 'confusion_matrix': array([[  0, 161,   0,   0,   0,   0,   0],
       [  0, 143,   0,   0,   0,   0,   0],
       [  0, 141,   0,   0,   0,   0,   0],
       [  0,  36,   0,   0,   0,   0,   0],
       [  0,  52,   0,   0,   0,   0,   0],
       [  0,  33,   0,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.42305518, 0.27466568, 0.39044642]}","{""Task 0 had these additional classes included:"": [""one"", ""right"", ""seven""], ""Task 1 had these additional classes included:"": [""sheila"", ""six""], ""Task 2 had these additional classes included:"": [""stop"", ""three""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316c2ac50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a235d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48137133, 'precision': 0.19860059935296357, 'recall': 0.30863456718719878, 'f1_score': 0.20564804453512557, 'confusion_matrix': array([[174,  17,   0,   0,   0,  97,   0],
       [152,  12,   0,   0,   0,  83,   0],
       [ 73,   6,   0,   0,   0,  50,   0],
       [ 32,   4,   0,   0,   0,  46,   0],
       [ 21,   1,   0,   0,   0,  32,   0],
       [  0,  10,   0,   0,   0,  42,   0],
       [  0,  11,   0,   0,   0,  37,   0]]), 'forgetting_measure': [0.52524552, 0.4106883, 0.3285519]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316c2ac50>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a235d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46606062, 'precision': 0.20702748379106407, 'recall': 0.29191538684439294, 'f1_score': 0.20692909574897151, 'confusion_matrix': array([[104,  13,   0,   0,   0,  86,   0],
       [ 90,  15,   0,   0,   0,  65,   0],
       [ 38,   6,   0,   0,   0,  32,   0],
       [ 11,   2,   0,   0,   0,  25,   0],
       [  9,   3,   0,   0,   0,  34,   0],
       [  0,   9,   0,   0,   0,  26,   0],
       [  0,  13,   0,   0,   0,  19,   0]]), 'forgetting_measure': [0.51268337, 0.4576961, 0.27748504]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553169bbad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553169c0190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.5167564, 'precision': 0.146031746031746035, 'recall': 0.24285714285714285, 'f1_score': 0.16962785114045619, 'confusion_matrix': array([[290,   0,   0,   0,   0,   0,   0],
       [265,   0,   0,   0,   0,   0,   0],
       [110,   0,   0,   0,   0,   0,   0],
       [ 70,   0,   0,   0,   0,   0,   0],
       [ 65,   0,   0,   0,   0,   0,   0],
       [ 48,   0,   0,   0,   0,   0,   0],
       [ 52,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.52524552, 0.35468557, 0.086767584]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1553169bbad0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553169c0190>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51460673, 'precision': 0.14666666666666667, 'recall': 0.24285714285714285, 'f1_score': 0.17035175879396985, 'confusion_matrix': array([[196,   0,   0,   0,   0,   0,   0],
       [167,   0,   0,   0,   0,   0,   0],
       [ 73,   0,   0,   0,   0,   0,   0],
       [ 43,   0,   0,   0,   0,   0,   0],
       [ 54,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 31,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51268337, 0.432465, -0.26775852]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e90510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316bddf90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48711513, 'precision': 0.18775282688326166, 'recall': 0.24298262124349082, 'f1_score': 0.16396923986986099, 'confusion_matrix': array([[  1, 206,   0,   0,   0,   0,   0],
       [  1, 252,   0,   0,   0,   0,   0],
       [  1, 207,   0,   0,   0,   0,   0],
       [  0,  35,   0,   0,   0,   0,   0],
       [  0,  97,   0,   0,   0,   0,   0],
       [  0,  62,   0,   0,   0,   0,   0],
       [  0,  38,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.53566188, 0.43599364, 0.2675794]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e90510>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316bddf90>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.4582995, 'precision': 0.13928571428571429, 'recall': 0.24285714285714285, 'f1_score': 0.16162464985994399, 'confusion_matrix': array([[  0, 123,   0,   0,   0,   0,   0],
       [  0, 165,   0,   0,   0,   0,   0],
       [  0, 152,   0,   0,   0,   0,   0],
       [  0,  29,   0,   0,   0,   0,   0],
       [  0,  64,   0,   0,   0,   0,   0],
       [  0,  40,   0,   0,   0,   0,   0],
       [  0,  27,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.48488838, 0.38740355, 0.34588143]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e80dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a14250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42323792, 'precision': 0.21047263362496815, 'recall': 0.24931165813518757, 'f1_score': 0.2111108874982967, 'confusion_matrix': array([[ 53, 158,  49,   0,   0,   0,   0],
       [ 25, 123,  37,   0,   0,   0,   0],
       [ 32, 150,  39,   0,   0,   0,   0],
       [ 19,  44,   2,   0,   0,   0,   0],
       [ 13,  50,   6,   0,   0,   0,   0],
       [ 41,  26,   0,   0,   0,   0,   0],
       [ 19,  14,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.38162184, 0.3667634, -0.17621712]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x155316e80dd0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x155316a14250>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.41602081, 'precision': 0.19229944901937383, 'recall': 0.22552014837815462, 'f1_score': 0.18767272609313773, 'confusion_matrix': array([[ 44, 138,  14,   0,   0,   0,   0],
       [ 39,  74,  11,   0,   0,   0,   0],
       [ 24,  91,   7,   0,   0,   0,   0],
       [ 11,  35,   0,   0,   0,   0,   0],
       [ 11,  34,   0,   0,   0,   0,   0],
       [ 41,   5,   0,   0,   0,   0,   0],
       [ 20,   1,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3555425, 0.18338536, 0.11903156]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e375c850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553168ab510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.54659776, 'precision': 0.14708876869233216, 'recall': 0.24189837008628955, 'f1_score': 0.1707118967988533, 'confusion_matrix': array([[296,   0,   2,   0,   0,   0,   0],
       [259,   0,   0,   0,   0,   0,   0],
       [115,   0,   0,   0,   0,   0,   0],
       [ 67,   0,   0,   0,   0,   0,   0],
       [ 61,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0],
       [ 55,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.4866944, 0.09824512, 0.12706591]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e375c850>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1553168ab510>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.48964782, 'precision': 0.145, 'recall': 0.24285714285714285, 'f1_score': 0.16844106463878327, 'confusion_matrix': array([[189,   0,   0,   0,   0,   0,   0],
       [180,   0,   0,   0,   0,   0,   0],
       [ 75,   0,   0,   0,   0,   0,   0],
       [ 39,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [ 35,   0,   0,   0,   0,   0,   0],
       [ 32,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.51268337, 0.29854184, 0.42386374]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec24e090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed0e63d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.43862875, 'precision': 0.192587228439763, 'recall': 0.24000265617712457, 'f1_score': 0.20573902230982982, 'confusion_matrix': array([[126,  42,  31,   0,   0,   0,   0],
       [162,  52,  47,   0,   0,   0,   0],
       [125,  54,  31,   0,   0,   0,   0],
       [ 15,   5,  14,   0,   0,   0,   0],
       [ 37,  19,  40,   0,   0,   0,   0],
       [  0,  55,   6,   0,   0,   0,   0],
       [  0,  33,   6,   0,   0,   0,   0]]), 'forgetting_measure': [0.42603085, 0.40703768, -0.016590416]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ec24e090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ed0e63d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46176488, 'precision': 0.20306628731157033, 'recall': 0.24910760607864018, 'f1_score': 0.2171451162187614, 'confusion_matrix': array([[ 66,  28,  22,   0,   0,   0,   0],
       [103,  53,  40,   0,   0,   0,   0],
       [ 74,  35,  28,   0,   0,   0,   0],
       [  7,   5,   8,   0,   0,   0,   0],
       [ 15,  12,  37,   0,   0,   0,   0],
       [  0,  33,   0,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.35704888, 0.056921814, -0.17907737]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ece13110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552921e63d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46552895, 'precision': 0.1901783149649854, 'recall': 0.3124353800624987, 'f1_score': 0.21220341814736735, 'confusion_matrix': array([[183,   0,  21,   0,   0,   0,  32],
       [164,   0,  17,   0,   0,   0,  32],
       [168,   0,  13,   0,   0,   0,  44],
       [ 58,   0,   3,   0,   0,   0,   9],
       [ 45,   0,   2,   0,   0,   0,   9],
       [  2,   0,  11,   0,   0,   0,  35],
       [  6,   0,  12,   0,   0,   0,  34]]), 'forgetting_measure': [0.42869673, 0.23134875, 0.14809299]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552ece13110>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552921e63d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.42549781, 'precision': 0.16605311355311357, 'recall': 0.35050301810865194, 'f1_score': 0.20300202940717329, 'confusion_matrix': array([[107,   0,   1,   0,   0,   0,  34],
       [115,   0,   1,   0,   0,   0,  45],
       [111,   0,   0,   0,   0,   0,  35],
       [ 33,   0,   1,   0,   0,   0,   7],
       [ 34,   0,   1,   0,   0,   0,   8],
       [  0,   0,   1,   0,   0,   0,  28],
       [  0,   0,   0,   0,   0,   0,  38]]), 'forgetting_measure': [0.39805472, 0.40788954, -0.14435552]}","{""Task 0 had these additional classes included:"": [""right"", ""seven"", ""sheila""], ""Task 1 had these additional classes included:"": [""six"", ""stop""], ""Task 2 had these additional classes included:"": [""three"", ""tree""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e03281d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d16e9810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.51183448, 'precision': 0.21297539149888143, 'recall': 0.243278174697026, 'f1_score': 0.16819216842733959, 'confusion_matrix': array([[  3, 206,   0,   0,   0,   0,   0],
       [  3, 260,   0,   0,   0,   0,   0],
       [  0, 192,   0,   0,   0,   0,   0],
       [  0,  39,   0,   0,   0,   0,   0],
       [  0,  97,   0,   0,   0,   0,   0],
       [  0,  53,   0,   0,   0,   0,   0],
       [  0,  47,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.54160634, 0.3613421, 0.24881178]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e03281d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d16e9810>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46991016, 'precision': 0.1419047619047619, 'recall': 0.24285714285714285, 'f1_score': 0.16480117820324005, 'confusion_matrix': array([[  0, 115,   0,   0,   0,   0,   0],
       [  0, 176,   0,   0,   0,   0,   0],
       [  0, 145,   0,   0,   0,   0,   0],
       [  0,  19,   0,   0,   0,   0,   0],
       [  0,  78,   0,   0,   0,   0,   0],
       [  0,  41,   0,   0,   0,   0,   0],
       [  0,  26,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.48488838, 0.3795327, 0.22100873]}","{""Task 0 had these additional classes included:"": [""dog"", ""down"", ""eight""], ""Task 1 had these additional classes included:"": [""five"", ""four""], ""Task 2 had these additional classes included:"": [""go"", ""happy""]}"
"{'Name Experiment': 'Learning AGEM with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e1f26090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e24de3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.44269426, 'precision': 0.133650793650793646, 'recall': 0.24285714285714285, 'f1_score': 0.154470709146968145, 'confusion_matrix': array([[212,   0,   0,   0,   0,   0,   0],
       [266,   0,   0,   0,   0,   0,   0],
       [189,   0,   0,   0,   0,   0,   0],
       [ 77,   0,   0,   0,   0,   0,   0],
       [ 56,   0,   0,   0,   0,   0,   0],
       [ 58,   0,   0,   0,   0,   0,   0],
       [ 42,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44112647, 0.4579857, -0.09283855]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning AGEM with ECHO Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e1f26090>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e24de3d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.451504, 'precision': 0.136904761904761905, 'recall': 0.24285714285714285, 'f1_score': 0.15865657521286661, 'confusion_matrix': array([[155,   0,   0,   0,   0,   0,   0],
       [131,   0,   0,   0,   0,   0,   0],
       [158,   0,   0,   0,   0,   0,   0],
       [ 49,   0,   0,   0,   0,   0,   0],
       [ 40,   0,   0,   0,   0,   0,   0],
       [ 46,   0,   0,   0,   0,   0,   0],
       [ 21,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.44886697, 0.39985472, 0.06255252]}","{""Task 0 had these additional classes included:"": [""cat"", ""dog"", ""down""], ""Task 1 had these additional classes included:"": [""eight"", ""five""], ""Task 2 had these additional classes included:"": [""four"", ""go""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e5bca2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecbde910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.53428153, 'precision': 0.21338788100492958, 'recall': 0.24081959965620833, 'f1_score': 0.20227712568403317, 'confusion_matrix': array([[  9, 144,  11,   0,   0,   0,   0],
       [ 18, 303,  31,   0,   0,   0,   0],
       [ 11, 135,  11,   0,   0,   0,   0],
       [  0,  81,   0,   0,   0,   0,   0],
       [  3,  43,   0,   0,   0,   0,   0],
       [  0,  48,   0,   0,   0,   0,   0],
       [  2,  50,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.5058723, 0.1905489, 0.18291928]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e5bca2d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecbde910>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.61215542, 'precision': 0.26317027662853897, 'recall': 0.24731604187077812, 'f1_score': 0.19675184865349427, 'confusion_matrix': array([[  4,  82,   0,   0,   0,   0,   0],
       [  5, 240,   1,   0,   0,   0,   0],
       [  1, 108,   1,   0,   0,   0,   0],
       [  0,  56,   1,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0],
       [  0,  34,   0,   0,   0,   0,   0],
       [  0,  33,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.7203708, 0.50504786, -0.006473346]}","{""Task 0 had these additional classes included:"": [""five"", ""four"", ""go""], ""Task 1 had these additional classes included:"": [""happy"", ""house""], ""Task 2 had these additional classes included:"": [""left"", ""marvel""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552baeb4690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecf382d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33846338, 'precision': 0.26287938979818845, 'recall': 0.24333175130517323, 'f1_score': 0.13606802501326811, 'confusion_matrix': array([[  1,   0, 300,   0,   0,   0,   0],
       [  0,   0, 237,   0,   0,   0,   0],
       [  0,   0, 126,   0,   0,   0,   0],
       [  0,   0,  65,   0,   0,   0,   0],
       [  0,   0,  71,   0,   0,   0,   0],
       [  0,   0,  45,   0,   0,   0,   0],
       [  0,   0,  55,   0,   0,   0,   0]]), 'forgetting_measure': [0.28699919, 0.3304532, 0.17585987]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552baeb4690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552ecf382d0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.33998902, 'precision': 0.12142857142857143, 'recall': 0.24285714285714285, 'f1_score': 0.137267080745341616, 'confusion_matrix': array([[  0,   0, 171,   0,   0,   0,   0],
       [  0,   0, 180,   0,   0,   0,   0],
       [  0,   0,  90,   0,   0,   0,   0],
       [  0,   0,  34,   0,   0,   0,   0],
       [  0,   0,  58,   0,   0,   0,   0],
       [  0,   0,  35,   0,   0,   0,   0],
       [  0,   0,  32,   0,   0,   0,   0]]), 'forgetting_measure': [0.28564329, 0.2520191, 0.31248924]}","{""Task 0 had these additional classes included:"": [""no"", ""off"", ""on""], ""Task 1 had these additional classes included:"": [""one"", ""right""], ""Task 2 had these additional classes included:"": [""seven"", ""sheila""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c299c690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bacebed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.38972616, 'precision': 0.15505932362990664, 'recall': 0.32652227000053088, 'f1_score': 0.18766650138715984, 'confusion_matrix': array([[169,   0,   0,   0,   0,   0,  38],
       [163,   0,   0,   0,   0,   0,  42],
       [215,   0,   0,   0,   0,   0,  46],
       [ 68,   0,   0,   0,   0,   0,  11],
       [ 39,   0,   0,   0,   0,   0,   9],
       [ 19,   0,   0,   0,   0,   0,  42],
       [  9,   0,   0,   0,   0,   0,  30]]), 'forgetting_measure': [0.34509577, 0.25080764, 0.23507315]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 700 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552c299c690>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552bacebed0>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 700, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.45694838, 'precision': 0.15963078008485787, 'recall': 0.31856714713857572, 'f1_score': 0.1930672987635013, 'confusion_matrix': array([[129,   0,   0,   0,   0,   0,  25],
       [122,   0,   0,   0,   0,   0,  21],
       [130,   0,   0,   0,   0,   0,  21],
       [ 51,   0,   0,   0,   0,   0,  10],
       [ 23,   0,   0,   0,   0,   0,   1],
       [ 15,   0,   0,   0,   0,   0,  26],
       [  8,   0,   0,   0,   0,   0,  18]]), 'forgetting_measure': [0.48972297, 0.44582477, 0.23533967]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0b5a350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f0867890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.39977495, 'precision': 0.24159587055509112, 'recall': 0.23815033927977313, 'f1_score': 0.17597604261405962, 'confusion_matrix': array([[  1, 201,  51,   0,   0,   0,   0],
       [  0, 148,  38,   0,   0,   0,   0],
       [  1, 188,  38,   0,   0,   0,   0],
       [  0,  66,   0,   0,   0,   0,   0],
       [  0,  68,   0,   0,   0,   0,   0],
       [  0,  73,   0,   0,   0,   0,   0],
       [  0,  27,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.37441138, 0.34386414, 0.19543768]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; with TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e0b5a350>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552f0867890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': True, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.37774402, 'precision': 0.164569290613772, 'recall': 0.24066802762454936, 'f1_score': 0.15900025955278699, 'confusion_matrix': array([[  0, 173,  16,   0,   0,   0,   0],
       [  0, 106,   9,   0,   0,   0,   0],
       [  0, 134,   9,   0,   0,   0,   0],
       [  0,  32,   0,   0,   0,   0,   0],
       [  0,  54,   0,   0,   0,   0,   0],
       [  0,  48,   0,   0,   0,   0,   0],
       [  0,  19,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.362059, 0.5332636, -0.21705124]}","{""Task 0 had these additional classes included:"": [""happy"", ""house"", ""left""], ""Task 1 had these additional classes included:"": [""marvel"", ""nine""], ""Task 2 had these additional classes included:"": [""no"", ""off""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e28e01d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3169050>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46746035, 'precision': 0.13829651994279358, 'recall': 0.2422668240850059, 'f1_score': 0.16034806560661075, 'confusion_matrix': array([[  0,   0, 211,   0,   0,   0,   0],
       [  0,   0, 210,   0,   0,   0,   0],
       [  1,   0, 241,   0,   0,   0,   0],
       [  0,   0,  92,   0,   0,   0,   0],
       [  0,   0,  45,   0,   0,   0,   0],
       [  0,   0,  58,   0,   0,   0,   0],
       [  0,   0,  42,   0,   0,   0,   0]]), 'forgetting_measure': [0.518069, 0.42811865, 0.39257732]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning GEM with DRNN Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552e28e01d0>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552e3169050>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.46496738, 'precision': 0.137142857142857144, 'recall': 0.24285714285714285, 'f1_score': 0.15895691609977325, 'confusion_matrix': array([[  0,   0, 139,   0,   0,   0,   0],
       [  0,   0, 154,   0,   0,   0,   0],
       [  0,   0, 156,   0,   0,   0,   0],
       [  0,   0,  62,   0,   0,   0,   0],
       [  0,   0,  22,   0,   0,   0,   0],
       [  0,   0,  39,   0,   0,   0,   0],
       [  0,   0,  28,   0,   0,   0,   0]]), 'forgetting_measure': [0.45104913, 0.38480935, -0.055235524]}","{""Task 0 had these additional classes included:"": [""down"", ""eight"", ""five""], ""Task 1 had these additional classes included:"": [""four"", ""go""], ""Task 2 had these additional classes included:"": [""happy"", ""house""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d6ef6e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6da7890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.3797978, 'precision': 0.124444444444444442, 'recall': 0.24285714285714285, 'f1_score': 0.141745730550284625, 'confusion_matrix': array([[154,   0,   0,   0,   0,   0,   0],
       [349,   0,   0,   0,   0,   0,   0],
       [176,   0,   0,   0,   0,   0,   0],
       [ 45,   0,   0,   0,   0,   0,   0],
       [ 76,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0],
       [ 50,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.3664055, 0.41853714, 0.23770641]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
"{'Name Experiment': 'Learning GEM with ECHO Model; no TEM (CIL) with 500 chunks', 'Optimizer': <keras.src.optimizers.adam.Adam object at 0x1552d6ef6e10>, 'Loss function': <keras.src.losses.SparseCategoricalCrossentropy object at 0x1552d6da7890>, 'Number of epochs per task': 300, 'Learning_rate': 5e-05, 'Embedding dimension chunk- and task-embeddings': 100, 'Use a seperate task embedding model': False, 'Initialize task embedding model with zero bias (True), or random bias (False)': True, 'Target network dimension': (416, 832), 'Convolutional layers': [(16, (4, 4), 1), (64, (5, 5), 16), (64, (3, 3), 64), (32, (3, 3), 64)], 'A final trainable soft max layer in the target network?': True, 'Dropout rate in target network': 0.3, ""Number of 'chunks'"": 500, 'Hypernetwork dimension': (200, 250), 'Number (initial) classes': 3, 'Class Incremental Case': (True, 0.35, 75, (True, 0.9), (60, 0.02), 0.4, 3), 'Testing while training': True, 'L2 regularization strenght': 1e-05, 'Validation accuracy': 300, 'Max attempts when using validation accuracy': 1}","{'accuracy': 0.40804188, 'precision': 0.12666666666666667, 'recall': 0.24285714285714285, 'f1_score': 0.1449438202247191, 'confusion_matrix': array([[112,   0,   0,   0,   0,   0,   0],
       [243,   0,   0,   0,   0,   0,   0],
       [ 80,   0,   0,   0,   0,   0,   0],
       [ 36,   0,   0,   0,   0,   0,   0],
       [ 62,   0,   0,   0,   0,   0,   0],
       [ 32,   0,   0,   0,   0,   0,   0],
       [ 35,   0,   0,   0,   0,   0,   0]]), 'forgetting_measure': [0.34717468, 0.064789794, 0.36930925]}","{""Task 0 had these additional classes included:"": [""nine"", ""no"", ""off""], ""Task 1 had these additional classes included:"": [""on"", ""one""], ""Task 2 had these additional classes included:"": [""right"", ""seven""]}"
